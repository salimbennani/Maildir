Return-Path: <linux-kernel-owner@vger.kernel.org>
Delivered-To: unknown
Received: from linux.intel.com (10.54.29.200:995) by likexu-workstation with
  POP3-SSL; 12 Dec 2018 08:49:50 -0000
X-Original-To: like.xu@linux.intel.com
Delivered-To: like.xu@linux.intel.com
Received: from fmsmga005.fm.intel.com (fmsmga005.fm.intel.com [10.253.24.32])
	(using TLSv1.2 with cipher ECDHE-RSA-AES256-GCM-SHA384 (256/256 bits))
	(No client certificate requested)
	by linux.intel.com (Postfix) with ESMTPS id 90DB7580380;
	Tue, 11 Dec 2018 07:55:30 -0800 (PST)
Received: from fmsmga101.fm.intel.com ([10.1.193.65])
  by fmsmga005-1.fm.intel.com with ESMTP/TLS/DHE-RSA-AES256-GCM-SHA384; 11 Dec 2018 07:55:30 -0800
X-SG-BADATTACHMENTNOREPLY: True
IronPort-PHdr: =?us-ascii?q?9a23=3AImrBRhVQi+pRDIFkKnZWHTmgNUrV8LGtZVwlr6E/?=
 =?us-ascii?q?grcLSJyIuqrYZhCPuqdThVPEFb/W9+hDw7KP9fy4CSpYud6oizMrSNR0TRgLiM?=
 =?us-ascii?q?EbzUQLIfWuLgnFFsPsdDEwB89YVVVorDmROElRH9viNRWJ+iXhpTEdFQ/iOgVr?=
 =?us-ascii?q?O+/7BpDdj9it1+C15pbffxhEiCCybL9uLxi6txndutULioZ+N6g9zQfErGFVcO?=
 =?us-ascii?q?pM32NoIlyTnxf45siu+ZNo7jpdtfE8+cNeSKv2Z6s3Q6BWAzQgKGA1+dbktQLf?=
 =?us-ascii?q?QguV53sTSXsZnxxVCAXY9h76X5Pxsizntuph3SSRIMP7QawoVTmk8qxmUwHjhj?=
 =?us-ascii?q?sZODEl8WHXks1wg7xdoBK9vBx03orYbJiIOPZiYq/ReNUXTndDUMlMTSxMGoOy?=
 =?us-ascii?q?YZUSAeQPPuhWqIvyp1UAohSxGQaiC/jvyidKi3Ltwa030OosHR3c0QE6Hd8Dtm?=
 =?us-ascii?q?nfotXvNKcVVOC41KjGzS/dYPNZxDzz7ZLIchc7rvGMRL5+c9DeyVMzFwPAlFqQ?=
 =?us-ascii?q?r5HuMjSa1uQXrWeb4OlgVeK0hm4jqgFxpCWvx8giionOm4IVzE3L+j9lwIY0It?=
 =?us-ascii?q?24TlR3Ydm+EJtfriyXMZZ9TMA6Q2xwpio21rkLtYSmcCUE1pgr3QPTZv+bf4SS?=
 =?us-ascii?q?4x/uVv6dLDR2iX5/e7+yhgy+/Eukx+HmS8W4zFRHoyxYmdfWrH8NzQbc6s2fR/?=
 =?us-ascii?q?t94Eih3TGP2hjN6uFLP080j7DXK50/zb4qkJocr0DDEjXxmEXsg6+abkQk+u62?=
 =?us-ascii?q?5OT7erjquIOQOotuhg3jPKkihNazDfk7PwQSRWSW+Oax2KXm/ULjQbVKivM2kr?=
 =?us-ascii?q?PesJDfPckboq+5AwlI0ocs8hq/DCmp0M4enXYZKFJJYRWHjobvO17QOvD1Fum/?=
 =?us-ascii?q?g1uynzdx3fzGPaPuAo/LLnfdlLftZ7F961RTyAYr19BQ+4pUCq0dIPL0QkLxsN?=
 =?us-ascii?q?3YDhwnPACuzOfnFc5w1ocfWWKJH6+YP7nesV6O5uIzPeaMYJUZtyr6K/gg//Tu?=
 =?us-ascii?q?l2M2mUcBfam12psacHC4Ee5nI0WFe3Xshc0NEWcXvgUkSuzqh0aPUTpSZ3a0Qq?=
 =?us-ascii?q?I96Ss3CIOgDYffWI+thKaN0zu8Hp1TfmpGEEyDEW/0d4WYXPcBcCCSIsh/nTAe?=
 =?us-ascii?q?VrihTIkh1ReptALhz7pnL+zU+jAXtJ751dh14fHTmg829TBuE8ud1GSNRXlunm?=
 =?us-ascii?q?wUXz82wLx/oUtlx1iZyqh4g/tYFd9J6/NTSAg6N4XRz+h7C9D0RwLAcc2FSFeg?=
 =?us-ascii?q?QtW6Hz4xSsg9zMMJY0Z4A9+ilAzM3zK2A78JkLyGHJ80/bja33TrI8Z9ymzJ1K?=
 =?us-ascii?q?8uj1Q9RstPNGumhrNw9gTJBo7JlVmZmLiudagGwCHN82KDx3KUvE5ESA5wTbnF?=
 =?us-ascii?q?XXcHa0TLt9v5+F3NQ6WuCbs9NAtB0tCNKq1NZt3tjlVGQfPjNc/aY2KwnWewGB?=
 =?us-ascii?q?mJyqmNbIrsZ2USwiHdBFIYnAAU+HaMLRI+CTu5o2LCEDxuEkribF72/ulgtny3?=
 =?us-ascii?q?VE80wBuMb016ybW1/AUYhfidS/MVw7IFtz0tqzRyHFahwd3WD8CMqBZmfKVZed?=
 =?us-ascii?q?k9+ktI1XrFtwxhOZytN7xihl8bcwRwo0Pu1xV2Bp9ckcQwq3Mq1g5yKaOe0FNO?=
 =?us-ascii?q?bD6Y2ZHwOrvKKmj95hyvaqjW2k3A39aS4KsA9PM4q1D7tgGzCkUi62ln08VS03?=
 =?us-ascii?q?aE/JrKCBQdUJ3vXUc37RR1vKzabTQn6IPS1n1sNre0vyTG29IoAusl1xmhc81e?=
 =?us-ascii?q?MKOCCA/9DckaC9KyJ+wtnlijdggEM/xK9K4oI8OmcOOL2a62POp6gD2ql2VG4I?=
 =?us-ascii?q?Bn3UKK+CpxUerI35cDw/GF0QqLTTb8jFG9ss/pnYBIfy0dHm26ySL8Ho5eerVy?=
 =?us-ascii?q?fZoXCWepO8C33NR+iIL3VH5C6VGjAEkK2Mm3dhqIblzxxBFf2l4ToXO6hyS41T?=
 =?us-ascii?q?t0kzcyo6qb3SzOxfnidRUdNm5KQmlikUnjIYyug98GW0ioahAjlAG56kbi26hb?=
 =?us-ascii?q?uKN/InHTQEdJZST3L3tuUrCttrqEeMNP7JIosSNKUOWze1yaS7j9owcE3CPnBW?=
 =?us-ascii?q?dR2Dc7dzSysJXjgxN6kH6dLGp0rHfBe8F/3w3f5N/fRf5WxDYGXzN3iTrUBli9?=
 =?us-ascii?q?Odmm49OUmozHsuC/UWKhS5JSfTPqzYOGqCu0+2lqDQejkPC0n93tCRI63jPj19?=
 =?us-ascii?q?l2SSXIqw7xY4nx2KS9K+5nfEhoBFnn5sp+G4F+lJYwhZ4K1XgbgJWV4WQIkWPp?=
 =?us-ascii?q?PdpH3qL+aWIHRSQXzN7N/AjlxEpjI2qKx43jV3WR2MthZ8SgbWMQ1SIw9MRKCK?=
 =?us-ascii?q?aS7LxZkip5uFu4rQTNYfdjmjcR0+ch6Hkfg+sRogoi0j2dAqwOHUlfJSHskhWI?=
 =?us-ascii?q?79Oko6lNamegb6Ow1FZgktC7F76NvBtcWHnid5cmHC9w6Nh/MV3W3H3y7IHkZM?=
 =?us-ascii?q?ffbdYJuhKIlBfAivBfKIgtmfoSmSpnJWX9sGU5y+48iBxix5C7s5KBK2Vw56K5?=
 =?us-ascii?q?GR9YOybxZ8MS/DHtkKlfktyX34CpApVuBDELUIH0QvKvFTIYre7nOBqWED0gtn?=
 =?us-ascii?q?ebHqLSEhSF50dhq3LPDoqnN3WKJHQCydViRR+dJFFQgQwOXTU6mII5GR6uxMD7?=
 =?us-ascii?q?bEh54TUR7EbiqhRQ0uJoKwX/UmDHqQeqcDg0TYaQLAFM4gFe/UvVMtGe7uFuHy?=
 =?us-ascii?q?Fe5JKhtxeAKmiaZwROEGEIVVaIB1HlPrmy+9bA9/KUCfa5L/vLeb+Os/BRV++U?=
 =?us-ascii?q?xZKz1Ytr5zaNNsKSPnl7Ev00wExDUWpiG8TenTUPRDcalybMb86duRe99Td7rs?=
 =?us-ascii?q?G58PT3Rg3v4ZGDBKdVMdVq4xq2m7uMN/aMhCZlLjZVzpMMymHJyLgc314Sijti?=
 =?us-ascii?q?dzq3EbQHui7CUrjQmrJMDxMAbyNzNc1I778z3wVXOM7bjM/12aB8jvIvF1hFUl?=
 =?us-ascii?q?nhkNmzZcMWO2G9KE/HBEGTObucOD3E2Nv3br28SLFKiOVUtga9uTKaE0/lIzSC?=
 =?us-ascii?q?mCPlVxGpMeFQki6bOAZSt526chZoEWLjVs7pagWnMN9rij072aE0hnLPNWIGLT?=
 =?us-ascii?q?dwaV9Crr2O4iNemfh/H21B7nx4LeiLgSqZ7u/YKooIvvtvGCh7i+Va4HEiwbtP?=
 =?us-ascii?q?8C5EXOB1mDfVrtN2o1CpiO+Pyj9mUBpIsjlKhYKLsl9kOaXW7ZRAXXfE/BQQ7W?=
 =?us-ascii?q?SfERgKpt1lCsHxtKBU0NTAiKXzKDIRu+7TqM8dAdXEbcGKKnwsNTL3FzPOSggI?=
 =?us-ascii?q?VzimMSfYnUMOvuuV8yi6tJU14rv2n5MOD59STkAwH/VSXkt/EdMBIL9zXzU5gb?=
 =?us-ascii?q?CckcgE7Ga/qx+XQ99V6MOUHsmOCOnifW7KxYJPYAEFlPahddwe?=
X-IronPort-Anti-Spam-Filtered: true
X-IronPort-Anti-Spam-Result: =?us-ascii?q?A0ANAACW3Q9ch0O0hNFkHAEBAQQBAQcEA?=
 =?us-ascii?q?QGBUQcBAQsBg2sng3uIGV+LMYIhiH+OPxSBXxQYEwGHLiI0CQ0BAwEBAQEBAQI?=
 =?us-ascii?q?BEwEBAQgNCQgpIwyCNiQBgmIDAwECIAQLAQ0BATcBBQkBASQCBSECAgMMEjYZB?=
 =?us-ascii?q?YMcgWoDFQQBpG1wfAwngnYBAQWFBg2CFAiBC4ZxgyOBHBeBf4EQAYVpghODG4J?=
 =?us-ascii?q?XiT2GBJEOLgmOIoMkI4FchReKTY8kig+BRoIOMxoIKAiDJ4IbDBeIXoVAPzKBA?=
 =?us-ascii?q?gMBASETh2ACAiIHgiABAQ?=
X-IPAS-Result: =?us-ascii?q?A0ANAACW3Q9ch0O0hNFkHAEBAQQBAQcEAQGBUQcBAQsBg2s?=
 =?us-ascii?q?ng3uIGV+LMYIhiH+OPxSBXxQYEwGHLiI0CQ0BAwEBAQEBAQIBEwEBAQgNCQgpI?=
 =?us-ascii?q?wyCNiQBgmIDAwECIAQLAQ0BATcBBQkBASQCBSECAgMMEjYZBYMcgWoDFQQBpG1?=
 =?us-ascii?q?wfAwngnYBAQWFBg2CFAiBC4ZxgyOBHBeBf4EQAYVpghODG4JXiT2GBJEOLgmOI?=
 =?us-ascii?q?oMkI4FchReKTY8kig+BRoIOMxoIKAiDJ4IbDBeIXoVAPzKBAgMBASETh2ACAiI?=
 =?us-ascii?q?HgiABAQ?=
X-IronPort-AV: E=Sophos;i="5.56,342,1539673200"; 
   d="scan'208";a="66306164"
X-Amp-Result: SKIPPED(no attachment in message)
X-Amp-File-Uploaded: False
Received: from vger.kernel.org ([209.132.180.67])
  by mga01b.intel.com with ESMTP; 11 Dec 2018 07:55:29 -0800
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
        id S1730286AbeLKPyy (ORCPT <rfc822;like.xu@linux.intel.com>
        + 23 others); Tue, 11 Dec 2018 10:54:54 -0500
Received: from mail.kernel.org ([198.145.29.99]:43436 "EHLO mail.kernel.org"
        rhost-flags-OK-OK-OK-OK) by vger.kernel.org with ESMTP
        id S1730255AbeLKPyt (ORCPT <rfc822;linux-kernel@vger.kernel.org>);
        Tue, 11 Dec 2018 10:54:49 -0500
Received: from localhost (5356596B.cm-6-7b.dynamic.ziggo.nl [83.86.89.107])
        (using TLSv1.2 with cipher ECDHE-RSA-AES256-GCM-SHA384 (256/256 bits))
        (No client certificate requested)
        by mail.kernel.org (Postfix) with ESMTPSA id 4FCED20855;
        Tue, 11 Dec 2018 15:54:48 +0000 (UTC)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/simple; d=kernel.org;
        s=default; t=1544543688;
        bh=uR/9YGiQZop8UYZFY7iK9FwZoDNRFbpdtcoVndc4lpM=;
        h=From:To:Cc:Subject:Date:In-Reply-To:References:From;
        b=RU5Brvyb1n7DAeEG2PasdREgRP/IXJnzVETXpppTwurgAW4oZ51WN8x25NzjVYfvb
         DBUCDT7siMzb2zIwqISEILPPLxCJ0LJvwI88g7usmqQIX+Hpq4Xvsp/tb05mu95/PG
         nEPY2P/gJ3FidCC9L1z4yMN1AkZYRASZtfIZE4zM=
From: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
To: linux-kernel@vger.kernel.org
Cc: Greg Kroah-Hartman <gregkh@linuxfoundation.org>,
        stable@vger.kernel.org, James Smart <jsmart2021@gmail.com>,
        Christoph Hellwig <hch@lst.de>, Sasha Levin <sashal@kernel.org>
Subject: [PATCH 4.19 025/118] nvme-fc: resolve io failures during connect
Date: Tue, 11 Dec 2018 16:40:44 +0100
Message-Id: <20181211151645.258102072@linuxfoundation.org>
X-Mailer: git-send-email 2.20.0
In-Reply-To: <20181211151644.216668863@linuxfoundation.org>
References: <20181211151644.216668863@linuxfoundation.org>
User-Agent: quilt/0.65
X-stable: review
X-Patchwork-Hint: ignore
MIME-Version: 1.0
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: 8bit
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: <linux-kernel.vger.kernel.org>
X-Mailing-List: linux-kernel@vger.kernel.org

4.19-stable review patch.  If anyone has any objections, please let me know.

------------------

[ Upstream commit 4cff280a5fccf6513ed9e895bb3a4e7ad8b0cedc ]

If an io error occurs on an io issued while connecting, recovery
of the io falls flat as the state checking ends up nooping the error
handler.

Create an err_work work item that is scheduled upon an io error while
connecting. The work thread terminates all io on all queues and marks
the queues as not connected.  The termination of the io will return
back to the callee, which will then back out of the connection attempt
and will reschedule, if possible, the connection attempt.

The changes:
- in case there are several commands hitting the error handler, a
  state flag is kept so that the error work is only scheduled once,
  on the first error. The subsequent errors can be ignored.
- The calling sequence to stop keep alive and terminate the queues
  and their io is lifted from the reset routine. Made a small
  service routine used by both reset and err_work.
- During debugging, found that the teardown path can reference
  an uninitialized pointer, resulting in a NULL pointer oops.
  The aen_ops weren't initialized yet. Add validation on their
  initialization before calling the teardown routine.

Signed-off-by: James Smart <jsmart2021@gmail.com>
Signed-off-by: Christoph Hellwig <hch@lst.de>
Signed-off-by: Sasha Levin <sashal@kernel.org>
---
 drivers/nvme/host/fc.c | 73 ++++++++++++++++++++++++++++++++++++------
 1 file changed, 63 insertions(+), 10 deletions(-)

diff --git a/drivers/nvme/host/fc.c b/drivers/nvme/host/fc.c
index 611e70cae754..9375fa705d82 100644
--- a/drivers/nvme/host/fc.c
+++ b/drivers/nvme/host/fc.c
@@ -144,6 +144,7 @@ struct nvme_fc_ctrl {
 
 	bool			ioq_live;
 	bool			assoc_active;
+	atomic_t		err_work_active;
 	u64			association_id;
 
 	struct list_head	ctrl_list;	/* rport->ctrl_list */
@@ -152,6 +153,7 @@ struct nvme_fc_ctrl {
 	struct blk_mq_tag_set	tag_set;
 
 	struct delayed_work	connect_work;
+	struct work_struct	err_work;
 
 	struct kref		ref;
 	u32			flags;
@@ -1523,6 +1525,10 @@ nvme_fc_abort_aen_ops(struct nvme_fc_ctrl *ctrl)
 	struct nvme_fc_fcp_op *aen_op = ctrl->aen_ops;
 	int i;
 
+	/* ensure we've initialized the ops once */
+	if (!(aen_op->flags & FCOP_FLAGS_AEN))
+		return;
+
 	for (i = 0; i < NVME_NR_AEN_COMMANDS; i++, aen_op++)
 		__nvme_fc_abort_op(ctrl, aen_op);
 }
@@ -2036,7 +2042,25 @@ nvme_fc_nvme_ctrl_freed(struct nvme_ctrl *nctrl)
 static void
 nvme_fc_error_recovery(struct nvme_fc_ctrl *ctrl, char *errmsg)
 {
-	/* only proceed if in LIVE state - e.g. on first error */
+	int active;
+
+	/*
+	 * if an error (io timeout, etc) while (re)connecting,
+	 * it's an error on creating the new association.
+	 * Start the error recovery thread if it hasn't already
+	 * been started. It is expected there could be multiple
+	 * ios hitting this path before things are cleaned up.
+	 */
+	if (ctrl->ctrl.state == NVME_CTRL_CONNECTING) {
+		active = atomic_xchg(&ctrl->err_work_active, 1);
+		if (!active && !schedule_work(&ctrl->err_work)) {
+			atomic_set(&ctrl->err_work_active, 0);
+			WARN_ON(1);
+		}
+		return;
+	}
+
+	/* Otherwise, only proceed if in LIVE state - e.g. on first error */
 	if (ctrl->ctrl.state != NVME_CTRL_LIVE)
 		return;
 
@@ -2802,6 +2826,7 @@ nvme_fc_delete_ctrl(struct nvme_ctrl *nctrl)
 {
 	struct nvme_fc_ctrl *ctrl = to_fc_ctrl(nctrl);
 
+	cancel_work_sync(&ctrl->err_work);
 	cancel_delayed_work_sync(&ctrl->connect_work);
 	/*
 	 * kill the association on the link side.  this will block
@@ -2854,23 +2879,30 @@ nvme_fc_reconnect_or_delete(struct nvme_fc_ctrl *ctrl, int status)
 }
 
 static void
-nvme_fc_reset_ctrl_work(struct work_struct *work)
+__nvme_fc_terminate_io(struct nvme_fc_ctrl *ctrl)
 {
-	struct nvme_fc_ctrl *ctrl =
-		container_of(work, struct nvme_fc_ctrl, ctrl.reset_work);
-	int ret;
-
-	nvme_stop_ctrl(&ctrl->ctrl);
+	nvme_stop_keep_alive(&ctrl->ctrl);
 
 	/* will block will waiting for io to terminate */
 	nvme_fc_delete_association(ctrl);
 
-	if (!nvme_change_ctrl_state(&ctrl->ctrl, NVME_CTRL_CONNECTING)) {
+	if (ctrl->ctrl.state != NVME_CTRL_CONNECTING &&
+	    !nvme_change_ctrl_state(&ctrl->ctrl, NVME_CTRL_CONNECTING))
 		dev_err(ctrl->ctrl.device,
 			"NVME-FC{%d}: error_recovery: Couldn't change state "
 			"to CONNECTING\n", ctrl->cnum);
-		return;
-	}
+}
+
+static void
+nvme_fc_reset_ctrl_work(struct work_struct *work)
+{
+	struct nvme_fc_ctrl *ctrl =
+		container_of(work, struct nvme_fc_ctrl, ctrl.reset_work);
+	int ret;
+
+	__nvme_fc_terminate_io(ctrl);
+
+	nvme_stop_ctrl(&ctrl->ctrl);
 
 	if (ctrl->rport->remoteport.port_state == FC_OBJSTATE_ONLINE)
 		ret = nvme_fc_create_association(ctrl);
@@ -2885,6 +2917,24 @@ nvme_fc_reset_ctrl_work(struct work_struct *work)
 			ctrl->cnum);
 }
 
+static void
+nvme_fc_connect_err_work(struct work_struct *work)
+{
+	struct nvme_fc_ctrl *ctrl =
+			container_of(work, struct nvme_fc_ctrl, err_work);
+
+	__nvme_fc_terminate_io(ctrl);
+
+	atomic_set(&ctrl->err_work_active, 0);
+
+	/*
+	 * Rescheduling the connection after recovering
+	 * from the io error is left to the reconnect work
+	 * item, which is what should have stalled waiting on
+	 * the io that had the error that scheduled this work.
+	 */
+}
+
 static const struct nvme_ctrl_ops nvme_fc_ctrl_ops = {
 	.name			= "fc",
 	.module			= THIS_MODULE,
@@ -2995,6 +3045,7 @@ nvme_fc_init_ctrl(struct device *dev, struct nvmf_ctrl_options *opts,
 	ctrl->cnum = idx;
 	ctrl->ioq_live = false;
 	ctrl->assoc_active = false;
+	atomic_set(&ctrl->err_work_active, 0);
 	init_waitqueue_head(&ctrl->ioabort_wait);
 
 	get_device(ctrl->dev);
@@ -3002,6 +3053,7 @@ nvme_fc_init_ctrl(struct device *dev, struct nvmf_ctrl_options *opts,
 
 	INIT_WORK(&ctrl->ctrl.reset_work, nvme_fc_reset_ctrl_work);
 	INIT_DELAYED_WORK(&ctrl->connect_work, nvme_fc_connect_ctrl_work);
+	INIT_WORK(&ctrl->err_work, nvme_fc_connect_err_work);
 	spin_lock_init(&ctrl->lock);
 
 	/* io queue count */
@@ -3092,6 +3144,7 @@ nvme_fc_init_ctrl(struct device *dev, struct nvmf_ctrl_options *opts,
 fail_ctrl:
 	nvme_change_ctrl_state(&ctrl->ctrl, NVME_CTRL_DELETING);
 	cancel_work_sync(&ctrl->ctrl.reset_work);
+	cancel_work_sync(&ctrl->err_work);
 	cancel_delayed_work_sync(&ctrl->connect_work);
 
 	ctrl->ctrl.opts = NULL;
-- 
2.19.1



