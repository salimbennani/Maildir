Return-Path: <linux-kernel-owner@vger.kernel.org>
Delivered-To: unknown
Received: from linux.intel.com (10.54.29.200:995) by i7-8700 with POP3-SSL;
  14 Dec 2018 20:24:51 -0000
X-Original-To: like.xu@linux.intel.com
Delivered-To: like.xu@linux.intel.com
Received: from orsmga001.jf.intel.com (orsmga001.jf.intel.com [10.7.209.18])
	(using TLSv1.2 with cipher ECDHE-RSA-AES256-GCM-SHA384 (256/256 bits))
	(No client certificate requested)
	by linux.intel.com (Postfix) with ESMTPS id 9C68C58079D;
	Thu, 13 Dec 2018 22:28:45 -0800 (PST)
Received: from fmsmga105.fm.intel.com ([10.1.193.10])
  by orsmga001-1.jf.intel.com with ESMTP/TLS/DHE-RSA-AES256-GCM-SHA384; 13 Dec 2018 22:28:44 -0800
X-SG-BADATTACHMENTNOREPLY: True
IronPort-PHdr: =?us-ascii?q?9a23=3AGjFaSx16gDHlaXm2smDT+DRfVm0co7zxezQtwd8Z?=
 =?us-ascii?q?segSL/rxwZ3uMQTl6Ol3ixeRBMOHs6IC07KempujcFRI2YyGvnEGfc4EfD4+ou?=
 =?us-ascii?q?JSoTYdBtWYA1bwNv/gYn9yNs1DUFh44yPzahANS47xaFLIv3K98yMZFAnhOgpp?=
 =?us-ascii?q?POT1HZPZg9iq2+yo9JDffwZFiCChbb9uMR67sRjfus4KjIV4N60/0AHJonxGe+?=
 =?us-ascii?q?RXwWNnO1eelAvi68mz4ZBu7T1et+ou+MBcX6r6eb84TaFDAzQ9L281/szrugLd?=
 =?us-ascii?q?QgaJ+3ART38ZkhtMAwjC8RH6QpL8uTb0u+ZhxCWXO9D9QKsqUjq+8ahkVB7oiD?=
 =?us-ascii?q?8GNzEn9mHXltdwh79frB64uhBz35LYbISTOfFjfK3SYMkaSHJBUMhPSiJPDICy?=
 =?us-ascii?q?YYwNAOoPJuZYt4vwqkASoReiHwSgGPnixiNUinLwwKY00/4hEQbD3AE4HdwOrW?=
 =?us-ascii?q?7brNP6NKwPU++1za/IzTreZP5R2Tb96Y7Ich87rfGMQLJ/a8zRyUY0GgPEiFWQ?=
 =?us-ascii?q?tZLqPzeP2usRtGib6vNtWOSygGAkswF8uiajytsoh4XTm44YxE7I+T9kzIs2Od?=
 =?us-ascii?q?G0Uk92bNy8HJdNuSyXOJF6Tt4sTmxnoio217MLtJ+hcCQX1Jgr2xjSYOGdfYeS?=
 =?us-ascii?q?+BLsTuORLC94hH17fLK/gA6/8VavyuLiTMm4ylVKoTRfktnKqH8N0wbf6s+dSv?=
 =?us-ascii?q?ty5kuh2DCP2B7P6uxcP0w4ia7WJ4Q8zrM+iJYfq1nPEyzqlEnsjaKbdF0o+u2y?=
 =?us-ascii?q?5OTmZrXmqIWcN4hxigzmNqQum8q/Afk3MwQXXGiU5/681Lv98k39WblKifM3kq?=
 =?us-ascii?q?/Hv5DAPskbuKG5DBFP0oo56BawES2m0NIGknkDNl5FfwiHj4fxN1HUPP/4Feu/?=
 =?us-ascii?q?g0irkDpzw/DGP77hDYvXInnMjbfsZrJ9609ayAouwtFT/ZNUCrcdIP3tXk/9rs?=
 =?us-ascii?q?DXDhg8Mwas2eboFM191p8CWWKIGqKZMLndsV6U5u01JOmAfo8VuCvnJPgj6P7j?=
 =?us-ascii?q?lns5mV4bfam00pobcnG4HvJ6I0qHZXrgmMsOEWAPvgAmVuzllEWCUSJPZ3a1R6?=
 =?us-ascii?q?885DY7B5y8AYfAQYCthrqB3CCgE51SZ2BGDE2MEHjye4WFXfcMdDydIst7njMY?=
 =?us-ascii?q?UrihTpcr1Quyuw/i17pnMu3U9zUCupL41Nh14O7TmQso9TNuDcSQyGWNT2Bynm?=
 =?us-ascii?q?MVSD46xqF/oUphylid1ah0meBXFdtW5/lRSAc1KYbcz/BmC9D1Qg/Bfc2GSFC8?=
 =?us-ascii?q?TtWiADE+VNQxw9AVbkZ5GtWiiA3D3iWwD78UkbyLGII78qbG03ftIMZ9zm7M1L?=
 =?us-ascii?q?M9gFk+XstPKWqmi7Zi+AfJGY7GjV+Vl6aweqQaxy7C6mGDwW2KvEFbVQ5wVb7I?=
 =?us-ascii?q?XXQeZkvQsNT46VnOT76oCbQ7LARBzdSOJbdNat3slV9GXuvsOMzCY2KtnGe9HQ?=
 =?us-ascii?q?uHyamSbIX0YWkd3D/SCE4fkw8N+3aLLgw+Biano2LDAz1iD1PvY0Xw8eZgrHO3?=
 =?us-ascii?q?VFM7zwaPb0d5zbq65gYVheCAS/MUxr8EpCYhqzBzHFah39LXC8CMpxZ7cKVbe9?=
 =?us-ascii?q?M95FZH1WTWtwFmOpygLqZihkMRcghtvkPu0Ql3BZtEkcQwsHwqyw9yI7qC0Fxd?=
 =?us-ascii?q?bzOYwYzwOrrPJ2bo+BCgdaHX1U/e0dqM4agP9ek3pE/lvAGqEUoi7W5q091U03?=
 =?us-ascii?q?ua+5XLAxAeUZP3UkYr6Rd6o6vWbTU654PRzXdsK7W7sife29I1A+so0hahf8pF?=
 =?us-ascii?q?PKyYDgPzEs0aCNKoKOwlgFWpahMEPOZP9K87Jc+mdv2G2LK1M+Zkhj6pkWNH4I?=
 =?us-ascii?q?Vl2EKW6yV8UvLI34oCw/yAxAuHVivzg027ss/qnoBIfzcSEXSlySjlHYJeerd9?=
 =?us-ascii?q?fYIWBmiwOc23wdN+ioXpW35Z8l6jGlwH1NWoeRqUc1zywwlQ2V4LrnygnCuy1y?=
 =?us-ascii?q?Z0nC0xrqqDwCzOxPzvdRoGOmJRRGhul0zsIZWyj90BWEiobg4plAaq5Ergxqhb?=
 =?us-ascii?q?orh/IHfXQUtSYyf2KGRiWLOqtrWee85P9I8osSJPXeS+e1+aUL39oxgd0y/5BG?=
 =?us-ascii?q?tR3jM7dzKrupX/gRN6jnmQLHJyrHrfZMFxyg3T5N3aRf5NwDUGQDN0hiXQBli5?=
 =?us-ascii?q?J9Op58mbl4/fsuCiUGKsTp1SfjPszY+atiu75GtqDAa7n/CynN3nDAc73TX619?=
 =?us-ascii?q?lsSSXHshL8bpP32KS9NOJtZlNoC0Pk68pmBoF+lZM9hJIK1ngbnJmV/WcHnn31?=
 =?us-ascii?q?MdVUwq/+aHsNRTgWw9/a+gTl2UtjLm6XyIL9THmS3sxhZ9yiaGMMxi0999xKCL?=
 =?us-ascii?q?uT7LFcmCt1o1m4ohjLbflzgDgd0ucu52AAg+4SpgUt1CqdD6sWHUlZOyzsihuJ?=
 =?us-ascii?q?48q/rKVReGagb7yw2FBiktCmCbGIuhtcV2rhepc+AS9w6d1yME7L0H328I3lec?=
 =?us-ascii?q?PfbdQOth2PiBfAjvNYKJYwlvoMmCpmNnjxvXwjy+4nkxNu2Yu2s5SAK2Vo5Ki5?=
 =?us-ascii?q?GAJXNiXpZ8MP/THglb1RkdyR34CrA5VtADELXIbzQPKsETISs+nnNgmUHD09rH?=
 =?us-ascii?q?ebBaTQHQuF5Eh6qHLPFoihN2uLK3kB0dViWB6dKVRdgA8OWTU1gIU5Ghq2xMD7?=
 =?us-ascii?q?c0d5+zMR5kP+qhRW0eJlLB3/UmbZpAe1ZTY4UpmfLBxK7g5c40fZK9CR7uV2Hy?=
 =?us-ascii?q?tA5J2usBSNKnCHZwRPFWwIWkuEB036Prmz/9bA9fKUBvG5L/vIbrWDsuheV/aO?=
 =?us-ascii?q?xZKy3Ypq5TeMNsOTPnZ8C/03wFZMXXd8G87BgTUAVzQXlz7Rb86cvBq8+jN4rs?=
 =?us-ascii?q?G88PToWQLj/4iPC6FVMdVg5R+2m7qDN/WLiSZ9KDZY0I4MxHDSxLge2l4Slz9h?=
 =?us-ascii?q?dz23Hbscsi7NSbramrVLAB4DdyNzKMxI4rom0QlQIsHbkM36175igv4xCldITl?=
 =?us-ascii?q?jhmsCvZcwXLGCxLlLHBECXNLuYIT3H2d34YaS5SbdIluVbqwWwuSqHE0/kJjmD?=
 =?us-ascii?q?izjpVxW1Pe5Qli2UIBxet5+7cht2DWjjTdTmagC0MdNtjD02x6E0iW3ONWIGLT?=
 =?us-ascii?q?d8dEZNpKWK7SxEmvV/B3BB7n19IOiEgSmZ6ezYKpcQsfRzAyV0l/hV4HI1y7ZO?=
 =?us-ascii?q?6CFERfp1mDbdr9J0olGmlPWPxSRjUBZUtjlLg4eL7g1ePvDw8JVaVGmM2RUX8W?=
 =?us-ascii?q?KWQ0ADpMNgItnuvb1Aj9bIiaT/IStD9NSS+tETUZv6MsWCZVo8OBzmUA/VCgRN?=
 =?us-ascii?q?GS+qM26Zh1FUlv6693uJo5x8oZ/pzsldAoRHXUA4Q6tJQn9uG8YPddIuBmsp?=
X-IronPort-Anti-Spam-Filtered: true
X-IronPort-Anti-Spam-Result: =?us-ascii?q?A0AAAAACTRNch0O0hNFjGgEBAQEBAgEBA?=
 =?us-ascii?q?QEHAgEBAQGBUQUBAQEBCwGDayeMFYwRgiGXQYEkBUoUGBMBh0UiNAkNAQMBAQE?=
 =?us-ascii?q?BAQECARMBAQEIDQkIKS+CNiQBgmIDAwECJFIGCQEBGDgDVAYTBYMcggEFp24zi?=
 =?us-ascii?q?i+HfYRBghaDdYsKAolBgXOFEpBNBwKRTgsYX36IRocnAZlQgUZtgSEzGiODPII?=
 =?us-ascii?q?nF44qMgEBMQGBBAEBjGUBAQ?=
X-IPAS-Result: =?us-ascii?q?A0AAAAACTRNch0O0hNFjGgEBAQEBAgEBAQEHAgEBAQGBUQU?=
 =?us-ascii?q?BAQEBCwGDayeMFYwRgiGXQYEkBUoUGBMBh0UiNAkNAQMBAQEBAQECARMBAQEID?=
 =?us-ascii?q?QkIKS+CNiQBgmIDAwECJFIGCQEBGDgDVAYTBYMcggEFp24zii+HfYRBghaDdYs?=
 =?us-ascii?q?KAolBgXOFEpBNBwKRTgsYX36IRocnAZlQgUZtgSEzGiODPIInF44qMgEBMQGBB?=
 =?us-ascii?q?AEBjGUBAQ?=
X-IronPort-AV: E=Sophos;i="5.56,351,1539673200"; 
   d="scan'208";a="142103370"
X-Amp-Result: SKIPPED(no attachment in message)
X-Amp-File-Uploaded: False
Received: from vger.kernel.org ([209.132.180.67])
  by mtab.intel.com with ESMTP; 13 Dec 2018 22:28:42 -0800
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
        id S1729173AbeLNG2k (ORCPT <rfc822;like.xu@linux.intel.com>
        + 23 others); Fri, 14 Dec 2018 01:28:40 -0500
Received: from mga07.intel.com ([134.134.136.100]:52325 "EHLO mga07.intel.com"
        rhost-flags-OK-OK-OK-OK) by vger.kernel.org with ESMTP
        id S1729054AbeLNG2i (ORCPT <rfc822;linux-kernel@vger.kernel.org>);
        Fri, 14 Dec 2018 01:28:38 -0500
X-Amp-Result: SKIPPED(no attachment in message)
X-Amp-File-Uploaded: False
Received: from fmsmga002.fm.intel.com ([10.253.24.26])
  by orsmga105.jf.intel.com with ESMTP/TLS/DHE-RSA-AES256-GCM-SHA384; 13 Dec 2018 22:28:38 -0800
X-ExtLoop1: 1
X-IronPort-AV: E=Sophos;i="5.56,351,1539673200"; 
   d="scan'208";a="125841109"
Received: from yhuang-mobile.sh.intel.com ([10.239.197.226])
  by fmsmga002.fm.intel.com with ESMTP; 13 Dec 2018 22:28:35 -0800
From: Huang Ying <ying.huang@intel.com>
To: Andrew Morton <akpm@linux-foundation.org>
Cc: linux-mm@kvack.org, linux-kernel@vger.kernel.org,
        Huang Ying <ying.huang@intel.com>,
        "Kirill A. Shutemov" <kirill.shutemov@linux.intel.com>,
        Andrea Arcangeli <aarcange@redhat.com>,
        Michal Hocko <mhocko@kernel.org>,
        Johannes Weiner <hannes@cmpxchg.org>,
        Shaohua Li <shli@kernel.org>, Hugh Dickins <hughd@google.com>,
        Minchan Kim <minchan@kernel.org>,
        Rik van Riel <riel@redhat.com>,
        Dave Hansen <dave.hansen@linux.intel.com>,
        Naoya Horiguchi <n-horiguchi@ah.jp.nec.com>,
        Zi Yan <zi.yan@cs.rutgers.edu>,
        Daniel Jordan <daniel.m.jordan@oracle.com>
Subject: [PATCH -V9 20/21] swap: Support PMD swap mapping in common path
Date: Fri, 14 Dec 2018 14:27:53 +0800
Message-Id: <20181214062754.13723-21-ying.huang@intel.com>
X-Mailer: git-send-email 2.18.1
In-Reply-To: <20181214062754.13723-1-ying.huang@intel.com>
References: <20181214062754.13723-1-ying.huang@intel.com>
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: <linux-kernel.vger.kernel.org>
X-Mailing-List: linux-kernel@vger.kernel.org

Original code is only for PMD migration entry, it is revised to
support PMD swap mapping.

Signed-off-by: "Huang, Ying" <ying.huang@intel.com>
Cc: "Kirill A. Shutemov" <kirill.shutemov@linux.intel.com>
Cc: Andrea Arcangeli <aarcange@redhat.com>
Cc: Michal Hocko <mhocko@kernel.org>
Cc: Johannes Weiner <hannes@cmpxchg.org>
Cc: Shaohua Li <shli@kernel.org>
Cc: Hugh Dickins <hughd@google.com>
Cc: Minchan Kim <minchan@kernel.org>
Cc: Rik van Riel <riel@redhat.com>
Cc: Dave Hansen <dave.hansen@linux.intel.com>
Cc: Naoya Horiguchi <n-horiguchi@ah.jp.nec.com>
Cc: Zi Yan <zi.yan@cs.rutgers.edu>
Cc: Daniel Jordan <daniel.m.jordan@oracle.com>
---
 fs/proc/task_mmu.c | 12 +++++-------
 mm/gup.c           | 36 ++++++++++++++++++++++++------------
 mm/huge_memory.c   |  7 ++++---
 mm/mempolicy.c     |  2 +-
 4 files changed, 34 insertions(+), 23 deletions(-)

diff --git a/fs/proc/task_mmu.c b/fs/proc/task_mmu.c
index dc36909a73c6..fa41822574e1 100644
--- a/fs/proc/task_mmu.c
+++ b/fs/proc/task_mmu.c
@@ -986,7 +986,7 @@ static inline void clear_soft_dirty_pmd(struct vm_area_struct *vma,
 		pmd = pmd_clear_soft_dirty(pmd);
 
 		set_pmd_at(vma->vm_mm, addr, pmdp, pmd);
-	} else if (is_migration_entry(pmd_to_swp_entry(pmd))) {
+	} else if (is_swap_pmd(pmd)) {
 		pmd = pmd_swp_clear_soft_dirty(pmd);
 		set_pmd_at(vma->vm_mm, addr, pmdp, pmd);
 	}
@@ -1320,9 +1320,8 @@ static int pagemap_pmd_range(pmd_t *pmdp, unsigned long addr, unsigned long end,
 			if (pm->show_pfn)
 				frame = pmd_pfn(pmd) +
 					((addr & ~PMD_MASK) >> PAGE_SHIFT);
-		}
-#ifdef CONFIG_ARCH_ENABLE_THP_MIGRATION
-		else if (is_swap_pmd(pmd)) {
+		} else if (IS_ENABLED(CONFIG_HAVE_PMD_SWAP_ENTRY) &&
+			   is_swap_pmd(pmd)) {
 			swp_entry_t entry = pmd_to_swp_entry(pmd);
 			unsigned long offset;
 
@@ -1335,10 +1334,9 @@ static int pagemap_pmd_range(pmd_t *pmdp, unsigned long addr, unsigned long end,
 			flags |= PM_SWAP;
 			if (pmd_swp_soft_dirty(pmd))
 				flags |= PM_SOFT_DIRTY;
-			VM_BUG_ON(!is_pmd_migration_entry(pmd));
-			page = migration_entry_to_page(entry);
+			if (is_pmd_migration_entry(pmd))
+				page = migration_entry_to_page(entry);
 		}
-#endif
 
 		if (page && page_mapcount(page) == 1)
 			flags |= PM_MMAP_EXCLUSIVE;
diff --git a/mm/gup.c b/mm/gup.c
index 6dd33e16a806..460565825ef0 100644
--- a/mm/gup.c
+++ b/mm/gup.c
@@ -215,6 +215,7 @@ static struct page *follow_pmd_mask(struct vm_area_struct *vma,
 	spinlock_t *ptl;
 	struct page *page;
 	struct mm_struct *mm = vma->vm_mm;
+	swp_entry_t entry;
 
 	pmd = pmd_offset(pudp, address);
 	/*
@@ -242,18 +243,22 @@ static struct page *follow_pmd_mask(struct vm_area_struct *vma,
 	if (!pmd_present(pmdval)) {
 		if (likely(!(flags & FOLL_MIGRATION)))
 			return no_page_table(vma, flags);
-		VM_BUG_ON(thp_migration_supported() &&
-				  !is_pmd_migration_entry(pmdval));
-		if (is_pmd_migration_entry(pmdval))
+		entry = pmd_to_swp_entry(pmdval);
+		if (thp_migration_supported() && is_migration_entry(entry)) {
 			pmd_migration_entry_wait(mm, pmd);
-		pmdval = READ_ONCE(*pmd);
-		/*
-		 * MADV_DONTNEED may convert the pmd to null because
-		 * mmap_sem is held in read mode
-		 */
-		if (pmd_none(pmdval))
+			pmdval = READ_ONCE(*pmd);
+			/*
+			 * MADV_DONTNEED may convert the pmd to null because
+			 * mmap_sem is held in read mode
+			 */
+			if (pmd_none(pmdval))
+				return no_page_table(vma, flags);
+			goto retry;
+		}
+		if (IS_ENABLED(CONFIG_THP_SWAP) && !non_swap_entry(entry))
 			return no_page_table(vma, flags);
-		goto retry;
+		WARN_ON(1);
+		return no_page_table(vma, flags);
 	}
 	if (pmd_devmap(pmdval)) {
 		ptl = pmd_lock(mm, pmd);
@@ -275,11 +280,18 @@ static struct page *follow_pmd_mask(struct vm_area_struct *vma,
 		return no_page_table(vma, flags);
 	}
 	if (unlikely(!pmd_present(*pmd))) {
+		entry = pmd_to_swp_entry(*pmd);
 		spin_unlock(ptl);
 		if (likely(!(flags & FOLL_MIGRATION)))
 			return no_page_table(vma, flags);
-		pmd_migration_entry_wait(mm, pmd);
-		goto retry_locked;
+		if (thp_migration_supported() && is_migration_entry(entry)) {
+			pmd_migration_entry_wait(mm, pmd);
+			goto retry_locked;
+		}
+		if (IS_ENABLED(CONFIG_THP_SWAP) && !non_swap_entry(entry))
+			return no_page_table(vma, flags);
+		WARN_ON(1);
+		return no_page_table(vma, flags);
 	}
 	if (unlikely(!pmd_trans_huge(*pmd))) {
 		spin_unlock(ptl);
diff --git a/mm/huge_memory.c b/mm/huge_memory.c
index 6d144d687e69..38904d673339 100644
--- a/mm/huge_memory.c
+++ b/mm/huge_memory.c
@@ -2122,7 +2122,7 @@ static inline int pmd_move_must_withdraw(spinlock_t *new_pmd_ptl,
 static pmd_t move_soft_dirty_pmd(pmd_t pmd)
 {
 #ifdef CONFIG_MEM_SOFT_DIRTY
-	if (unlikely(is_pmd_migration_entry(pmd)))
+	if (unlikely(is_swap_pmd(pmd)))
 		pmd = pmd_swp_mksoft_dirty(pmd);
 	else if (pmd_present(pmd))
 		pmd = pmd_mksoft_dirty(pmd);
@@ -2206,11 +2206,12 @@ int change_huge_pmd(struct vm_area_struct *vma, pmd_t *pmd,
 	preserve_write = prot_numa && pmd_write(*pmd);
 	ret = 1;
 
-#ifdef CONFIG_ARCH_ENABLE_THP_MIGRATION
+#if defined(CONFIG_ARCH_ENABLE_THP_MIGRATION) || defined(CONFIG_THP_SWAP)
 	if (is_swap_pmd(*pmd)) {
 		swp_entry_t entry = pmd_to_swp_entry(*pmd);
 
-		VM_BUG_ON(!is_pmd_migration_entry(*pmd));
+		VM_BUG_ON(!IS_ENABLED(CONFIG_THP_SWAP) &&
+			  !is_migration_entry(entry));
 		if (is_write_migration_entry(entry)) {
 			pmd_t newpmd;
 			/*
diff --git a/mm/mempolicy.c b/mm/mempolicy.c
index d4496d9d34f5..253d9aa25667 100644
--- a/mm/mempolicy.c
+++ b/mm/mempolicy.c
@@ -436,7 +436,7 @@ static int queue_pages_pmd(pmd_t *pmd, spinlock_t *ptl, unsigned long addr,
 	struct queue_pages *qp = walk->private;
 	unsigned long flags;
 
-	if (unlikely(is_pmd_migration_entry(*pmd))) {
+	if (unlikely(is_swap_pmd(*pmd))) {
 		ret = 1;
 		goto unlock;
 	}
-- 
2.18.1

