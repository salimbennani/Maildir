Return-Path: <linux-kernel-owner@vger.kernel.org>
Delivered-To: unknown
Received: from linux.intel.com (10.54.29.200:995) by i7-8700 with POP3-SSL;
  16 Dec 2018 10:42:47 -0000
X-Original-To: like.xu@linux.intel.com
Delivered-To: like.xu@linux.intel.com
Received: from orsmga003.jf.intel.com (orsmga003.jf.intel.com [10.7.209.27])
	(using TLSv1.2 with cipher ECDHE-RSA-AES256-GCM-SHA384 (256/256 bits))
	(No client certificate requested)
	by linux.intel.com (Postfix) with ESMTPS id 1576C5805F0;
	Sat, 15 Dec 2018 10:53:00 -0800 (PST)
Received: from fmsmga105.fm.intel.com ([10.1.193.10])
  by orsmga003-1.jf.intel.com with ESMTP/TLS/DHE-RSA-AES256-GCM-SHA384; 15 Dec 2018 10:52:59 -0800
X-SG-BADATTACHMENTNOREPLY: True
IronPort-PHdr: =?us-ascii?q?9a23=3APCipnhMAy0QguD+HFgQl6mtUPXoX/o7sNwtQ0KIM?=
 =?us-ascii?q?zox0KPj9psbcNUDSrc9gkEXOFd2Cra4c26yO6+jJYi8p2d65qncMcZhBBVcuqP?=
 =?us-ascii?q?49uEgeOvODElDxN/XwbiY3T4xoXV5h+GynYwAOQJ6tL1LdrWev4jEMBx7xKRR6?=
 =?us-ascii?q?JvjvGo7Vks+7y/2+94fcbglUhzexe69+IAmrpgjNq8cahpdvJLwswRXTuHtIfO?=
 =?us-ascii?q?pWxWJsJV2Nmhv3+9m98p1+/SlOovwt78FPX7n0cKQ+VrxYES8pM3sp683xtBnM?=
 =?us-ascii?q?VhWA630BWWgLiBVIAgzF7BbnXpfttybxq+Rw1DWGMcDwULs5Qiqp4bt1RxD0iS?=
 =?us-ascii?q?cHLz85/3/Risxsl6JQvRatqwViz4LIfI2ZMfxzdb7fc9wHX2pMRsleVyJDDY28?=
 =?us-ascii?q?YYUBDPcPM/hEoInmv1sDrwCzBRWwCO711jNEmmP60K883u88EQ/GxgsgH9cWvX?=
 =?us-ascii?q?nIqtX6KacTWv2zwqnV0TXDaPZW2Tbn6IjTcRAhoOyHULV0ccrM1UkvEBjIjlaO?=
 =?us-ascii?q?poz/OTOayOANv3Kc7+p6WuKikmgqoBxyrDi33soglJXFi4YPxlzZ+yh13pw5Kc?=
 =?us-ascii?q?C7RUJne9KpEZlduzmEO4dqRs4uWWJltSYgxrEYp5K3YTIGxZspyhPZdveJaZKH?=
 =?us-ascii?q?4gj5W+aUOTp4hGxqeLa4hxuq70igxfPzVtOu3FZJsCVFiN/MuW4J1xDJ7ciHUP?=
 =?us-ascii?q?R98l+g2TaJyQ/T9vlJLV4omaffMZIt37A9moQJvUjeHSL6hF/6ga6Ue0k8/+in?=
 =?us-ascii?q?8eXnYrHopp+GMI90jxnzMqAvmsy5HOQ5PRECX2uF9uSm0r3s40n5TKxNjvw4lK?=
 =?us-ascii?q?nWroraKN8Fpq62HQBVyJwv6xWhADe81tQXg30HIEhCeBKdgIjlI0vOL+zgDfej?=
 =?us-ascii?q?n1Ssly9mx/THPr3iHJrBNHfCkKr6cLZ56k5czhczzN9F65JVDLEBPOz8WkvruN?=
 =?us-ascii?q?PECR85NhS+w/z7B9VlyoMeRWWPD7eZMKzIsF+I+vggI+6WaI8VpTbyMf4l5/H1?=
 =?us-ascii?q?gH89mF8de7Sp3JQNZHC5GPRmP1uWYX72jtgdFmcKuxI0TPb2h12aTT5Te3GyUr?=
 =?us-ascii?q?o+5jE8Fo2qF4TDRoergLyH2ye2BZlWZmFAClCRHnbkbYSEW/EQaC2MJs9tiCAL?=
 =?us-ascii?q?Vb+kS4U5zxGhqBf6y6Z7LurT4iAXr4nj1Nhy5+3Qjx0y7yZ7D8aG3mGJTmF0mH?=
 =?us-ascii?q?4IRjAs0KB+p0x91kmM0axij/NEEtxT4utDUh0mOp7E0+x6F9fyVxrCftiTTlaq?=
 =?us-ascii?q?WNGmATArQdI3zN8DeEJ9G9SkjhDe0CumGb4Vl7qXBJMq9qLQxWT+J8F4y3zezq?=
 =?us-ascii?q?kuk0EmQtdTNW2hnqNw6hLcB5DXnEmDl6alb6Ic3DXT+2eFymaOuEJYUAt0Uaje?=
 =?us-ascii?q?WXAfZ03Wrcn250/YTr+uD6gnPRVFycKYNqRKbdjph01cRPj/INTef36xm2CoCB?=
 =?us-ascii?q?mV3LyMcpTld38d3CrHDkgEiB4c/XCdOAg6ByehpX/eDTN0GVLuZUPs7fdxqHeh?=
 =?us-ascii?q?QkAoyAGKalVr16Cp9R4NmfycV/QT06oYuCcgrjV0G0q939LWCtaauwptZqJcYc?=
 =?us-ascii?q?k54FdG02LZuBdwPpihL6Bkm14ffB57v0Lo1xVrFIpAldImo28tzAp3MaiYyk9O?=
 =?us-ascii?q?dyuE3ZDsPb3aMnP9/BSxZK/ZxF7f0Mya9bwS6PslsVrjugKpFk0883h819lV0n?=
 =?us-ascii?q?2c5ojFDQYIUJLxVFo3+AZ+p73AfiY94IbU32V2Maaoqj/Cx84pBOw9xxegYtdT?=
 =?us-ascii?q?Kr+LGBXzEs0aHceuLuMqlkOtbhIFOuBS6aE1M9mnd/uAxK6kIuJgkCi6gmRA5Y?=
 =?us-ascii?q?B3yliM+DZkSu7Uw5YFxOmV3hGGVzjgllihqN34mYdeaTEUAGW/0ynkCJdNaaJo?=
 =?us-ascii?q?eYYEFHmhI9ewxtV4nJPtX39Y9Fi+B1IJwsOpeBySb0Dj0g1Uz0gYvXunmS6gxT?=
 =?us-ascii?q?xujz4ptraf3DDJw+n6dBsHO3RHRWl4gVf3PIi0icsXXEypbwgviRuk6lz2x6ld?=
 =?us-ascii?q?pKRjMWbTRV1EcDTxL2FnSqGwrKaNY9ZT6JM0tiVaSOa8bkqASr7+oBsa1DnvH3?=
 =?us-ascii?q?BEyzA4dDGqu5P5kAJ8iG+GKHZzrXzZedx/xBvF5dzcQ+JR0SQCRCVilTbXAV28?=
 =?us-ascii?q?NcGz/dqIj5fDrvy+V2W5W5xTaybrypmMtCm65W1sGhC/m/Gzmtv6EQk1yyP71t?=
 =?us-ascii?q?9qVTnWoxb4eIXky6O6Med/dElyGFD889Z6Gp15koYoh5Efw3kaio+V/Xoai2jz?=
 =?us-ascii?q?N9pb1Ln6bHoMQz4L3tHU7BLk2E1lMnKG2Yb5Wm+BzctmYtmwenkW1T4l78BWFK?=
 =?us-ascii?q?eU66RJnS50olq7tw3de/Z8kSkGyfsy9nEamfoGtxQ3ziWSGb0SGUhYPSrxlxWH?=
 =?us-ascii?q?9dy+raNXZHqxfri0zkZxgdehDLSaqAFGRHn5YosiHTN37shnLFLM13jz5pvled?=
 =?us-ascii?q?bKa9ITqwaUkwzBj+VOLJIxl/wKhTdoOG7nvH0lzfI7ggJq3Z2goIeHLGBt9rqj?=
 =?us-ascii?q?AhFELj31e98T+jb1gKlFhMmW2ISvHoh7FjUPQZvlVvaoEDMUtfT6OAeCCjw8qn?=
 =?us-ascii?q?GHGbXBGQ+T8ltpr3XKE5qzLXGYOGEZzcl+RBmaPEFfghobXDAkkZ4iDAyq2Nbt?=
 =?us-ascii?q?cERk5jAS+174rAFDyvlzOhn7U2ffohqoazguRJieKhpW8h9N50PPPcOC6eJzGj?=
 =?us-ascii?q?lS/oe9owyVNmybewNIAHkJW0yDGlDjJ6Su6sPG8+SCHeq+KP3OYbqVpOxaVveI?=
 =?us-ascii?q?w4+v04R88zaNMMWPImdtD/kh1kVfWnB5HtzTmy8TRCwPiyLNc8mbqQ+8+iJpr8?=
 =?us-ascii?q?C/8/frWAP16YuMEbtSNtpv9A6sgaeeLO6dnyJ5KTde1pMRyn7E0rkf3FgOiy5w?=
 =?us-ascii?q?czmhC6gPtSnITKjIgK9YEwYbaz9vNMtP968zxBRNNtXBitzr1r90lPo1C1ZeWF?=
 =?us-ascii?q?zlm8GpY9EKIm6nOFPGAkaLKKqJJTnRz87rZqO8TKVajP9IuB2opTabD0jjMyyf?=
 =?us-ascii?q?lznoUhCjK/1DgDuHMxxepo69dA1gCWziTNLgdx26P8V7jTwwwb0omHzKMXQQPi?=
 =?us-ascii?q?R7c0NItreQ9z9Xgu1jG2xd6XpoNemFlDyf7+ndK5YWt+NkAyV0l+1A5nQ6xKBY?=
 =?us-ascii?q?7CVFRPxzhSvTocRio1CgkumT1DVnVABCpSpMhIKO7g1ePvCT25VPVH3D+RgAqS?=
 =?us-ascii?q?2qCh8J7+MvQon1uqtTjMCJma78JTxF9tjZ1coaG8XQbsmANSxyHwDuHWv9CgcU?=
 =?us-ascii?q?BRq2KWbahlZGk/DaonmIsp8SqZX2npcKDLhBWwpmRbshFk15EYlac99MVTQ+nO?=
 =?us-ascii?q?ve1ZZQ6A=3D=3D?=
X-IronPort-Anti-Spam-Filtered: true
X-IronPort-Anti-Spam-Result: =?us-ascii?q?A0AWAADxTBVch0O0hNFeBRwBAQEEAQEHB?=
 =?us-ascii?q?AEBgVIGAQELAYFaghEng3yUEFABAQaBNRSJD441FIFYGxgTAYdHIjUIDQEDAQE?=
 =?us-ascii?q?BAQEBAgETAQEBCgsJCCkjDII2JAGCYQEBAQECAQECIAQZAQE3AQUJAQEKCwcGA?=
 =?us-ascii?q?gImAgIDHxIBBQEODgYTBRaDB4F0BQgFmSw8iiBwfDOCdgEBBYcfCIELiheBHBd?=
 =?us-ascii?q?4gQeBEYIUUC6EPS0LgxSCV4kgIBMfgUaEF36QTgmKTYcNGIFdhRyKWYpBjxQPI?=
 =?us-ascii?q?YEnAYILfQg7MQaCNYIbDBd/AQEBh1yFYB8yAYEEAQGNDwEB?=
X-IPAS-Result: =?us-ascii?q?A0AWAADxTBVch0O0hNFeBRwBAQEEAQEHBAEBgVIGAQELAYF?=
 =?us-ascii?q?aghEng3yUEFABAQaBNRSJD441FIFYGxgTAYdHIjUIDQEDAQEBAQEBAgETAQEBC?=
 =?us-ascii?q?gsJCCkjDII2JAGCYQEBAQECAQECIAQZAQE3AQUJAQEKCwcGAgImAgIDHxIBBQE?=
 =?us-ascii?q?ODgYTBRaDB4F0BQgFmSw8iiBwfDOCdgEBBYcfCIELiheBHBd4gQeBEYIUUC6EP?=
 =?us-ascii?q?S0LgxSCV4kgIBMfgUaEF36QTgmKTYcNGIFdhRyKWYpBjxQPIYEnAYILfQg7MQa?=
 =?us-ascii?q?CNYIbDBd/AQEBh1yFYB8yAYEEAQGNDwEB?=
X-IronPort-AV: E=Sophos;i="5.56,358,1539673200"; 
   d="scan'208";a="142274717"
X-Amp-Result: SKIPPED(no attachment in message)
X-Amp-File-Uploaded: False
Received: from vger.kernel.org ([209.132.180.67])
  by mtab.intel.com with ESMTP; 15 Dec 2018 10:52:57 -0800
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
        id S1729214AbeLOSwz (ORCPT <rfc822;like.xu@linux.intel.com>
        + 23 others); Sat, 15 Dec 2018 13:52:55 -0500
Received: from mail.kernel.org ([198.145.29.99]:50742 "EHLO mail.kernel.org"
        rhost-flags-OK-OK-OK-OK) by vger.kernel.org with ESMTP
        id S1726520AbeLOSwz (ORCPT <rfc822;linux-kernel@vger.kernel.org>);
        Sat, 15 Dec 2018 13:52:55 -0500
Received: from mail-wr1-f43.google.com (mail-wr1-f43.google.com [209.85.221.43])
        (using TLSv1.2 with cipher ECDHE-RSA-AES128-GCM-SHA256 (128/128 bits))
        (No client certificate requested)
        by mail.kernel.org (Postfix) with ESMTPSA id 2153D2177B
        for <linux-kernel@vger.kernel.org>; Sat, 15 Dec 2018 18:52:53 +0000 (UTC)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/simple; d=kernel.org;
        s=default; t=1544899973;
        bh=Iy54GkS4B6mRSnQF3AhOvFyagZKuuCXzU/TIfaDvW3E=;
        h=References:In-Reply-To:From:Date:Subject:To:Cc:From;
        b=MwivbiHGetBqCVIgjG3mLl3HybkxF9Tkv04ipY8gyJib3r929PogK2CHp8I0i60hl
         d+1yHn+90Ort/Q5S5ZF/AzvJPzoDRTK6IIot643WeK+vLcCH6Um/iOxGRB7vfKf0LF
         kQ3KPCSzNFxFlE+3IlEWp3e9BDv5xt7nZMWV39QI=
Received: by mail-wr1-f43.google.com with SMTP id t27so8467005wra.6
        for <linux-kernel@vger.kernel.org>; Sat, 15 Dec 2018 10:52:53 -0800 (PST)
X-Gm-Message-State: AA+aEWaMdpCt+t6D0T58O6wv4j+ri6PiTS1qZcLrJpFqWP5dEOMc4j5D
        ByagG19j4d/+MyWgqZ7QGgkl//9WTSzfgIkqFs+Srw==
X-Google-Smtp-Source: AFSGD/XO8czHSQ1SWdceGk5/H//doAKQbU0Udyk1nVZ/5CduXwJxlD+chjYk5z8q0m+y5MYz1QEfTB72VEX8KZGoeRU=
X-Received: by 2002:adf:e08c:: with SMTP id c12mr5676171wri.199.1544899971481;
 Sat, 15 Dec 2018 10:52:51 -0800 (PST)
MIME-Version: 1.0
References: <20181212000354.31955-1-rick.p.edgecombe@intel.com>
 <20181212000354.31955-2-rick.p.edgecombe@intel.com> <CALCETrVP577NvdeYj8bzpEfTXj3GZD3nFcJxnUq5n1daDBxU=g@mail.gmail.com>
 <f5cbf6aefeb19f12faafa6f213c6ff72bf693ddc.camel@intel.com>
 <CALCETrV0BGagp8stapCPBQ9iWOeepGkcKybzmi2WwLU_zzy2sQ@mail.gmail.com> <096da253543acc3d1aa23df22db5ce0acfc0c961.camel@intel.com>
In-Reply-To: <096da253543acc3d1aa23df22db5ce0acfc0c961.camel@intel.com>
From: Andy Lutomirski <luto@kernel.org>
Date: Sat, 15 Dec 2018 10:52:39 -0800
X-Gmail-Original-Message-ID: <CALCETrW+5JZOQDnJ6HYkDRvMHiz+cY5HAn06SrxCxmk2XzoyDQ@mail.gmail.com>
Message-ID: <CALCETrW+5JZOQDnJ6HYkDRvMHiz+cY5HAn06SrxCxmk2XzoyDQ@mail.gmail.com>
Subject: Re: [PATCH v2 1/4] vmalloc: New flags for safe vfree on special perms
To: "Edgecombe, Rick P" <rick.p.edgecombe@intel.com>
Cc: "luto@kernel.org" <luto@kernel.org>,
        "linux-kernel@vger.kernel.org" <linux-kernel@vger.kernel.org>,
        "daniel@iogearbox.net" <daniel@iogearbox.net>,
        "jeyu@kernel.org" <jeyu@kernel.org>,
        "rostedt@goodmis.org" <rostedt@goodmis.org>,
        "ast@kernel.org" <ast@kernel.org>,
        "ard.biesheuvel@linaro.org" <ard.biesheuvel@linaro.org>,
        "linux-mm@kvack.org" <linux-mm@kvack.org>,
        "jannh@google.com" <jannh@google.com>,
        "Dock, Deneen T" <deneen.t.dock@intel.com>,
        "kristen@linux.intel.com" <kristen@linux.intel.com>,
        "akpm@linux-foundation.org" <akpm@linux-foundation.org>,
        "will.deacon@arm.com" <will.deacon@arm.com>,
        "mingo@redhat.com" <mingo@redhat.com>,
        "namit@vmware.com" <namit@vmware.com>,
        "kernel-hardening@lists.openwall.com" 
        <kernel-hardening@lists.openwall.com>,
        "Keshavamurthy, Anil S" <anil.s.keshavamurthy@intel.com>,
        "mhiramat@kernel.org" <mhiramat@kernel.org>,
        "naveen.n.rao@linux.vnet.ibm.com" <naveen.n.rao@linux.vnet.ibm.com>,
        "davem@davemloft.net" <davem@davemloft.net>,
        "netdev@vger.kernel.org" <netdev@vger.kernel.org>,
        "Hansen, Dave" <dave.hansen@intel.com>
Content-Type: text/plain; charset="UTF-8"
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: <linux-kernel.vger.kernel.org>
X-Mailing-List: linux-kernel@vger.kernel.org

On Wed, Dec 12, 2018 at 2:01 PM Edgecombe, Rick P
<rick.p.edgecombe@intel.com> wrote:
>
> On Wed, 2018-12-12 at 11:57 -0800, Andy Lutomirski wrote:
> > On Wed, Dec 12, 2018 at 11:50 AM Edgecombe, Rick P
> > <rick.p.edgecombe@intel.com> wrote:
> > >
> > > On Tue, 2018-12-11 at 18:20 -0800, Andy Lutomirski wrote:
> > > > On Tue, Dec 11, 2018 at 4:12 PM Rick Edgecombe
> > > > <rick.p.edgecombe@intel.com> wrote:
> > > > >
> > > > > This adds two new flags VM_IMMEDIATE_UNMAP and VM_HAS_SPECIAL_PERMS, for
> > > > > enabling vfree operations to immediately clear executable TLB entries to
> > > > > freed
> > > > > pages, and handle freeing memory with special permissions.
> > > > >
> > > > > In order to support vfree being called on memory that might be RO, the
> > > > > vfree
> > > > > deferred list node is moved to a kmalloc allocated struct, from where it
> > > > > is
> > > > > today, reusing the allocation being freed.
> > > > >
> > > > > arch_vunmap is a new __weak function that implements the actual
> > > > > unmapping
> > > > > and
> > > > > resetting of the direct map permissions. It can be overridden by more
> > > > > efficient
> > > > > architecture specific implementations.
> > > > >
> > > > > For the default implementation, it uses architecture agnostic methods
> > > > > which
> > > > > are
> > > > > equivalent to what most usages do before calling vfree. So now it is
> > > > > just
> > > > > centralized here.
> > > > >
> > > > > This implementation derives from two sketches from Dave Hansen and Andy
> > > > > Lutomirski.
> > > > >
> > > > > Suggested-by: Dave Hansen <dave.hansen@intel.com>
> > > > > Suggested-by: Andy Lutomirski <luto@kernel.org>
> > > > > Suggested-by: Will Deacon <will.deacon@arm.com>
> > > > > Signed-off-by: Rick Edgecombe <rick.p.edgecombe@intel.com>
> > > > > ---
> > > > >  include/linux/vmalloc.h |  2 ++
> > > > >  mm/vmalloc.c            | 73 +++++++++++++++++++++++++++++++++++++----
> > > > >  2 files changed, 69 insertions(+), 6 deletions(-)
> > > > >
> > > > > diff --git a/include/linux/vmalloc.h b/include/linux/vmalloc.h
> > > > > index 398e9c95cd61..872bcde17aca 100644
> > > > > --- a/include/linux/vmalloc.h
> > > > > +++ b/include/linux/vmalloc.h
> > > > > @@ -21,6 +21,8 @@ struct notifier_block;                /* in notifier.h
> > > > > */
> > > > >  #define VM_UNINITIALIZED       0x00000020      /* vm_struct is not
> > > > > fully
> > > > > initialized */
> > > > >  #define VM_NO_GUARD            0x00000040      /* don't add guard page
> > > > > */
> > > > >  #define VM_KASAN               0x00000080      /* has allocated kasan
> > > > > shadow memory */
> > > > > +#define VM_IMMEDIATE_UNMAP     0x00000200      /* flush before
> > > > > releasing
> > > > > pages */
> > > > > +#define VM_HAS_SPECIAL_PERMS   0x00000400      /* may be freed with
> > > > > special
> > > > > perms */
> > > > >  /* bits [20..32] reserved for arch specific ioremap internals */
> > > > >
> > > > >  /*
> > > > > diff --git a/mm/vmalloc.c b/mm/vmalloc.c
> > > > > index 97d4b25d0373..02b284d2245a 100644
> > > > > --- a/mm/vmalloc.c
> > > > > +++ b/mm/vmalloc.c
> > > > > @@ -18,6 +18,7 @@
> > > > >  #include <linux/interrupt.h>
> > > > >  #include <linux/proc_fs.h>
> > > > >  #include <linux/seq_file.h>
> > > > > +#include <linux/set_memory.h>
> > > > >  #include <linux/debugobjects.h>
> > > > >  #include <linux/kallsyms.h>
> > > > >  #include <linux/list.h>
> > > > > @@ -38,6 +39,11 @@
> > > > >
> > > > >  #include "internal.h"
> > > > >
> > > > > +struct vfree_work {
> > > > > +       struct llist_node node;
> > > > > +       void *addr;
> > > > > +};
> > > > > +
> > > > >  struct vfree_deferred {
> > > > >         struct llist_head list;
> > > > >         struct work_struct wq;
> > > > > @@ -50,9 +56,13 @@ static void free_work(struct work_struct *w)
> > > > >  {
> > > > >         struct vfree_deferred *p = container_of(w, struct
> > > > > vfree_deferred,
> > > > > wq);
> > > > >         struct llist_node *t, *llnode;
> > > > > +       struct vfree_work *cur;
> > > > >
> > > > > -       llist_for_each_safe(llnode, t, llist_del_all(&p->list))
> > > > > -               __vunmap((void *)llnode, 1);
> > > > > +       llist_for_each_safe(llnode, t, llist_del_all(&p->list)) {
> > > > > +               cur = container_of(llnode, struct vfree_work, node);
> > > > > +               __vunmap(cur->addr, 1);
> > > > > +               kfree(cur);
> > > > > +       }
> > > > >  }
> > > > >
> > > > >  /*** Page table manipulation functions ***/
> > > > > @@ -1494,6 +1504,48 @@ struct vm_struct *remove_vm_area(const void
> > > > > *addr)
> > > > >         return NULL;
> > > > >  }
> > > > >
> > > > > +/*
> > > > > + * This function handles unmapping and resetting the direct map as
> > > > > efficiently
> > > > > + * as it can with cross arch functions. The three categories of
> > > > > architectures
> > > > > + * are:
> > > > > + *   1. Architectures with no set_memory implementations and no direct
> > > > > map
> > > > > + *      permissions.
> > > > > + *   2. Architectures with set_memory implementations but no direct map
> > > > > + *      permissions
> > > > > + *   3. Architectures with set_memory implementations and direct map
> > > > > permissions
> > > > > + */
> > > > > +void __weak arch_vunmap(struct vm_struct *area, int deallocate_pages)
> > > >
> > > > My general preference is to avoid __weak functions -- they don't
> > > > optimize well.  Instead, I prefer either:
> > > >
> > > > #ifndef arch_vunmap
> > > > void arch_vunmap(...);
> > > > #endif
> > > >
> > > > or
> > > >
> > > > #ifdef CONFIG_HAVE_ARCH_VUNMAP
> > > > ...
> > > > #endif
> > >
> > > Ok.
> > > >
> > > > > +{
> > > > > +       unsigned long addr = (unsigned long)area->addr;
> > > > > +       int immediate = area->flags & VM_IMMEDIATE_UNMAP;
> > > > > +       int special = area->flags & VM_HAS_SPECIAL_PERMS;
> > > > > +
> > > > > +       /*
> > > > > +        * In case of 2 and 3, use this general way of resetting the
> > > > > permissions
> > > > > +        * on the directmap. Do NX before RW, in case of X, so there is
> > > > > no
> > > > > W^X
> > > > > +        * violation window.
> > > > > +        *
> > > > > +        * For case 1 these will be noops.
> > > > > +        */
> > > > > +       if (immediate)
> > > > > +               set_memory_nx(addr, area->nr_pages);
> > > > > +       if (deallocate_pages && special)
> > > > > +               set_memory_rw(addr, area->nr_pages);
> > > >
> > > > Can you elaborate on the intent here?  VM_IMMEDIATE_UNMAP means "I
> > > > want that alias gone before any deallocation happens".
> > > > VM_HAS_SPECIAL_PERMS means "I mucked with the direct map -- fix it for
> > > > me, please".  deallocate means "this was vfree -- please free the
> > > > pages".  I'm not convinced that all the various combinations make
> > > > sense.  Do we really need both flags?
> > >
> > > VM_HAS_SPECIAL_PERMS is supposed to mean, like you said, "reset the direct
> > > map".
> > > Where VM_IMMEDIATE_UNMAP means, the vmalloc allocation has extra capabilties
> > > where we don't want to leave an enhanced capability TLB entry to the freed
> > > page.
> > >
> > > I was trying to pick names that could apply more generally for potential
> > > future
> > > special memory capabilities. Today VM_HAS_SPECIAL_PERMS does just mean reset
> > > write to the directmap and VM_IMMEDIATE_UNMAP means vmalloc mapping is
> > > executable.
> > >
> > > A present day reason for keeping both flags is, it is more efficient in the
> > > arch-agnostic implementation when freeing memory that is just RO and not
> > > executable. It saves a TLB flush.
> > >
> > > > (VM_IMMEDIATE_UNMAP is a bit of a lie, since, if in_interrupt(), it's
> > > > not immediate.)
> > >
> > > True, maybe VM_MUST_FLUSH or something else?
> > >
> > > > If we do keep both flags, maybe some restructuring would make sense,
> > > > like this, perhaps.  Sorry about horrible whitespace damage.
> > > >
> > > > if (special) {
> > > >   /* VM_HAS_SPECIAL_PERMS makes little sense without deallocate_pages. */
> > > >   WARN_ON_ONCE(!deallocate_pages);
> > > >
> > > >   if (immediate) {
> > > >     /* It's possible that the vmap alias is X and we're about to make
> > > > the direct map RW.  To avoid a window where executable memory is
> > > > writable, first mark the vmap alias NX.  This is silly, since we're
> > > > about to *unmap* it, but this is the best we can do if all we have to
> > > > work with is the set_memory_abc() APIs.  Architectures should override
> > > > this whole function to get better behavior. */
> > > >     set_memory_nx(...);
> > > >   }
> > > >
> > > >   set_memory_rw(addr, area->nr_pages);
> > > > }
> > >
> > > Ok.
> > >
> > > >
> > > > > +
> > > > > +       /* Always actually remove the area */
> > > > > +       remove_vm_area(area->addr);
> > > > > +
> > > > > +       /*
> > > > > +        * Need to flush the TLB before freeing pages in the case of
> > > > > this
> > > > > flag.
> > > > > +        * As long as that's happening, unmap aliases.
> > > > > +        *
> > > > > +        * For 2 and 3, this will not be needed because of the
> > > > > set_memory_nx
> > > > > +        * above, because the stale TLBs will be NX.
> > > >
> > > > I'm not sure I agree with this comment.  If the caller asked for an
> > > > immediate unmap, we should give an immediate unmap.  But I'm still not
> > > > sure I see why VM_IMMEDIATE_UNMAP needs to exist as a separate flag.
> > >
> > > Yea. I was just trying to save a TLB flush, since for today's callers that
> > > have
> > > set_memory there isn't a security downside I know of to just leaving it NX.
> > > Maybe its not worth the tradeoff of confusion? Or I can clarify that in the
> > > comment.
> >
> > Don't both of the users in your series set both flags, though?  My
> > real objection to having them be separate is that, in the absence of
> > users, it's less clear exactly what they should do and the code
> > doesn't get exercised.
> The only "just RO" user today is one of the BPF allocations. I don't have a
> strong objection to combining them, just explaining the thinking. I guess if we
> could always add another flag later if it becomes more needed.
>
> > If you document that VM_IMMEDIATE_UNMAP means "I want the TLB entries
> > gone", then I can re-review the code in light of that.  But then I'm
> > unconvinced by your generic implementation, since set_memory_nx()
> > seems like an odd way to go about it.
> Masami Hiramatsu pointed out if we don't do set_memory_nx before set_memory_rw,
> then there will be a small window of W^X violation. So that was the concern for
> the executable case, regardless of the semantics. I think the concern applies
> for any "special capability" permissions. Alternatively, if we remove_vm_area
> before we reset the direct map perms RW, maybe that would accomplish the same
> thing, if that's possible in a cross arch way. Maybe this is too much designing
> for hypothetical future... just was trying to avoid having to change the
> interface, and could just update the generic implementation if new permissions
> or usages come up.
>
> The set_memory_ stuff is really only needed for arm64 which seems to be the only
> other one with directmap permissions. So if it could eventually have its own
> arch_vunmap then all of the set_memory_ parts could be dropped and the default
> would just be the simple unmap then flush logic that it was originally.

I think that's probably the best solution.  If there are only two
arches that have anything fancy here, let's just fix both of them up
for real.

>
> Or we have up to three flushes for the generic version and meet the name
> expectations and needed functionality today. I guess I'll just try that.
> > >
> > > > > +        */
> > > > > +       if (immediate && !IS_ENABLED(ARCH_HAS_SET_MEMORY))
> > > > > +               vm_unmap_aliases();
> > > > > +}
> > > > > +
> > > > >  static void __vunmap(const void *addr, int deallocate_pages)
> > > > >  {
> > > > >         struct vm_struct *area;
> > > > > @@ -1515,7 +1567,8 @@ static void __vunmap(const void *addr, int
> > > > > deallocate_pages)
> > > > >         debug_check_no_locks_freed(area->addr, get_vm_area_size(area));
> > > > >         debug_check_no_obj_freed(area->addr, get_vm_area_size(area));
> > > > >
> > > > > -       remove_vm_area(addr);
> > > > > +       arch_vunmap(area, deallocate_pages);
> > > > > +
> > > > >         if (deallocate_pages) {
> > > > >                 int i;
> > > > >
> > > > > @@ -1542,8 +1595,15 @@ static inline void __vfree_deferred(const void
> > > > > *addr)
> > > > >          * nother cpu's list.  schedule_work() should be fine with this
> > > > > too.
> > > > >          */
> > > > >         struct vfree_deferred *p = raw_cpu_ptr(&vfree_deferred);
> > > > > +       struct vfree_work *w = kmalloc(sizeof(struct vfree_work),
> > > > > GFP_ATOMIC);
> > > > > +
> > > > > +       /* If no memory for the deferred list node, give up */
> > > > > +       if (!w)
> > > > > +               return;
> > > >
> > > > That's nasty.  I see what you're trying to do here, but I think you're
> > > > solving a problem that doesn't need solving quite so urgently.  How
> > > > about dropping this part and replacing it with a comment like "NB:
> > > > this writes a word to a potentially executable address.  It would be
> > > > nice if we could avoid doing this."  And maybe a future patch could
> > > > more robustly avoid it without risking memory leaks.
> > >
> > > Yea, sorry I should have called this out, because I wasn't sure on how
> > > likely
> > > that was to happen. I did find some other places in the kernel with the same
> > > ignoring logic.
> > >
> > > I'll have to think though, I am not sure what the alternative is. Since the
> > > memory can be RO in the module_memfree case, the old method of re-using the
> > > allocation will no longer work. The list node could be stuffed on the
> > > vm_struct,
> > > but then the all of the spin_lock(&vmap_area_lock)'s need to be changed to
> > > work
> > > with interrupts so that the struct could be looked up. Not sure of the
> > > implications of that. Or maybe have some slow backup that resets the
> > > permissions
> > > and re-uses the allocation if kmalloc fails?
> > >
> > > I guess it could also go back to the old v1 implementation that doesn't
> > > handle
> > > RO and the directmap, and leave the W^X violation window during teardown.
> > > Then
> > > solve that problem when modules are loaded via something like Nadav's stuff.
> > >
> >
> > Hmm.  Switching to spin_lock_irqsave() doesn't seem so bad to me.
> Ok.

Actually, I think I have a better solution.  Just declare the
problematic case to be illegal: say that you may not free memory with
the new flags set while IRQs are off.  Enforce this with a VM_WARN_ON
in the code that reads the vfree_deferred list.
