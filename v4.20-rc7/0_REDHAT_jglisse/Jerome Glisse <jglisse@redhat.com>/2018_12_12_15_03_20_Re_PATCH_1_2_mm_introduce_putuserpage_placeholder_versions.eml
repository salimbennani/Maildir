Return-Path: <linux-kernel-owner@vger.kernel.org>
Delivered-To: unknown
Received: from linux.intel.com (10.54.29.200:995) by i7-8700 with POP3-SSL;
  13 Dec 2018 08:51:41 -0000
X-Original-To: like.xu@linux.intel.com
Delivered-To: like.xu@linux.intel.com
Received: from orsmga003.jf.intel.com (orsmga003.jf.intel.com [10.7.209.27])
	(using TLSv1.2 with cipher ECDHE-RSA-AES256-GCM-SHA384 (256/256 bits))
	(No client certificate requested)
	by linux.intel.com (Postfix) with ESMTPS id 6A3E858079D;
	Wed, 12 Dec 2018 07:03:33 -0800 (PST)
Received: from fmsmga101.fm.intel.com ([10.1.193.65])
  by orsmga003-1.jf.intel.com with ESMTP/TLS/DHE-RSA-AES256-GCM-SHA384; 12 Dec 2018 07:03:32 -0800
X-SG-BADATTACHMENTNOREPLY: True
IronPort-PHdr: =?us-ascii?q?9a23=3AeMG7xBxcLV1reL7XCy+O+j09IxM/srCxBDY+r6Qd?=
 =?us-ascii?q?0e4SLfad9pjvdHbS+e9qxAeQG9mDu7Qc06L/iOPJYSQ4+5GPsXQPItRndiQuro?=
 =?us-ascii?q?EopTEmG9OPEkbhLfTnPGQQFcVGU0J5rTngaRAGUMnxaEfPrXKs8DUcBgvwNRZv?=
 =?us-ascii?q?JuTyB4Xek9m72/q99pHPYAhEniaxba9vJxiqsAvdsdUbj5F/Iagr0BvJpXVIe+?=
 =?us-ascii?q?VSxWx2IF+Yggjx6MSt8pN96ipco/0u+dJOXqX8ZKQ4UKdXDC86PGAv5c3krgfM?=
 =?us-ascii?q?QA2S7XYBSGoWkx5IAw/Y7BHmW5r6ryX3uvZh1CScIMb7Vq4/Vyi84Kh3SR/okC?=
 =?us-ascii?q?YHOCA/8GHLkcx7kaZXrAu8qxBj34LYZYeYP+d8cKzAZ9MXXWRPUMZPWSJcAY28?=
 =?us-ascii?q?YYQAAPYcMuhXrYbyqUAOrQO8CAS3GOPiySVFimPq0aAgzugsFxzN0gw6H9IJtX?=
 =?us-ascii?q?TZtNH7O7kIUeCyyanH0yjIYfJS2Tf884jIaQ4uquyLULJyfsrRzUgvFxjejlqO?=
 =?us-ascii?q?soHlJS2a2fkNs2eB8+psT/6gi2kiqwxopDWk28QiipHRi44L1lzJ8T91zJs7KN?=
 =?us-ascii?q?GmUkJ3fN2pHIdKuyybNYZ6Wt0uT31stSog17ELt4C3cDIXxJkkyRPTceKLfouO?=
 =?us-ascii?q?7xn+TuieOy14i2hgeL+nhxa970ygyurkW8mq31ZFsDBFnsPPtn8TzRzT7NaISv?=
 =?us-ascii?q?9n8kemwzaP2Bjf6uBCIU8qiarWM4AtzqI0m5YJrEjOEDH6lF/rgKKVakko4Oml?=
 =?us-ascii?q?5ub/brXjvJCcNot0ig/kMqQpn8yyGeA4MgkIX2iG9uWwzb7j8lPjQLVMkPI2lr?=
 =?us-ascii?q?DVsJfUJMQduKG5GRRY0pgs6xmhFTeqytcYkmcdLFJDZh2Hi5LlO1bUIPD3Ffu/?=
 =?us-ascii?q?mUijkC93x/DaOb3sGpHNLnnAkLj/Z7p85FNcxRE3zdBe4ZJUF74ALOjyWk/3qN?=
 =?us-ascii?q?zXEBs5PxaozObgDdV3zpkeVn6XAq+FLKPStkeF5uI1LOmNeI8aojH9J+Il5/7z?=
 =?us-ascii?q?l3A5n1AdcLKt3ZsWbnC4A/tnL1+YYXrqntcOD2MKshAiQ+ztjV2ISSRTaGqqX6?=
 =?us-ascii?q?Ig+jE7D5qrDYXERo+zmrCB3yC7HptQZmBBEV2MFXbod4OZW/YDci6SI8lhkiAa?=
 =?us-ascii?q?WrilUYMuyRautAriwbp9MuXU4jEYtY7k1NVt/eLTjhEy9Tt3D8iHyWGCVWN0k3?=
 =?us-ascii?q?gMRz832qB/vEN8xk2C0ah+n/xXC9hT6+lVXQc9MJ7W1/Z6BMzqWgLdYteJT06r?=
 =?us-ascii?q?Qta8DjE3VN4xx94ObFx7G9WtlR3D2yuqA7kIl72EHpA086Tc32TvKMZ50XrJyK?=
 =?us-ascii?q?4hj1w+SMtVKWKmnrJ/9xTUB4PRjkqWjbiqeroG0C7N7miDy3GOs19eUAJ3VaXF?=
 =?us-ascii?q?XnUfZk/NoNT950PCSaKuCLs9PgtAz86CNrVFatnzgVpaQ/fjPczUY3itlGeoGR?=
 =?us-ascii?q?aI2rSMYZL3dGoHwiXSFlIIkwAJ8naALggxGCGhrnnaDDxvE1Lvfkzt/fN/qHO9?=
 =?us-ascii?q?Uk870QWKY1d92Lqy/x4fneacRO8L3rIYpCchrC15HEq839LTDNqAuwphfaVGbd?=
 =?us-ascii?q?Mh+ltH0njZtwh8PpymIKBvnVoecwVxv0Pz2BR7EIRAkc42rHw0yAp+M76X0FRE?=
 =?us-ascii?q?dzmAx5D/JqXXKnXu/BCoc6PZwFXe38iZ+6gR6PU0sU7svBy0GUU49XVn0N5V02?=
 =?us-ascii?q?WH65XODQoSV4/xU0kt+xh7obHafjcy54fO2XJwNqm0tyfI28g1C+s91hagY9Bf?=
 =?us-ascii?q?PbuEFQ/vCcEVG9KiKe0qm1ezaBIEM/tf9Ko1P8OgavuH17SnPOdmnDK6k2tH5J?=
 =?us-ascii?q?px3V6L9yp5UuTIxYoKw+mE3gubUDfxlE2hssHrlo9efzEdA22/xTLiBIFPfK1y?=
 =?us-ascii?q?fJ8HBnu0LM2z29pxmYTtW3le9FO4A1MG2cmpeQedblDn3A1Q01gXrmKjmSei0z?=
 =?us-ascii?q?N0lDQppLKF3CPS2+TiaAYHOmlTSWhijFfgO4i1g8oBXEi1aQgkjx+l5Uf8x6hG?=
 =?us-ascii?q?q6VzNWjTQUFUfyfoK2FuSLe/tr2HY8RX8pMnrT1XUPigYVCdUrP9oQEV0zngH2?=
 =?us-ascii?q?tdwzA3bSqqtY/6nxx5iWKdKmh8rHzCdMF0xBff4sHcRPFL0joHQil4lSfYBlym?=
 =?us-ascii?q?M9a1+tWUko/JsvqiWGK5Sp1TbS7rwJuAtSSh4m1mGx+/n/G1mtD8FQg60Cn718?=
 =?us-ascii?q?RlVCnSrRb8ZJXr2Lq+Me59YkZoA1r84dJgGo5iioswmI0Q2X8Ci5WW53UHkH3/?=
 =?us-ascii?q?MdVG2a3kanoNSiUGw9rU4AjjxU1iIWiFx4P/VnWB3MRhY8O2bX8R2iI498pKEr?=
 =?us-ascii?q?ub7KRYnStppVq1tQfRYfl+njgH0/cv5mAVg/oVuAUz1CWSGa4dHVNXPSH3kxSI?=
 =?us-ascii?q?7ta+rLhYZWq1cLiw0lZ+ks6lDL2Yvg5cX3P5cI84HSBs9sV/LE7M0Hrr54H4f9?=
 =?us-ascii?q?nQaMgftxyOnBfGkuhVM4kxlvsRiCpjOGL9u2AlyuEhgRxv25G6oJaIK2F38K2l?=
 =?us-ascii?q?BR5YMyX/Z9kP9TH1kaZegsGW0pi0EZp7HTULWIboQeisEDIPrvnnMweOEDshqn?=
 =?us-ascii?q?aUA7bfHAmf6Ft4oHLLCZykK3aXJHwBx9V4WBadPFBfgBwTXDginJ42DAWqy9L6?=
 =?us-ascii?q?cEtj+jAd/F34qgZPyuJ1MRnwSHzfqRysajc1TpifMRVX4htD50fTLcyR8OZzEz?=
 =?us-ascii?q?tE8Z2mqQyHMnabaBhQDWEVRkyEAEjuP7mp5dnd6uiYG/CxL/3UbbWVruxeUfiI?=
 =?us-ascii?q?yImr0otn+TaMK8qOMmNjD/09xkpMQ3R5F97FlDUITiwdjzjNYNKDpBeg5i13qd?=
 =?us-ascii?q?iy8PT1VwLu5ouPCLpSPc9s+xCshqeDOPCfhDxkKTZDzZ4MwX7IyL4C3F8dkS1u?=
 =?us-ascii?q?dj+tEageui7JVq7fhqhXDxsDYSNpKMRI97483hVKOcPDkNz1y6V3juQrBFZFT1?=
 =?us-ascii?q?DhnsCpaNcOI2G8MlPHGUmKOK6HJT3N38H4f6e8RadMg+VTsh26oSybHFP7PjSf?=
 =?us-ascii?q?iznpUAiiMf1NjCGeJhBRpJuxfQptCWf9StLrcRm7MN5xjT0rzrw4nHLKNWgAMT?=
 =?us-ascii?q?did0NBtKGf7SRdgv9nAWxO8mJlLfWYmyae9+TZKowZsf1uAiR1keJV+HU7y7tP?=
 =?us-ascii?q?4yFCS/x4gy/Srt9oo1G7neiD0DtnUBxSqjlVgIKHp1ltOaLc9soIZXGR3hsLpU?=
 =?us-ascii?q?aZER1C89lsAd7HoL1Lx57EhvSgBi1F9of28NEbAsWcB8aGK2EseU7rFzrVFxAI?=
 =?us-ascii?q?ZSSmOWHWmwpWl/TEpS7dlYQztpW5wMlGcbRcTlFgU6pCUkk=3D?=
X-IronPort-Anti-Spam-Filtered: true
X-IronPort-Anti-Spam-Result: =?us-ascii?q?A0AHAAC7IhFch0O0hNFkGQEBAQEBAQEBA?=
 =?us-ascii?q?QEBAQcBAQEBAQGBVAEBAQEBAQsBAYFUghaNGoszgg0UaJheKwGBG4YjIjcGDQE?=
 =?us-ascii?q?DAQEBAQEBAgETAQEBCA0JCCkvQgEOAYFkJAGCYQEBAQECAQECCRsLAUYFAQkBA?=
 =?us-ascii?q?QoOCgklAwwFKSAYFgODA4F6CAWmYjOKL4w8F4FAP4ERgl01hE2DaYImAokZIIF?=
 =?us-ascii?q?3hROQSQmRTAsYgVyIDTaHJyyZE4FcgXgzGggbFTuCbYImF447IQEBgTYBARyGU?=
 =?us-ascii?q?4YKAwEB?=
X-IPAS-Result: =?us-ascii?q?A0AHAAC7IhFch0O0hNFkGQEBAQEBAQEBAQEBAQcBAQEBAQG?=
 =?us-ascii?q?BVAEBAQEBAQsBAYFUghaNGoszgg0UaJheKwGBG4YjIjcGDQEDAQEBAQEBAgETA?=
 =?us-ascii?q?QEBCA0JCCkvQgEOAYFkJAGCYQEBAQECAQECCRsLAUYFAQkBAQoOCgklAwwFKSA?=
 =?us-ascii?q?YFgODA4F6CAWmYjOKL4w8F4FAP4ERgl01hE2DaYImAokZIIF3hROQSQmRTAsYg?=
 =?us-ascii?q?VyIDTaHJyyZE4FcgXgzGggbFTuCbYImF447IQEBgTYBARyGU4YKAwEB?=
X-IronPort-AV: E=Sophos;i="5.56,344,1539673200"; 
   d="scan'208";a="66488004"
X-Amp-Result: UNKNOWN
X-Amp-Original-Verdict: FILE UNKNOWN
X-Amp-File-Uploaded: False
Received: from vger.kernel.org ([209.132.180.67])
  by mga01b.intel.com with ESMTP; 12 Dec 2018 07:03:31 -0800
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
        id S1727729AbeLLPD1 (ORCPT <rfc822;like.xu@linux.intel.com>
        + 23 others); Wed, 12 Dec 2018 10:03:27 -0500
Received: from mx1.redhat.com ([209.132.183.28]:38786 "EHLO mx1.redhat.com"
        rhost-flags-OK-OK-OK-OK) by vger.kernel.org with ESMTP
        id S1726269AbeLLPD1 (ORCPT <rfc822;linux-kernel@vger.kernel.org>);
        Wed, 12 Dec 2018 10:03:27 -0500
Received: from smtp.corp.redhat.com (int-mx07.intmail.prod.int.phx2.redhat.com [10.5.11.22])
        (using TLSv1.2 with cipher AECDH-AES256-SHA (256/256 bits))
        (No client certificate requested)
        by mx1.redhat.com (Postfix) with ESMTPS id B7FF3811D9;
        Wed, 12 Dec 2018 15:03:25 +0000 (UTC)
Received: from redhat.com (ovpn-124-14.rdu2.redhat.com [10.10.124.14])
        by smtp.corp.redhat.com (Postfix) with ESMTPS id 45B68101962E;
        Wed, 12 Dec 2018 15:03:22 +0000 (UTC)
Date: Wed, 12 Dec 2018 10:03:20 -0500
From: Jerome Glisse <jglisse@redhat.com>
To: Jan Kara <jack@suse.cz>
Cc: John Hubbard <jhubbard@nvidia.com>,
        Matthew Wilcox <willy@infradead.org>,
        Dan Williams <dan.j.williams@intel.com>,
        John Hubbard <john.hubbard@gmail.com>,
        Andrew Morton <akpm@linux-foundation.org>,
        Linux MM <linux-mm@kvack.org>, tom@talpey.com,
        Al Viro <viro@zeniv.linux.org.uk>, benve@cisco.com,
        Christoph Hellwig <hch@infradead.org>,
        Christopher Lameter <cl@linux.com>,
        "Dalessandro, Dennis" <dennis.dalessandro@intel.com>,
        Doug Ledford <dledford@redhat.com>,
        Jason Gunthorpe <jgg@ziepe.ca>,
        Michal Hocko <mhocko@kernel.org>, mike.marciniszyn@intel.com,
        rcampbell@nvidia.com,
        Linux Kernel Mailing List <linux-kernel@vger.kernel.org>,
        linux-fsdevel <linux-fsdevel@vger.kernel.org>
Subject: Re: [PATCH 1/2] mm: introduce put_user_page*(), placeholder versions
Message-ID: <20181212150319.GA3432@redhat.com>
References: <CAPcyv4iNtamDAY9raab=iXhSZByecedBpnGybjLM+PuDMwq7SQ@mail.gmail.com>
 <3c91d335-921c-4704-d159-2975ff3a5f20@nvidia.com>
 <20181205011519.GV10377@bombadil.infradead.org>
 <20181205014441.GA3045@redhat.com>
 <59ca5c4b-fd5b-1fc6-f891-c7986d91908e@nvidia.com>
 <7b4733be-13d3-c790-ff1b-ac51b505e9a6@nvidia.com>
 <20181207191620.GD3293@redhat.com>
 <3c4d46c0-aced-f96f-1bf3-725d02f11b60@nvidia.com>
 <20181208022445.GA7024@redhat.com>
 <20181210102846.GC29289@quack2.suse.cz>
MIME-Version: 1.0
Content-Type: text/plain; charset=iso-8859-1
Content-Disposition: inline
Content-Transfer-Encoding: 8bit
In-Reply-To: <20181210102846.GC29289@quack2.suse.cz>
User-Agent: Mutt/1.10.1 (2018-07-13)
X-Scanned-By: MIMEDefang 2.84 on 10.5.11.22
X-Greylist: Sender IP whitelisted, not delayed by milter-greylist-4.5.16 (mx1.redhat.com [10.5.110.27]); Wed, 12 Dec 2018 15:03:26 +0000 (UTC)
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: <linux-kernel.vger.kernel.org>
X-Mailing-List: linux-kernel@vger.kernel.org

On Mon, Dec 10, 2018 at 11:28:46AM +0100, Jan Kara wrote:
> On Fri 07-12-18 21:24:46, Jerome Glisse wrote:
> > Another crazy idea, why not treating GUP as another mapping of the page
> > and caller of GUP would have to provide either a fake anon_vma struct or
> > a fake vma struct (or both for PRIVATE mapping of a file where you can
> > have a mix of both private and file page thus only if it is a read only
> > GUP) that would get added to the list of existing mapping.
> >
> > So the flow would be:
> >     somefunction_thatuse_gup()
> >     {
> >         ...
> >         GUP(_fast)(vma, ..., fake_anon, fake_vma);
> >         ...
> >     }
> > 
> >     GUP(vma, ..., fake_anon, fake_vma)
> >     {
> >         if (vma->flags == ANON) {
> >             // Add the fake anon vma to the anon vma chain as a child
> >             // of current vma
> >         } else {
> >             // Add the fake vma to the mapping tree
> >         }
> > 
> >         // The existing GUP except that now it inc mapcount and not
> >         // refcount
> >         GUP_old(..., &nanonymous, &nfiles);
> > 
> >         atomic_add(&fake_anon->refcount, nanonymous);
> >         atomic_add(&fake_vma->refcount, nfiles);
> > 
> >         return nanonymous + nfiles;
> >     }
> 
> Thanks for your idea! This is actually something like I was suggesting back
> at LSF/MM in Deer Valley. There were two downsides to this I remember
> people pointing out:
> 
> 1) This cannot really work with __get_user_pages_fast(). You're not allowed
> to get necessary locks to insert new entry into the VMA tree in that
> context. So essentially we'd loose get_user_pages_fast() functionality.
> 
> 2) The overhead e.g. for direct IO may be noticeable. You need to allocate
> the fake tracking VMA, get VMA interval tree lock, insert into the tree.
> Then on IO completion you need to queue work to unpin the pages again as you
> cannot remove the fake VMA directly from interrupt context where the IO is
> completed.
> 
> You are right that the cost could be amortized if gup() is called for
> multiple consecutive pages however for small IOs there's no help...
> 
> So this approach doesn't look like a win to me over using counter in struct
> page and I'd rather try looking into squeezing HMM public page usage of
> struct page so that we can fit that gup counter there as well. I know that
> it may be easier said than done...

So i want back to the drawing board and first i would like to ascertain
that we all agree on what the objectives are:

    [O1] Avoid write back from a page still being written by either a
         device or some direct I/O or any other existing user of GUP.
         This would avoid possible file system corruption.

    [O2] Avoid crash when set_page_dirty() is call on a page that is
         considered clean by core mm (buffer head have been remove and
         with some file system this turns into an ugly mess).

    [O3] DAX and the device block problems, ie with DAX the page map in
         userspace is the same as the block (persistent memory) and no
         filesystem nor block device understand page as block or pinned
         block.

For [O3] i don't think any pin count would help in anyway. I believe
that the current long term GUP API that does not allow GUP of DAX is
the only sane solution for now. The real fix would be to teach file-
system about DAX/pinned block so that a pinned block is not reuse
by filesystem.


For [O1] and [O2] i believe a solution with mapcount would work. So
no new struct, no fake vma, nothing like that. In GUP for file back
pages we increment both refcount and mapcount (we also need a special
put_user_page to decrement mapcount when GUP user are done with the
page).

Now for [O1] the write back have to call page_mkclean() to go through
all reverse mapping of the page and map read only. This means that
we can count the number of real mapping and see if the mapcount is
bigger than that. If mapcount is bigger than page is pin and we need
to use a bounce page to do the writeback.

Note that their can be no concurrent new real mapping added as the
page is lock thus we are protected on that front. So only race is
with a GUP running before page_mkclean() had remove all pte with
write permission. To close that race we should check for the page
write back flags in GUP and returns either ERR_PTR(EBUSY) for the
page or return the page and set some flag in the lower bit of the
page struct pointer so that user of GUP can wait on write back to
finish before doing anything else.


For [O2] i believe we can handle that case in the put_user_page()
function to properly dirty the page without causing filesystem
freak out.

Impact of that approach seems pretty small, direct IO would only
be affected for page under active write back which is one of the
thing we are trying to fix anyway.

Did i miss anything ?

Cheers,
Jérôme
