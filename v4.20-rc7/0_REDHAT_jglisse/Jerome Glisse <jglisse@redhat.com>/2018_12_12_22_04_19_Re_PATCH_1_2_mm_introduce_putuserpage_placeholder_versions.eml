Return-Path: <linux-kernel-owner@vger.kernel.org>
Delivered-To: unknown
Received: from linux.intel.com (10.54.29.200:995) by i7-8700 with POP3-SSL;
  13 Dec 2018 08:56:07 -0000
X-Original-To: like.xu@linux.intel.com
Delivered-To: like.xu@linux.intel.com
Received: from orsmga001.jf.intel.com (orsmga001.jf.intel.com [10.7.209.18])
	(using TLSv1.2 with cipher ECDHE-RSA-AES256-GCM-SHA384 (256/256 bits))
	(No client certificate requested)
	by linux.intel.com (Postfix) with ESMTPS id 2232458079D;
	Wed, 12 Dec 2018 14:07:30 -0800 (PST)
Received: from fmsmga105.fm.intel.com ([10.1.193.10])
  by orsmga001-1.jf.intel.com with ESMTP/TLS/DHE-RSA-AES256-GCM-SHA384; 12 Dec 2018 14:07:29 -0800
X-SG-BADATTACHMENTNOREPLY: True
IronPort-PHdr: =?us-ascii?q?9a23=3A9vi58heqeb8P6ssTx7bcPV7AlGMj4u6mDksu8pMi?=
 =?us-ascii?q?zoh2WeGdxc6+YRyN2/xhgRfzUJnB7Loc0qyK6/CmATRIyK3CmUhKSIZLWR4BhJ?=
 =?us-ascii?q?detC0bK+nBN3fGKuX3ZTcxBsVIWQwt1Xi6NU9IBJS2PAWK8TW94jEIBxrwKxd+?=
 =?us-ascii?q?KPjrFY7OlcS30P2594HObwlSizexfbB/IA+qoQnNq8IbnZZsJqEtxxXTv3BGYf?=
 =?us-ascii?q?5WxWRmJVKSmxbz+MK994N9/ipTpvws6ddOXb31cKokQ7NYCi8mM30u683wqRbD?=
 =?us-ascii?q?VwqP6WACXWgQjxFFHhLK7BD+Xpf2ryv6qu9w0zSUMMHqUbw5Xymp4rx1QxH0li?=
 =?us-ascii?q?gIKz858HnWisNuiqJbvAmhrAF7z4LNfY2ZKOZycqbbcNgHR2ROQ9xRWjRPDI28?=
 =?us-ascii?q?cYUBEukPPehXoIbhulQAohmxCge3BOP3yDJFnWP20K4g3ug9DQ3LxhEsEtQTu3?=
 =?us-ascii?q?rUttX1M6ISXPixwqbW1zXDaPZW1ing44bJdhAhoOqMXalufsHMzkQvFQzFjlGR?=
 =?us-ascii?q?qYz+JDOayP8As3KF4OV9VeKgkXInpxttrTiow8chk4/EjZ8WxFDc7Sh13po5KN?=
 =?us-ascii?q?miREJmb9OoDoFcuzyZOodqWM8vQmNltD4kxrEavZO3ZjUGxZo5yxLFdvCKcIaF?=
 =?us-ascii?q?7gj9WOuSJzpzmWhrd6ilhxmo9Eit0u38Wdew0FZNtidFjNbMuW4X1xDJ6ciIVO?=
 =?us-ascii?q?F9/kG/1jaLzQzT7ftEIU8smaraLZ4u3KIwm4INvUjfGiL6glj6gaGIekk+5+Sl?=
 =?us-ascii?q?6Pjrbq/nq5KeL4N0jxvxMqUqmsyxG+Q4NQ0OUnCf+eS90r3j4EL4TKxJjvIoiK?=
 =?us-ascii?q?nZto7VJcACqq6+DQ5V1Jgs6wykAje439QXg2MHIEhGeB2ZlYjpPU/BIPTiAfe4?=
 =?us-ascii?q?mVSsny9nx+raMb35HpXNMn/Dna/lfbZ86E5T1hA/zN9C559PDrEBIfTzWlL+td?=
 =?us-ascii?q?DCDx85NRC0zPjjCNlnyoweXmePCLeDMKzOqV+I+v4vI+6UaY8Vojn9KuQl6OTp?=
 =?us-ascii?q?jXMjmV8dYLOm3Z0YaH2jGvRmIkOZYWfjg9sbEGcKuBY+Q/LuiFGYTTFTYHOyVb?=
 =?us-ascii?q?om5j4nEIKmEZvDRoe1jbyD2ye0AIdaZmNBClCKF3focJ6JW/MNaCKUP89gnSYI?=
 =?us-ascii?q?VbmnS489yx6usBX2xKZgLurR4icYr47s1MBp5+3PkhE/7SZ7D9+d02GKTGF4hH?=
 =?us-ascii?q?kISCU03K1kpUx9y1GD0bV3gvBCFNxT4e9JXRk+NZLG0+N6DNXyUBrbftiVUFam?=
 =?us-ascii?q?XsmmATYpQ9Iy2dAOZVxxG9Gjjh/Z2SqqDKQYl7iKBJwy76Ld0GL9J8d7y3bayq?=
 =?us-ascii?q?Yhi0MqTddINW2jnqR/7RTcB5bVk0WFkKanbbkT0zTT9Gid12aOvFtXUAhrUarb?=
 =?us-ascii?q?W3ATYU/Wrdf85kPGVLKuDbUnMg1cyc+NMKdKa9vpjUlYS/fnItjRf2Wxm2KoDx?=
 =?us-ascii?q?aS2ryMdJbqe3ka3CjFFUcLiR4T8micOQg+HCihpXneAyJoFV/0Z0Ps8O9+qG60?=
 =?us-ascii?q?T0MuzgGKaVFh2KSx+hIPmfOcTPYT1KoeuCg9szV0AEq939XOBtqcpgpheaJcYc?=
 =?us-ascii?q?894FZHz27ZqxZxPpu6L6Bmh14edQt3sljq1xV2DIVAjMcroGkrzAp0NaKXzldB?=
 =?us-ascii?q?eymE0pD3P73dMnPy8wy3a67KxlHe186b9b0L6PsmpFTsogGoGlA5/HV6ztZayX?=
 =?us-ascii?q?2c5pbNDAoMSp/xVkc39x5np7DVeCU95oXU1WFyPqmwqDPNx9UpBO49wBa6Y9hf?=
 =?us-ascii?q?KL+EFBP1E8ACB8muNfYmlESzYhMFPOBd7qg0P8y9evuC2a6rOvtgnT28gWRG5o?=
 =?us-ascii?q?B9zlyD9y5mRuHU2JYFxumS3hGbWDfkkFehrsf3lJheZTETAmWw0zLkC5NWZqFo?=
 =?us-ascii?q?e4YEF32uI8yuytpinZHtX2NX+0C5B1MB3s+kYh6Sb1373Q1N2kUbu32nmS2kzz?=
 =?us-ascii?q?NqlzEltLaQ3CvLw+76bhoIJnZLRHV+jVfrOYW1j9EaUFKobgQzjxul+ED6yrNf?=
 =?us-ascii?q?pKR+KWnTXEhJczL3L2FkTqu/qL6Cb9RT55MvtCVdSP68bkyCSr7hvxsa1DvuH2?=
 =?us-ascii?q?lEyzAhdDGquZL5kwZhiG2HL3Zzr3vZecduyhfZ/9HcQf9R3jwbRCh3kzXXB168?=
 =?us-ascii?q?P8W38tWQjZvMrue+V2e5XJ1JbSbr1Z+AtDe85WByARywhfezlsflEQg71y/2zN?=
 =?us-ascii?q?1qVSTOrBbhbYjnzaW6MeR7fkZ2AF/w8dZ1GoZ7koEonpEfxWAahomJ/XoAiWrz?=
 =?us-ascii?q?Ms9U2aPkYHoNWD4E2djV4Af+1U1nL3KJwZ/5V3qHzstgYdm6fn0Z2iYn489WD6?=
 =?us-ascii?q?eU6aROnTFprVqgsQLRff99ky8Yyfsv634VmfsFuQQzwSWGHrAdA1NYMjfymBSS?=
 =?us-ascii?q?4NCzt6FXZGepcbit20tyh9GhDLeeog5CXHb1YIstHSh17s9nKlLDzGXz6p34eN?=
 =?us-ascii?q?nXdd8TqhqUkxLag+lUMp0xkOcKhTF8OWL8pnAlz+87jRpz3ZC1poSHKmNt/L6n?=
 =?us-ascii?q?DR5cLDH6e8QT+jT1h6ZEgsmWx5yvHolmGjgTR5TnV/WoEDYPtfj9MwaODSYxqn?=
 =?us-ascii?q?OaGbrZAA+e511qr3PJE5C3KX6XIGMVwsllRBmYPEZfmhwbXC0mnp4lEQCn3M7h?=
 =?us-ascii?q?f1185j8P/V70sAdMxvhrNxniUWffuQGoZS0vSJWEKBpW7wdC51raMMCE7+JzGT?=
 =?us-ascii?q?1Y8YOlrACXNmObYAFIB3kTWkOYH1DjIqWu5d7Y/umYAeq+MuLOYaiUpuxYTfuI?=
 =?us-ascii?q?3pWv0o1p/zuXMsWPP39iD+A020ZZXHB5HdjZlCsLSyANiy3NaMubrg+m+iJrts?=
 =?us-ascii?q?C/7OjrWAX36IuPFbRSMNZv+xO3gauZNO6QniF5KTlG2ZMW2H/I06MS3FoTiyFo?=
 =?us-ascii?q?ajmsHq4MtS/LTKLMhKBXCwQXZD90NMtN96g8xBVCOdbHitPp0b51luQ6C0peWl?=
 =?us-ascii?q?z7hM6oZdYGI2W8NF7cAEaLNbKGJSDEws3tYKO8T6FQg/tQtxGqpTmbFErjNCyZ?=
 =?us-ascii?q?lzb1TxCvLf1MjCaDMRxCuYG9dwxhBnT5QN36ah20Ltl3gCYywb01gHPKKGEdPS?=
 =?us-ascii?q?J9c0NLsr2f8ydYju9jFGxG63pvNfOElDqB7+nENpYWtuNmAyRumOJc5XQ6yr1V?=
 =?us-ascii?q?4zlFRfx1giTSqNFurkqikumOzDpnTRVPpixKhIKNoUVtJ6HZ+oNcVnbD+RJepV?=
 =?us-ascii?q?mXXjYNp90tKsDlsalKxpCblqLuIj1L6d78+9UdC8ndbsmANSxyHwDuHWv2AREC?=
 =?us-ascii?q?SDPjGmXenFdQ2KWQ+XmUtYM3goLhlJoHVvlQU1ljRaBSMVhsANFXeMQ/ZTgji7?=
 =?us-ascii?q?POyZdQvXc=3D?=
X-IronPort-Anti-Spam-Filtered: true
X-IronPort-Anti-Spam-Result: =?us-ascii?q?A0AgAACShRFch0O0hNFkGQEBAQEBAQEBA?=
 =?us-ascii?q?QEBAQcBAQEBAQGBZQKBVAWCESeMdIs0gg0UmTIUGBMBhz4iOBIBAwEBAQEBAQI?=
 =?us-ascii?q?BEwEBAQgNCQgpL0IBDgGBZCQBgmEBAQEBAgEBAgkbCwFGBgkBAQoOCgklAwwFK?=
 =?us-ascii?q?SATBRYDgjhLgXoIBad6M4osjDwXgUA/gRGCFH6ETYYPAokZIIF3hROQSQmRTAs?=
 =?us-ascii?q?YgVyIDTaHJyyKAo8RgV2BdzMaCBsVO4JsgicXjjshAQExgQUBARyGTIM2KIIlA?=
 =?us-ascii?q?QE?=
X-IPAS-Result: =?us-ascii?q?A0AgAACShRFch0O0hNFkGQEBAQEBAQEBAQEBAQcBAQEBAQG?=
 =?us-ascii?q?BZQKBVAWCESeMdIs0gg0UmTIUGBMBhz4iOBIBAwEBAQEBAQIBEwEBAQgNCQgpL?=
 =?us-ascii?q?0IBDgGBZCQBgmEBAQEBAgEBAgkbCwFGBgkBAQoOCgklAwwFKSATBRYDgjhLgXo?=
 =?us-ascii?q?IBad6M4osjDwXgUA/gRGCFH6ETYYPAokZIIF3hROQSQmRTAsYgVyIDTaHJyyKA?=
 =?us-ascii?q?o8RgV2BdzMaCBsVO4JsgicXjjshAQExgQUBARyGTIM2KIIlAQE?=
X-IronPort-AV: E=Sophos;i="5.56,346,1539673200"; 
   d="scan'208";a="141898624"
X-Amp-Result: UNKNOWN
X-Amp-Original-Verdict: FILE UNKNOWN
X-Amp-File-Uploaded: False
Received: from vger.kernel.org ([209.132.180.67])
  by mtab.intel.com with ESMTP; 12 Dec 2018 14:07:27 -0800
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
        id S1728345AbeLLWEY (ORCPT <rfc822;like.xu@linux.intel.com>
        + 23 others); Wed, 12 Dec 2018 17:04:24 -0500
Received: from mx1.redhat.com ([209.132.183.28]:37886 "EHLO mx1.redhat.com"
        rhost-flags-OK-OK-OK-OK) by vger.kernel.org with ESMTP
        id S1726263AbeLLWEY (ORCPT <rfc822;linux-kernel@vger.kernel.org>);
        Wed, 12 Dec 2018 17:04:24 -0500
Received: from smtp.corp.redhat.com (int-mx04.intmail.prod.int.phx2.redhat.com [10.5.11.14])
        (using TLSv1.2 with cipher AECDH-AES256-SHA (256/256 bits))
        (No client certificate requested)
        by mx1.redhat.com (Postfix) with ESMTPS id 58478307DAAF;
        Wed, 12 Dec 2018 22:04:23 +0000 (UTC)
Received: from redhat.com (ovpn-124-14.rdu2.redhat.com [10.10.124.14])
        by smtp.corp.redhat.com (Postfix) with ESMTPS id 093A05D9C7;
        Wed, 12 Dec 2018 22:04:20 +0000 (UTC)
Date: Wed, 12 Dec 2018 17:04:19 -0500
From: Jerome Glisse <jglisse@redhat.com>
To: John Hubbard <jhubbard@nvidia.com>
Cc: Dan Williams <dan.j.williams@intel.com>, Jan Kara <jack@suse.cz>,
        Matthew Wilcox <willy@infradead.org>,
        John Hubbard <john.hubbard@gmail.com>,
        Andrew Morton <akpm@linux-foundation.org>,
        Linux MM <linux-mm@kvack.org>, tom@talpey.com,
        Al Viro <viro@zeniv.linux.org.uk>, benve@cisco.com,
        Christoph Hellwig <hch@infradead.org>,
        Christopher Lameter <cl@linux.com>,
        "Dalessandro, Dennis" <dennis.dalessandro@intel.com>,
        Doug Ledford <dledford@redhat.com>,
        Jason Gunthorpe <jgg@ziepe.ca>,
        Michal Hocko <mhocko@kernel.org>,
        Mike Marciniszyn <mike.marciniszyn@intel.com>,
        rcampbell@nvidia.com,
        Linux Kernel Mailing List <linux-kernel@vger.kernel.org>,
        linux-fsdevel <linux-fsdevel@vger.kernel.org>
Subject: Re: [PATCH 1/2] mm: introduce put_user_page*(), placeholder versions
Message-ID: <20181212220418.GH5037@redhat.com>
References: <59ca5c4b-fd5b-1fc6-f891-c7986d91908e@nvidia.com>
 <7b4733be-13d3-c790-ff1b-ac51b505e9a6@nvidia.com>
 <20181207191620.GD3293@redhat.com>
 <3c4d46c0-aced-f96f-1bf3-725d02f11b60@nvidia.com>
 <20181208022445.GA7024@redhat.com>
 <20181210102846.GC29289@quack2.suse.cz>
 <20181212150319.GA3432@redhat.com>
 <CAPcyv4go0Xzhz8rXdfscWuXDu83BO9v8WD4upDUJWb7gKzX5OQ@mail.gmail.com>
 <20181212213005.GE5037@redhat.com>
 <514cc9e1-dc4d-b979-c6bc-88ac503c098d@nvidia.com>
MIME-Version: 1.0
Content-Type: text/plain; charset=iso-8859-1
Content-Disposition: inline
Content-Transfer-Encoding: 8bit
In-Reply-To: <514cc9e1-dc4d-b979-c6bc-88ac503c098d@nvidia.com>
User-Agent: Mutt/1.10.1 (2018-07-13)
X-Scanned-By: MIMEDefang 2.79 on 10.5.11.14
X-Greylist: Sender IP whitelisted, not delayed by milter-greylist-4.5.16 (mx1.redhat.com [10.5.110.42]); Wed, 12 Dec 2018 22:04:23 +0000 (UTC)
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: <linux-kernel.vger.kernel.org>
X-Mailing-List: linux-kernel@vger.kernel.org

On Wed, Dec 12, 2018 at 01:56:00PM -0800, John Hubbard wrote:
> On 12/12/18 1:30 PM, Jerome Glisse wrote:
> > On Wed, Dec 12, 2018 at 08:27:35AM -0800, Dan Williams wrote:
> >> On Wed, Dec 12, 2018 at 7:03 AM Jerome Glisse <jglisse@redhat.com> wrote:
> >>>
> >>> On Mon, Dec 10, 2018 at 11:28:46AM +0100, Jan Kara wrote:
> >>>> On Fri 07-12-18 21:24:46, Jerome Glisse wrote:
> >>>>> Another crazy idea, why not treating GUP as another mapping of the page
> >>>>> and caller of GUP would have to provide either a fake anon_vma struct or
> >>>>> a fake vma struct (or both for PRIVATE mapping of a file where you can
> >>>>> have a mix of both private and file page thus only if it is a read only
> >>>>> GUP) that would get added to the list of existing mapping.
> >>>>>
> >>>>> So the flow would be:
> >>>>>     somefunction_thatuse_gup()
> >>>>>     {
> >>>>>         ...
> >>>>>         GUP(_fast)(vma, ..., fake_anon, fake_vma);
> >>>>>         ...
> >>>>>     }
> >>>>>
> >>>>>     GUP(vma, ..., fake_anon, fake_vma)
> >>>>>     {
> >>>>>         if (vma->flags == ANON) {
> >>>>>             // Add the fake anon vma to the anon vma chain as a child
> >>>>>             // of current vma
> >>>>>         } else {
> >>>>>             // Add the fake vma to the mapping tree
> >>>>>         }
> >>>>>
> >>>>>         // The existing GUP except that now it inc mapcount and not
> >>>>>         // refcount
> >>>>>         GUP_old(..., &nanonymous, &nfiles);
> >>>>>
> >>>>>         atomic_add(&fake_anon->refcount, nanonymous);
> >>>>>         atomic_add(&fake_vma->refcount, nfiles);
> >>>>>
> >>>>>         return nanonymous + nfiles;
> >>>>>     }
> >>>>
> >>>> Thanks for your idea! This is actually something like I was suggesting back
> >>>> at LSF/MM in Deer Valley. There were two downsides to this I remember
> >>>> people pointing out:
> >>>>
> >>>> 1) This cannot really work with __get_user_pages_fast(). You're not allowed
> >>>> to get necessary locks to insert new entry into the VMA tree in that
> >>>> context. So essentially we'd loose get_user_pages_fast() functionality.
> >>>>
> >>>> 2) The overhead e.g. for direct IO may be noticeable. You need to allocate
> >>>> the fake tracking VMA, get VMA interval tree lock, insert into the tree.
> >>>> Then on IO completion you need to queue work to unpin the pages again as you
> >>>> cannot remove the fake VMA directly from interrupt context where the IO is
> >>>> completed.
> >>>>
> >>>> You are right that the cost could be amortized if gup() is called for
> >>>> multiple consecutive pages however for small IOs there's no help...
> >>>>
> >>>> So this approach doesn't look like a win to me over using counter in struct
> >>>> page and I'd rather try looking into squeezing HMM public page usage of
> >>>> struct page so that we can fit that gup counter there as well. I know that
> >>>> it may be easier said than done...
> >>>
> >>> So i want back to the drawing board and first i would like to ascertain
> >>> that we all agree on what the objectives are:
> >>>
> >>>     [O1] Avoid write back from a page still being written by either a
> >>>          device or some direct I/O or any other existing user of GUP.
> >>>          This would avoid possible file system corruption.
> >>>
> >>>     [O2] Avoid crash when set_page_dirty() is call on a page that is
> >>>          considered clean by core mm (buffer head have been remove and
> >>>          with some file system this turns into an ugly mess).
> >>>
> >>>     [O3] DAX and the device block problems, ie with DAX the page map in
> >>>          userspace is the same as the block (persistent memory) and no
> >>>          filesystem nor block device understand page as block or pinned
> >>>          block.
> >>>
> >>> For [O3] i don't think any pin count would help in anyway. I believe
> >>> that the current long term GUP API that does not allow GUP of DAX is
> >>> the only sane solution for now.
> >>
> >> No, that's not a sane solution, it's an emergency hack.
> >>
> >>> The real fix would be to teach file-
> >>> system about DAX/pinned block so that a pinned block is not reuse
> >>> by filesystem.
> >>
> >> We already have taught filesystems about pinned dax pages, see
> >> dax_layout_busy_page(). As much as possible I want to eliminate the
> >> concept of "dax pages" as a special case that gets sprinkled
> >> throughout the mm.
> > 
> > So thinking on O3 issues what about leveraging the recent change i
> > did to mmu notifier. Add a event for truncate or any other file
> > event that need to invalidate the file->page for a range of offset.
> > 
> > Add mmu notifier listener to GUP user (except direct I/O) so that
> > they invalidate they hardware mapping or switch the hardware mapping
> > to use a crappy page. When such event happens what ever user do to
> > the page through that driver is broken anyway. So it is better to
> > be loud about it then trying to make it pass under the radar.
> > 
> > This will put the burden on broken user and allow you to properly
> > recycle your DAX page.
> > 
> > Think of it as revoke through mmu notifier.
> > 
> > So patchset would be:
> >     enum mmu_notifier_event {
> > +       MMU_NOTIFY_TRUNCATE,
> >     };
> > 
> > +   Change truncate code path to emit MMU_NOTIFY_TRUNCATE
> > 
> 
> That part looks good.
> 
> > Then for each user of GUP (except direct I/O or other very short
> > term GUP):
> 
> but, why is there a difference between how we handle long- and
> short-term callers? Aren't we just leaving a harder-to-reproduce race
> condition, if we ignore the short-term gup callers?
> 
> So, how does activity (including direct IO and other short-term callers)
> get quiesced (stopped, and guaranteed not to restart or continue), so 
> that truncate or umount can continue on?

The fs would delay block reuse to after refcount is gone so it would
wait for that. It is ok to do that only for short term user in case of
direct I/O this should really not happen as it means that the application
is doing something really stupid. So the waiting on short term user
would be a rare event.


> >     Patch 1: register mmu notifier
> >     Patch 2: listen to MMU_NOTIFY_TRUNCATE and MMU_NOTIFY_UNMAP
> >              when that happens update the device page table or
> >              usage to point to a crappy page and do put_user_page
> >              on all previously held page
> 
> Minor point, this sequence should be done within a wrapper around existing 
> get_user_pages(), such as get_user_pages_revokable() or something.

No we want to teach everyone to abide by the rules, if we add yet another
GUP function prototype people will use the one where they don;t have to
say they abide by the rules. It is time we advertise the fact that GUP
should not be use willy nilly for anything without worrying about the
implication it has :)

So i would rather see a consolidation in the number of GUP prototype we
have than yet another one.

Cheers,
Jérôme
