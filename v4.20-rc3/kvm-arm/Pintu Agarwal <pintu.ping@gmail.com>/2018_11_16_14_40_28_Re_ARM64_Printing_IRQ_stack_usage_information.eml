Return-Path: <linux-kernel-owner@vger.kernel.org>
Delivered-To: unknown
Received: from pop3.zju.edu.cn (61.164.42.155:110) by
  likexu-MOBL1.ccr.corp.intel.com with POP3; 17 Nov 2018 03:12:14 -0000
Received: from icoremail.net (unknown [209.85.210.179])
	by mail-app2 (Coremail) with SMTP id by_KCgDXv+4H1+5bkWmjAQ--.49052S3;
	Fri, 16 Nov 2018 22:41:12 +0800 (CST)
Received: from mail-pf1-f179.google.com (unknown [209.85.210.179])
	by mx2.icoremail.net (Coremail) with SMTP id AQAAfwA3HkoE1+5bpONJAA--.671S3;
	Fri, 16 Nov 2018 22:41:09 +0800 (CST)
Received: by mail-pf1-f179.google.com with SMTP id c72so6824500pfc.6
        for <xuliker@zju.edu.cn>; Fri, 16 Nov 2018 06:41:09 -0800 (PST)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20161025;
        h=x-gm-message-state:delivered-to:dkim-signature:mime-version
         :references:in-reply-to:from:date:message-id:subject:to:cc:sender
         :precedence:list-id;
        bh=Dj133bQt9UjDgAy+Qd184kS0Dv4p8xQ0fBSz7eQ3h38=;
        b=tidWcDW0F0AqME1HcRebeVWjW4xTh1LTHAEVFrw2fGPt0HiHKWx4V9FGKPkENYewRP
         g+2L7XPghPRXjAnzJbkMhpDKbQj2YZ/j75CKBg3eABWUaRpczrXhGRr3/zFDAaKZZ0+z
         zm4AvQQmdYWpY6EYmoCciF/6+VI0YUAksr0ItfTWdOpfWbkFPkymQQd2xncUP3/GUd8d
         /DZNCLO/yFYUtuZQgA/18/skj3ezOKX4lMDqdfTbI4h1hAB9LtIr1p2iztrQrWGpPMZa
         AQ33OtNADgwdt9pTHmwBvVB8DPbwni9kD4ceTEJRK/WBgu5O/Kq+3uhNfGEmwPpvlDsB
         /s6w==
X-Gm-Message-State: AGRZ1gKIrcJVEiuepWQYXgu65tubLtZL7mrzlCogXINgRNBgSWmMP9au
	wluntaERHJEIc/g6u9NuLTyEP/qRoDKyUN2WY5+54aYVlfrszWA=
X-Received: by 2002:a62:5e83:: with SMTP id s125-v6mr11257332pfb.232.1542379268524;
        Fri, 16 Nov 2018 06:41:08 -0800 (PST)
X-Forwarded-To: xuliker@zju.edu.cn
X-Forwarded-For: liker.xu@gmail.com xuliker@zju.edu.cn
Delivered-To: liker.xu@gmail.com
Received: by 2002:a17:90a:d106:0:0:0:0 with SMTP id l6-v6csp501615pju;
        Fri, 16 Nov 2018 06:41:07 -0800 (PST)
X-Google-Smtp-Source: AJdET5eH9fAilIwZqpKQC5pflukvzndNd5+YTxvuS/K5bxjKk5j3y1YP58/ssPAMcJU1MdcdB2+j
X-Received: by 2002:a63:585c:: with SMTP id i28mr10290759pgm.178.1542379267321;
        Fri, 16 Nov 2018 06:41:07 -0800 (PST)
ARC-Seal: i=1; a=rsa-sha256; t=1542379267; cv=none;
        d=google.com; s=arc-20160816;
        b=GMsiIq8ibPhkGTmL+6YhghI7e+L1XXs6z42n1k230c8KBx1W+gc0Y0iTJ7QweQ+THU
         yYaEegZmawLodGaLI36wEP1SXLnOATwN5AVpqbX768dnsIawo5c6eeAlraBW5EUq0AZu
         weJj9Q+ex9QRYq/GyN0eir/QPMmcu/h+isv9EYizxsmgSAtxayVJAViJ0kljdBfM6bar
         EGFkUPZ+YKCJO289ig5m73nokS8JjW39X6ZjXrRu0J2diLoGTx/YuyK/iYu7BXUPt8gV
         5uWTy+TP2oqF+MsGsNt/pxtTv0ZW01QPRb95bh/KljAp3fV1TvECaAxJR9vAxM6c/HMN
         cvMQ==
ARC-Message-Signature: i=1; a=rsa-sha256; c=relaxed/relaxed; d=google.com; s=arc-20160816;
        h=list-id:precedence:sender:cc:to:subject:message-id:date:from
         :in-reply-to:references:mime-version:dkim-signature;
        bh=Dj133bQt9UjDgAy+Qd184kS0Dv4p8xQ0fBSz7eQ3h38=;
        b=DZBjyEOSn4IfdkzFUx1QTxW/w5xnLH2hOEcp/eYQUyiOzOTzx7dC4Ql8GYDwWkgBae
         DT2B/G1tz05Eu+IE6btYCtUxpO6pd0zuzaek2E1BNbiHYinmqPTkJqcYSj/Fkgcuorgc
         MbWZR0f7JoPWupZR8Tayhp57I/5ivGvjkQJuOk9viIzl5DzMvZ3bkexWpVdMlRG3vqSc
         QIFyxBtjWZyR1SUD2aFTOHXeh40853nC64dO5jy0m9DbQxz8TZEVHNJ6s2xVhTHafi+y
         WoBDlxGUMzweoPzDPZ90xlRYD2/Ze7O5SHlwDWP7xxxrBXUvCix4bN1BSNi0Z7hKNOrX
         eLuA==
ARC-Authentication-Results: i=1; mx.google.com;
       dkim=pass header.i=@gmail.com header.s=20161025 header.b="AL/+4ah0";
       spf=pass (google.com: best guess record for domain of linux-kernel-owner@vger.kernel.org designates 209.132.180.67 as permitted sender) smtp.mailfrom=linux-kernel-owner@vger.kernel.org;
       dmarc=pass (p=NONE sp=QUARANTINE dis=NONE) header.from=gmail.com
Received: from vger.kernel.org (vger.kernel.org. [209.132.180.67])
        by mx.google.com with ESMTP id w75si2947866pfd.55.2018.11.16.06.40.51;
        Fri, 16 Nov 2018 06:41:07 -0800 (PST)
Received-SPF: pass (google.com: best guess record for domain of linux-kernel-owner@vger.kernel.org designates 209.132.180.67 as permitted sender) client-ip=209.132.180.67;
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
        id S2389890AbeKQAxV (ORCPT <rfc822;jroi.martin@gmail.com>
        + 99 others); Fri, 16 Nov 2018 19:53:21 -0500
Received: from mail-vs1-f67.google.com ([209.85.217.67]:45122 "EHLO
        mail-vs1-f67.google.com" rhost-flags-OK-OK-OK-OK) by vger.kernel.org
        with ESMTP id S1728114AbeKQAxU (ORCPT
        <rfc822;linux-kernel@vger.kernel.org>);
        Fri, 16 Nov 2018 19:53:20 -0500
Received: by mail-vs1-f67.google.com with SMTP id v10so6454401vsv.12
        for <linux-kernel@vger.kernel.org>; Fri, 16 Nov 2018 06:40:41 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20161025;
        h=mime-version:references:in-reply-to:from:date:message-id:subject:to
         :cc;
        bh=Dj133bQt9UjDgAy+Qd184kS0Dv4p8xQ0fBSz7eQ3h38=;
        b=AL/+4ah0O+d42MfPSUDqqj6Np6RP/rXb6tBHnttoisa/71z/ZzxEYcyE/s0MNMXuq/
         O3Ig1MAfvuBS4TjZXU9OtgK9OzmyLuxf7TOeQy/hVdWzR9pF2fmZbiq2uxOxpOEnwVy1
         R73TkPY/DnphGi5APs7XDKy2YpirHobYcVQvbibV01K2wO1EoaXxEZSj6u8jxyTHJCDX
         P/L43eM0ieN3usJgOfPsjdnvWOEkttLFg7STunSUZTyLO6qoU9S2OOXhQ2iYUBFYlRCH
         S4Qj/DBial0z7lYjsCnUhJP70zvQ4FNtatCbfo6evIzkumFDZmdSsYghg+aE/guxwbqN
         5RBA==
X-Received: by 2002:a67:f756:: with SMTP id w22mr4683239vso.30.1542379240624;
 Fri, 16 Nov 2018 06:40:40 -0800 (PST)
MIME-Version: 1.0
References: <CAOuPNLiLj9be5iUdpUiLqiTge-xYY_v4_VLs-ah2_PygG7vxdg@mail.gmail.com>
 <28496.1542300549@turing-police.cc.vt.edu> <CAOuPNLj8wj=tPJo8L3oS7o8iTQcyhZ0W-GH6xmP_GsG4r7YdAQ@mail.gmail.com>
 <49219.1542367988@turing-police.cc.vt.edu>
In-Reply-To: <49219.1542367988@turing-police.cc.vt.edu>
From: Pintu Agarwal <pintu.ping@gmail.com>
Date: Fri, 16 Nov 2018 20:10:28 +0530
Message-ID: <CAOuPNLg4tM6Cw8Yf9rdpkBOU=+Fh654yFQeAhJf1y88Gb3MAew@mail.gmail.com>
Subject: Re: [ARM64] Printing IRQ stack usage information
To: Valdis Kletnieks <valdis.kletnieks@vt.edu>
Cc: open list <linux-kernel@vger.kernel.org>,
        linux-arm-kernel@lists.infradead.org,
        Russell King - ARM Linux <linux@armlinux.org.uk>,
        kernelnewbies@kernelnewbies.org,
        Jungseok Lee <jungseoklee85@gmail.com>,
        catalin.marinas@arm.com, will.deacon@arm.com,
        Takahiro Akashi <takahiro.akashi@linaro.org>,
        mark.rutland@arm.com, Sungjinn Chung <barami97@gmail.com>
Content-Type: text/plain; charset="UTF-8"
Sender: liker.xu+caf_=xuliker=zju.edu.cn@gmail.com
Precedence: bulk
List-ID: <linux-kernel.vger.kernel.org>
X-Mailing-List: linux-kernel@vger.kernel.org
X-CM-TRANSID: AQAAfwA3HkoE1+5bpONJAA--.671S3
Authentication-Results: mail-app2; spf=pass smtp.mail=liker.xu+caf_=xu
	liker=zju.edu.cn@gmail.com;
X-Coremail-Antispam: 1UD129KBjvJXoWxWry8JrW5urWDCr4kAF18Krg_yoWrZryfpa
	9xK3ZFkr48Xr10g347Jw1kXFy7Grs0qrnxGr9rtr40yr15Xr1YqryfKFy3ZFWDCryvqa12
	9w4YvrsrCa9Iy3DanT9S1TB71UUUUUUqnTZGkaVYY2UrUUUU0bIjqfuFe4nvWSU8nxnvy2
	9KBjDU0xBIdaVrnRJUUU92b7Iv0xC_Kw4lb4IE77IF4wAFF20E14v26r1j6r4UM7CIcVAF
	z4kK6r1j6r18M28lY4IEw2IIxxk0rwA2F7IY1VAKz4vEj48ve4kI8wA2z4x0Y4vE2Ix0cI
	8IcVAFwI0_tr0E3s1l84ACjcxK6xIIjxv20xvEc7CjxVAFwI0_Gr1j6F4UJwA2z4x0Y4vE
	x4A2jsIE14v26rxl6s0DM28EF7xvwVC2z280aVCY1x0267AKxVW0oVCq3wAS0I0E0xvYzx
	vE52x082IY62kv0487Mc02F40EFcxC0VAKzVAqx4xG6I80ewAv7VC0I7IYx2IY67AKxVWU
	JVWUGwAv7VC2z280aVAFwI0_Gr0_Cr1lOx8S6xCaFVCjc4AY6r1j6r4UM4x0Y48IcVAKI4
	8JMx02cVCv0xWlc7CjxVAKzI0EY4vE52x082I5MxkI7II2jI8vz4vEwIxGrwCYIxAIcVC0
	I7IYx2IY67AKxVWUCVW8JwCYIxAIcVC0I7IYx2IY6xkF7I0E14v26r1j6r4UMxvI42IY6I
	8E87Iv67AKxVWxJr0_GcWlcIIF0xvEx4A2jsIEc7CjxVAFwI0_Cr1j6rxdMxAIw28IcxkI
	7VAKI48JMxAIw28IcVAKzI0EY4vE52x082I5MxCjnVCjjxCrMxC20s026xCaFVCjc4AY6r
	1j6r4UMI8I3I0E5I8CrVAFwI0_Jr0_Jr4lx2IqxVCjr7xvwVAFwI0_JrI_JrWlx4CE17CE
	b7AF67AKxVWUtVW8ZwCIc40Y0x0EwIxGrwCI42IY6xAIw20EY4v20xvaj40_Zr0_Wr1UYx
	BIdaVFxhVjvjDU0xZFpf9x07bSCJQUUUUU=

On Fri, Nov 16, 2018 at 5:03 PM <valdis.kletnieks@vt.edu> wrote:
>
> On Fri, 16 Nov 2018 11:44:36 +0530, Pintu Agarwal said:
>
> > > If your question is "Did one
> > > of the CPUs blow out its IRQ stack (or come close to doing so)?" there's better
> > > approaches.
> > >
> > Yes, exactly, this is what the main intention.
> > If you have any better idea about this approach, please refer me.
> > It will be of great help.
>
> Look at the code controlled by '#ifdef CONFIG_DEBUG_STACK_USAGE'
> which does the same thing for process stacks, or CONFIG_SCHED_STACK_END_CHECK
> or the use of guard pages for detecting stack overrun....

Hi,

Thank you so much for your reference.
Yes, I have already gone through the process stack usage, which I
found slightly different.
However, I will go through it in more detail, and see if I can gain
some ideas from there.

I found a similar irq_stack_usage implementation in parisc architecture:
https://git.kernel.org/pub/scm/linux/kernel/git/stable/linux.git/tree/arch/parisc/kernel/irq.c?h=v4.19.1

I have also gone through the unwind_frame() part in arch/arm64/stacktrace.c:
https://git.kernel.org/pub/scm/linux/kernel/git/stable/linux.git/tree/arch/arm64/kernel/stacktrace.c?h=v4.9.137

By referring to these, I tried to make a similar approach for arm64:
I created a new function: dump_irq_stack_info()
[arch/arm64/kernel/traps.c], and called it as part of show_stack().

This is the experimental patch I created.
Note: This is just for my experiment purpose. I know this is ugly and
in very bad shape right now.
It is only to get some idea about irq stack usage.

diff --git a/arch/arm64/kernel/traps.c b/arch/arm64/kernel/traps.c
index 11e5eae..6ac855d 100644
--- a/arch/arm64/kernel/traps.c
+++ b/arch/arm64/kernel/traps.c
@@ -214,9 +214,39 @@ static void dump_backtrace(struct pt_regs *regs,
struct task_struct *tsk)
        }
 }

+void dump_irq_stack_info(void)
+{
+        int cpu, actual;
+        unsigned long irq_stack_ptr;
+        unsigned long stack_start;
+        unsigned long free_stack;
+
+        actual = IRQ_STACK_SIZE;
+        free_stack = 0;
+        pr_info("CPU UNUSED-STACK ACTUAL-STACK\n");
+
+       for_each_present_cpu(cpu) {
+               unsigned long sp;
+               irq_stack_ptr = IRQ_STACK_PTR(cpu);
+               sp = current_stack_pointer;
+               //sp = IRQ_STACK_TO_TASK_STACK(irq_stack_ptr);
+               stack_start = (unsigned long)per_cpu(irq_stack, cpu);
+               if (on_irq_stack(sp, cpu)) {
+                       pr_info("cpu:%d : sp: on irq_stack\n", cpu);
+                       free_stack = sp - stack_start;
+               } else {
+                       free_stack = irq_stack_ptr - stack_start;
+               }
+               pr_info("%2d %10lu %10d\n", cpu, free_stack, actual);
+       }
+}
+
 void show_stack(struct task_struct *tsk, unsigned long *sp)
 {
        dump_backtrace(NULL, tsk);
+       dump_irq_stack_info();
        barrier();
 }

Then, I developed a sample kernel module for timer handler
(timerirq.c) and called the dump_stack() function from inside my timer
interrupt handler.
The dump_stack() will internally call show_stack(), which will then
call our function: dump_irq_stack_info().

/* From interrupt context */
static void my_timer_irq_handler(unsigned long ptr)
{
        int i;
        unsigned long flags;

        if (in_interrupt()) {
                pr_info("[timerirq]: %s: in interrupt context, count: %d\n",
                                        __func__, count);
                spin_lock_irqsave(&mylock, flags);
+               dump_stack();
                spin_unlock_irqrestore(&mylock, flags);
        } else {
                /* This is not needed here*/
        }
        tasklet_schedule(&my_tasklet);
}

OUTPUT:
------------
With this, I got the below output as part of dump_stack() and backtrace:
<snip>
[   43.267923] CPU UNUSED-STACK ACTUAL-STACK
[   43.271925]  0      16368      16384
[   43.275493]  1      16368      16384
[   43.279061]  2      16368      16384
[   43.282628] cpu:3 : sp: on irq_stack
[   43.286195]  3      15616      16384
[   43.289762]  4      16368      16384
[   43.293330]  5      16368      16384
[   43.296898]  6      16368      16384
[   43.300465]  7      16368      16384
<snip>

So, I observed that my interrupt handler was executed by cpu3, and
it's irq_stack usage is shown:
3      15616      16384

With this information, I can know that which interrupt handler is
using how much irq_stack ?

Is this approach valid ?
Or still there is much better way to dump the information ?

For example: is it possible to keep storing the irq_stack_usage (for
each cpu in a variable) information from boot time, and then use this
variable to dump the irq_stack information, after the system booted,
may be from proc entry ?


Thanks,
Pintu
