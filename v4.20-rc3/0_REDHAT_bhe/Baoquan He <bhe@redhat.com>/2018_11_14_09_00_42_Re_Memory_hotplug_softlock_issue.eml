Return-Path: <linux-kernel-owner@vger.kernel.org>
Delivered-To: unknown
Received: from pop3.zju.edu.cn (61.164.42.155:110) by
  likexu-MOBL1.ccr.corp.intel.com with POP3; 14 Nov 2018 14:44:46 -0000
Received: from icoremail.net (unknown [209.85.210.171])
	by mail-app2 (Coremail) with SMTP id by_KCgD3_ydu5Otb0cKOAQ--.43051S3;
	Wed, 14 Nov 2018 17:01:34 +0800 (CST)
Received: from mail-pf1-f171.google.com (unknown [209.85.210.171])
	by mx2.icoremail.net (Coremail) with SMTP id AQAAfwDHrkpq5OtbHaI9AA--.7124S3;
	Wed, 14 Nov 2018 17:01:31 +0800 (CST)
Received: by mail-pf1-f171.google.com with SMTP id 64so3103501pfr.9
        for <xuliker@zju.edu.cn>; Wed, 14 Nov 2018 01:01:31 -0800 (PST)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20161025;
        h=x-original-authentication-results:x-gm-message-state:delivered-to
         :date:from:to:cc:subject:message-id:references:mime-version
         :content-disposition:in-reply-to:user-agent:sender:precedence
         :list-id;
        bh=WUz5n5TSrJ4zNJWvWm/gad30Zion/WmL8yVg42yZaRo=;
        b=XAys/S0ZJu7i+S7cDIJNXW+dqAfWfNq79OOCQP6985PFSiUIJcyyNmefd89ZFMeaRw
         oZgSyhoF9f4F/19NWOwtcA2G530OFBlFShTNfxmXCIp1H3SeZCvHnsKetbOqleibHw7c
         5ieHeN9X1J02+ka64NeEio0KOkXEYHdiD4IEkQq4HsfI+EjldBjArfkIF05cOWdSyo9a
         6fbAC4xp6XlyXAQHgjSOw5VWSbFM55iKwHW3W+w2djtj0D4woXa1VugXZtZspuGIlVRf
         v1QdOSbDF6IzDbRMzQcEh1kCqXVqq7FKiptjVHk3i2OVE7CYtuE97XCKvQgwGxvyzYYx
         vUsQ==
X-Original-Authentication-Results: mx.google.com;       spf=pass (google.com: best guess record for domain of linux-kernel-owner@vger.kernel.org designates 209.132.180.67 as permitted sender) smtp.mailfrom=linux-kernel-owner@vger.kernel.org;       dmarc=fail (p=NONE sp=NONE dis=NONE) header.from=redhat.com
X-Gm-Message-State: AGRZ1gILBb9w/HXPcNobUZG67SR1HKIlpgqDeaRYMqNNgNmwwiqoCaST
	FQCyQpVC0sZSO7JV3Yy2odsRGv9i7r7qIgpNnbcjafFPpQv0wl3hJQ==
X-Received: by 2002:a63:1d10:: with SMTP id d16-v6mr942151pgd.228.1542186090776;
        Wed, 14 Nov 2018 01:01:30 -0800 (PST)
X-Forwarded-To: xuliker@zju.edu.cn
X-Forwarded-For: liker.xu@gmail.com xuliker@zju.edu.cn
Delivered-To: liker.xu@gmail.com
Received: by 2002:a17:90a:c304:0:0:0:0 with SMTP id g4-v6csp5551020pjt;
        Wed, 14 Nov 2018 01:01:29 -0800 (PST)
X-Google-Smtp-Source: AJdET5cFGr1iwtFGxEObcWQcioJZRn9eJgScDvmqy+rQaHlz5BZnO3CDTSf4xIjkYfKfAcU8DK0Y
X-Received: by 2002:a17:902:2849:: with SMTP id e67-v6mr1045332plb.269.1542186089306;
        Wed, 14 Nov 2018 01:01:29 -0800 (PST)
ARC-Seal: i=1; a=rsa-sha256; t=1542186089; cv=none;
        d=google.com; s=arc-20160816;
        b=jwkOxjz65sTwUxtwLfDFmKPTJy551LUUN+b+FUZ18NMxolV0GJjjprZLZh2uYTCJuW
         Yu25ayNBdImgpJLNXsaCJYn7wuQsqIxcn2QrQnTmw8K4RRPXSuOwPZ1BVUZvUc5Hive4
         j/VhINdlzWXByOHKgQ5PQCFOqsW3Hdx06etXh8X2N/g4Z7fN4plyXBETOQJh/V4W3EE8
         Ae7Upj52O9hg9+e0+wNCeFlEKOhB0+58M6ioKM4z6QnDyqnxaN1msfYzKFl89/8zIVQY
         AoL6JwbhP9R356+Gb2l7RJr5EsvimWx8fbHLy9jAaHd0e9o4DW6RWpR4ogJLqKlbG9rN
         oprw==
ARC-Message-Signature: i=1; a=rsa-sha256; c=relaxed/relaxed; d=google.com; s=arc-20160816;
        h=list-id:precedence:sender:user-agent:in-reply-to
         :content-disposition:mime-version:references:message-id:subject:cc
         :to:from:date;
        bh=WUz5n5TSrJ4zNJWvWm/gad30Zion/WmL8yVg42yZaRo=;
        b=sZs436gbiWQ6bATgMY4R3WXlLM4cftXARU7IhKAVynMM1JguZDyWTfvDO4Eo350OGQ
         DBo07FxEoo+nIpfskcDRoCxbPf/Kj1NEAS4BpB9ZWDa6TQJEi5SMRovOF6EeJkAC0Pj0
         uqRxFICaZWe/6N+pZtEZMjsAQJHNjdZjB4nF1auTSEeybhtUeKgTXp/U7WKzMbriY1id
         dep9ya48j2W27fNFfCYOANxN6GowpjO8uNMTPH9pheApwu+jlfrZ4i1FEv2I30xEZO82
         pceTC+mbRbeI10C7dE+lvfEoJJuhPGv3f1HHqYtV4GkH/ojyp+2P0rfcJvTPgDILUvQm
         pmrg==
ARC-Authentication-Results: i=1; mx.google.com;
       spf=pass (google.com: best guess record for domain of linux-kernel-owner@vger.kernel.org designates 209.132.180.67 as permitted sender) smtp.mailfrom=linux-kernel-owner@vger.kernel.org;
       dmarc=fail (p=NONE sp=NONE dis=NONE) header.from=redhat.com
Received: from vger.kernel.org (vger.kernel.org. [209.132.180.67])
        by mx.google.com with ESMTP id z14si23246924pgj.73.2018.11.14.01.01.14;
        Wed, 14 Nov 2018 01:01:29 -0800 (PST)
Received-SPF: pass (google.com: best guess record for domain of linux-kernel-owner@vger.kernel.org designates 209.132.180.67 as permitted sender) client-ip=209.132.180.67;
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
        id S1732469AbeKNTDU (ORCPT <rfc822;zhaoweiliew@gmail.com>
        + 99 others); Wed, 14 Nov 2018 14:03:20 -0500
Received: from mx1.redhat.com ([209.132.183.28]:45276 "EHLO mx1.redhat.com"
        rhost-flags-OK-OK-OK-OK) by vger.kernel.org with ESMTP
        id S1727595AbeKNTDK (ORCPT <rfc822;linux-kernel@vger.kernel.org>);
        Wed, 14 Nov 2018 14:03:10 -0500
Received: from smtp.corp.redhat.com (int-mx02.intmail.prod.int.phx2.redhat.com [10.5.11.12])
        (using TLSv1.2 with cipher AECDH-AES256-SHA (256/256 bits))
        (No client certificate requested)
        by mx1.redhat.com (Postfix) with ESMTPS id C68953078ADC;
        Wed, 14 Nov 2018 09:00:49 +0000 (UTC)
Received: from localhost (ovpn-8-29.pek2.redhat.com [10.72.8.29])
        by smtp.corp.redhat.com (Postfix) with ESMTPS id C4C9760C6D;
        Wed, 14 Nov 2018 09:00:44 +0000 (UTC)
Date: Wed, 14 Nov 2018 17:00:42 +0800
From: Baoquan He <bhe@redhat.com>
To: David Hildenbrand <david@redhat.com>
Cc: linux-mm@kvack.org, linux-kernel@vger.kernel.org, mhocko@suse.com,
        akpm@linux-foundation.org, aarcange@redhat.com
Subject: Re: Memory hotplug softlock issue
Message-ID: <20181114090042.GD2653@MiWiFi-R3L-srv>
References: <20181114070909.GB2653@MiWiFi-R3L-srv>
 <5a6c6d6b-ebcd-8bfa-d6e0-4312bfe86586@redhat.com>
MIME-Version: 1.0
Content-Type: text/plain; charset=us-ascii
Content-Disposition: inline
In-Reply-To: <5a6c6d6b-ebcd-8bfa-d6e0-4312bfe86586@redhat.com>
User-Agent: Mutt/1.9.1 (2017-09-22)
X-Scanned-By: MIMEDefang 2.79 on 10.5.11.12
X-Greylist: Sender IP whitelisted, not delayed by milter-greylist-4.5.16 (mx1.redhat.com [10.5.110.48]); Wed, 14 Nov 2018 09:00:50 +0000 (UTC)
Sender: liker.xu+caf_=xuliker=zju.edu.cn@gmail.com
Precedence: bulk
List-ID: <linux-kernel.vger.kernel.org>
X-Mailing-List: linux-kernel@vger.kernel.org
X-CM-TRANSID: AQAAfwDHrkpq5OtbHaI9AA--.7124S3
Authentication-Results: mail-app2; spf=permerror smtp.mail=liker.xu+ca
	f_=xuliker=zju.edu.cn@gmail.com;
X-Coremail-Antispam: 1UD129KBjvJXoWxZF17urWkWF4UJw1Dtw1DWrg_yoW5Kw47pF
	4fKw48tF48Ka4vyFWxXw1rGFyruan3GF4UJr9ayr9Iya15Xr1avFWYyF1jvr15CryfAw4U
	Za10y34rXr1rAF7anT9S1TB71UUUUUUqnTZGkaVYY2UrUUUU0bIjqfuFe4nvWSU8nxnvy2
	9KBjDU0xBIdaVrnRJUUUPFb7Iv0xC_Kw4lb4IE77IF4wAFF20E14v26r1j6r4UM7CIcVAF
	z4kK6r1j6r18M28lY4IEw2IIxxk0rwA2F7IY1VAKz4vEj48ve4kI8wA2z4x0Y4vE2Ix0cI
	8IcVAFwI0_Ar0_tr1l84ACjcxK6xIIjxv20xvEc7CjxVAFwI0_Cr0_Gr1UM28EF7xvwVC2
	z280aVAFwI0_GcCE3s1l84ACjcxK6I8E87Iv6xkF7I0E14v26rxl6s0DM2AIxVAIcxkEcV
	Aq07x20xvEncxIr21l5I8CrVACY4xI64kE6c02F40Ex7xfMcIj6xIIjxv20xvE14v26r1j
	6r18McIj6I8E87Iv67AKxVW8JVWxJwAm72CE4IkC6x0Yz7v_Jr0_Gr1lF7xvr2IY64vIr4
	1l7I0Y6sxI4wCY1x0264kExVAvwVAq07x20xylc7Ca8VAvwVCFzxkY4VCF77xAMxkIecxE
	wVCI4VW8uwCY0x0Ix7I2Y4AK64vIr41lcIIF0xvE2Ix0cI8IcVAFwI0_Gr0_Xr1lcIIF0x
	vE2Ix0cI8IcVCY1x0267AKxVW8JVWxJwCYIxAIcVC2z280aVAFwI0_Cr1j6rxdMxvI42IY
	6I8E87Iv6xkF7I0E14v26F4UJVW0owCF04k20xvY0x0EwIxGrwCF04k20xvEw4C26cxK6c
	8Ij28IcwCF72vE0xvYzxyl4I8I3I0E4IkC6x0Yz7v_Jr0_Gr1lx2IqxVAqx4xG67AKxVWU
	JVWUGwC20s026x8GjcxK67AKxVWUGVWUWwC2zVAF1VAY17CE14v26r126r1DMIIYrxkI7V
	AKI48JMIIF0xvE42xK8VAvwI8IcIk0rVWUJVWUCbIYCTnIWIevJa73UjIFyTuYvjxUdN6J
	UUUUU

Hi David,

On 11/14/18 at 09:18am, David Hildenbrand wrote:
> Code seems to be waiting for the mem_hotplug_lock in read.
> We hold mem_hotplug_lock in write whenever we online/offline/add/remove
> memory. There are two ways to trigger offlining of memory:
> 
> 1. Offlining via "cat offline > /sys/devices/system/memory/memory0/state"
> 
> This always properly took the mem_hotplug_lock. Nothing changed
> 
> 2. Offlining via "cat 0 > /sys/devices/system/memory/memory0/online"
> 
> This didn't take the mem_hotplug_lock and I fixed that for this release.
> 
> So if you were testing with 1., you should have seen the same error
> before this release (unless there is something else now broken in this
> release).

Thanks a lot for looking into this.

I triggered sysrq+t to check threads' state. You can see that we use
firmware to trigger ACPI event to go to acpi_bus_offline(), it truly
didn't take mem_hotplug_lock() and has taken it with your fix in
commit 381eab4a6ee mm/memory_hotplug: fix online/offline_pages called w.o. mem_hotplug_lock

[  +0.007062] Workqueue: kacpi_hotplug acpi_hotplug_work_fn
[  +0.005398] Call Trace:
[  +0.002476]  ? page_vma_mapped_walk+0x307/0x710
[  +0.004538]  ? page_remove_rmap+0xa2/0x340
[  +0.004104]  ? ptep_clear_flush+0x54/0x60
[  +0.004027]  ? enqueue_entity+0x11c/0x620
[  +0.005904]  ? schedule+0x28/0x80
[  +0.003336]  ? rmap_walk_file+0xf9/0x270
[  +0.003940]  ? try_to_unmap+0x9c/0xf0
[  +0.003695]  ? migrate_pages+0x2b0/0xb90
[  +0.003959]  ? try_offline_node+0x160/0x160
[  +0.004214]  ? __offline_pages+0x6ce/0x8e0
[  +0.004134]  ? memory_subsys_offline+0x40/0x60
[  +0.004474]  ? device_offline+0x81/0xb0
[  +0.003867]  ? acpi_bus_offline+0xdb/0x140
[  +0.004117]  ? acpi_device_hotplug+0x21c/0x460
[  +0.004458]  ? acpi_hotplug_work_fn+0x1a/0x30
[  +0.004372]  ? process_one_work+0x1a1/0x3a0
[  +0.004195]  ? worker_thread+0x30/0x380
[  +0.003851]  ? drain_workqueue+0x120/0x120
[  +0.004117]  ? kthread+0x112/0x130
[  +0.003411]  ? kthread_park+0x80/0x80
[  +0.005325]  ? ret_from_fork+0x35/0x40


> 
> 
> The real question is, however, why offlining of the last block doesn't
> succeed. In __offline_pages() we basically have an endless loop (while
> holding the mem_hotplug_lock in write). Now I consider this piece of
> code very problematic (we should automatically fail after X
> attempts/after X seconds, we should not ignore -ENOMEM), and we've had
> other BUGs whereby we would run into an endless loop here (e.g. related
> to hugepages I guess).

Hmm, even though memory hotplug stalled there, there are still much
memory. E.g in this system, it has 8 nodes and each node has 64 GB
memory, it's 512 GB in all. Now I run "stress -m 200" to trigger 200
processes to malloc then free 256 MB contiously, and it's eating 50 GB
in all. In theory, it still has much memory for migrating to.

> 
> You mentioned memory pressure, if our host is under memory pressure we
> can easily trigger running into an endless loop there, because we
> basically ignore -ENOMEM e.g. when we cannot get a page to migrate some
> memory to be offlined. I assume this is the case here.
> do_migrate_range() could be the bad boy if it keeps failing forever and
> we keep retrying.

Not sure what other people think about this. If failed the memory removing
when still much free memory left, I worry customer will complain.

Yeah, it stoped at do_migrate_range() when try to migrate the last
memory block. And each time it's the last memory block which can't be
offlined and hang.

If any message or information needed, I can provide.

Thanks
Baoquan
