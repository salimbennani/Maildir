Return-Path: <linux-kernel-owner@vger.kernel.org>
Delivered-To: unknown
Received: from pop3.zju.edu.cn (124.160.105.205:110) by
  likexu-MOBL1.ccr.corp.intel.com with POP3; 13 Nov 2018 04:47:29 -0000
Received: from icoremail.net (unknown [209.85.210.182])
	by mail-app2 (Coremail) with SMTP id by_KCgD3_6eoPOpbeUKCAQ--.39273S3;
	Tue, 13 Nov 2018 10:53:29 +0800 (CST)
Received: from mail-pf1-f182.google.com (unknown [209.85.210.182])
	by mx2.icoremail.net (Coremail) with SMTP id AQAAfwCngj6mPOpbT2Q1AA--.4704S3;
	Tue, 13 Nov 2018 10:53:27 +0800 (CST)
Received: by mail-pf1-f182.google.com with SMTP id y18-v6so5276205pfn.1
        for <xuliker@zju.edu.cn>; Mon, 12 Nov 2018 18:53:27 -0800 (PST)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20161025;
        h=x-original-authentication-results:x-gm-message-state:delivered-to
         :subject:to:cc:references:from:message-id:date:user-agent
         :mime-version:in-reply-to:content-language:content-transfer-encoding
         :sender:precedence:list-id;
        bh=MCAlL2++gS4SlvC6PIjo8fFRfmXQuFlUxMq0vayoyHw=;
        b=pcqjrASh/ApQktYyH1xkdeOEjP/nCyTjrt/PEiEqlAP/xOpO03IXM2gnYWlxbpewz1
         sYSrQ2FLAT2WelTn7uPGgng3mzNPYugzUTi0z0QmKCVmF1Ms/4mgy8mQaz3d4tssUOYS
         aEmVBFVuc0tS4KKFfcYAKG3MZE7UQLkJsyCKLetFC5QzoEekH93JpZkCxlXT/bDr5jmC
         sjN613oSq9QAqD2k2qJ23bWN0Fbzkk8olabplLPUBnbaeSqt1p6+RGYQo+1S4W/HYaVS
         Wy15fnoUt8Stz+6lVblCCSH7WiF2vh9LI3N5SG19v1z3+0BmlcWlSOd+5AaTCeu5ty8W
         JbWg==
X-Original-Authentication-Results: mx.google.com;       spf=pass (google.com: best guess record for domain of linux-kernel-owner@vger.kernel.org designates 209.132.180.67 as permitted sender) smtp.mailfrom=linux-kernel-owner@vger.kernel.org
X-Gm-Message-State: AGRZ1gIihNuNmmoMDxOPbULBML9F8YRW3Npyr7fL8wSVhzbCo0CVfWOo
	PfmUev4AQyvc8yENdLwQD91YvFOa1vLVthi5pNCBhcAROiHVIoa7Kg==
X-Received: by 2002:a63:9402:: with SMTP id m2mr3012745pge.93.1542077606673;
        Mon, 12 Nov 2018 18:53:26 -0800 (PST)
X-Forwarded-To: xuliker@zju.edu.cn
X-Forwarded-For: liker.xu@gmail.com xuliker@zju.edu.cn
Delivered-To: liker.xu@gmail.com
Received: by 2002:a17:90a:c304:0:0:0:0 with SMTP id g4-v6csp3950931pjt;
        Mon, 12 Nov 2018 18:53:24 -0800 (PST)
X-Google-Smtp-Source: AJdET5eDTySsf8PW/Crb8cmPotbDtGmTOaZxvLtKyrq9SKEf2IrJ4wGlZ1QHhwVt+poIyv0n2Ezg
X-Received: by 2002:a63:f444:: with SMTP id p4mr3119559pgk.124.1542077604794;
        Mon, 12 Nov 2018 18:53:24 -0800 (PST)
ARC-Seal: i=1; a=rsa-sha256; t=1542077604; cv=none;
        d=google.com; s=arc-20160816;
        b=vLmJXlhZrhmPNbuGfw7xtTcrM+hfwXUmGKCW4a887vI/YSYO8evU4u4sonpm+E2bz/
         yyGwK8ogmnt98Mcx/tv3J1KTCsUDh61fdL8CDcyZbNzLjTOVMyJNwdMtbQktbjds32SS
         H9DW9qNGuHYBBwvHerxhq3VolmwudZdl5qjcYK35cBsC30LLDhQanvOPPTTmjniE+FF7
         e1/yGKL9XOvxonhXbj8neHG7mC/1F/KCjew7jhiHmOZzs7XuUr06EqQXjw62jLEBuVEa
         0S/SfaWcOxeHN6TDS5fqCdiRugy+/UDjojt2ods18fxwEErllNExjdtVl01bZu/6TR1i
         TrGw==
ARC-Message-Signature: i=1; a=rsa-sha256; c=relaxed/relaxed; d=google.com; s=arc-20160816;
        h=list-id:precedence:sender:content-transfer-encoding
         :content-language:in-reply-to:mime-version:user-agent:date
         :message-id:from:references:cc:to:subject;
        bh=MCAlL2++gS4SlvC6PIjo8fFRfmXQuFlUxMq0vayoyHw=;
        b=PbF9ChgfU5RmvIOPfAx4Zoo4x/kp8Y0gf2ohT+Cj36MmRV8nQeYJdPGcYj79Wj0b0I
         yVI6s4vVKuHu1GRUGoBva8BcDhqvjbMgK1RLZtTuUu/Oa0+SYFYO2TWiIhZ9eaEe342G
         rdgvJhk0V3hHwYeaXxQutZsEq7CXE3mpz/LfeUUUIsfEuaxPWijOkN9J8gg3Jv7Nodfm
         DzOqLl/ZZR5CwBr/MOTDPmQOKSrhF5zOAGvhFt7cqmLWcg8PvZf/t2DD3434KD6H51hf
         t9O4LlsXoRSPDIcXMNRHkW/ZgR45ujZPDs7/B9kXAlgY4vw3fIuN99c/sBAuXSviDdT1
         WAAg==
ARC-Authentication-Results: i=1; mx.google.com;
       spf=pass (google.com: best guess record for domain of linux-kernel-owner@vger.kernel.org designates 209.132.180.67 as permitted sender) smtp.mailfrom=linux-kernel-owner@vger.kernel.org
Received: from vger.kernel.org (vger.kernel.org. [209.132.180.67])
        by mx.google.com with ESMTP id d82-v6si21035615pfe.190.2018.11.12.18.53.09;
        Mon, 12 Nov 2018 18:53:24 -0800 (PST)
Received-SPF: pass (google.com: best guess record for domain of linux-kernel-owner@vger.kernel.org designates 209.132.180.67 as permitted sender) client-ip=209.132.180.67;
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
        id S1730527AbeKMMtE (ORCPT <rfc822;jbenoit100@gmail.com>
        + 99 others); Tue, 13 Nov 2018 07:49:04 -0500
Received: from foss.arm.com ([217.140.101.70]:46318 "EHLO foss.arm.com"
        rhost-flags-OK-OK-OK-OK) by vger.kernel.org with ESMTP
        id S1726341AbeKMMtE (ORCPT <rfc822;linux-kernel@vger.kernel.org>);
        Tue, 13 Nov 2018 07:49:04 -0500
Received: from usa-sjc-imap-foss1.foss.arm.com (unknown [10.72.51.249])
        by usa-sjc-mx-foss1.foss.arm.com (Postfix) with ESMTP id C98D5A78;
        Mon, 12 Nov 2018 18:53:02 -0800 (PST)
Received: from [192.168.33.175] (usa-sjc-mx-foss1.foss.arm.com [217.140.101.70])
        by usa-sjc-imap-foss1.foss.arm.com (Postfix) with ESMTPSA id 46D9B3F5CF;
        Mon, 12 Nov 2018 18:53:02 -0800 (PST)
Subject: Re: [PATCH v6 2/2] sched/fair: update scale invariance of PELT
To: Vincent Guittot <vincent.guittot@linaro.org>, peterz@infradead.org,
        mingo@kernel.org, linux-kernel@vger.kernel.org
Cc: rjw@rjwysocki.net, Morten.Rasmussen@arm.com,
        patrick.bellasi@arm.com, pjt@google.com, bsegall@google.com,
        thara.gopinath@linaro.org, pkondeti@codeaurora.org,
        quentin.perret@arm.com
References: <1541780454-9934-1-git-send-email-vincent.guittot@linaro.org>
 <1541780454-9934-3-git-send-email-vincent.guittot@linaro.org>
From: Dietmar Eggemann <dietmar.eggemann@arm.com>
Message-ID: <f7725461-bb0e-27fd-04cc-a225c97a9940@arm.com>
Date: Mon, 12 Nov 2018 18:53:01 -0800
User-Agent: Mozilla/5.0 (X11; Linux x86_64; rv:60.0) Gecko/20100101
 Thunderbird/60.2.1
MIME-Version: 1.0
In-Reply-To: <1541780454-9934-3-git-send-email-vincent.guittot@linaro.org>
Content-Type: text/plain; charset=utf-8; format=flowed
Content-Language: en-GB
Content-Transfer-Encoding: 7bit
Sender: liker.xu+caf_=xuliker=zju.edu.cn@gmail.com
Precedence: bulk
List-ID: <linux-kernel.vger.kernel.org>
X-Mailing-List: linux-kernel@vger.kernel.org
X-CM-TRANSID: AQAAfwCngj6mPOpbT2Q1AA--.4704S3
Authentication-Results: mail-app2; spf=pass smtp.mail=liker.xu+caf_=xu
	liker=zju.edu.cn@gmail.com;
X-Coremail-Antispam: 1UD129KBjvJXoW3Xw1kKFy8tr1ktF4rWrWfZrb_yoW7ArWfp3
	yfX3W3G3Z3tr1Skwn2vF4kZwn5uwn5AF15JF1rA34xJr9xCw4vkF93Ja95ZFy8u397AasI
	qFWjgr9xWFyq9rDanT9S1TB71UUUUUUqnTZGkaVYY2UrUUUU0bIjqfuFe4nvWSU8nxnvy2
	9KBjDU0xBIdaVrnRJUUUmqb7Iv0xC_Kw4lb4IE77IF4wAFF20E14v26r1j6r4UM7CIcVAF
	z4kK6r1j6r18M28lY4IEw2IIxxk0rwA2F7IY1VAKz4vEj48ve4kI8wA2z4x0Y4vE2Ix0cI
	8IcVAFwI0_Xr0_Ar1l84ACjcxK6xIIjxv20xvEc7CjxVAFwI0_Gr0_Cr1l84ACjcxK6I8E
	87Iv67AKxVW0oVCq3wA2z4x0Y4vEx4A2jsIEc7CjxVAFwI0_GcCE3s1le2I262IYc4CY6c
	8Ij28IcVAaY2xG8wAqx4xG64xvF2IEw4CE5I8CrVC2j2WlYx0E2Ix0cI8IcVAFwI0_JrI_
	JrylYx0Ex4A2jsIE14v26r4j6F4UMcvjeVCFs4IE7xkEbVWUJVW8JwACjcxG0xvEwIxGrw
	CjxxvEa2IrMxk0xIA0c2IEe2xFo4CEbIxvr21lc7CjxVAKzI0EY4vE52x082I5MxkFs20E
	Y4vE44CYbxCE4x80FwCY02Avz4vEIxC_Gr1lc2IjII80xcxEwVAKI48JMxvI42IY6xIIjx
	v20xvE14v26r1I6r4UMxvI42IY6xIIjxv20xvEc7CjxVAFwI0_Jr0_Gr1lcIIF0xvEx4A2
	jsIE14v26r4UJVWxJr1lcIIF0xvEx4A2jsIEc7CjxVAFwI0_Gr1j6F4UJwCF04k20xvY0x
	0EwIxGrwCF04k20xvEw4C26cxK6c8Ij28IcwCF72vE77IF4wCFx2IqxVCFs4IE7xkEbVWU
	JVW8JwC20s026c02F40E14v26r1j6r18MI8I3I0E7480Y4vE14v26r106r1rMI8E67AF67
	kF1VAFwI0_Jw0_GFylIxkGc2Ij64vIr41lIxAIcVCF04k26cxKx2IYs7xG6Fyj6rWUJbIY
	CTnIWIevJa73UjIFyTuYvjxUHVMNUUUUU

On 11/9/18 8:20 AM, Vincent Guittot wrote:

[...]

> In order to achieve this time scaling, a new clock_pelt is created per rq.
> The increase of this clock scales with current capacity when something
> is running on rq and synchronizes with clock_task when rq is idle. With
> this mecanism, we ensure the same running and idle time whatever the

nitpick: s/mecanism/mechanism

[...]

> The responsivness of PELT is improved when CPU is not running at max

nitpick: s/responsivness/responsiveness

> capacity with this new algorithm. I have put below some examples of
> duration to reach some typical load values according to the capacity of the
> CPU with current implementation and with this patch. These values has been
> computed based on the geometric serie and the half period value:

nitpick: s/serie/series

[...]

> +/*
> + * The clock_pelt scales the time to reflect the effective amount of
> + * computation done during the running delta time but then sync back to
> + * clock_task when rq is idle.
> + *
> + *
> + * absolute time   | 1| 2| 3| 4| 5| 6| 7| 8| 9|10|11|12|13|14|15|16
> + * @ max capacity  ------******---------------******---------------
> + * @ half capacity ------************---------************---------
> + * clock pelt      | 1| 2|    3|    4| 7| 8| 9|   10|   11|14|15|16
> + *
> + */
> +static inline void update_rq_clock_pelt(struct rq *rq, s64 delta)
> +{
> +	if (unlikely(is_idle_task(rq->curr))) {
> +		/* The rq is idle, we can sync to clock_task */
> +		rq->clock_pelt  = rq_clock_task(rq);
> +		return;

I think the term (time) stretching was used to to describe what's 
happening to the clock_pelt values at lower capacity and to this re-sync 
with the clock task. But IMHO, one has to be called stretching and the 
other compressing so it makes sense. I think it's a question of definition.

> +	}
> +
> +	/*
> +	 * When a rq runs at a lower compute capacity, it will need
> +	 * more time to do the same amount of work than at max
> +	 * capacity: either because it takes more time to compute the
> +	 * same amount of work or because taking more time means
> +	 * sharing more often the CPU between entities.

I wonder if since clock_pelt is related to the sched_avg(s) of the rq 
isn't the only reason the first one "It takes more time to do the same 
amount of work"? IMHO, the sharing of sched entities shouldn't be 
visible here.

> +	 * In order to be invariant, we scale the delta to reflect how
> +	 * much work has been really done.
> +	 * Running at lower capacity also means running longer to do
> +	 * the same amount of work and this results in stealing some

This is already mentioned above.

> +	 * idle time that will disturb the load signal compared to
> +	 * max capacity; This stolen idle time will be automaticcally

nitpick: s/automaticcally/automatically

> +	 * reflected when the rq will be idle and the clock will be
> +	 * synced with rq_clock_task.
> +	 */
> +
> +	/*
> +	 * scale the elapsed time to reflect the real amount of
> +	 * computation
> +	 */
> +	delta = cap_scale(delta, arch_scale_cpu_capacity(NULL, cpu_of(rq)));
> +	delta = cap_scale(delta, arch_scale_freq_capacity(cpu_of(rq)));
> +
> +	rq->clock_pelt += delta;
> +}
> +
> +/*
> + * When rq becomes idle, we have to check if it has lost some idle time
> + * because it was fully busy. A rq is fully used when the /Sum util_sum
> + * is greater or equal to:
> + * (LOAD_AVG_MAX - 1024 + rq->cfs.avg.period_contrib) << SCHED_CAPACITY_SHIFT;
> + * For optimization and computing rounding purpose, we don't take into account
> + * the position in the current window (period_contrib) and we use the maximum
> + * util_avg value minus 1
> + */

In v4 you were using:

u32 divider = (LOAD_AVG_MAX - 1024 + rq->cfs.avg.period_contrib) << 
SCHED_CAPACITY_SHIFT;

and switched in v5 to:

u32 divider = ((LOAD_AVG_MAX - 1024) << SCHED_CAPACITY_SHIFT) - 
LOAD_AVG_MAX;

The period_contrib of rq->cfs.avg, rq->avg_rt and rq->avg_dl are not 
necessarily aligned but for overload you sum up the util_sum values for 
cfs, rt and dl. Was this also a reason why you now assume max util_avg - 
1 ?

> +static inline void update_idle_rq_clock_pelt(struct rq *rq)
> +{
> +	u32 divider = ((LOAD_AVG_MAX - 1024) << SCHED_CAPACITY_SHIFT) - LOAD_AVG_MAX;

util_avg = util_sum / divider   ,maximum util_avg = 1024

1024 = util_sum / (LOAD_AVG_MAX - 1024)   w/ period_contrib = 0

util_sum >= (LOAD_AVG_MAX - 1024) * 1024

util_sum >= (LOAD_AVG_MAX - 1024) << SCHED_CAPACITY_SHIFT;

So you want to use 1024 - 1 = 1023 instead. Wouldn't you have to 
subtract (LOAD_AVG_MAX - 1024) from (LOAD_AVG_MAX - 1024) << 
SCHED_CAPACITY_SHIFT in this case?

util_sum >= (LOAD_AVG_MAX - 1024) << SCHED_CAPACITY_SHIFT - 
(LOAD_AVG_MAX - 1024)

> +	u32 overload = rq->cfs.avg.util_sum;
> +	overload += rq->avg_rt.util_sum;
> +	overload += rq->avg_dl.util_sum;
> +
> +	/*
> +	 * Reflecting some stolen time makes sense only if the idle
> +	 * phase would be present at max capacity. As soon as the
> +	 * utilization of a rq has reached the maximum value, it is
> +	 * considered as an always runnnig rq without idle time to

nitpick: s/runnnig/runnig

> +	 * steal. This potential idle time is considered as lost in
> +	 * this case. We keep track of this lost idle time compare to
> +	 * rq's clock_task.
> +	 */
> +	if ((overload >= divider))
> +		rq->lost_idle_time += rq_clock_task(rq) - rq->clock_pelt;

Shouldn't overload still be called util_sum? Overload (or overutilized 
is IMHO the state when util_sum >= divider.

[...]
