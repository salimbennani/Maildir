Return-Path: <linux-kernel-owner@vger.kernel.org>
Delivered-To: unknown
Received: from pop3.zju.edu.cn (61.164.42.155:110) by
  likexu-MOBL1.ccr.corp.intel.com with POP3; 17 Nov 2018 03:16:18 -0000
Received: from icoremail.net (unknown [209.85.214.176])
	by mail-app2 (Coremail) with SMTP id by_KCgDHH3pTgu9bSA2nAQ--.49453S3;
	Sat, 17 Nov 2018 10:52:14 +0800 (CST)
Received: from mail-pl1-f176.google.com (unknown [209.85.214.176])
	by mx2.icoremail.net (Coremail) with SMTP id AQAAfwB3X0tSgu9bEgJMAA--.4309S3;
	Sat, 17 Nov 2018 10:52:02 +0800 (CST)
Received: by mail-pl1-f176.google.com with SMTP id b22-v6so6536998pls.7
        for <xuliker@zju.edu.cn>; Fri, 16 Nov 2018 18:52:02 -0800 (PST)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20161025;
        h=x-gm-message-state:delivered-to:dkim-signature:date:from:to:cc
         :subject:message-id:reply-to:references:mime-version
         :content-disposition:in-reply-to:user-agent:sender:precedence
         :list-id;
        bh=5TLIYNEVARxGwK/XJnA4BtoZJzochE2UFBxQ2gakYF0=;
        b=RMa09C1RSSY5b3cz2Fod42TwSavzNpSf5A8wVIX8TRNF8L3uLrzNmWpbCnsaxX/wtz
         m5OZ+VLLO6Z1f5svw/ohioDSmJjJGQ355RATt0rrRWtQSCBrPmO2pTFepdnENXn6bXhM
         3dKumiQdrMLzosRfEeJDvOHyANuznNkeCNdxXd8MfmLv0hOyfCZFWtAlEpXGXBy0RCDA
         vTde4P45uhADD5laLSiIm7OKrRWYOo8Cqc2JHsfqWLewIOTHiytEG8kE04SIVLN/6Etk
         p2iaCbTJnjxTSOph+7W9Fpk88aPcdoAZVC1m5vGgIwk/f9m0Kz7s47xVBZVtMiD4dRk7
         rekA==
X-Gm-Message-State: AGRZ1gLVfzWgNwqbfH0VorOtx041LKGO+oY4q4ngHwdPfxtF8vKwvst7
	4bCvH9E6OlKb/90D04b/ZpyycdqvZqKS0jNpgjKKH1VVXpONKDQ=
X-Received: by 2002:a17:902:6686:: with SMTP id e6-v6mr13268278plk.173.1542423121894;
        Fri, 16 Nov 2018 18:52:01 -0800 (PST)
X-Forwarded-To: xuliker@zju.edu.cn
X-Forwarded-For: liker.xu@gmail.com xuliker@zju.edu.cn
Delivered-To: liker.xu@gmail.com
Received: by 2002:a17:90a:d106:0:0:0:0 with SMTP id l6-v6csp80020pju;
        Fri, 16 Nov 2018 18:52:00 -0800 (PST)
X-Google-Smtp-Source: AJdET5dc9ElWSZ60NMpYHArSkH00nrW2ZBQLBMkNtJw+3lTAGOzFt4+3zJqO2HLqdrclKSATX0Z/
X-Received: by 2002:a17:902:1105:: with SMTP id d5-v6mr13849193pla.28.1542423120921;
        Fri, 16 Nov 2018 18:52:00 -0800 (PST)
ARC-Seal: i=1; a=rsa-sha256; t=1542423120; cv=none;
        d=google.com; s=arc-20160816;
        b=OjxaUQK70+lnIgAC10Yc/ETw4ZfRR8sEyKCMFEVdz+8Xm029h2iHdnO3rICj87PsPU
         Be60lhltPoIdtOMI0Pv9H9u7wLlHsga3KE7hrqkltAoFa70jBPfA9kaBsfZwKfJTcQve
         voMzfSiZryZnT4XxNOL8SpOZwMvD/SgKjqzJCplBaYzmSa/tJzkwugFnkU/eOrXVU7ZJ
         XOgaGVOxR1bTTuuSPj9CIKd8rHYEu6X4y4EoQbSAMK3KJR0l+1JyZW7W9qmGgeBfItAs
         qSAt3pa3OGSPOXD2l8DnAsK6l61ksnx0YtFNFHhWTUok0LqZO5WOzhTFdyoFHRDHk3VR
         JUsw==
ARC-Message-Signature: i=1; a=rsa-sha256; c=relaxed/relaxed; d=google.com; s=arc-20160816;
        h=list-id:precedence:sender:user-agent:in-reply-to
         :content-disposition:mime-version:references:reply-to:message-id
         :subject:cc:to:from:date:dkim-signature;
        bh=5TLIYNEVARxGwK/XJnA4BtoZJzochE2UFBxQ2gakYF0=;
        b=PagHpjgY9s1ELIQyc/ZyZcAW6ZRJLHf97h8lKYJ5tNA185wOGcwIBv+5yXUyts1+Vg
         BvSIS4ISY2Bm77LyP3/UpoLsgxNt6A+RMlZ3MCeakMMFURPPTkwvQAhDUSx7wxwYeUf3
         7Qr6rCPbxXXB0GQb0jJ9N+3Dex1DWp30P4N6Mq4IzBtto28VxLlLqEMbHnOYeRsg4GUH
         VX5+FjzZ0hVxDr8otgfimMJQtAj46EnbnUg8wHSqDR743KQemvFNAX+6ZCDIlVDyg6JT
         tHrwbEKkInlf7NY7f/utbB5lCR6VqukbPwt8cwVc1r0P2Cy7lJaGYh2M6qaEXrJRq4ex
         yYaw==
ARC-Authentication-Results: i=1; mx.google.com;
       dkim=pass header.i=@gmail.com header.s=20161025 header.b=OyEA0jnG;
       spf=pass (google.com: best guess record for domain of linux-kernel-owner@vger.kernel.org designates 209.132.180.67 as permitted sender) smtp.mailfrom=linux-kernel-owner@vger.kernel.org;
       dmarc=pass (p=NONE sp=QUARANTINE dis=NONE) header.from=gmail.com
Received: from vger.kernel.org (vger.kernel.org. [209.132.180.67])
        by mx.google.com with ESMTP id e1-v6si34577340plk.4.2018.11.16.18.51.45;
        Fri, 16 Nov 2018 18:52:00 -0800 (PST)
Received-SPF: pass (google.com: best guess record for domain of linux-kernel-owner@vger.kernel.org designates 209.132.180.67 as permitted sender) client-ip=209.132.180.67;
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
        id S1730007AbeKQNGi (ORCPT <rfc822;xjxyklwx@gmail.com> + 99 others);
        Sat, 17 Nov 2018 08:06:38 -0500
Received: from mail-ed1-f68.google.com ([209.85.208.68]:32917 "EHLO
        mail-ed1-f68.google.com" rhost-flags-OK-OK-OK-OK) by vger.kernel.org
        with ESMTP id S1729793AbeKQNGh (ORCPT
        <rfc822;linux-kernel@vger.kernel.org>);
        Sat, 17 Nov 2018 08:06:37 -0500
Received: by mail-ed1-f68.google.com with SMTP id r27so18208525eda.0
        for <linux-kernel@vger.kernel.org>; Fri, 16 Nov 2018 18:51:35 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20161025;
        h=date:from:to:cc:subject:message-id:reply-to:references:mime-version
         :content-disposition:in-reply-to:user-agent;
        bh=5TLIYNEVARxGwK/XJnA4BtoZJzochE2UFBxQ2gakYF0=;
        b=OyEA0jnGEcKUVNK2PM7cSXVTRRQtMZJQx17O2OOEZ2WuX1rKb4eoUvNIkokLysrc49
         iC3N1mJyxT1kddRPiw0GVD8d6fC1bGHDZQn02Y8lHav02s4Mv6oILyUI93dS6/Qpz9Ve
         Qe/Bnv3pa9hVJgYPe4i03+g5tPEd1Lt8wnRqxOyln0CTSDuQvmUWGpW9zBWgX2SZFywo
         9Jr8WvDTlRBEf8G2GBjOnrhiyTs9lQyVE94Ko0T9wnLksa6JnColnZU9uKhUyI2ip2kt
         FmFZx10T8eFkEYJwtf11crVFQpa1CLqKBA7zWphIEd/OG1meGUpikjqdVkLeQVCiuOWr
         sRSw==
X-Received: by 2002:aa7:ca0d:: with SMTP id y13mr11563537eds.285.1542423094323;
        Fri, 16 Nov 2018 18:51:34 -0800 (PST)
Received: from localhost ([185.92.221.13])
        by smtp.gmail.com with ESMTPSA id gp22-v6sm5222265ejb.4.2018.11.16.18.51.33
        (version=TLS1_2 cipher=ECDHE-RSA-CHACHA20-POLY1305 bits=256/256);
        Fri, 16 Nov 2018 18:51:33 -0800 (PST)
Date: Sat, 17 Nov 2018 02:51:33 +0000
From: Wei Yang <richard.weiyang@gmail.com>
To: Wengang Wang <wen.gang.wang@oracle.com>
Cc: cl@linux.com, penberg@kernel.org, rientjes@google.com,
        iamjoonsoo.kim@lge.com, akpm@linux-foundation.org,
        linux-mm@kvack.org, linux-kernel@vger.kernel.org
Subject: Re: [PATCH] mm: use this_cpu_cmpxchg_double in put_cpu_partial
Message-ID: <20181117025133.czjubpjqm4b6kqin@master>
Reply-To: Wei Yang <richard.weiyang@gmail.com>
References: <20181117013335.32220-1-wen.gang.wang@oracle.com>
MIME-Version: 1.0
Content-Type: text/plain; charset=us-ascii
Content-Disposition: inline
In-Reply-To: <20181117013335.32220-1-wen.gang.wang@oracle.com>
User-Agent: NeoMutt/20170113 (1.7.2)
Sender: liker.xu+caf_=xuliker=zju.edu.cn@gmail.com
Precedence: bulk
List-ID: <linux-kernel.vger.kernel.org>
X-Mailing-List: linux-kernel@vger.kernel.org
X-CM-TRANSID: AQAAfwB3X0tSgu9bEgJMAA--.4309S3
Authentication-Results: mail-app2; spf=pass smtp.mail=liker.xu+caf_=xu
	liker=zju.edu.cn@gmail.com;
X-Coremail-Antispam: 1UD129KBjvJXoWxWw43Wr4xXw1rAryUur15urg_yoWrWr17pF
	WfG3W3GFWkCryIkwsxGFWvk34Fq34fZFW7Aa4aqw15urn8Xr10qFyxAryqvFy5ur1xur1I
	yr4qv3WSgFWjyaUanT9S1TB71UUUUUUqnTZGkaVYY2UrUUUUjbIjqfuFe4nvWSU8nxnvy2
	9KBjDU0xBIdaVrnRJUUUBFb7Iv0xC_tr1lb4IE77IF4wAFF20E14v26r1j6r4UM7CIcVAF
	z4kK6r1j6r18M28lY4IEw2IIxxk0rwA2F7IY1VAKz4vEj48ve4kI8wA2z4x0Y4vE2Ix0cI
	8IcVAFwI0_Ar0_tr1l84ACjcxK6xIIjxv20xvEc7CjxVAFwI0_Gr0_Cr1l84ACjcxK6I8E
	87Iv67AKxVW0oVCq3wA2z4x0Y4vEx4A2jsIEc7CjxVAFwI0_GcCE3s1le2I262IYc4CY6c
	8Ij28IcVAaY2xG8wAqx4xG64xvF2IEw4CE5I8CrVC2j2WlYx0E2Ix0cI8IcVAFwI0_Jr0_
	Jr4lYx0Ex4A2jsIE14v26r4j6F4UMcvjeVCFs4IE7xkEbVWUJVW8JwACjcxG0xvEwIxGrw
	CjxxvEa2IrMxkF7I0Ew4C26cxK6c8Ij28IcwCY02Avz4vEIxC_Gr1lc2IjII80xcxEwVAK
	I48JMxvI42IY6xIIjxv20xvE14v26r4j6ryUMxvI42IY6xIIjxv20xvEc7CjxVAFwI0_Gr
	0_Cr1lcIIF0xvEx4A2jsIE14v26r4UJVWxJr1lcIIF0xvEx4A2jsIEc7CjxVAFwI0_Gr1j
	6F4UJwCF04k20xvY0x0EwIxGrwCF04k20xvEw4C26cxK6c8Ij28IcwCF72vE77IF4wCFx2
	IqxVCFs4IE7xkEbVWUJVW8JwC20s026c02F40E14v26r1j6r18MI8I3I0E7480Y4vE14v2
	6r106r1rMI8E67AF67kF1VAFwI0_Jw0_GFylIxkGc2Ij64vIr41lIxAIcVCF04k26cxKx2
	IYs7xG6rWUJVWrZr1UYxBIdaVFxhVjvjDU0xZFpf9x07b03kZUUUUU=

On Fri, Nov 16, 2018 at 05:33:35PM -0800, Wengang Wang wrote:
>The this_cpu_cmpxchg makes the do-while loop pass as long as the
>s->cpu_slab->partial as the same value. It doesn't care what happened to
>that slab. Interrupt is not disabled, and new alloc/free can happen in the
>interrupt handlers. Theoretically, after we have a reference to the it,
>stored in _oldpage_, the first slab on the partial list on this CPU can be
>moved to kmem_cache_node and then moved to different kmem_cache_cpu and
>then somehow can be added back as head to partial list of current
>kmem_cache_cpu, though that is a very rare case. If that rare case really

I didn't fully catch up with this case.

When put_cpu_partial() is called, this means we are trying to freeze an
frozen page and this pages is fully occupied. Since page->freelist is
NULL.

A full page is supposed to be on no where when has_cpu_partial() is
true.

So I don't understand when it will be moved to different kmem_cache_cpu.

>happened, the reading of oldpage->pobjects may get a 0xdead0000
>unexpectedly, stored in _pobjects_, if the reading happens just after
>another CPU removed the slab from kmem_cache_node, setting lru.prev to
>LIST_POISON2 (0xdead000000000200). The wrong _pobjects_(negative) then
>prevents slabs from being moved to kmem_cache_node and being finally freed.

Looks this page is removed from some list. This happens in which case? I
mean the page is previouly on which list?

>
>We see in a vmcore, there are 375210 slabs kept in the partial list of one
>kmem_cache_cpu, but only 305 in-use objects in the same list for
>kmalloc-2048 cache. We see negative values for page.pobjects, the last page
>with negative _pobjects_ has the value of 0xdead0004, the next page looks
>good (_pobjects is 1).
>
>For the fix, I wanted to call this_cpu_cmpxchg_double with
>oldpage->pobjects, but failed due to size difference between
>oldpage->pobjects and cpu_slab->partial. So I changed to call
>this_cpu_cmpxchg_double with _tid_. I don't really want no alloc/free
>happen in between, but just want to make sure the first slab did expereince
>a remove and re-add. This patch is more to call for ideas.
>
>Signed-off-by: Wengang Wang <wen.gang.wang@oracle.com>
>---
> mm/slub.c | 20 +++++++++++++++++---
> 1 file changed, 17 insertions(+), 3 deletions(-)
>
>diff --git a/mm/slub.c b/mm/slub.c
>index e3629cd..26539e6 100644
>--- a/mm/slub.c
>+++ b/mm/slub.c
>@@ -2248,6 +2248,7 @@ static void put_cpu_partial(struct kmem_cache *s, struct page *page, int drain)
> {
> #ifdef CONFIG_SLUB_CPU_PARTIAL
> 	struct page *oldpage;
>+	unsigned long tid;
> 	int pages;
> 	int pobjects;
> 
>@@ -2255,8 +2256,12 @@ static void put_cpu_partial(struct kmem_cache *s, struct page *page, int drain)
> 	do {
> 		pages = 0;
> 		pobjects = 0;
>-		oldpage = this_cpu_read(s->cpu_slab->partial);
> 
>+		tid = this_cpu_read(s->cpu_slab->tid);
>+		/* read tid before reading oldpage */
>+		barrier();
>+
>+		oldpage = this_cpu_read(s->cpu_slab->partial);
> 		if (oldpage) {
> 			pobjects = oldpage->pobjects;
> 			pages = oldpage->pages;
>@@ -2283,8 +2288,17 @@ static void put_cpu_partial(struct kmem_cache *s, struct page *page, int drain)
> 		page->pobjects = pobjects;
> 		page->next = oldpage;
> 
>-	} while (this_cpu_cmpxchg(s->cpu_slab->partial, oldpage, page)
>-								!= oldpage);
>+		/* we dont' change tid, but want to make sure it didn't change
>+		 * in between. We don't really hope alloc/free not happen on
>+		 * this CPU, but don't want the first slab be removed from and
>+		 * then re-added as head to this partial list. If that case
>+		 * happened, pobjects may read 0xdead0000 when this slab is just
>+		 * removed from kmem_cache_node by other CPU setting lru.prev
>+		 * to LIST_POISON2.
>+		 */
>+	} while (this_cpu_cmpxchg_double(s->cpu_slab->partial, s->cpu_slab->tid,
>+					 oldpage, tid, page, tid) == 0);
>+
> 	if (unlikely(!s->cpu_partial)) {
> 		unsigned long flags;
> 
>-- 
>2.9.5

-- 
Wei Yang
Help you, Help me
