Return-Path: <linux-kernel-owner@vger.kernel.org>
Delivered-To: unknown
Received: from pop3.zju.edu.cn (124.160.105.205:110) by
  likexu-MOBL1.ccr.corp.intel.com with POP3; 15 Nov 2018 00:44:10 -0000
Received: from icoremail.net (unknown [209.85.210.171])
	by mail-app2 (Coremail) with SMTP id by_KCgD3_6c8tuxbVRKUAQ--.44497S3;
	Thu, 15 Nov 2018 07:56:45 +0800 (CST)
Received: from mail-pf1-f171.google.com (unknown [209.85.210.171])
	by mx2.icoremail.net (Coremail) with SMTP id AQAAfwDHqEQ6tuxbLr9AAA--.3030S3;
	Thu, 15 Nov 2018 07:56:42 +0800 (CST)
Received: by mail-pf1-f171.google.com with SMTP id u3-v6so6035165pfm.4
        for <xuliker@zju.edu.cn>; Wed, 14 Nov 2018 15:56:42 -0800 (PST)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20161025;
        h=x-gm-message-state:delivered-to:dkim-signature:mime-version
         :references:in-reply-to:from:date:message-id:subject:to:cc:sender
         :precedence:list-id;
        bh=ZmLmN3dt/zfxfkpEIFGDIdCpD+4zRk/tFFa9swpMP8U=;
        b=khinVCOxZow9KH5b/p5QNZM4a5Jp3lQXCz86RB4VYcbHx395O4UZoOnPGj6KYrMaLL
         PQLhdWavc+8YXsxGciYRBKw2IzcRMe8uVNf+RuvQMaNi5tILHaWVt7jHr2bZbPzCmM9Y
         Ho3dUjc22nMKIAvUTY5u3jH7/CfkUR2O7+2Nakov6AIXQ/T/oRFQGEwsJFt9Bu9/TIQI
         e9umMXhPyQAb28TMAJXLovkAU+mmopkI6t9niAWImitfzGlx9nKGWFs37xwiONHHshQe
         88W3JW06KCwOH6PAp7x2Lv1xeIr2abh7mUVM/kQh/pKIXZuiypA6wMvPPbMwwL7sx97n
         gnrg==
X-Gm-Message-State: AGRZ1gI4CLiAqFTOiq74IFJitCPI8xgT94lYShxT7mhWbjYDwgVM4lmN
	kK+iNtF9h2Zd0k0vg1VdeYMXObyyixPDNibN9dvBvKxqMdoA/Gf5LA==
X-Received: by 2002:a62:3687:: with SMTP id d129-v6mr4099102pfa.56.1542239801825;
        Wed, 14 Nov 2018 15:56:41 -0800 (PST)
X-Forwarded-To: xuliker@zju.edu.cn
X-Forwarded-For: liker.xu@gmail.com xuliker@zju.edu.cn
Delivered-To: liker.xu@gmail.com
Received: by 2002:a17:90a:c304:0:0:0:0 with SMTP id g4-v6csp6468442pjt;
        Wed, 14 Nov 2018 15:56:40 -0800 (PST)
X-Google-Smtp-Source: AJdET5eEpQRM455sGssmLcJNCkdOg3XnGEBCccWCAySw2Hzph47u0qsdH31sUpaI5SpNGPQ2m1gD
X-Received: by 2002:a63:f901:: with SMTP id h1mr3705290pgi.154.1542239800856;
        Wed, 14 Nov 2018 15:56:40 -0800 (PST)
ARC-Seal: i=1; a=rsa-sha256; t=1542239800; cv=none;
        d=google.com; s=arc-20160816;
        b=YOJPM7Vyqj2rt1JJGxdlWzh9gvbMfaPgNJxcQaoCMf0sHoF9aIbWSJD9nZueIwC6qx
         Iupy4joWMlvH952Xli/gFN6objW6XorKylChQJuXR4Z0e0eobrASTOgamH7s9Goiounw
         tKNJTkiGtzC8+ReX6HYkLa6R3aRTgBtDmnDE3XWxbcfi+51nWmcYZN6D9ummwya4JMRC
         PeT3wqEvoyPod+S3233Dvt0MNk4ngIrpuDUffNOpOvI49Ko7w8hC60PZOGtZLMMCCyGl
         giaJy9n+ictc+CRVHRlGL7aXM5kuONajaheDNIFVfdk1+axqvViEIdoOxVDhPlrizgiT
         Aw6w==
ARC-Message-Signature: i=1; a=rsa-sha256; c=relaxed/relaxed; d=google.com; s=arc-20160816;
        h=list-id:precedence:sender:cc:to:subject:message-id:date:from
         :in-reply-to:references:mime-version:dkim-signature;
        bh=ZmLmN3dt/zfxfkpEIFGDIdCpD+4zRk/tFFa9swpMP8U=;
        b=jNJ8wO999XMhroiFWHQmrTdnzalylvcvzfsM27tczCxQCarZFhGiJODw5LGU/whrU+
         PIx1JQxtg8vNb+fbP4Y4uTN/FTNrrgBEkpRq80NlorExOr+LklHppF25Nz3xWQ14Vryq
         FcLK77UzDQ40JKhGijM/cSgCGRPAQNeUsC+hfjGg68k3edKT9tqk8NmilGe7BWjrfVjh
         n6W3H4o8zo/t3vSX9X0m+p60qCM+2evxO7dhsUcZTzHoXiyf3hxiucSrEJGTfhCSoWov
         hpftyvzygz7INy3k2nZ6wgcB+BBWziczlqDFnJwtfRn7hIwN7yXY/QZofbleK4GShF47
         8Skw==
ARC-Authentication-Results: i=1; mx.google.com;
       dkim=pass header.i=@linaro.org header.s=google header.b=aJ4ReI51;
       spf=pass (google.com: best guess record for domain of linux-kernel-owner@vger.kernel.org designates 209.132.180.67 as permitted sender) smtp.mailfrom=linux-kernel-owner@vger.kernel.org;
       dmarc=pass (p=NONE sp=NONE dis=NONE) header.from=linaro.org
Received: from vger.kernel.org (vger.kernel.org. [209.132.180.67])
        by mx.google.com with ESMTP id r68-v6si28540777pfk.151.2018.11.14.15.56.26;
        Wed, 14 Nov 2018 15:56:40 -0800 (PST)
Received-SPF: pass (google.com: best guess record for domain of linux-kernel-owner@vger.kernel.org designates 209.132.180.67 as permitted sender) client-ip=209.132.180.67;
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
        id S1726775AbeKOKBr (ORCPT <rfc822;kristofer.rye@gmail.com>
        + 99 others); Thu, 15 Nov 2018 05:01:47 -0500
Received: from mail-io1-f68.google.com ([209.85.166.68]:34220 "EHLO
        mail-io1-f68.google.com" rhost-flags-OK-OK-OK-OK) by vger.kernel.org
        with ESMTP id S1725952AbeKOKBr (ORCPT
        <rfc822;linux-kernel@vger.kernel.org>);
        Thu, 15 Nov 2018 05:01:47 -0500
Received: by mail-io1-f68.google.com with SMTP id f6so10119876iob.1
        for <linux-kernel@vger.kernel.org>; Wed, 14 Nov 2018 15:56:19 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=linaro.org; s=google;
        h=mime-version:references:in-reply-to:from:date:message-id:subject:to
         :cc;
        bh=ZmLmN3dt/zfxfkpEIFGDIdCpD+4zRk/tFFa9swpMP8U=;
        b=aJ4ReI512rE1zygMoPShZbLYLtO+QqkVTc/LbTOkMUM8rPAWb/FvB651R8mDw4g+Cc
         +msWHC7hBa3FnfFP69I+tQJ7CjlKquwJWG/DMUQzK1F7PGG6yq9+mAkLTSVqHqpBcqK2
         3VE7knwR9Ot7DVT7W6woAGdtvqOZqRvAziqEE=
X-Received: by 2002:a6b:c8c9:: with SMTP id y192mr3083979iof.183.1542239778678;
 Wed, 14 Nov 2018 15:56:18 -0800 (PST)
MIME-Version: 1.0
References: <1541780454-9934-1-git-send-email-vincent.guittot@linaro.org>
 <1541780454-9934-3-git-send-email-vincent.guittot@linaro.org> <f7725461-bb0e-27fd-04cc-a225c97a9940@arm.com>
In-Reply-To: <f7725461-bb0e-27fd-04cc-a225c97a9940@arm.com>
From: Vincent Guittot <vincent.guittot@linaro.org>
Date: Wed, 14 Nov 2018 15:56:07 -0800
Message-ID: <CAKfTPtB6Fm2xJQ04GSs5o58Kh-GHxX_Wmn2bfLu=wJPmydijyw@mail.gmail.com>
Subject: Re: [PATCH v6 2/2] sched/fair: update scale invariance of PELT
To: Dietmar Eggemann <dietmar.eggemann@arm.com>
Cc: Peter Zijlstra <peterz@infradead.org>,
        Ingo Molnar <mingo@kernel.org>,
        linux-kernel <linux-kernel@vger.kernel.org>,
        "Rafael J. Wysocki" <rjw@rjwysocki.net>,
        Morten Rasmussen <Morten.Rasmussen@arm.com>,
        Patrick Bellasi <patrick.bellasi@arm.com>,
        Paul Turner <pjt@google.com>, Ben Segall <bsegall@google.com>,
        Thara Gopinath <thara.gopinath@linaro.org>,
        pkondeti@codeaurora.org, Quentin Perret <quentin.perret@arm.com>
Content-Type: text/plain; charset="UTF-8"
Sender: liker.xu+caf_=xuliker=zju.edu.cn@gmail.com
Precedence: bulk
List-ID: <linux-kernel.vger.kernel.org>
X-Mailing-List: linux-kernel@vger.kernel.org
X-CM-TRANSID: AQAAfwDHqEQ6tuxbLr9AAA--.3030S3
Authentication-Results: mail-app2; spf=pass smtp.mail=liker.xu+caf_=xu
	liker=zju.edu.cn@gmail.com;
X-Coremail-Antispam: 1UD129KBjvJXoWxtrWUGw17Jry7Gw1xur17KFg_yoWxJr45p3
	yfXa13G3Z7tr1Sk3s2vFs5Zw1ru3s5AF15JF1rAa4Iyr9xAw4vkF93t3yruFyxu3yxAasI
	vFWjgr9xu3Z09rDanT9S1TB71UUUUUUqnTZGkaVYY2UrUUUU0bIjqfuFe4nvWSU8nxnvy2
	9KBjDU0xBIdaVrnRJUUUP0b7Iv0xC_Kw4lb4IE77IF4wAFF20E14v26r1j6r4UM7CIcVAF
	z4kK6r1j6r18M28lY4IEw2IIxxk0rwA2F7IY1VAKz4vEj48ve4kI8wA2z4x0Y4vE2Ix0cI
	8IcVAFwI0_Xr0_Ar1l84ACjcxK6xIIjxv20xvEc7CjxVAFwI0_Gr0_Cr1l84ACjcxK6I8E
	87Iv67AKxVW0oVCq3wA2z4x0Y4vEx4A2jsIEc7CjxVAFwI0_GcCE3s1le2I262IYc4CY6c
	8Ij28IcVAaY2xG8wAqx4xG64xvF2IEw4CE5I8CrVC2j2WlYx0E2Ix0cI8IcVAFwI0_JrI_
	JrylYx0Ex4A2jsIE14v26r4j6F4UMcvjeVCFs4IE7xkEbVWUJVW8JwACjcxG0xvEwIxGrw
	CjxxvEa2IrMxkF7I0Ew4C26cxK6c8Ij28IcwCY1Ik26cxK6xAEc7vF6xCjj44lc2xSY4AK
	6IIF6FWlc2IjII80xcxEwVAKI48JMxvI42IY6xIIjxv20xvE14v26r1I6r4UMxvI42IY6x
	IIjxv20xvEc7CjxVAFwI0_Jr0_Gr1lcIIF0xvEx4A2jsIE14v26F4UJVW0owCYIxAIcVC2
	z280aVCY1x0267AKxVWxJr0_GcWl42xK82IYc2Ij64vIr41l42xK82IY64kExVAvwVAq07
	x20xyl4x8a6x804xWl4I8I3I0E4IkC6x0Yz7v_Jr0_Gr1lx2IqxVAqx4xG67AKxVWUJVWU
	GwC20s026x8GjcxK67AKxVWUGVWUWwC2zVAF1VAY17CE14v26r1q6r43MIIYrxkI7VAKI4
	8JMIIF0xvE42xK8VAvwI8IcIk0rVW3JVWrJrUvcSsGvfC2KfnxnUUI43ZEXa7IUOGzutUU
	UUU==

On Mon, 12 Nov 2018 at 18:53, Dietmar Eggemann <dietmar.eggemann@arm.com> wrote:
>
> On 11/9/18 8:20 AM, Vincent Guittot wrote:
>
> [...]
>
> > In order to achieve this time scaling, a new clock_pelt is created per rq.
> > The increase of this clock scales with current capacity when something
> > is running on rq and synchronizes with clock_task when rq is idle. With
> > this mecanism, we ensure the same running and idle time whatever the
>
> nitpick: s/mecanism/mechanism
>
> [...]
>
> > The responsivness of PELT is improved when CPU is not running at max
>
> nitpick: s/responsivness/responsiveness
>
> > capacity with this new algorithm. I have put below some examples of
> > duration to reach some typical load values according to the capacity of the
> > CPU with current implementation and with this patch. These values has been
> > computed based on the geometric serie and the half period value:
>
> nitpick: s/serie/series

ok for this and previous

>
> [...]
>
> > +/*
> > + * The clock_pelt scales the time to reflect the effective amount of
> > + * computation done during the running delta time but then sync back to
> > + * clock_task when rq is idle.
> > + *
> > + *
> > + * absolute time   | 1| 2| 3| 4| 5| 6| 7| 8| 9|10|11|12|13|14|15|16
> > + * @ max capacity  ------******---------------******---------------
> > + * @ half capacity ------************---------************---------
> > + * clock pelt      | 1| 2|    3|    4| 7| 8| 9|   10|   11|14|15|16
> > + *
> > + */
> > +static inline void update_rq_clock_pelt(struct rq *rq, s64 delta)
> > +{
> > +     if (unlikely(is_idle_task(rq->curr))) {
> > +             /* The rq is idle, we can sync to clock_task */
> > +             rq->clock_pelt  = rq_clock_task(rq);
> > +             return;
>
> I think the term (time) stretching was used to to describe what's
> happening to the clock_pelt values at lower capacity and to this re-sync
> with the clock task. But IMHO, one has to be called stretching and the
> other compressing so it makes sense. I think it's a question of definition.
>
> > +     }
> > +
> > +     /*
> > +      * When a rq runs at a lower compute capacity, it will need
> > +      * more time to do the same amount of work than at max
> > +      * capacity: either because it takes more time to compute the
> > +      * same amount of work or because taking more time means
> > +      * sharing more often the CPU between entities.
>
> I wonder if since clock_pelt is related to the sched_avg(s) of the rq
> isn't the only reason the first one "It takes more time to do the same
> amount of work"? IMHO, the sharing of sched entities shouldn't be
> visible here.

yes probably

>
> > +      * In order to be invariant, we scale the delta to reflect how
> > +      * much work has been really done.
> > +      * Running at lower capacity also means running longer to do
> > +      * the same amount of work and this results in stealing some
>
> This is already mentioned above.
>
> > +      * idle time that will disturb the load signal compared to
> > +      * max capacity; This stolen idle time will be automaticcally
>
> nitpick: s/automaticcally/automatically
>
> > +      * reflected when the rq will be idle and the clock will be
> > +      * synced with rq_clock_task.
> > +      */
> > +
> > +     /*
> > +      * scale the elapsed time to reflect the real amount of
> > +      * computation
> > +      */
> > +     delta = cap_scale(delta, arch_scale_cpu_capacity(NULL, cpu_of(rq)));
> > +     delta = cap_scale(delta, arch_scale_freq_capacity(cpu_of(rq)));
> > +
> > +     rq->clock_pelt += delta;
> > +}
> > +
> > +/*
> > + * When rq becomes idle, we have to check if it has lost some idle time
> > + * because it was fully busy. A rq is fully used when the /Sum util_sum
> > + * is greater or equal to:
> > + * (LOAD_AVG_MAX - 1024 + rq->cfs.avg.period_contrib) << SCHED_CAPACITY_SHIFT;
> > + * For optimization and computing rounding purpose, we don't take into account
> > + * the position in the current window (period_contrib) and we use the maximum
> > + * util_avg value minus 1
> > + */
>
> In v4 you were using:
>
> u32 divider = (LOAD_AVG_MAX - 1024 + rq->cfs.avg.period_contrib) <<
> SCHED_CAPACITY_SHIFT;
>
> and switched in v5 to:
>
> u32 divider = ((LOAD_AVG_MAX - 1024) << SCHED_CAPACITY_SHIFT) -
> LOAD_AVG_MAX;
>
> The period_contrib of rq->cfs.avg, rq->avg_rt and rq->avg_dl are not
> necessarily aligned but for overload you sum up the util_sum values for
> cfs, rt and dl. Was this also a reason why you now assume max util_avg -
> 1 ?

The original reason is optimization

>
> > +static inline void update_idle_rq_clock_pelt(struct rq *rq)
> > +{
> > +     u32 divider = ((LOAD_AVG_MAX - 1024) << SCHED_CAPACITY_SHIFT) - LOAD_AVG_MAX;
>
> util_avg = util_sum / divider   ,maximum util_avg = 1024
>
> 1024 = util_sum / (LOAD_AVG_MAX - 1024)   w/ period_contrib = 0
>
> util_sum >= (LOAD_AVG_MAX - 1024) * 1024
>
> util_sum >= (LOAD_AVG_MAX - 1024) << SCHED_CAPACITY_SHIFT;
>
> So you want to use 1024 - 1 = 1023 instead. Wouldn't you have to
> subtract (LOAD_AVG_MAX - 1024) from (LOAD_AVG_MAX - 1024) <<
> SCHED_CAPACITY_SHIFT in this case?
>
> util_sum >= (LOAD_AVG_MAX - 1024) << SCHED_CAPACITY_SHIFT -
> (LOAD_AVG_MAX - 1024)

(LOAD_AVG_MAX - 1024) is the lower bound of the max value ( it's in
fact LOAD_AVG_MAX*y) so in order to be conservative and prevent any
rounding effect, I'm using the higher bound (LOAD_AVG_MAX*y + a full
new window (1024)) = LOAD_AVG_MAX for the Sum of util_sum side

And his is even more true now that we sum 3 util_sum values

> > +     u32 overload = rq->cfs.avg.util_sum;
> > +     overload += rq->avg_rt.util_sum;
> > +     overload += rq->avg_dl.util_sum;
> > +
> > +     /*
> > +      * Reflecting some stolen time makes sense only if the idle
> > +      * phase would be present at max capacity. As soon as the
> > +      * utilization of a rq has reached the maximum value, it is
> > +      * considered as an always runnnig rq without idle time to
>
> nitpick: s/runnnig/runnig

ok

>
> > +      * steal. This potential idle time is considered as lost in
> > +      * this case. We keep track of this lost idle time compare to
> > +      * rq's clock_task.
> > +      */
> > +     if ((overload >= divider))
> > +             rq->lost_idle_time += rq_clock_task(rq) - rq->clock_pelt;
>
> Shouldn't overload still be called util_sum? Overload (or overutilized
> is IMHO the state when util_sum >= divider.

yes i can rename it

>
> [...]
>
