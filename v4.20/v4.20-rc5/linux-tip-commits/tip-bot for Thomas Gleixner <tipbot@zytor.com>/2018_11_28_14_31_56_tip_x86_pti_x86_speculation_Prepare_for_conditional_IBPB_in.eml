Return-Path: <linux-kernel-owner@vger.kernel.org>
Delivered-To: unknown
Received: from linux.intel.com (10.54.29.200:995) by likexu-workstation with
  POP3-SSL; 29 Nov 2018 08:37:09 -0000
X-Original-To: like.xu@linux.intel.com
Delivered-To: like.xu@linux.intel.com
Received: from orsmga006.jf.intel.com (orsmga006.jf.intel.com [10.7.209.51])
	(using TLSv1.2 with cipher ECDHE-RSA-AES256-GCM-SHA384 (256/256 bits))
	(No client certificate requested)
	by linux.intel.com (Postfix) with ESMTPS id AA2B15802E4;
	Wed, 28 Nov 2018 06:32:48 -0800 (PST)
Received: from orsmga102-1.jf.intel.com (HELO mga09.intel.com) ([10.7.208.27])
  by orsmga006-1.jf.intel.com with ESMTP; 28 Nov 2018 06:32:48 -0800
X-SG-BADATTACHMENTNOREPLY: True
IronPort-PHdr: =?us-ascii?q?9a23=3AVx8/MBM+XoG94ROJA5Il6mtUPXoX/o7sNwtQ0KIM?=
 =?us-ascii?q?zox0Kfz5psbcNUDSrc9gkEXOFd2Cra4c26yO6+jJYi8p2d65qncMcZhBBVcuqP?=
 =?us-ascii?q?49uEgeOvODElDxN/XwbiY3T4xoXV5h+GynYwAOQJ6tL1LdrWev4jEMBx7xKRR6?=
 =?us-ascii?q?JvjvGo7Vks+7y/2+94fcbglUhzexe69+IAmrpgjNq8cahpdvJLwswRXTuHtIfO?=
 =?us-ascii?q?pWxWJsJV2Nmhv3+9m98p1+/SlOovwt78FPX7n0cKQ+VrxYES8pM3sp683xtBnM?=
 =?us-ascii?q?VhWA630BWWgLiBVIAgzF7BbnXpfttybxq+Rw1DWGMcDwULs5Xymp4aV2Rx/ykC?=
 =?us-ascii?q?oJOT43/mLNisNygqJVvg+vqRtwzIDbfI6aKeF+frvfcN4BWWpMXdxcWzBbD4+g?=
 =?us-ascii?q?bYYCCfcKM+ZCr4n6olsDtQe+BQi0BO/20TBIgWP21rA00+QmCwHNwRIuH9IJsH?=
 =?us-ascii?q?TRttr1L7oZX+GxzKbWzDXCYPVW1inn6IPVdR0hvfCMXaprfsrW1UkiDALEj1WM?=
 =?us-ascii?q?qYziJTOZzPgCs2+e7+d5U++klmApqwZ0oje1x8csjJHEhoELxVDe8yV23oI1Kc?=
 =?us-ascii?q?e/SE5hbt6pFoZbuSKCN4ZuXM8uX2VltDwnxrAIp5K3ZjUGxZc7yxLFavGKcZCE?=
 =?us-ascii?q?7g/nWeuSOzt0mXxodbClixqs7USs1PfwWtS63VtLqCdOj8PCuWoX1xPJ78iKUv?=
 =?us-ascii?q?t98Vml2TaIzw3T9O5ELl4ulabBKJ4u3KQwlpwNvkTHBCP2n1/2jKCOekUl/Oin?=
 =?us-ascii?q?9fjnb634qpOAM4J4kBzyP6owlsClHOg1MRQCU3Ka9Om+zLHj+Ff2QLROjv04iK?=
 =?us-ascii?q?nZt5XaKNwfpq64BQ9Vz4ki5w+8Dzi4ytQYm2cILFZcdBKAgYnpPU/BIOrjAPeh?=
 =?us-ascii?q?jFSjji1ry+rFPrL/GJXNKGbMkLP7cbZ68U5cxxI/zcpD6JJMFrEBPPXzV1f1tN?=
 =?us-ascii?q?zZDR82LRa4wun6CNhm0oMeWGSPArKWMa/IsF+I4P4vLPeIZIMPpDn9LP0l7eb0?=
 =?us-ascii?q?jXAlgV8dYbWp3ZwPZXC4BPtmIlmZbmDrgtsbEWcKoxAxTOrliFCZVT5TZnCyX7?=
 =?us-ascii?q?8z5z0hCYKmC5vDSZ6pgLCbwCi7GZhWbHhcCl+QCXfoa5mEW/AUZSKQJc9ujCYI?=
 =?us-ascii?q?VbumS48n0xGusxT3y75mLurS5y0Zuojv1Nlz5+3Pix4y8SZ4ANia02GIV2t0hH?=
 =?us-ascii?q?8HRycq3KBjpkxw0k2M0bN4g/xfFtxf/elJXR04NZPHy+x6CtbyWh/Of9uTSVam?=
 =?us-ascii?q?RMmmDi81Tt4r39AOZEN9Ec24jh/fxyqqH6MVl7uTCZw36K3c2WL9J8J8y3nc0q?=
 =?us-ascii?q?khgEIrQs9ONW2gm65++BLfB4/Pk0WFiamqcb4Q0zLK9GeG1WCOpl1XUBZsUaXZ?=
 =?us-ascii?q?WnASflbZos7n5kzcVbOuCa4oMg1aycGcLKtGbdnpjVZDRPfnI9neZ2Oxm2GtBR?=
 =?us-ascii?q?eH3L+MbYzqe3kD0yXZEkQLjwcT/XOePwgkGiihu37eDCBpFV/3fkzj6/d+p22h?=
 =?us-ascii?q?Qk801Q6KaVZh2KSz+hMOgfycSvUT3q8LuSs7qjV0Gkq90MzSC9aauwVhe6Bca8?=
 =?us-ascii?q?sn4FhbzWLZqxB9Ppu4IqB+h14edgN3v1/u1xR3EIlAjdImrHQwzAp2KKKY1lxB?=
 =?us-ascii?q?eiic3ZDxPL3XN2bz8Aqua67QxlHRztKW9r0T5/Q/rlXppBupGVY683V7z9lV1G?=
 =?us-ascii?q?OR6Y/ODAUMXpP+TEY2+wJhqLHHfyYy/YXU1X5rMamqqTLC39MpBO04yhevZdtf?=
 =?us-ascii?q?MaWEFBPsHM0eHcShNOsqm12xZBIeIO9S7LI0P9+hd/ae2K+rIfxsky68gWVG4I?=
 =?us-ascii?q?ByyESM9yVnR+7M3pYFxeyY3wSdWzf9ilehrt74mYReaT4OGWq/zDDuBJRNaa1q?=
 =?us-ascii?q?YYYLFWCuLtWtxtV/m5HiQWRY+0OkB18c3s+mZwCSb13k0QJMz0sXpWGoljWizz?=
 =?us-ascii?q?xzlTEkta6f3C3Iw+T/exsLIG9LRG9+jVjyJYi4lcwVXE+tbwIxjhuq+V76x7RH?=
 =?us-ascii?q?pKR4N2TSQUZIczL2Lm14Sauwq7yCbtVL6JMptyVXTeu9bUqbSr77vxsVzSfjE3?=
 =?us-ascii?q?FCyzA8cjGgoo/5kABiiGKBMHZzq2LUecNqyhfF59zcRvlR0iAdRCZiijnXBVm8?=
 =?us-ascii?q?P9+38tWSjJrDtuG+V2S8VpxcayXrzIWAtDel6m1uGxGwg/ezmtj/GwggzSD7z8?=
 =?us-ascii?q?VqVTnPrBvkYojkzaO6PfhlfklpAl/x8M56GoB4kosti5Acw3kahpOJ/XUZlWf/?=
 =?us-ascii?q?K8lU2aX7bHAVXz4E38bV4BT52E1kNn+JxJj2VnSHzsthetm1eGUW2i0m4sBOCa?=
 =?us-ascii?q?eU6qFEnCRvrlq5qwLRfeZynjMHxfQy734ahvkDuBAxwSWFHrASAU5YMDTplxSJ?=
 =?us-ascii?q?7NCxtr9bZWixfriryEpxg8qhA6qcrQFGV3b0YZMiHS527sViP1PAynzz6of4eN?=
 =?us-ascii?q?bOadIfrAGbkxDFj+JNMpI+iuIKhTZ7OWL6pXAl1+k7jRl00ZC7poeHLXht/Lmi?=
 =?us-ascii?q?Ah5ZLTD1Y8IT+jfwjadRhMqW3oavHol/FTUPRpfnUfWoEDcKv/T9KwmOCCE8qm?=
 =?us-ascii?q?ucGbfHBgCQ8kBmr3bSE5yxM3GXOWIUzdFjRBmbOUxejxoYXDQ8np4lCA+qwNbt?=
 =?us-ascii?q?f1t+5jAU/lT4sAdDyvp0NxnjVWfSvAWoZS0xSJeBNxpa9B1C613WMcyD7eJzAi?=
 =?us-ascii?q?dY8Ye6rAGWLmybZgJIDXwGW0CeBlDjOKWu6sfE8+SCGuW+KP7Oa62UqeNCT/eI?=
 =?us-ascii?q?2Y6v0ox+8jeMMcWPI2BiD+Ah1UpFR3x5AMPZmzMASyEMkyLNbsibpAqz+yFtr8?=
 =?us-ascii?q?C/9ujrVxzr5YeVF7RSNtBv8QisgaifL+6QmDp5KTFA25MM23DIybsf3F0Tiy10?=
 =?us-ascii?q?dDmtC7MAtSHTQ6LKh69XFAUWaydyNMtO8qI90RNBOc/ditPpyLF4iuQ5BEtCVV?=
 =?us-ascii?q?zkgsupf9AFI3mhNFPbA0aGLK6JJSDQzMHtf6y9SadcjOFVtxCrvTabEknjPimM?=
 =?us-ascii?q?ljXzVhCvN/1Mgz+fPBBEpI69dRNtA3D5TN36ch27LMN3jTouzL0oh3PKMHQQPi?=
 =?us-ascii?q?Rmf0xRrr2f8yVYj+57G2xA6HplMOaFlzyY7+neNpYZr/9rDj5omOJd5XQw06FV?=
 =?us-ascii?q?4z1cRPxphCvSqcZjolG8nemJzzpnURxOpS5KhYKLp0piP6rZ+4JEWXbF+hIN8G?=
 =?us-ascii?q?qRBw4Lp9tjFt3gpaRQxsLTm6L0LTcRu+7TqM8dAdXEbd6GKD8qNh/sGSLPJBUK?=
 =?us-ascii?q?QCTtNmzFgUFZ1vaI+S6vo4A+u6TrzYYBTq9zUF0zC+8ADUJkDJoOLdM/USkpnr?=
 =?us-ascii?q?2bpMoJ42euoh7MQslTopHAULSVG/qrYDKei7ZBbh1ZmuKkBYsWP4z/nUdlbx0y?=
 =?us-ascii?q?lY3QEEPWUt1luCBtbgYo5k5K9Tw2Umw2nUmjYQOg5lcXFPipjlg3jBdzZaIm8z?=
 =?us-ascii?q?Koq1s+OFeMpCI2i0Q3sdTjnT2VNjX2KeP4UZ5TFAL9skEjNZW9SAEzcA721U5v?=
 =?us-ascii?q?MR/eSr5RhqcmfmduzEfYpIdIMf1RV6tJZFkX3/7TL+kvy0pVrim87UtG4/bVTJ?=
 =?us-ascii?q?VliQ0meIKtqHQG3BhsKJY8P67ZIoJNz15NluSPuDOl0qY6xwpab0QO93iTficg?=
 =?us-ascii?q?o1ETO/8tNW7g8uVy6ADEkH1YZGUTXuA2ivNs6k45fe+Hymao06ZKAlKgK+uFaa?=
 =?us-ascii?q?ieviyIlsOFWVg30UAgnElf+r13zMJldFCbEwgmz5OVFhIUJYzDLx1Ya4xZ832X?=
 =?us-ascii?q?NS+VsPmLwtRwNoG5F+vrZe6IqKsQxEmjGUJhGoUK4cMpHZS21kzca8D9I/pNzR?=
 =?us-ascii?q?Qr+RSuJ1ifCvlNUAyEnS1BoMylypJzm45HKXVVHWV6NCysoLLaoAMji/mSdN4z?=
 =?us-ascii?q?bjERWY5AfnAuX8y/kSlUl25NADm+zqQSzw3GpyfxuinKHhH9adR5bfuZbB8qD8?=
 =?us-ascii?q?u5vX00+rO7mBjM+ZXXOm/+OM5Ku9nT5OdcrJGCWN1OSrwor0bE3oNfWzSkVHSH?=
 =?us-ascii?q?Ld6yIpHrI6YoYN3kDHugGgijiio/SNvZLsexKbLOigbtE9UH+LKH1SwuYJfuXg?=
 =?us-ascii?q?oVHA198rkO?=
X-IronPort-Anti-Spam-Filtered: true
X-IronPort-Anti-Spam-Result: =?us-ascii?q?A0A4AAAHpv5bh0O0hNFkHgEGBwaBUQkLA?=
 =?us-ascii?q?QGBVIEUgQIng3mId4spAYIhaIIbhXmFXoFzhmEggUwZAQEYCwgBh24iNAkNAQM?=
 =?us-ascii?q?BAQEBAQECARMBAQEIDQkIKSMMQgEQAYFiIoJlAwMBAggYBAQBBgFGBgkBASQCJ?=
 =?us-ascii?q?gICAx4OAQ4BGBkFA4MZAYFpAQEBFQUKpjZ8Mw0RhA8BgQOCPAQKGQ2CFwUTeIs?=
 =?us-ascii?q?LF4F/gRGCXYMMghaDGIJXAokFDxGGdlCOahguCYZ9hwiDRIs8CgERP4R+LI0og?=
 =?us-ascii?q?QuJQgIEAgQFAhRabIINTSMVgW8OCwEMBAaBCBOCFBeIXoVgHgEyAQEIewEBhFS?=
 =?us-ascii?q?GE4JMAQE?=
X-IPAS-Result: =?us-ascii?q?A0A4AAAHpv5bh0O0hNFkHgEGBwaBUQkLAQGBVIEUgQIng3m?=
 =?us-ascii?q?Id4spAYIhaIIbhXmFXoFzhmEggUwZAQEYCwgBh24iNAkNAQMBAQEBAQECARMBA?=
 =?us-ascii?q?QEIDQkIKSMMQgEQAYFiIoJlAwMBAggYBAQBBgFGBgkBASQCJgICAx4OAQ4BGBk?=
 =?us-ascii?q?FA4MZAYFpAQEBFQUKpjZ8Mw0RhA8BgQOCPAQKGQ2CFwUTeIsLF4F/gRGCXYMMg?=
 =?us-ascii?q?haDGIJXAokFDxGGdlCOahguCYZ9hwiDRIs8CgERP4R+LI0ogQuJQgIEAgQFAhR?=
 =?us-ascii?q?abIINTSMVgW8OCwEMBAaBCBOCFBeIXoVgHgEyAQEIewEBhFSGE4JMAQE?=
X-IronPort-AV: E=Sophos;i="5.56,290,1539673200"; 
   d="scan'208";a="55193708"
X-Amp-Result: UNSCANNABLE
X-Amp-File-Uploaded: False
Unscannable: 2
Received: from vger.kernel.org ([209.132.180.67])
  by mtab.intel.com with ESMTP; 28 Nov 2018 06:32:46 -0800
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
        id S1728413AbeK2Bec (ORCPT <rfc822;like.xu@linux.intel.com>
        + 23 others); Wed, 28 Nov 2018 20:34:32 -0500
Received: from terminus.zytor.com ([198.137.202.136]:55107 "EHLO
        terminus.zytor.com" rhost-flags-OK-OK-OK-OK) by vger.kernel.org
        with ESMTP id S1727872AbeK2Bec (ORCPT
        <rfc822;linux-kernel@vger.kernel.org>);
        Wed, 28 Nov 2018 20:34:32 -0500
Received: from terminus.zytor.com (localhost [127.0.0.1])
        by terminus.zytor.com (8.15.2/8.15.2) with ESMTPS id wASEVu8w2323696
        (version=TLSv1.2 cipher=ECDHE-RSA-AES256-GCM-SHA384 bits=256 verify=NO);
        Wed, 28 Nov 2018 06:31:56 -0800
Received: (from tipbot@localhost)
        by terminus.zytor.com (8.15.2/8.15.2/Submit) id wASEVuDH2323693;
        Wed, 28 Nov 2018 06:31:56 -0800
Date: Wed, 28 Nov 2018 06:31:56 -0800
X-Authentication-Warning: terminus.zytor.com: tipbot set sender to tipbot@zytor.com using -f
From: tip-bot for Thomas Gleixner <tipbot@zytor.com>
Message-ID: <tip-4c71a2b6fd7e42814aa68a6dec88abf3b42ea573@git.kernel.org>
Cc: casey.schaufler@intel.com, jpoimboe@redhat.com,
        peterz@infradead.org, linux-kernel@vger.kernel.org,
        thomas.lendacky@amd.com, keescook@chromium.org, hpa@zytor.com,
        jkosina@suse.cz, david.c.stewart@intel.com, arjan@linux.intel.com,
        torvalds@linux-foundation.org, mingo@kernel.org,
        asit.k.mallick@intel.com, ak@linux.intel.com, jcm@redhat.com,
        dwmw@amazon.co.uk, luto@kernel.org, tglx@linutronix.de,
        gregkh@linuxfoundation.org, dave.hansen@intel.com,
        tim.c.chen@linux.intel.com, longman9394@gmail.com,
        aarcange@redhat.com
Reply-To: tglx@linutronix.de, gregkh@linuxfoundation.org,
          longman9394@gmail.com, aarcange@redhat.com,
          tim.c.chen@linux.intel.com, dave.hansen@intel.com,
          dwmw@amazon.co.uk, jcm@redhat.com, luto@kernel.org,
          torvalds@linux-foundation.org, arjan@linux.intel.com,
          jkosina@suse.cz, david.c.stewart@intel.com, hpa@zytor.com,
          keescook@chromium.org, ak@linux.intel.com,
          asit.k.mallick@intel.com, mingo@kernel.org,
          linux-kernel@vger.kernel.org, thomas.lendacky@amd.com,
          jpoimboe@redhat.com, peterz@infradead.org,
          casey.schaufler@intel.com
In-Reply-To: <20181125185005.466447057@linutronix.de>
References: <20181125185005.466447057@linutronix.de>
To: linux-tip-commits@vger.kernel.org
Subject: [tip:x86/pti] x86/speculation: Prepare for conditional IBPB in
 switch_mm()
Git-Commit-ID: 4c71a2b6fd7e42814aa68a6dec88abf3b42ea573
X-Mailer: tip-git-log-daemon
Robot-ID: <tip-bot.git.kernel.org>
Robot-Unsubscribe: Contact <mailto:hpa@kernel.org> to get blacklisted from
 these emails
MIME-Version: 1.0
Content-Transfer-Encoding: 8bit
Content-Type: text/plain; charset=UTF-8
Content-Disposition: inline
X-Spam-Status: No, score=1.5 required=5.0 tests=ALL_TRUSTED,BAYES_00,
        DATE_IN_FUTURE_24_48,FREEMAIL_FORGED_REPLYTO,
        FREEMAIL_REPLYTO_END_DIGIT autolearn=no autolearn_force=no
        version=3.4.2
X-Spam-Level: *
X-Spam-Checker-Version: SpamAssassin 3.4.2 (2018-09-13) on terminus.zytor.com
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: <linux-kernel.vger.kernel.org>
X-Mailing-List: linux-kernel@vger.kernel.org

Commit-ID:  4c71a2b6fd7e42814aa68a6dec88abf3b42ea573
Gitweb:     https://git.kernel.org/tip/4c71a2b6fd7e42814aa68a6dec88abf3b42ea573
Author:     Thomas Gleixner <tglx@linutronix.de>
AuthorDate: Sun, 25 Nov 2018 19:33:49 +0100
Committer:  Thomas Gleixner <tglx@linutronix.de>
CommitDate: Wed, 28 Nov 2018 11:57:11 +0100

x86/speculation: Prepare for conditional IBPB in switch_mm()

The IBPB speculation barrier is issued from switch_mm() when the kernel
switches to a user space task with a different mm than the user space task
which ran last on the same CPU.

An additional optimization is to avoid IBPB when the incoming task can be
ptraced by the outgoing task. This optimization only works when switching
directly between two user space tasks. When switching from a kernel task to
a user space task the optimization fails because the previous task cannot
be accessed anymore. So for quite some scenarios the optimization is just
adding overhead.

The upcoming conditional IBPB support will issue IBPB only for user space
tasks which have the TIF_SPEC_IB bit set. This requires to handle the
following cases:

  1) Switch from a user space task (potential attacker) which has
     TIF_SPEC_IB set to a user space task (potential victim) which has
     TIF_SPEC_IB not set.

  2) Switch from a user space task (potential attacker) which has
     TIF_SPEC_IB not set to a user space task (potential victim) which has
     TIF_SPEC_IB set.

This needs to be optimized for the case where the IBPB can be avoided when
only kernel threads ran in between user space tasks which belong to the
same process.

The current check whether two tasks belong to the same context is using the
tasks context id. While correct, it's simpler to use the mm pointer because
it allows to mangle the TIF_SPEC_IB bit into it. The context id based
mechanism requires extra storage, which creates worse code.

When a task is scheduled out its TIF_SPEC_IB bit is mangled as bit 0 into
the per CPU storage which is used to track the last user space mm which was
running on a CPU. This bit can be used together with the TIF_SPEC_IB bit of
the incoming task to make the decision whether IBPB needs to be issued or
not to cover the two cases above.

As conditional IBPB is going to be the default, remove the dubious ptrace
check for the IBPB always case and simply issue IBPB always when the
process changes.

Move the storage to a different place in the struct as the original one
created a hole.

Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
Reviewed-by: Ingo Molnar <mingo@kernel.org>
Cc: Peter Zijlstra <peterz@infradead.org>
Cc: Andy Lutomirski <luto@kernel.org>
Cc: Linus Torvalds <torvalds@linux-foundation.org>
Cc: Jiri Kosina <jkosina@suse.cz>
Cc: Tom Lendacky <thomas.lendacky@amd.com>
Cc: Josh Poimboeuf <jpoimboe@redhat.com>
Cc: Andrea Arcangeli <aarcange@redhat.com>
Cc: David Woodhouse <dwmw@amazon.co.uk>
Cc: Tim Chen <tim.c.chen@linux.intel.com>
Cc: Andi Kleen <ak@linux.intel.com>
Cc: Dave Hansen <dave.hansen@intel.com>
Cc: Casey Schaufler <casey.schaufler@intel.com>
Cc: Asit Mallick <asit.k.mallick@intel.com>
Cc: Arjan van de Ven <arjan@linux.intel.com>
Cc: Jon Masters <jcm@redhat.com>
Cc: Waiman Long <longman9394@gmail.com>
Cc: Greg KH <gregkh@linuxfoundation.org>
Cc: Dave Stewart <david.c.stewart@intel.com>
Cc: Kees Cook <keescook@chromium.org>
Cc: stable@vger.kernel.org
Link: https://lkml.kernel.org/r/20181125185005.466447057@linutronix.de

---
 arch/x86/include/asm/nospec-branch.h |   2 +
 arch/x86/include/asm/tlbflush.h      |   8 ++-
 arch/x86/kernel/cpu/bugs.c           |  29 +++++++--
 arch/x86/mm/tlb.c                    | 115 ++++++++++++++++++++++++++---------
 4 files changed, 118 insertions(+), 36 deletions(-)

diff --git a/arch/x86/include/asm/nospec-branch.h b/arch/x86/include/asm/nospec-branch.h
index be0b0aa780e2..d4d35baf0430 100644
--- a/arch/x86/include/asm/nospec-branch.h
+++ b/arch/x86/include/asm/nospec-branch.h
@@ -312,6 +312,8 @@ do {									\
 } while (0)
 
 DECLARE_STATIC_KEY_FALSE(switch_to_cond_stibp);
+DECLARE_STATIC_KEY_FALSE(switch_mm_cond_ibpb);
+DECLARE_STATIC_KEY_FALSE(switch_mm_always_ibpb);
 
 #endif /* __ASSEMBLY__ */
 
diff --git a/arch/x86/include/asm/tlbflush.h b/arch/x86/include/asm/tlbflush.h
index d760611cfc35..f4204bf377fc 100644
--- a/arch/x86/include/asm/tlbflush.h
+++ b/arch/x86/include/asm/tlbflush.h
@@ -169,10 +169,14 @@ struct tlb_state {
 
 #define LOADED_MM_SWITCHING ((struct mm_struct *)1)
 
+	/* Last user mm for optimizing IBPB */
+	union {
+		struct mm_struct	*last_user_mm;
+		unsigned long		last_user_mm_ibpb;
+	};
+
 	u16 loaded_mm_asid;
 	u16 next_asid;
-	/* last user mm's ctx id */
-	u64 last_ctx_id;
 
 	/*
 	 * We can be in one of several states:
diff --git a/arch/x86/kernel/cpu/bugs.c b/arch/x86/kernel/cpu/bugs.c
index 1e13dbfc0919..7c946a9af947 100644
--- a/arch/x86/kernel/cpu/bugs.c
+++ b/arch/x86/kernel/cpu/bugs.c
@@ -56,6 +56,10 @@ u64 __ro_after_init x86_amd_ls_cfg_ssbd_mask;
 
 /* Control conditional STIPB in switch_to() */
 DEFINE_STATIC_KEY_FALSE(switch_to_cond_stibp);
+/* Control conditional IBPB in switch_mm() */
+DEFINE_STATIC_KEY_FALSE(switch_mm_cond_ibpb);
+/* Control unconditional IBPB in switch_mm() */
+DEFINE_STATIC_KEY_FALSE(switch_mm_always_ibpb);
 
 void __init check_bugs(void)
 {
@@ -331,7 +335,17 @@ spectre_v2_user_select_mitigation(enum spectre_v2_mitigation_cmd v2_cmd)
 	/* Initialize Indirect Branch Prediction Barrier */
 	if (boot_cpu_has(X86_FEATURE_IBPB)) {
 		setup_force_cpu_cap(X86_FEATURE_USE_IBPB);
-		pr_info("Spectre v2 mitigation: Enabling Indirect Branch Prediction Barrier\n");
+
+		switch (mode) {
+		case SPECTRE_V2_USER_STRICT:
+			static_branch_enable(&switch_mm_always_ibpb);
+			break;
+		default:
+			break;
+		}
+
+		pr_info("mitigation: Enabling %s Indirect Branch Prediction Barrier\n",
+			mode == SPECTRE_V2_USER_STRICT ? "always-on" : "conditional");
 	}
 
 	/* If enhanced IBRS is enabled no STIPB required */
@@ -955,10 +969,15 @@ static char *stibp_state(void)
 
 static char *ibpb_state(void)
 {
-	if (boot_cpu_has(X86_FEATURE_USE_IBPB))
-		return ", IBPB";
-	else
-		return "";
+	if (boot_cpu_has(X86_FEATURE_IBPB)) {
+		switch (spectre_v2_user) {
+		case SPECTRE_V2_USER_NONE:
+			return ", IBPB: disabled";
+		case SPECTRE_V2_USER_STRICT:
+			return ", IBPB: always-on";
+		}
+	}
+	return "";
 }
 
 static ssize_t cpu_show_common(struct device *dev, struct device_attribute *attr,
diff --git a/arch/x86/mm/tlb.c b/arch/x86/mm/tlb.c
index bddd6b3cee1d..03b6b4c2238d 100644
--- a/arch/x86/mm/tlb.c
+++ b/arch/x86/mm/tlb.c
@@ -7,7 +7,6 @@
 #include <linux/export.h>
 #include <linux/cpu.h>
 #include <linux/debugfs.h>
-#include <linux/ptrace.h>
 
 #include <asm/tlbflush.h>
 #include <asm/mmu_context.h>
@@ -30,6 +29,12 @@
  *	Implement flush IPI by CALL_FUNCTION_VECTOR, Alex Shi
  */
 
+/*
+ * Use bit 0 to mangle the TIF_SPEC_IB state into the mm pointer which is
+ * stored in cpu_tlb_state.last_user_mm_ibpb.
+ */
+#define LAST_USER_MM_IBPB	0x1UL
+
 /*
  * We get here when we do something requiring a TLB invalidation
  * but could not go invalidate all of the contexts.  We do the
@@ -181,17 +186,87 @@ static void sync_current_stack_to_mm(struct mm_struct *mm)
 	}
 }
 
-static bool ibpb_needed(struct task_struct *tsk, u64 last_ctx_id)
+static inline unsigned long mm_mangle_tif_spec_ib(struct task_struct *next)
+{
+	unsigned long next_tif = task_thread_info(next)->flags;
+	unsigned long ibpb = (next_tif >> TIF_SPEC_IB) & LAST_USER_MM_IBPB;
+
+	return (unsigned long)next->mm | ibpb;
+}
+
+static void cond_ibpb(struct task_struct *next)
 {
+	if (!next || !next->mm)
+		return;
+
 	/*
-	 * Check if the current (previous) task has access to the memory
-	 * of the @tsk (next) task. If access is denied, make sure to
-	 * issue a IBPB to stop user->user Spectre-v2 attacks.
-	 *
-	 * Note: __ptrace_may_access() returns 0 or -ERRNO.
+	 * Both, the conditional and the always IBPB mode use the mm
+	 * pointer to avoid the IBPB when switching between tasks of the
+	 * same process. Using the mm pointer instead of mm->context.ctx_id
+	 * opens a hypothetical hole vs. mm_struct reuse, which is more or
+	 * less impossible to control by an attacker. Aside of that it
+	 * would only affect the first schedule so the theoretically
+	 * exposed data is not really interesting.
 	 */
-	return (tsk && tsk->mm && tsk->mm->context.ctx_id != last_ctx_id &&
-		ptrace_may_access_sched(tsk, PTRACE_MODE_SPEC_IBPB));
+	if (static_branch_likely(&switch_mm_cond_ibpb)) {
+		unsigned long prev_mm, next_mm;
+
+		/*
+		 * This is a bit more complex than the always mode because
+		 * it has to handle two cases:
+		 *
+		 * 1) Switch from a user space task (potential attacker)
+		 *    which has TIF_SPEC_IB set to a user space task
+		 *    (potential victim) which has TIF_SPEC_IB not set.
+		 *
+		 * 2) Switch from a user space task (potential attacker)
+		 *    which has TIF_SPEC_IB not set to a user space task
+		 *    (potential victim) which has TIF_SPEC_IB set.
+		 *
+		 * This could be done by unconditionally issuing IBPB when
+		 * a task which has TIF_SPEC_IB set is either scheduled in
+		 * or out. Though that results in two flushes when:
+		 *
+		 * - the same user space task is scheduled out and later
+		 *   scheduled in again and only a kernel thread ran in
+		 *   between.
+		 *
+		 * - a user space task belonging to the same process is
+		 *   scheduled in after a kernel thread ran in between
+		 *
+		 * - a user space task belonging to the same process is
+		 *   scheduled in immediately.
+		 *
+		 * Optimize this with reasonably small overhead for the
+		 * above cases. Mangle the TIF_SPEC_IB bit into the mm
+		 * pointer of the incoming task which is stored in
+		 * cpu_tlbstate.last_user_mm_ibpb for comparison.
+		 */
+		next_mm = mm_mangle_tif_spec_ib(next);
+		prev_mm = this_cpu_read(cpu_tlbstate.last_user_mm_ibpb);
+
+		/*
+		 * Issue IBPB only if the mm's are different and one or
+		 * both have the IBPB bit set.
+		 */
+		if (next_mm != prev_mm &&
+		    (next_mm | prev_mm) & LAST_USER_MM_IBPB)
+			indirect_branch_prediction_barrier();
+
+		this_cpu_write(cpu_tlbstate.last_user_mm_ibpb, next_mm);
+	}
+
+	if (static_branch_unlikely(&switch_mm_always_ibpb)) {
+		/*
+		 * Only flush when switching to a user space task with a
+		 * different context than the user space task which ran
+		 * last on this CPU.
+		 */
+		if (this_cpu_read(cpu_tlbstate.last_user_mm) != next->mm) {
+			indirect_branch_prediction_barrier();
+			this_cpu_write(cpu_tlbstate.last_user_mm, next->mm);
+		}
+	}
 }
 
 void switch_mm_irqs_off(struct mm_struct *prev, struct mm_struct *next,
@@ -292,22 +367,12 @@ void switch_mm_irqs_off(struct mm_struct *prev, struct mm_struct *next,
 		new_asid = prev_asid;
 		need_flush = true;
 	} else {
-		u64 last_ctx_id = this_cpu_read(cpu_tlbstate.last_ctx_id);
-
 		/*
 		 * Avoid user/user BTB poisoning by flushing the branch
 		 * predictor when switching between processes. This stops
 		 * one process from doing Spectre-v2 attacks on another.
-		 *
-		 * As an optimization, flush indirect branches only when
-		 * switching into a processes that can't be ptrace by the
-		 * current one (as in such case, attacker has much more
-		 * convenient way how to tamper with the next process than
-		 * branch buffer poisoning).
 		 */
-		if (static_cpu_has(X86_FEATURE_USE_IBPB) &&
-				ibpb_needed(tsk, last_ctx_id))
-			indirect_branch_prediction_barrier();
+		cond_ibpb(tsk);
 
 		if (IS_ENABLED(CONFIG_VMAP_STACK)) {
 			/*
@@ -365,14 +430,6 @@ void switch_mm_irqs_off(struct mm_struct *prev, struct mm_struct *next,
 		trace_tlb_flush_rcuidle(TLB_FLUSH_ON_TASK_SWITCH, 0);
 	}
 
-	/*
-	 * Record last user mm's context id, so we can avoid
-	 * flushing branch buffer with IBPB if we switch back
-	 * to the same user.
-	 */
-	if (next != &init_mm)
-		this_cpu_write(cpu_tlbstate.last_ctx_id, next->context.ctx_id);
-
 	/* Make sure we write CR3 before loaded_mm. */
 	barrier();
 
@@ -441,7 +498,7 @@ void initialize_tlbstate_and_flush(void)
 	write_cr3(build_cr3(mm->pgd, 0));
 
 	/* Reinitialize tlbstate. */
-	this_cpu_write(cpu_tlbstate.last_ctx_id, mm->context.ctx_id);
+	this_cpu_write(cpu_tlbstate.last_user_mm_ibpb, LAST_USER_MM_IBPB);
 	this_cpu_write(cpu_tlbstate.loaded_mm_asid, 0);
 	this_cpu_write(cpu_tlbstate.next_asid, 1);
 	this_cpu_write(cpu_tlbstate.ctxs[0].ctx_id, mm->context.ctx_id);
