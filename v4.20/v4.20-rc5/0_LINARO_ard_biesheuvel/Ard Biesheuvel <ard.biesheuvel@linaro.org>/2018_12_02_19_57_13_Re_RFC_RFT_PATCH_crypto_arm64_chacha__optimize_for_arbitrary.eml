Return-Path: <linux-kernel-owner@vger.kernel.org>
Delivered-To: unknown
Received: from linux.intel.com (10.54.29.200:995) by likexu-workstation with
  POP3-SSL; 03 Dec 2018 08:41:21 -0000
X-Original-To: like.xu@linux.intel.com
Delivered-To: like.xu@linux.intel.com
Received: from orsmga005.jf.intel.com (orsmga005.jf.intel.com [10.7.209.41])
	(using TLSv1.2 with cipher ECDHE-RSA-AES256-GCM-SHA384 (256/256 bits))
	(No client certificate requested)
	by linux.intel.com (Postfix) with ESMTPS id EE686580224;
	Sun,  2 Dec 2018 11:57:38 -0800 (PST)
Received: from fmsmga103.fm.intel.com ([10.1.193.90])
  by orsmga005-1.jf.intel.com with ESMTP/TLS/DHE-RSA-AES256-GCM-SHA384; 02 Dec 2018 11:57:38 -0800
X-SG-BADATTACHMENTNOREPLY: True
IronPort-PHdr: =?us-ascii?q?9a23=3AFld+TB+sG60Ytv9uRHKM819IXTAuvvDOBiVQ1KB9?=
 =?us-ascii?q?1u0QIJqq85mqBkHD//Il1AaPAd2Lraocw8Pt8InYEVQa5piAtH1QOLdtbDQizf?=
 =?us-ascii?q?ssogo7HcSeAlf6JvO5JwYzHcBFSUM3tyrjaRsdF8nxfUDdrWOv5jAOBBr/KRB1?=
 =?us-ascii?q?JuPoEYLOksi7ze+/94HQbglSmDaxfa55IQmrownWqsQYm5ZpJLwryhvOrHtIeu?=
 =?us-ascii?q?BWyn1tKFmOgRvy5dq+8YB6/ShItP0v68BPUaPhf6QlVrNYFygpM3o05MLwqxbO?=
 =?us-ascii?q?SxaE62YGXWUXlhpIBBXF7A3/U5zsvCb2qvZx1S+HNsDtU7s6RSqt4LtqSB/wiS?=
 =?us-ascii?q?cIKTg58H3MisdtiK5XuQ+tqwBjz4LRZoyeKfhwcb7Hfd4CSmVBUMReWSxPDI2/?=
 =?us-ascii?q?coUBEfYOPf1Ar4T/vFYOsQeyCBOwCO/z1jNFhHn71rA63eQ7FgHG2RQtEs4UsH?=
 =?us-ascii?q?vJsd74KaYSXv6uzKnI0zrDcu1W1in56IPVdR0uu+uMUq9qfcXKyEkgCRjFjlWO?=
 =?us-ascii?q?poz4ITOayOANvnOf7+phU+KgkXQnqwZrrjio3McshZDEi4QIwV7K8iV5xZw6Jd?=
 =?us-ascii?q?y+SENjfdGkEIFfuD2aN4RsW88iRX9nuCE8yrEfpZG7ezIKx4o9yx7EcPOKdZWD?=
 =?us-ascii?q?7BH7VOuJPzt0mHZodKiiixu870Ss0PDwW8qo3FpQrydIkMHAum4R2xHX8MSKSf?=
 =?us-ascii?q?tw8l281TuO1g3f8OBJLEIymKHGMZAu2KQwmYAWsUnbHi/5hkH2jKiOe0U69ein?=
 =?us-ascii?q?9f7nbq/lppCCLY90jB/xMqA0lsy4G+Q4PRACX2md+euiyL3u5VP1TKlOg/Esj6?=
 =?us-ascii?q?XUvo7WKd4GqqO6HwNZyIcu5hSnAzejytsYnH0HLFxfeBKAiojkI1XOIPH+Dfei?=
 =?us-ascii?q?jFWgiTRryO7cPr3nHJrNKmHPkLDvfLZ79UFc0hE+zc5Q551KELENOvHzVVHrtN?=
 =?us-ascii?q?zeEBA5Nxa4w+H9CNVyzo8eQ36AAreFMKPOtl+F/uYvI+iPZIALojr8JOUl6uXq?=
 =?us-ascii?q?jX84n18dYKao0YEWaHC+AvRpPUGZbWDwjdcGFGcAphA+Q/DyiF2eTT5TYG6/X6?=
 =?us-ascii?q?Im6TE6FIKpF4DDSpqtgLycxii7GJJWa3tCClCNF3foaoqFV+0NaCKUPs9ujDgE?=
 =?us-ascii?q?WaK9RI8m0BGkrBX6xKZ/LurI5i0Ysoru1Npy5+LNjx0y9jt0D8Kb02GKVGx0mm?=
 =?us-ascii?q?IIRzkr3KFwu0B9y1GD0bRmjPxcD9Bc+/RJUgIiP57G0+N6E8zyWh7GftqRUlmm?=
 =?us-ascii?q?WdWmATYyTt4r2d8BeUR9Fs6mjhDC2SqqHrAUm6aKBJwy7qLTwXzxK9xhxHbB0a?=
 =?us-ascii?q?krl0MmTddXNW26mq5/8BDeB43TnEWfjaqqcaUc0zTL9GeM1meOuEBYUAhtUaTK?=
 =?us-ascii?q?R3wfZ03Wrcjn6UPGVbOhFbMnMg5Zw86YNqRKcsHpjUlBRPr7JdvReXyxlHmqCR?=
 =?us-ascii?q?aI3LyMapHqdHsb3CnaDEgEkAUT/XKdOAg6ByehpX/eDTN0GVLuZUPs7fdxqHeh?=
 =?us-ascii?q?QkAoyAGKalVr16Cp9R4NmfycV/QT06oZtyg7tTV7Akyx39LMBNqGvApuYqNcbM?=
 =?us-ascii?q?g54FdG02LZqgN8MoahL6Bkml4RbQB3s1ny2BVwD4VKidIqo28yzApuNaKY10tM?=
 =?us-ascii?q?dy+Z3ZD1Pb3XNmny/RC1Z67KwF3e18yW+qMO6PQ+pFXupwWpFksk83V63NhZyX?=
 =?us-ascii?q?qc5pPWDAUMVZL9SFo49x9/p7vCeCky+5vU1WFwMamzqjLNwdYpC/Uqyxm+f9ZT?=
 =?us-ascii?q?KriLFBLvHMIAAciuK+sqm0ayYxIAPeBS8rM0Psy8e/uH3q6rIPhvnDa8gWtb54?=
 =?us-ascii?q?B911qG9zBgRe7Qw5YF3/aY0xOHVjfhlluurtr7mIFEZT4IGGq/xjPpBIpQZq10?=
 =?us-ascii?q?YIYKBn2iI8yxxtVimZHtX2RU+0KkB1MDwMWpYwadb0Th3Q1M0kQauWanmSqkwD?=
 =?us-ascii?q?NuiTEms62f0DbIw+v8bhoHO3dHS3V4glfoPIe7kcoaXE+ubwUykBul5ED6x7VU?=
 =?us-ascii?q?pahlLmnTR1tIcDbyL214TqSwsb+CadZV6Jw0qSVXTPi8YVeCR7/9ohsWySPiE3?=
 =?us-ascii?q?FFxDAmcTGnoZH5nx18iGKAI3d/tnvZecdsxRjB4NzQX+Je3j0DRCNgkznYGkC8?=
 =?us-ascii?q?P8W1/dWTj5rDsPqxV3iiVp1Qdinn15iAuzG45W1pAB2/me68mtv8HAg+0C/70c?=
 =?us-ascii?q?RqVCrSoBb9ZInry7q1MeZ9ckZ0A1/87tJwGptinYsomJEQxX8ai42V/HUdlmf/?=
 =?us-ascii?q?K9db2aP4bHcWQT4LwtjV4BXq2UF5L3KJwZ75WWuZwsd7e9a6ZWYW0Don789WEK?=
 =?us-ascii?q?eU8KBEnSxtr1q7tw3RYOJxnjcAyfQ07n4ajPoEuA4sziWbH7ATElNUPS3qlxSU?=
 =?us-ascii?q?8d++qL9ba3qocbi1zEB+h8yuDKmeogFAX3b0YpIiHS5z7splKl7N3mP86pr4eN?=
 =?us-ascii?q?bOd9IcrQObkw3Pj+VOLJIxl/wKhTdoOG7nvH0lzfI7ggJq3Z2goIeHLGBt9rqj?=
 =?us-ascii?q?AhFELj31e98T+jb1gKZCmcaW2pqjH5R7FTUNQZvoVumoEDMJuPTjNgaOFiA8q3?=
 =?us-ascii?q?iBFbreGw+f9Flpr3bVH5+3MHGXIWETzc9+SxmFOExfnAcUUS0hkZEjEQCqwNHh?=
 =?us-ascii?q?fF195jAM/VP4rhpMyuR1NxjwSGvfpQGoaisqR5ibNhZZ8gZC50LNO8yE8u1zBz?=
 =?us-ascii?q?1Y/oGmrAGVKGyUfQFIAn8SWkCeG1DvJLqu5cTD8+iFAOqxNeDObK6KqexfUfeI?=
 =?us-ascii?q?2J2u3pFn/zaKKsWAIH1iA+cn1UpEWHBzA97ZlCkXSywLiyLNaNaWpRe7+i1qt8?=
 =?us-ascii?q?C/7e7kWAT16YuUDLtSN9pv9guygaeCMe6QmSl4JSxZ1pMK2X/H1rwf0EQOhCFp?=
 =?us-ascii?q?cjmnCa4AujLVTKLMhq9XCAYWayNtO8tJ7KI83QhNNdTYitPv0b54geA6C01YVV?=
 =?us-ascii?q?z6gcypYc0KI2egNFLIHkqLNbKGJSHVzMHze6+zVbpQjOBMvR2qpTmbC1PjPiiE?=
 =?us-ascii?q?lzTxTR+vLPpDjDuFMx1eoo29dhdtBHPnTNLnbB27LdB2gSc3wb0ymnPFK2ocPS?=
 =?us-ascii?q?JgfENKq72a9TlYjelnG2xd8nplKvGJmzqY7+ndMJoZreFnDTh0l+1E5nQ30L9V?=
 =?us-ascii?q?7CBCRPxolyretN9uo1e6kuaRzjprSgZBqjFOhIiTp0VtJb3Z9oVcWXbD5B8M7X?=
 =?us-ascii?q?+fCxIPp9tkDN3go6FRytjVm6L1JzdP6NbU/coaB8jJJ8OLKnshMRz1GDHKCAsJ?=
 =?us-ascii?q?VyKkNWbahx8VrPbHvHqNo55yrpn3hMguY4V3a3UPO7sgI2JJO/lKBqpSdB4e2Z?=
 =?us-ascii?q?G2quMyzEaZllH6Y/939NiTUvOUHOWqIyyIlaVDTwUHzKm+LokJMID/nUt4ZQ8p?=
 =?us-ascii?q?sp7NHh/5R9wFiCxsdQ85vVtA9DAqR3c/nUjkZxit7WINGPqcmh8wgxF5J+M3+2?=
 =?us-ascii?q?G/sB8MOlPWqX5owwEKktL/jGXUKWapIQ=3D=3D?=
X-IronPort-Anti-Spam-Filtered: true
X-IronPort-Anti-Spam-Result: =?us-ascii?q?A0AtAACtOARch0O0hNFiHQEBBQEHBQGBU?=
 =?us-ascii?q?wYBCwGDayeDeZQggg0UaJZMgWwzEwGHdiI2Bw0BAwEBAQEBAQIBEwEBAQoLCQg?=
 =?us-ascii?q?pIwyCNiQBgmEBAQEBAgEBAiAdAQEqDQEEAQkBAQoLDQICJgICAx8SAQUBHAYTB?=
 =?us-ascii?q?YMcgXoIBZZFPIodcIEvgnYBAQWHGAgSeYkLRIFCgVc/gRGCXTWETYM4gleJLoF?=
 =?us-ascii?q?zlSEHAoIfBI8ZGIFbj0uCe4cMjlcwgSwLgXt9dAaCNYIbCQMFEohehUA+M4EFA?=
 =?us-ascii?q?QGMLgEB?=
X-IPAS-Result: =?us-ascii?q?A0AtAACtOARch0O0hNFiHQEBBQEHBQGBUwYBCwGDayeDeZQ?=
 =?us-ascii?q?ggg0UaJZMgWwzEwGHdiI2Bw0BAwEBAQEBAQIBEwEBAQoLCQgpIwyCNiQBgmEBA?=
 =?us-ascii?q?QEBAgEBAiAdAQEqDQEEAQkBAQoLDQICJgICAx8SAQUBHAYTBYMcgXoIBZZFPIo?=
 =?us-ascii?q?dcIEvgnYBAQWHGAgSeYkLRIFCgVc/gRGCXTWETYM4gleJLoFzlSEHAoIfBI8ZG?=
 =?us-ascii?q?IFbj0uCe4cMjlcwgSwLgXt9dAaCNYIbCQMFEohehUA+M4EFAQGMLgEB?=
X-IronPort-AV: E=Sophos;i="5.56,307,1539673200"; 
   d="scan'208";a="54206960"
X-Amp-Result: SKIPPED(no attachment in message)
X-Amp-File-Uploaded: False
Received: from vger.kernel.org ([209.132.180.67])
  by mtab.intel.com with ESMTP; 02 Dec 2018 11:57:36 -0800
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
        id S1725784AbeLBT53 (ORCPT <rfc822;like.xu@linux.intel.com>
        + 23 others); Sun, 2 Dec 2018 14:57:29 -0500
Received: from mail-io1-f67.google.com ([209.85.166.67]:43191 "EHLO
        mail-io1-f67.google.com" rhost-flags-OK-OK-OK-OK) by vger.kernel.org
        with ESMTP id S1725710AbeLBT53 (ORCPT
        <rfc822;linux-kernel@vger.kernel.org>);
        Sun, 2 Dec 2018 14:57:29 -0500
Received: by mail-io1-f67.google.com with SMTP id f10so2879796iop.10
        for <linux-kernel@vger.kernel.org>; Sun, 02 Dec 2018 11:57:25 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=linaro.org; s=google;
        h=mime-version:references:in-reply-to:from:date:message-id:subject:to
         :cc;
        bh=oT7FrA4WVZh5UlWYxwLUSym9qcZhgcaFyM9+h+p+4jg=;
        b=CTpJKB3YGC4bp2rlPMaeT8VuTK5k9ROBhfPSoqxZ1FHwm4QVerpZLlwcQnTkASTcul
         sjg+FBUwib/bsrKw3qVCDl/bfs0+juqCAkqK9Kl9vinEAu96fFI8ki8Sq0q31V0S2jSE
         RwJ4FDp8RPV5m5RVGGEpW78HZMyE1gJ4m/EaI=
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20161025;
        h=x-gm-message-state:mime-version:references:in-reply-to:from:date
         :message-id:subject:to:cc;
        bh=oT7FrA4WVZh5UlWYxwLUSym9qcZhgcaFyM9+h+p+4jg=;
        b=r86R9B4E/3PjsBhcRgIzyU2ytSpNGqjtzrS2Wsj28kGpS5SYneqf7/DOQwELGUElkS
         FHx9o25WYialI2h02wIW2q7/cP350/Z1kzexw9Bdhfdd3lFl8uJ8p/J9ofxXzfByPhsQ
         eZwwyfr/7ttPwD8ekGU/UeXSMSCax+Mzk0NXaXxzZjwfh4dwWwrWnQbbSTzza1Bkl9Dj
         QX48oSxX3V4C60IBhu7RC2CYV08FXy4n2LgACzf4u7k0JHyoBWxANWlqp5ciPotZTKmU
         rxQS8q7cRq1OA2NUnsQMxBSpWTGroeGrLa4ebl+Ksib9JPWbx2QfECrrsS8nO0JO0YKX
         EwQg==
X-Gm-Message-State: AA+aEWaDE4oMRt8ofzURbaHPMno8P+Q9I4XI+kr1SHDqdP1lnHVotcbr
        AAGCkQnipMJKj1WaeYTw9GGcMvQ6zAyFTfud3JDueQ==
X-Google-Smtp-Source: AFSGD/UtTWzAH6yL5S52y/nXXTJLJoPRB9clu9tZ6Xmb9dMgLgnwQqPACd5dbbsQfLw4PG5OL9xU9l2iZcQ45Y+JXhQ=
X-Received: by 2002:a6b:5d01:: with SMTP id r1mr11118003iob.170.1543780645075;
 Sun, 02 Dec 2018 11:57:25 -0800 (PST)
MIME-Version: 1.0
References: <20181130203811.30269-1-ard.biesheuvel@linaro.org>
In-Reply-To: <20181130203811.30269-1-ard.biesheuvel@linaro.org>
From: Ard Biesheuvel <ard.biesheuvel@linaro.org>
Date: Sun, 2 Dec 2018 20:57:13 +0100
Message-ID: <CAKv+Gu8zFDS_hJSB916h7eni2t8Occ0-2U_eSayZDAz-=ApwQg@mail.gmail.com>
Subject: Re: [RFC/RFT PATCH] crypto: arm64/chacha - optimize for arbitrary
 length inputs
To: "open list:HARDWARE RANDOM NUMBER GENERATOR CORE" 
        <linux-crypto@vger.kernel.org>
Cc: Linux Kernel Mailing List <linux-kernel@vger.kernel.org>,
        linux-arm-kernel <linux-arm-kernel@lists.infradead.org>,
        Herbert Xu <herbert@gondor.apana.org.au>,
        Eric Biggers <ebiggers@kernel.org>,
        Martin Willi <martin@strongswan.org>
Content-Type: text/plain; charset="UTF-8"
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: <linux-kernel.vger.kernel.org>
X-Mailing-List: linux-kernel@vger.kernel.org

On Fri, 30 Nov 2018 at 21:38, Ard Biesheuvel <ard.biesheuvel@linaro.org> wrote:
>
> Update the 4-way NEON ChaCha routine so it can handle input of any
> length >64 bytes in its entirety, rather than having to call into
> the 1-way routine and/or do memcpy()s via temp buffers to handle the
> tail of a ChaCha invocation that is not a multiple of 256 bytes.
>
> On inputs that are a multiple of 256 bytes (and thus in tcrypt
> benchmarks), performance drops by around 1% on Cortex-A57, while
> performance for inputs drawn randomly from the range [64, 1024+64)
> increases by around 30% (using ChaCha20). On Cortex-A72, performance
> gains are similar. On Cortex-A53, performance improves but only by 5%.
>
> Cc: Eric Biggers <ebiggers@kernel.org>
> Cc: Martin Willi <martin@strongswan.org>
> Signed-off-by: Ard Biesheuvel <ard.biesheuvel@linaro.org>
> ---
> Test program after the patch.
>

Perhaps a better benchmark below: I added 1472 byte blocks to the
tcrypt template (which should reflect the VPN case IIUC), and that
gives me (before/after)

tcrypt: test 0 (256 bit key, 16 byte blocks): 2848103 operations in 1
seconds (45569648 bytes)
tcrypt: test 1 (256 bit key, 64 byte blocks): 2840030 operations in 1
seconds (181761920 bytes)
tcrypt: test 2 (256 bit key, 256 byte blocks): 1408404 operations in 1
seconds (360551424 bytes)
tcrypt: test 3 (256 bit key, 1024 byte blocks): 390180 operations in 1
seconds (399544320 bytes)
tcrypt: test 4 (256 bit key, 1472 byte blocks): 217175 operations in 1
seconds (319681600 bytes)
tcrypt: test 5 (256 bit key, 8192 byte blocks): 49271 operations in 1
seconds (403628032 bytes)

tcrypt: test 0 (256 bit key, 16 byte blocks): 2960809 operations in 1
seconds (47372944 bytes)
tcrypt: test 1 (256 bit key, 64 byte blocks): 2970977 operations in 1
seconds (190142528 bytes)
tcrypt: test 2 (256 bit key, 256 byte blocks): 1404117 operations in 1
seconds (359453952 bytes)
tcrypt: test 3 (256 bit key, 1024 byte blocks): 390356 operations in 1
seconds (399724544 bytes)
tcrypt: test 4 (256 bit key, 1472 byte blocks): 261865 operations in 1
seconds (385465280 bytes)
tcrypt: test 5 (256 bit key, 8192 byte blocks): 49311 operations in 1
seconds (403955712 bytes)


>  arch/arm64/crypto/chacha-neon-core.S | 185 ++++++++++++++++++--
>  arch/arm64/crypto/chacha-neon-glue.c |  36 ++--
>  2 files changed, 188 insertions(+), 33 deletions(-)
>
> diff --git a/arch/arm64/crypto/chacha-neon-core.S b/arch/arm64/crypto/chacha-neon-core.S
> index 75b4e06cee79..45ffc51cb437 100644
> --- a/arch/arm64/crypto/chacha-neon-core.S
> +++ b/arch/arm64/crypto/chacha-neon-core.S
> @@ -19,6 +19,7 @@
>   */
>
>  #include <linux/linkage.h>
> +#include <asm/cache.h>
>
>         .text
>         .align          6
> @@ -164,6 +165,7 @@ ENTRY(chacha_4block_xor_neon)
>         // x1: 4 data blocks output, o
>         // x2: 4 data blocks input, i
>         // w3: nrounds
> +       // x4: byte count
>
>         //
>         // This function encrypts four consecutive ChaCha blocks by loading
> @@ -177,11 +179,11 @@ ENTRY(chacha_4block_xor_neon)
>         ld1             {v30.4s-v31.4s}, [x9]
>
>         // x0..15[0-3] = s0..3[0..3]
> -       mov             x4, x0
> -       ld4r            { v0.4s- v3.4s}, [x4], #16
> -       ld4r            { v4.4s- v7.4s}, [x4], #16
> -       ld4r            { v8.4s-v11.4s}, [x4], #16
> -       ld4r            {v12.4s-v15.4s}, [x4]
> +       mov             x8, x0
> +       ld4r            { v0.4s- v3.4s}, [x8], #16
> +       ld4r            { v4.4s- v7.4s}, [x8], #16
> +       ld4r            { v8.4s-v11.4s}, [x8], #16
> +       ld4r            {v12.4s-v15.4s}, [x8]
>
>         // x12 += counter values 0-3
>         add             v12.4s, v12.4s, v30.4s
> @@ -425,24 +427,47 @@ ENTRY(chacha_4block_xor_neon)
>         zip1            v30.4s, v14.4s, v15.4s
>         zip2            v31.4s, v14.4s, v15.4s
>
> +       mov             x3, #64
> +       subs            x5, x4, #64
> +       add             x6, x5, x2
> +       csel            x3, x3, xzr, ge
> +       csel            x2, x2, x6, ge
> +
>         // interleave 64-bit words in state n, n+2
>         zip1            v0.2d, v16.2d, v18.2d
>         zip2            v4.2d, v16.2d, v18.2d
>         zip1            v8.2d, v17.2d, v19.2d
>         zip2            v12.2d, v17.2d, v19.2d
> -       ld1             {v16.16b-v19.16b}, [x2], #64
> +       ld1             {v16.16b-v19.16b}, [x2], x3
> +
> +       subs            x6, x4, #128
> +       ccmp            x3, xzr, #4, lt
> +       add             x7, x6, x2
> +       csel            x3, x3, xzr, eq
> +       csel            x2, x2, x7, eq
>
>         zip1            v1.2d, v20.2d, v22.2d
>         zip2            v5.2d, v20.2d, v22.2d
>         zip1            v9.2d, v21.2d, v23.2d
>         zip2            v13.2d, v21.2d, v23.2d
> -       ld1             {v20.16b-v23.16b}, [x2], #64
> +       ld1             {v20.16b-v23.16b}, [x2], x3
> +
> +       subs            x7, x4, #192
> +       ccmp            x3, xzr, #4, lt
> +       add             x8, x7, x2
> +       csel            x3, x3, xzr, eq
> +       csel            x2, x2, x8, eq
>
>         zip1            v2.2d, v24.2d, v26.2d
>         zip2            v6.2d, v24.2d, v26.2d
>         zip1            v10.2d, v25.2d, v27.2d
>         zip2            v14.2d, v25.2d, v27.2d
> -       ld1             {v24.16b-v27.16b}, [x2], #64
> +       ld1             {v24.16b-v27.16b}, [x2], x3
> +
> +       subs            x8, x4, #256
> +       ccmp            x3, xzr, #4, lt
> +       add             x9, x8, x2
> +       csel            x2, x2, x9, eq
>
>         zip1            v3.2d, v28.2d, v30.2d
>         zip2            v7.2d, v28.2d, v30.2d
> @@ -451,29 +476,167 @@ ENTRY(chacha_4block_xor_neon)
>         ld1             {v28.16b-v31.16b}, [x2]
>
>         // xor with corresponding input, write to output
> +       tbnz            x5, #63, 0f
>         eor             v16.16b, v16.16b, v0.16b
>         eor             v17.16b, v17.16b, v1.16b
>         eor             v18.16b, v18.16b, v2.16b
>         eor             v19.16b, v19.16b, v3.16b
> +       st1             {v16.16b-v19.16b}, [x1], #64
> +
> +       tbnz            x6, #63, 1f
>         eor             v20.16b, v20.16b, v4.16b
>         eor             v21.16b, v21.16b, v5.16b
> -       st1             {v16.16b-v19.16b}, [x1], #64
>         eor             v22.16b, v22.16b, v6.16b
>         eor             v23.16b, v23.16b, v7.16b
> +       st1             {v20.16b-v23.16b}, [x1], #64
> +
> +       tbnz            x7, #63, 2f
>         eor             v24.16b, v24.16b, v8.16b
>         eor             v25.16b, v25.16b, v9.16b
> -       st1             {v20.16b-v23.16b}, [x1], #64
>         eor             v26.16b, v26.16b, v10.16b
>         eor             v27.16b, v27.16b, v11.16b
> -       eor             v28.16b, v28.16b, v12.16b
>         st1             {v24.16b-v27.16b}, [x1], #64
> +
> +       tbnz            x8, #63, 3f
> +       eor             v28.16b, v28.16b, v12.16b
>         eor             v29.16b, v29.16b, v13.16b
>         eor             v30.16b, v30.16b, v14.16b
>         eor             v31.16b, v31.16b, v15.16b
>         st1             {v28.16b-v31.16b}, [x1]
>
>         ret
> +
> +       // fewer than 64 bytes of in/output
> +0:     adr             x12, .Lpermute
> +       add             x12, x12, x5
> +       sub             x2, x1, #64
> +       add             x1, x1, x5
> +       add             x13, x12, #64
> +       ld1             {v8.16b}, [x12]
> +       ld1             {v9.16b}, [x13]
> +       movi            v10.16b, #16
> +
> +       ld1             {v16.16b-v19.16b}, [x2]
> +       tbl             v4.16b, {v0.16b-v3.16b}, v8.16b
> +       tbx             v20.16b, {v16.16b-v19.16b}, v9.16b
> +       add             v8.16b, v8.16b, v10.16b
> +       add             v9.16b, v9.16b, v10.16b
> +       tbl             v5.16b, {v0.16b-v3.16b}, v8.16b
> +       tbx             v21.16b, {v16.16b-v19.16b}, v9.16b
> +       add             v8.16b, v8.16b, v10.16b
> +       add             v9.16b, v9.16b, v10.16b
> +       tbl             v6.16b, {v0.16b-v3.16b}, v8.16b
> +       tbx             v22.16b, {v16.16b-v19.16b}, v9.16b
> +       add             v8.16b, v8.16b, v10.16b
> +       add             v9.16b, v9.16b, v10.16b
> +       tbl             v7.16b, {v0.16b-v3.16b}, v8.16b
> +       tbx             v23.16b, {v16.16b-v19.16b}, v9.16b
> +
> +       eor             v20.16b, v20.16b, v4.16b
> +       eor             v21.16b, v21.16b, v5.16b
> +       eor             v22.16b, v22.16b, v6.16b
> +       eor             v23.16b, v23.16b, v7.16b
> +       st1             {v20.16b-v23.16b}, [x1]
> +       ret
> +
> +       // fewer than 128 bytes of in/output
> +1:     adr             x12, .Lpermute
> +       add             x12, x12, x6
> +       add             x1, x1, x6
> +       add             x13, x12, #64
> +       ld1             {v8.16b}, [x12]
> +       ld1             {v9.16b}, [x13]
> +       movi            v10.16b, #16
> +       tbl             v0.16b, {v4.16b-v7.16b}, v8.16b
> +       tbx             v20.16b, {v16.16b-v19.16b}, v9.16b
> +       add             v8.16b, v8.16b, v10.16b
> +       add             v9.16b, v9.16b, v10.16b
> +       tbl             v1.16b, {v4.16b-v7.16b}, v8.16b
> +       tbx             v21.16b, {v16.16b-v19.16b}, v9.16b
> +       add             v8.16b, v8.16b, v10.16b
> +       add             v9.16b, v9.16b, v10.16b
> +       tbl             v2.16b, {v4.16b-v7.16b}, v8.16b
> +       tbx             v22.16b, {v16.16b-v19.16b}, v9.16b
> +       add             v8.16b, v8.16b, v10.16b
> +       add             v9.16b, v9.16b, v10.16b
> +       tbl             v3.16b, {v4.16b-v7.16b}, v8.16b
> +       tbx             v23.16b, {v16.16b-v19.16b}, v9.16b
> +
> +       eor             v20.16b, v20.16b, v0.16b
> +       eor             v21.16b, v21.16b, v1.16b
> +       eor             v22.16b, v22.16b, v2.16b
> +       eor             v23.16b, v23.16b, v3.16b
> +       st1             {v20.16b-v23.16b}, [x1]
> +       ret
> +
> +       // fewer than 192 bytes of in/output
> +2:     adr             x12, .Lpermute
> +       add             x12, x12, x7
> +       add             x1, x1, x7
> +       add             x13, x12, #64
> +       ld1             {v4.16b}, [x12]
> +       ld1             {v5.16b}, [x13]
> +       movi            v6.16b, #16
> +       tbl             v0.16b, {v8.16b-v11.16b}, v4.16b
> +       tbx             v24.16b, {v20.16b-v23.16b}, v5.16b
> +       add             v4.16b, v4.16b, v6.16b
> +       add             v5.16b, v5.16b, v6.16b
> +       tbl             v1.16b, {v8.16b-v11.16b}, v4.16b
> +       tbx             v25.16b, {v20.16b-v23.16b}, v5.16b
> +       add             v4.16b, v4.16b, v6.16b
> +       add             v5.16b, v5.16b, v6.16b
> +       tbl             v2.16b, {v8.16b-v11.16b}, v4.16b
> +       tbx             v26.16b, {v20.16b-v23.16b}, v5.16b
> +       add             v4.16b, v4.16b, v6.16b
> +       add             v5.16b, v5.16b, v6.16b
> +       tbl             v3.16b, {v8.16b-v11.16b}, v4.16b
> +       tbx             v27.16b, {v20.16b-v23.16b}, v5.16b
> +
> +       eor             v24.16b, v24.16b, v0.16b
> +       eor             v25.16b, v25.16b, v1.16b
> +       eor             v26.16b, v26.16b, v2.16b
> +       eor             v27.16b, v27.16b, v3.16b
> +       st1             {v24.16b-v27.16b}, [x1]
> +       ret
> +
> +       // fewer than 256 bytes of in/output
> +3:     adr             x12, .Lpermute
> +       add             x12, x12, x8
> +       add             x1, x1, x8
> +       add             x13, x12, #64
> +       ld1             {v4.16b}, [x12]
> +       ld1             {v5.16b}, [x13]
> +       movi            v6.16b, #16
> +       tbl             v0.16b, {v12.16b-v15.16b}, v4.16b
> +       tbx             v28.16b, {v24.16b-v27.16b}, v5.16b
> +       add             v4.16b, v4.16b, v6.16b
> +       add             v5.16b, v5.16b, v6.16b
> +       tbl             v1.16b, {v12.16b-v15.16b}, v4.16b
> +       tbx             v29.16b, {v24.16b-v27.16b}, v5.16b
> +       add             v4.16b, v4.16b, v6.16b
> +       add             v5.16b, v5.16b, v6.16b
> +       tbl             v2.16b, {v12.16b-v15.16b}, v4.16b
> +       tbx             v30.16b, {v24.16b-v27.16b}, v5.16b
> +       add             v4.16b, v4.16b, v6.16b
> +       add             v5.16b, v5.16b, v6.16b
> +       tbl             v3.16b, {v12.16b-v15.16b}, v4.16b
> +       tbx             v31.16b, {v24.16b-v27.16b}, v5.16b
> +
> +       eor             v28.16b, v28.16b, v0.16b
> +       eor             v29.16b, v29.16b, v1.16b
> +       eor             v30.16b, v30.16b, v2.16b
> +       eor             v31.16b, v31.16b, v3.16b
> +       st1             {v28.16b-v31.16b}, [x1]
> +       ret
>  ENDPROC(chacha_4block_xor_neon)
>
>  CTRINC:        .word           0, 1, 2, 3
>  ROT8:  .word           0x02010003, 0x06050407, 0x0a09080b, 0x0e0d0c0f
> +
> +       .align          L1_CACHE_SHIFT
> +       .set            .Lpermute, . + 64
> +       .set            .Li, 0
> +       .rept           192
> +       .byte           (.Li - 64)
> +       .set            .Li, .Li + 1
> +       .endr
> diff --git a/arch/arm64/crypto/chacha-neon-glue.c b/arch/arm64/crypto/chacha-neon-glue.c
> index 346eb85498a1..458d9b36cf9d 100644
> --- a/arch/arm64/crypto/chacha-neon-glue.c
> +++ b/arch/arm64/crypto/chacha-neon-glue.c
> @@ -32,41 +32,33 @@
>  asmlinkage void chacha_block_xor_neon(u32 *state, u8 *dst, const u8 *src,
>                                       int nrounds);
>  asmlinkage void chacha_4block_xor_neon(u32 *state, u8 *dst, const u8 *src,
> -                                      int nrounds);
> +                                      int nrounds, int bytes);
>  asmlinkage void hchacha_block_neon(const u32 *state, u32 *out, int nrounds);
>
>  static void chacha_doneon(u32 *state, u8 *dst, const u8 *src,
> -                         unsigned int bytes, int nrounds)
> +                         int bytes, int nrounds)
>  {
>         u8 buf[CHACHA_BLOCK_SIZE];
>
> -       while (bytes >= CHACHA_BLOCK_SIZE * 4) {
> +       if (bytes < CHACHA_BLOCK_SIZE) {
> +               memcpy(buf, src, bytes);
>                 kernel_neon_begin();
> -               chacha_4block_xor_neon(state, dst, src, nrounds);
> +               chacha_block_xor_neon(state, buf, buf, nrounds);
> +               kernel_neon_end();
> +               memcpy(dst, buf, bytes);
> +               return;
> +       }
> +
> +       while (bytes > 0) {
> +               kernel_neon_begin();
> +               chacha_4block_xor_neon(state, dst, src, nrounds,
> +                                      min(bytes, CHACHA_BLOCK_SIZE * 4));
>                 kernel_neon_end();
>                 bytes -= CHACHA_BLOCK_SIZE * 4;
>                 src += CHACHA_BLOCK_SIZE * 4;
>                 dst += CHACHA_BLOCK_SIZE * 4;
>                 state[12] += 4;
>         }
> -
> -       if (!bytes)
> -               return;
> -
> -       kernel_neon_begin();
> -       while (bytes >= CHACHA_BLOCK_SIZE) {
> -               chacha_block_xor_neon(state, dst, src, nrounds);
> -               bytes -= CHACHA_BLOCK_SIZE;
> -               src += CHACHA_BLOCK_SIZE;
> -               dst += CHACHA_BLOCK_SIZE;
> -               state[12]++;
> -       }
> -       if (bytes) {
> -               memcpy(buf, src, bytes);
> -               chacha_block_xor_neon(state, buf, buf, nrounds);
> -               memcpy(dst, buf, bytes);
> -       }
> -       kernel_neon_end();
>  }
>
>  static int chacha_neon_stream_xor(struct skcipher_request *req,
> --
> 2.19.1
>
>
> #include <stdlib.h>
> #include <string.h>
>
> extern void chacha_4block_xor_neon(unsigned int *state, unsigned char *dst,
>                                    unsigned char *src, int rounds, int bytes);
>
> extern void chacha_block_xor_neon(unsigned int *state, unsigned char *dst,
>                                   unsigned char *src, int rounds);
>
> int main(void)
> {
>         static char buf[1024];
>         unsigned int state[64];
>
>         srand(20181130);
>
>         for (int i = 0; i < 10 * 1000 * 1000; i++) {
>                 int l = 64 + rand() % (1024 - 64);
>
> #ifdef NEW
>                 while (l > 0) {
>                         chacha_4block_xor_neon(state, buf, buf, 20,
>                                                l > 256 ? 256 : l);
>                         l -= 256;
>                 }
> #else
>                 while (l >= 256) {
>                         chacha_4block_xor_neon(state, buf, buf, 20, 256);
>                         l -= 256;
>                 }
>                 while (l >= 64) {
>                         chacha_block_xor_neon(state, buf, buf, 20);
>                         l -= 64;
>                 }
>                 if (l > 0) {
>                         unsigned char tmp[64];
>
>                         memcpy(tmp, buf, l);
>                         chacha_block_xor_neon(state, tmp, tmp, 20);
>                         memcpy(buf, tmp, l);
>                 }
> #endif
>         }
>
>         return 0;
> }
