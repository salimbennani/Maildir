Return-Path: <linux-kernel-owner@vger.kernel.org>
Delivered-To: unknown
Received: from linux.intel.com (10.54.29.200:995) by likexu-workstation with
  POP3-SSL; 28 Nov 2018 12:09:45 -0000
X-Original-To: like.xu@linux.intel.com
Delivered-To: like.xu@linux.intel.com
Received: from orsmga007.jf.intel.com (orsmga007.jf.intel.com [10.7.209.58])
	(using TLSv1.2 with cipher ECDHE-RSA-AES256-GCM-SHA384 (256/256 bits))
	(No client certificate requested)
	by linux.intel.com (Postfix) with ESMTPS id 1E681580322;
	Tue, 27 Nov 2018 17:29:19 -0800 (PST)
Received: from fmsmga101.fm.intel.com ([10.1.193.65])
  by orsmga007-1.jf.intel.com with ESMTP/TLS/DHE-RSA-AES256-GCM-SHA384; 27 Nov 2018 17:29:18 -0800
X-SG-BADATTACHMENTNOREPLY: True
IronPort-PHdr: =?us-ascii?q?9a23=3AAcSyjx2ZP/UJozgEsmDT+DRfVm0co7zxezQtwd8Z?=
 =?us-ascii?q?segTK/XxwZ3uMQTl6Ol3ixeRBMOHs6IC07KempujcFRI2YyGvnEGfc4EfD4+ou?=
 =?us-ascii?q?JSoTYdBtWYA1bwNv/gYn9yNs1DUFh44yPzahANS47xaFLIv3K98yMZFAnhOgpp?=
 =?us-ascii?q?POT1HZPZg9iq2+yo9JDffwZFiCChbb9uMR67sRjfus4KjIV4N60/0AHJonxGe+?=
 =?us-ascii?q?RXwWNnO1eelAvi68mz4ZBu7T1et+ou+MBcX6r6eb84TaFDAzQ9L281/szrugLd?=
 =?us-ascii?q?QgaJ+3ART38ZkhtMAwjC8RH6QpL8uTb0u+ZhxCWXO9D9QKsqUjq+8ahkVB7oiD?=
 =?us-ascii?q?8GNzEn9mHXltdwh79frB64uhBz35LYbISTOfFjfK3SYMkaSHJcUMhPWSxPAoCy?=
 =?us-ascii?q?YYUBAOUOP+lXs4bzp0AWrRa8HgSsGODixyVUinPq06A30eIsGhzG0gw6GNIOtW?=
 =?us-ascii?q?zZosvyNKcXTOu70rPHzTHbb/xI2Tb29Y/FcgwmofGJRr9wbdDeyU03FwzbjlSc?=
 =?us-ascii?q?s5DqPzSQ1ukUtWWQ8uRuVeWqi2E9qgFxpCCixtw2hYnMnYIV11bE9SpjzIkpIt?=
 =?us-ascii?q?24TUh2asOnHptIryyWKZd6T8c4T211tis21KcKtYO4cSQW0pgqxhzSZ+SZf4WH?=
 =?us-ascii?q?+B7vSvudLDRiiH54e7+zmQy+/VWvx+DzUMS/zUxEoTBfktbWs3AAzxzT5daDSv?=
 =?us-ascii?q?t65kqhxzmP2B7J6u1eIkA7i7DbK5g/zb40jJYTtl7DHiDulEX3iq+ZaFkk9/C2?=
 =?us-ascii?q?5+j7ZrjqvIKQOoFqhg3kL6gjmdCzDf45PwUMR2Sb/P6z1Lzn/U33WrVKifg2n7?=
 =?us-ascii?q?HdsJDbI8Qbu6G4DxZW0ok98Ra/CSmp0NABkXkAIlNFfgyIj5LyNlHQL/D3E+2/?=
 =?us-ascii?q?j06vkDh13fDGOKPuApHXInjEirfhcq5x61RAxwor0dBf+5VUB6kFIPLyWU/+qs?=
 =?us-ascii?q?bUDxAkMwGvx+bnCdN91p4RWG6VA6+ZNr/SvkGM5u41P+aMY4oVsi7nK/c5//7u?=
 =?us-ascii?q?kWM5mVgFcKmpx5QXaWy4Ee5hI0mDYXrsn80OEWEFvgclSOzqiVuCUSNcZnqoXq?=
 =?us-ascii?q?I84C07B5yiDYvZWo+th7mB1j+hHpJKfmBGFkyMEXDweoWGXPcDdjieIsxmkjwC?=
 =?us-ascii?q?U7ihTJQs1RWvtA/81rpmIfDY+iwetZL/ytd14/ffmg019TxxF86dyX2CT3lonm?=
 =?us-ascii?q?MUQD87xLpwoVd9yleE0qh0meZYGsZR5/5SVgc6NJjcz/F1CtzoWwLBeMuJR0ii?=
 =?us-ascii?q?Qtm8HT4xSdcxyccUY0lhA9WikgzD3y2yDr8WjbOLAoY48qbd33frIcZ9xG3L1K?=
 =?us-ascii?q?0gj1kgX8tOOneqhq959wjPGYHJl1+VmLqtdaQZxCTN7nuMzXKSvEFEVw59SbjK?=
 =?us-ascii?q?UmoBZkTIt9j55lnNT7m1Cbs5NAtNzsqCKqhPat3tllhGQPbjONLDY2O+gWuwBB?=
 =?us-ascii?q?CIxq+SY4ruYWkSwCLdCE0cmQAJ4XmGLRQ+Bjumo2/GETNhD0zvbF32/el+sny7?=
 =?us-ascii?q?SFQ0wB+Mb0B607q1+xgVheGTSv8J37IEvjshpCtwHFqnw93WDN+ArRJ7fKpAed?=
 =?us-ascii?q?M9/EtH1WXBugxhP5ygKqdihkIecwV3pU/uyw97CoJakcgurXMqygVyJLmc0FNA?=
 =?us-ascii?q?cTOYwJ/xNqfWKmn04BCgdarW1kvC39aR/6cF8O44pEn7vAG1Ckoi9G1q3MNR03?=
 =?us-ascii?q?SC6ZTFEgoTXYjqXUYq6hd1vbfaYio654PKznBsNai0sjnf29MmHuclyxCgf8tB?=
 =?us-ascii?q?P6OADgP9D8oaB822Iuwwh1epdg4EPPxV9KMsP8KmauGK17KxMOdhnDKpl2JH4I?=
 =?us-ascii?q?9m30KI9ip8TPPI3pkfz/GZ2AuHSynzjFO7vs/rnoBEYCkYHnCjxij8GI5Reqpy?=
 =?us-ascii?q?cJ4RCWevP8K43M9+iIPqW3JC8l6sGUkG2M6wdRWOdVP92RBf2loNoXygnyu11D?=
 =?us-ascii?q?h0kzAvrqqC0y3C2eXidBwbOmFVQGlul0vjIY+xj9oCRkincxAplAe55Ub936Va?=
 =?us-ascii?q?pKV/I3PTQEtSZCj2MmdiX7C0trqDZc5P9ZwpvT9WUOS6fVCVVLr9rwEG3CPkGm?=
 =?us-ascii?q?tU3Co7eC2yupXlgxx6j3qQLHRpo3rDesFwxhDf6MbHRfFL3ToGRyh4iT/JCVi6?=
 =?us-ascii?q?JNSp+dSUl5HesuGxTW6hV5tTcTX1woOErie0+WpqARinlfCphtLnCRQ60TP819?=
 =?us-ascii?q?RyVSTHthH8bpPp16S7N+JqZU1oBF7668pnFYByiIowhJcM2XcEgpWZ52YIkWD2?=
 =?us-ascii?q?Md9Dw6LxcGINRSIXw97S+AXl21dsLnOTy4L5S3WS2M1hZ9ahb2MS2yI96d1KCa?=
 =?us-ascii?q?iO4LxFmyt1vkS3rQbLbfdhmTcdzOMk6GQGjOERpAot0iKdD6gXHUlZPizjjQ6E?=
 =?us-ascii?q?7t6go6VMeGagb6Kw21FgktC7A7GPuQVcWHf/epc/Ei589MR/MFTQ0HLt7oHoYs?=
 =?us-ascii?q?XfbdUWtheMiRfPk/BVKI4tlvoNnSdnJWX9vXg/x+86lxNu24y6vJOcK2Vs56+5?=
 =?us-ascii?q?Bh9YNjvoZ8Ic4D3tjKBentqI0ICrBJluBjILXJ7wR/KyDD0SrejnNxqJEDAksX?=
 =?us-ascii?q?iUA73fHQuC6Et8q3LPDoumN3WWJHkf0NVjSwORJE1ZgAAIQjo6moQ1GRytxMzk?=
 =?us-ascii?q?aE15/Cwe5kbkqhtQzeJlLxv/XX3apAi2cTc4UoSfIABV7gFf5EfVLMqe4fhoHy?=
 =?us-ascii?q?xD+p2hrQqNKnGUZghSDGEJXFCECE7nPrW0+dbA9O2YDPKkL/TSebWOtfBeV/CQ?=
 =?us-ascii?q?yJOv1Ytm4i+MNtiVMXlkFfE7wU1DXXZ2G8nCnzUPSioXlz/CbsKBpRe8/DF3od?=
 =?us-ascii?q?678PjxRA3v4o6PAaNIMdpz4xC2nbuDN+mIiSZ5NzlY15AMxXzJyLQF314SkSZu?=
 =?us-ascii?q?dzazHrQaqC7NV7ndmqtWDx4ddiNyO9FE76M63glRJ8Hbjsn52aJ/jv4wE11FT0?=
 =?us-ascii?q?Dumtm1ZcwWJGGwLEnIBFuQO7ScOzLKw9v7Yae9SbBLiOVUthuwuSuUEkP5PzSD?=
 =?us-ascii?q?kSXpWA6rMe1WkC6bOxlespmnchlxEWjjUM7mahqjPd9rjD02xKc4iW/QOWEAMT?=
 =?us-ascii?q?hzbUVNo6aU7SNZhPV/BmNA4mBkLemChyaW8e3YJowKvvtsByR+j/ha72giy7tJ?=
 =?us-ascii?q?8CFEQ+R4mSvIod5oplGmk++PxSJmURpOsDlLgo2LsF5mOaXY8JlARHnF8AgM7W?=
 =?us-ascii?q?WWFxQFud9lBsfztKBXz9ic3J70fRVF89Sc3dYWDcHOJIrTMno8OxDgAjL8ChUE?=
 =?us-ascii?q?QT+ic2rYghoZ2POV9nvTroUwoJH2lLIBT7ZaUBo+EfZeQkBkGsESZZJydjA6mL?=
 =?us-ascii?q?WYyskS6imQth7UEfldu9j7X/aKDOSnfCqeiJFYbh8QzKK+JoMWYN6ok3d+Y0V3?=
 =?us-ascii?q?ydyZU3HbWspA92g4Nlc5?=
X-IronPort-Anti-Spam-Filtered: true
X-IronPort-Anti-Spam-Result: =?us-ascii?q?A0ATAADr7v1bh0O0hNFkHAEBAQQBAQcEA?=
 =?us-ascii?q?QGBUQcBAQsBgVqBDwN/J4N5iBiOFRSXLIFzCiIPBAGHWiI0CQ0BAwEBAQEBAQI?=
 =?us-ascii?q?BEwEBAQgNCQgpIwyCNiQBgmIBAgMBAiAPAQVBBgkBAQgCDgoCAiYCAgNUBgEMB?=
 =?us-ascii?q?gIBAQGDHAGCAQUKinyaHgGBMYEvhDEEgQuFBTRXiwIXgX+BESeCa4MeAQOBOBO?=
 =?us-ascii?q?DGIJXAodZiD6PdQmCIIRdii4GGIFZiAkmhwORVIZWgVSCDU0jFYMnCYIeF38BC?=
 =?us-ascii?q?IJChlGEICIygQUBAYoKASWCJwEB?=
X-IPAS-Result: =?us-ascii?q?A0ATAADr7v1bh0O0hNFkHAEBAQQBAQcEAQGBUQcBAQsBgVq?=
 =?us-ascii?q?BDwN/J4N5iBiOFRSXLIFzCiIPBAGHWiI0CQ0BAwEBAQEBAQIBEwEBAQgNCQgpI?=
 =?us-ascii?q?wyCNiQBgmIBAgMBAiAPAQVBBgkBAQgCDgoCAiYCAgNUBgEMBgIBAQGDHAGCAQU?=
 =?us-ascii?q?KinyaHgGBMYEvhDEEgQuFBTRXiwIXgX+BESeCa4MeAQOBOBODGIJXAodZiD6Pd?=
 =?us-ascii?q?QmCIIRdii4GGIFZiAkmhwORVIZWgVSCDU0jFYMnCYIeF38BCIJChlGEICIygQU?=
 =?us-ascii?q?BAYoKASWCJwEB?=
X-IronPort-AV: E=Sophos;i="5.56,288,1539673200"; 
   d="scan'208";a="64283667"
X-Amp-Result: SKIPPED(no attachment in message)
X-Amp-File-Uploaded: False
Received: from vger.kernel.org ([209.132.180.67])
  by mga01b.intel.com with ESMTP; 27 Nov 2018 17:29:16 -0800
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
        id S1727211AbeK1M27 (ORCPT <rfc822;like.xu@linux.intel.com>
        + 23 others); Wed, 28 Nov 2018 07:28:59 -0500
Received: from p3plsmtpa08-09.prod.phx3.secureserver.net ([173.201.193.110]:43806
        "EHLO p3plsmtpa08-09.prod.phx3.secureserver.net" rhost-flags-OK-OK-OK-OK)
        by vger.kernel.org with ESMTP id S1726548AbeK1M26 (ORCPT
        <rfc822;linux-kernel@vger.kernel.org>);
        Wed, 28 Nov 2018 07:28:58 -0500
X-Greylist: delayed 439 seconds by postgrey-1.27 at vger.kernel.org; Wed, 28 Nov 2018 07:28:58 EST
Received: from [192.168.0.55] ([24.218.182.144])
        by :SMTPAUTH: with ESMTPSA
        id RoY3ggOhVxfLmRoY4g5zN9; Tue, 27 Nov 2018 18:21:52 -0700
Subject: Re: [PATCH v2 0/6] RFC: gup+dma: tracking dma-pinned pages
To: John Hubbard <jhubbard@nvidia.com>, john.hubbard@gmail.com,
        linux-mm@kvack.org
Cc: Andrew Morton <akpm@linux-foundation.org>,
        LKML <linux-kernel@vger.kernel.org>,
        linux-rdma <linux-rdma@vger.kernel.org>,
        linux-fsdevel@vger.kernel.org
References: <20181110085041.10071-1-jhubbard@nvidia.com>
 <942cb823-9b18-69e7-84aa-557a68f9d7e9@talpey.com>
 <97934904-2754-77e0-5fcb-83f2311362ee@nvidia.com>
 <5159e02f-17f8-df8b-600c-1b09356e46a9@talpey.com>
 <c1ba07d6-ebfa-ddb9-c25e-e5c1bfbecf74@nvidia.com>
From: Tom Talpey <tom@talpey.com>
Message-ID: <15e4a0c0-cadd-e549-962f-8d9aa9fc033a@talpey.com>
Date: Tue, 27 Nov 2018 20:21:51 -0500
User-Agent: Mozilla/5.0 (Windows NT 10.0; WOW64; rv:52.0) Gecko/20100101
 Thunderbird/52.9.1
MIME-Version: 1.0
In-Reply-To: <c1ba07d6-ebfa-ddb9-c25e-e5c1bfbecf74@nvidia.com>
Content-Type: text/plain; charset=utf-8; format=flowed
Content-Language: en-US
Content-Transfer-Encoding: 8bit
X-CMAE-Envelope: MS4wfIIl29Utz8p5+ukRKmjiKQaLUVSsvQE3AlWAWrTt+Son/m4gxdNeyXjald/IbGOAiB2GlCDAfqBafUL5+a8qa1fL58Qzm+hUtDDTPfmkEAp2A7Pzfu+E
 5YtueX0cBErA0OPMRrvSlF56RYFs1j11UcfEBCVRKBOUWb9LceWC2FylQtrDbOvrt2K8gI13xnmvGMWOJJqVSbjhuQ1tZbTq7YsmpUtvNEyZYWZAdYF4SDbQ
 XVeC4njq8FxI9iBs+4oJ+afwiNGyZWAOXfk9da7NeTr+7lgUnLaCOCgkvaC925gXt57PRVDBcXKto4s8mMvnj/rwFCdTeo24jydhWNB0a0Vd/0coQOupmiBh
 BtVSSAu4jn7Y1xrG3b/tzFlZcvfbZXUwL4wCY6Qs+NS1e6tTkAE=
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: <linux-kernel.vger.kernel.org>
X-Mailing-List: linux-kernel@vger.kernel.org

On 11/21/2018 5:06 PM, John Hubbard wrote:
> On 11/21/18 8:49 AM, Tom Talpey wrote:
>> On 11/21/2018 1:09 AM, John Hubbard wrote:
>>> On 11/19/18 10:57 AM, Tom Talpey wrote:
>>>> ~14000 4KB read IOPS is really, really low for an NVMe disk.
>>>
>>> Yes, but Jan Kara's original config file for fio is *intended* to highlight
>>> the get_user_pages/put_user_pages changes. It was *not* intended to get max
>>> performance,Â  as you can see by the numjobs and direct IO parameters:
>>>
>>> cat fio.conf
>>> [reader]
>>> direct=1
>>> ioengine=libaio
>>> blocksize=4096
>>> size=1g
>>> numjobs=1
>>> rw=read
>>> iodepth=64
>>
>> To be clear - I used those identical parameters, on my lower-spec
>> machine, and got 400,000 4KB read IOPS. Those results are nearly 30x
>> higher than yours!
> 
> OK, then something really is wrong here...
> 
>>
>>> So I'm thinking that this is not a "tainted" test, but rather, we're constraining
>>> things a lot with these choices. It's hard to find a good test config to run that
>>> allows decisions, but so far, I'm not really seeing anything that says "this
>>> is so bad that we can't afford to fix the brokenness." I think.
>>
>> I'm not suggesting we tune the benchmark, I'm suggesting the results
>> on your system are not meaningful since they are orders of magnitude
>> low. And without meaningful data it's impossible to see the performance
>> impact of the change...
>>
>>>> Can you confirm what type of hardware you're running this test on?
>>>> CPU, memory speed and capacity, and NVMe device especially?
>>>>
>>>> Tom.
>>>
>>> Yes, it's a nice new system, I don't expect any strange perf problems:
>>>
>>> CPU: Intel(R) Core(TM) i7-7800X CPU @ 3.50GHz
>>>  Â Â Â Â  (Intel X299 chipset)
>>> Block device: nvme-Samsung_SSD_970_EVO_250GB
>>> DRAM: 32 GB
>>
>> The Samsung Evo 970 250GB is speced to yield 200,000 random read IOPS
>> with a 4KB QD32 workload:
>>
>>
>> https://www.samsung.com/us/computing/memory-storage/solid-state-drives/ssd-970-evo-nvme-m-2-250gb-mz-v7e250bw/#specs
>>
>> And the I7-7800X is a 6-core processor (12 hyperthreads).
>>
>>> So, here's a comparison using 20 threads, direct IO, for the baseline vs.
>>> patched kernel (below). Highlights:
>>>
>>>  Â Â Â Â -- IOPS are similar, around 60k.
>>>  Â Â Â Â -- BW gets worse, dropping from 290 to 220 MB/s.
>>>  Â Â Â Â -- CPU is well under 100%.
>>>  Â Â Â Â -- latency is incredibly long, but...20 threads.
>>>
>>> Baseline:
>>>
>>> $ ./run.sh
>>> fio configuration:
>>> [reader]
>>> ioengine=libaio
>>> blocksize=4096
>>> size=1g
>>> rw=read
>>> group_reporting
>>> iodepth=256
>>> direct=1
>>> numjobs=20
>>
>> Ouch - 20 threads issuing 256 io's each!? Of course latency skyrockets.
>> That's going to cause tremendous queuing, and context switching, far
>> outside of the get_user_pages() change.
>>
>> But even so, it only brings IOPS to 74.2K, which is still far short of
>> the device's 200K spec.
>>
>> Comparing anyway:
>>
>>
>>> Patched:
>>>
>>> -------- Running fio:
>>> reader: (g=0): rw=read, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=libaio, iodepth=256
>>> ...
>>> fio-3.3
>>> Starting 20 processes
>>> Jobs: 13 (f=8): [_(1),R(1),_(1),f(1),R(2),_(1),f(2),_(1),R(1),f(1),R(1),f(1),R(1),_(2),R(1),_(1),R(1)][97.9%][r=229MiB/s,w=0KiB/s][r=58.5k,w=0 IOPS][eta 00m:02s]
>>> reader: (groupid=0, jobs=20): err= 0: pid=2104: Tue Nov 20 22:01:58 2018
>>>  Â Â Â  read: IOPS=56.8k, BW=222MiB/s (232MB/s)(20.0GiB/92385msec)
>>> ...
>>> Thoughts?
>>
>> Concern - the 74.2K IOPS unpatched drops to 56.8K patched!
> 
> ACK. :)
> 
>>
>> What I'd really like to see is to go back to the original fio parameters
>> (1 thread, 64 iodepth) and try to get a result that gets at least close
>> to the speced 200K IOPS of the NVMe device. There seems to be something
>> wrong with yours, currently.
> 
> I'll dig into what has gone wrong with the test. I see fio putting data files
> in the right place, so the obvious "using the wrong drive" is (probably)
> not it. Even though it really feels like that sort of thing. We'll see.
> 
>>
>> Then of course, the result with the patched get_user_pages, and
>> compare whichever of IOPS or CPU% changes, and how much.
>>
>> If these are within a few percent, I agree it's good to go. If it's
>> roughly 25% like the result just above, that's a rocky road.
>>
>> I can try this after the holiday on some basic hardware and might
>> be able to scrounge up better. Can you post that github link?
>>
> 
> Here:
> 
>     git@github.com:johnhubbard/linux (branch: gup_dma_testing)

I'm super-limited here this week hardware-wise and have not been able
to try testing with the patched kernel.

I was able to compare my earlier quick test with a Bionic 4.15 kernel
(400K IOPS) against a similar 4.20rc3 kernel, and the rate dropped to
~_375K_ IOPS. Which I found perhaps troubling. But it was only a quick
test, and without your change.

Say, that branch reports it has not had a commit since June 30. Is that
the right one? What about gup_dma_for_lpc_2018?

Tom.
