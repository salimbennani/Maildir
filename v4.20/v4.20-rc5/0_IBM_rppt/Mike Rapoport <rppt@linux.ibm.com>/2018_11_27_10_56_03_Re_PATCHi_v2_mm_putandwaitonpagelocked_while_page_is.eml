Return-Path: <linux-kernel-owner@vger.kernel.org>
Delivered-To: unknown
Received: from linux.intel.com (10.54.29.200:995) by likexu-workstation with
  POP3-SSL; 27 Nov 2018 19:20:05 -0000
X-Original-To: like.xu@linux.intel.com
Delivered-To: like.xu@linux.intel.com
Received: from orsmga002.jf.intel.com (orsmga002.jf.intel.com [10.7.209.21])
	(using TLSv1.2 with cipher ECDHE-RSA-AES256-GCM-SHA384 (256/256 bits))
	(No client certificate requested)
	by linux.intel.com (Postfix) with ESMTPS id CF2055802E4;
	Tue, 27 Nov 2018 02:56:23 -0800 (PST)
Received: from orsmga103.jf.intel.com ([10.7.208.35])
  by orsmga002-1.jf.intel.com with ESMTP/TLS/DHE-RSA-AES256-GCM-SHA384; 27 Nov 2018 02:56:23 -0800
X-SG-BADATTACHMENTNOREPLY: True
IronPort-PHdr: =?us-ascii?q?9a23=3AXckFiBPX6qzEoUSI3y4l6mtUPXoX/o7sNwtQ0KIM?=
 =?us-ascii?q?zox0KPjypcbcNUDSrc9gkEXOFd2Cra4c26yO6+jJYi8p2d65qncMcZhBBVcuqP?=
 =?us-ascii?q?49uEgeOvODElDxN/XwbiY3T4xoXV5h+GynYwAOQJ6tL1LdrWev4jEMBx7xKRR6?=
 =?us-ascii?q?JvjvGo7Vks+7y/2+94fcbglUhzexe69+IAmrpgjNq8cahpdvJLwswRXTuHtIfO?=
 =?us-ascii?q?pWxWJsJV2Nmhv3+9m98p1+/SlOovwt78FPX7n0cKQ+VrxYES8pM3sp683xtBnM?=
 =?us-ascii?q?VhWA630BWWgLiBVIAgzF7BbnXpfttybxq+Rw1DWGMcDwULs5Qiqp4bt1RxD0iS?=
 =?us-ascii?q?cHLz85/3/Risxsl6JQvRatqwViz4LIfI2ZMfxzdb7fc9wHX2pMRshfWSxfDI2h?=
 =?us-ascii?q?YYsAAPYOMvtaoIbzpFUOtgO+CAu3CePz1jNFnGP60bEg3ug/FwzNwQwuH8gJsH?=
 =?us-ascii?q?TRtNj7M6YSUeOrw6LV0TvMdetW2TDl6IjPaBAhveyHULVqccrJ0UkvCxjIjlGR?=
 =?us-ascii?q?qYzjIjOU2f4Bs2mA4OplT+6gl2knqwRorzWp28wihI7JhocPxVDF8yV02IM1Ks?=
 =?us-ascii?q?eiSEFne9KkEZ1Qty+dN4ZwX8gsQHlotT4kxrEavZO3ZjUGxZo5yxLFdvCKcJSE?=
 =?us-ascii?q?7gjiWeuTOTt1gGhpdK+wihux60Ss1PHwW8au3FpXridIkt/BvW0X2RPJ8MiIUP?=
 =?us-ascii?q?5981+h2TmR0wDT7flJIV47laXFMZ4t2L0wmYQJsUTFACD2nF/6jKiMdkUr4uSo?=
 =?us-ascii?q?6uLnbav6ppKEKYN4lgXzPr4zlsGxH+g0KBUCUmuH9eim1bDu/1X1QLBQgf03lq?=
 =?us-ascii?q?nZvoraJcMepqOhBw9V04Aj6wuwDju/09QXg2MHLFRbdxKDloTpPF/PIPbmAvel?=
 =?us-ascii?q?mFmsjjhryO7cPrH7AZXCMGLDkLH/crZ58UJczxAzzd9H65JOFr4BOO7zWlP2tN?=
 =?us-ascii?q?HACh85Mg+0zPj9BNRyy4MTQmaPAq6fMKPPvl6E/OMvI++QZIALvDbxMeQq5/nr?=
 =?us-ascii?q?jXUhg18SYbGp3YcLaHC/BvlmI1+WYXvwgtgbFmcGpAo+TPHwh12EXj5efHKyX6?=
 =?us-ascii?q?M65jEmB4OqF4bDRoaxgLOf2Ce3BIFZZmdDClqUC3fna52EW+sQaCKVOsJhkDsE?=
 =?us-ascii?q?Wqa7R48i0hGusgn6y718I+rQ+y0Ys4/j1ddv6+3SkxEy6SJ7D8CH326RSGF0m3?=
 =?us-ascii?q?sCRyUq06BnvUx91lCD3LBijPxDFdxT4PBJXh0gNZHGzex3ENTyWgPHfteUR1eq?=
 =?us-ascii?q?WNSmATctTt0vx98CeVpyG9KnjhrbxSqlH6cVl6CXBJwz6q/c3GL+J8Bnx3bC1a?=
 =?us-ascii?q?kulV8mQsRUOG2ih65/8RXTBoHTn0WYkaaqaboT3CrX+GifymqOuVlSUBRsXqXd?=
 =?us-ascii?q?QXAfekzWoMzk6UzYUb+hF64rMgtbxs6EMatFdNvpgVJCRPfgPdTeZ3m8m2OxBR?=
 =?us-ascii?q?aO27ONY5Dme2Qb3CXBFkcElxof8mqBNQg7Hi2huX7RDCRyFVLzZEPh6fRxp2ml?=
 =?us-ascii?q?TkAq1Q2Kb1du17yu+hELg/yRUPcT3rMCuCc8pDR4Ble939TKC9WeowptZrlTYd?=
 =?us-ascii?q?Q44F1fz2LWqxR9PoC8L6BlnlMebwV3v0bp1xVrCoVBkdImrG8wwAp1M6KY1FJB?=
 =?us-ascii?q?dzWX3Z3rPr3XK2/y/A2gaqLM21He1sqW9bkL6Pgit1rjuwSpHFI483p7y9lVz2?=
 =?us-ascii?q?ec5pLSAQUIVZL+TEk2+AZ6pr3AeSY9+p7b2mdqMam3tT/CxckkBO8kyhamYtde?=
 =?us-ascii?q?P7mIFA70E80GGceuLPYmlESubhIBJOpS7rI7P9u6d/ua366mJOZhnC+8gWtb+o?=
 =?us-ascii?q?x800KM+DB6Su7HxJsFx/CY3g2aVzbzlluhs8b3mZxaajEWBGaw1S/kBItJbK1o?=
 =?us-ascii?q?YYkLEXuuI9GwxthmnZ7tWmJX+0S5B1wb38+lYxySYELn3Q1RzEgYvWaomS+lwD?=
 =?us-ascii?q?NqiTEpqayf0TfKw+TjchoHJ2FKSHNjjVfqPYi7kdQaUFK0YAgukRuv/Vz6yLRD?=
 =?us-ascii?q?pKRjM2nTRl9Ffij3L214Uqq8rKGCY9NJ6J4ztSVXUeK8YU2VS7Lnohsa1T/jEH?=
 =?us-ascii?q?VaxDwhaz6qvZD5lQRgiG2BNHZzsGbZecZoyBfd/tPcX/1R3jkBRCVikjnYHFu8?=
 =?us-ascii?q?P9qo/dWSiZjDtPuzV2agVp1VbCnqwpmMtCq95W12HxK/m+q/lcHgEQg/ySX7zc?=
 =?us-ascii?q?VlVT3UrBbgZYnmz6S7PvhgfkVyBl/86sx6F5p6kosxgpEQxHcbio+U/XoBjWf8?=
 =?us-ascii?q?L9Fb1bjiY3oKQD4B28TV7xT92E1/MnKJwJr0VnaHzctgfdW6Yn4W1Tg778BFE6?=
 =?us-ascii?q?qU6L1EnS1oolu3tw7RYP59nisDxvsq8nIVn+YJuA81xCWHHr8SBVVYPTDrlxmQ?=
 =?us-ascii?q?6tC+raZXa3y1fbm+ykV+hsyhA6+Yog5HRnn5YJgiEDR07sV+NlLMzXLy5pvleN?=
 =?us-ascii?q?nWcdIcqBmUnw3cgOhSLZI7juAKijZ/OWLhoX0lzPY2jQBp3ZG/poSGKn9i/KSk?=
 =?us-ascii?q?Ah5DLT31Ztge+jXsjaZYg8aX0JqjHpRnGjUXQpToSeikHy4VtfTiLwyOCiEzqm?=
 =?us-ascii?q?+HGbrDGg+S8FxpoGjIE5CvKnGbPn0Zzch5SRmZJUxfhh0UXTogkp44EACq2NLu?=
 =?us-ascii?q?cENj6j8N4V74rwNGyvh0OBnnTmffuACoZy82SJeFKRpZ8BpC613JMcCE7eJzAi?=
 =?us-ascii?q?JY/oCnrAOXMWyWfABIDWAPWkyZCFHvJLiu5d/c8+eGAuqyNefBYbKLqeZGTfeH?=
 =?us-ascii?q?2Yqv0pd6/zaLLsiOPn5iD+Ai2kpeR395Hd7Vmy4ISywRmCLAdMqbpBa6+i1qoc?=
 =?us-ascii?q?Gz6vXrWATz5YSRD7teK8lg+xezga2bLe6fmD55KSpE1pML3XLIyKYQ3F8RiyFt?=
 =?us-ascii?q?djmhC7cAtTTKTKLfhKBXFQMbazhoOctM7qI82BRNOMHBhtP00L54kuA6C1NfWV?=
 =?us-ascii?q?P9ncGpYNQAI3uhO1PfGEaLKLOGKCXRzMHqeqy8U6NfjeVOux20uDaWCEvjPjWF?=
 =?us-ascii?q?lzn0WBGjK+BMjCeHPBNAvIGxaApiCW/mTNj+cB20LMd3jSEqwb0znn7KKW8cMT?=
 =?us-ascii?q?1mf0xRtLGf8SNYjet5G2Fa6nplLO+EmzuW7uXCK5YWt+drDTpwl+5A/Hs6zL5V?=
 =?us-ascii?q?5jleRPNpgCvSssJuo1a+n+iP0DVnVh9OqjdNhI2TvERiOb/W9p9PWXvf+BIN7G?=
 =?us-ascii?q?OQCwkFptd/C93vvbxQxcbLlK7pNDhC9NfUroMgAJ3xId6bMHc+eSXoHDXTHENR?=
 =?us-ascii?q?Uj+vMXD3hkpTivie+3SZ6J8gpc6/toAJT+p+VV84XskTEkN9G8YeaMNtRis4ub?=
 =?us-ascii?q?qaitMYo3u0qV/aQ8AM7cOPbe6bHfi6cGXRtrJDfRZdhOqgdYk=3D?=
X-IronPort-Anti-Spam-Filtered: true
X-IronPort-Anti-Spam-Result: =?us-ascii?q?A0ARAAB5Iv1bh0O0hNFcCBwBAQEEAQEHB?=
 =?us-ascii?q?AEBgVEHAQELAYJpgQInjBFfi3cBAQaBNRRoiCGJLIR3gSQDTBIBARgLCAGDLIV?=
 =?us-ascii?q?GIjQJDQEDAQEBAQEBAgETAQEBCA0JCCkjDII2JAGCYgEBAQMBAg8oOQYGCQEBC?=
 =?us-ascii?q?g4KCSUDDAVJEwUZBIJ/AYF0DQMBAQqaZIlYAQEBgh2KKgWMDRd4gQeBEYJdNYM?=
 =?us-ascii?q?eBBiBIAKDWoImAosVlCJVCYZ8iikjCgKQfyyNGopKAgQGBQITAYFGbIEhTSMVO?=
 =?us-ascii?q?4JsE4FtJxeGI4d8cIEFAQEhinyCTQEB?=
X-IPAS-Result: =?us-ascii?q?A0ARAAB5Iv1bh0O0hNFcCBwBAQEEAQEHBAEBgVEHAQELAYJ?=
 =?us-ascii?q?pgQInjBFfi3cBAQaBNRRoiCGJLIR3gSQDTBIBARgLCAGDLIVGIjQJDQEDAQEBA?=
 =?us-ascii?q?QEBAgETAQEBCA0JCCkjDII2JAGCYgEBAQMBAg8oOQYGCQEBCg4KCSUDDAVJEwU?=
 =?us-ascii?q?ZBIJ/AYF0DQMBAQqaZIlYAQEBgh2KKgWMDRd4gQeBEYJdNYMeBBiBIAKDWoImA?=
 =?us-ascii?q?osVlCJVCYZ8iikjCgKQfyyNGopKAgQGBQITAYFGbIEhTSMVO4JsE4FtJxeGI4d?=
 =?us-ascii?q?8cIEFAQEhinyCTQEB?=
X-IronPort-AV: E=Sophos;i="5.56,286,1539673200"; 
   d="scan'208";a="53867886"
X-Amp-Result: UNSCANNABLE
X-Amp-File-Uploaded: False
Unscannable: 2
Received: from vger.kernel.org ([209.132.180.67])
  by mtab.intel.com with ESMTP; 27 Nov 2018 02:56:21 -0800
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
        id S1730929AbeK0Vxt (ORCPT <rfc822;like.xu@linux.intel.com>
        + 23 others); Tue, 27 Nov 2018 16:53:49 -0500
Received: from mx0b-001b2d01.pphosted.com ([148.163.158.5]:41324 "EHLO
        mx0a-001b2d01.pphosted.com" rhost-flags-OK-OK-OK-FAIL)
        by vger.kernel.org with ESMTP id S1726501AbeK0Vxt (ORCPT
        <rfc822;linux-kernel@vger.kernel.org>);
        Tue, 27 Nov 2018 16:53:49 -0500
Received: from pps.filterd (m0098416.ppops.net [127.0.0.1])
        by mx0b-001b2d01.pphosted.com (8.16.0.22/8.16.0.22) with SMTP id wARArpsX036831
        for <linux-kernel@vger.kernel.org>; Tue, 27 Nov 2018 05:56:17 -0500
Received: from e06smtp05.uk.ibm.com (e06smtp05.uk.ibm.com [195.75.94.101])
        by mx0b-001b2d01.pphosted.com with ESMTP id 2p12nkwphj-1
        (version=TLSv1.2 cipher=AES256-GCM-SHA384 bits=256 verify=NOT)
        for <linux-kernel@vger.kernel.org>; Tue, 27 Nov 2018 05:56:17 -0500
Received: from localhost
        by e06smtp05.uk.ibm.com with IBM ESMTP SMTP Gateway: Authorized Use Only! Violators will be prosecuted
        for <linux-kernel@vger.kernel.org> from <rppt@linux.ibm.com>;
        Tue, 27 Nov 2018 10:56:14 -0000
Received: from b06cxnps4075.portsmouth.uk.ibm.com (9.149.109.197)
        by e06smtp05.uk.ibm.com (192.168.101.135) with IBM ESMTP SMTP Gateway: Authorized Use Only! Violators will be prosecuted;
        (version=TLSv1/SSLv3 cipher=AES256-GCM-SHA384 bits=256/256)
        Tue, 27 Nov 2018 10:56:08 -0000
Received: from d06av22.portsmouth.uk.ibm.com (d06av22.portsmouth.uk.ibm.com [9.149.105.58])
        by b06cxnps4075.portsmouth.uk.ibm.com (8.14.9/8.14.9/NCO v10.0) with ESMTP id wARAu7VK9568580
        (version=TLSv1/SSLv3 cipher=DHE-RSA-AES256-GCM-SHA384 bits=256 verify=FAIL);
        Tue, 27 Nov 2018 10:56:07 GMT
Received: from d06av22.portsmouth.uk.ibm.com (unknown [127.0.0.1])
        by IMSVA (Postfix) with ESMTP id 7CC224C050;
        Tue, 27 Nov 2018 10:56:07 +0000 (GMT)
Received: from d06av22.portsmouth.uk.ibm.com (unknown [127.0.0.1])
        by IMSVA (Postfix) with ESMTP id 96EC04C044;
        Tue, 27 Nov 2018 10:56:05 +0000 (GMT)
Received: from rapoport-lnx (unknown [9.148.204.155])
        by d06av22.portsmouth.uk.ibm.com (Postfix) with ESMTPS;
        Tue, 27 Nov 2018 10:56:05 +0000 (GMT)
Date: Tue, 27 Nov 2018 12:56:03 +0200
From: Mike Rapoport <rppt@linux.ibm.com>
To: Matthew Wilcox <willy@infradead.org>
Cc: Hugh Dickins <hughd@google.com>,
        Linus Torvalds <torvalds@linux-foundation.org>,
        Andrew Morton <akpm@linux-foundation.org>,
        Baoquan He <bhe@redhat.com>, Michal Hocko <mhocko@suse.com>,
        Vlastimil Babka <vbabka@suse.cz>,
        Andrea Arcangeli <aarcange@redhat.com>,
        David Hildenbrand <david@redhat.com>,
        Mel Gorman <mgorman@techsingularity.net>,
        David Herrmann <dh.herrmann@gmail.com>,
        Tim Chen <tim.c.chen@linux.intel.com>,
        Kan Liang <kan.liang@intel.com>,
        Andi Kleen <ak@linux.intel.com>,
        Davidlohr Bueso <dave@stgolabs.net>,
        Peter Zijlstra <peterz@infradead.org>,
        Christoph Lameter <cl@linux.com>,
        Nick Piggin <npiggin@gmail.com>, pifang@redhat.com,
        linux-kernel@vger.kernel.org, linux-mm@kvack.org
Subject: Re: [PATCHi v2] mm: put_and_wait_on_page_locked() while page is
 migrated
References: <alpine.LSU.2.11.1811241858540.4415@eggly.anvils>
 <CAHk-=wjeqKYevxGnfCM4UkxX8k8xfArzM6gKkG3BZg1jBYThVQ@mail.gmail.com>
 <alpine.LSU.2.11.1811251900300.1278@eggly.anvils>
 <alpine.LSU.2.11.1811261121330.1116@eggly.anvils>
 <20181126205351.GM3065@bombadil.infradead.org>
MIME-Version: 1.0
Content-Type: text/plain; charset=us-ascii
Content-Disposition: inline
In-Reply-To: <20181126205351.GM3065@bombadil.infradead.org>
User-Agent: Mutt/1.5.24 (2015-08-30)
X-TM-AS-GCONF: 00
x-cbid: 18112710-0020-0000-0000-000002EE5FAF
X-IBM-AV-DETECTION: SAVI=unused REMOTE=unused XFE=unused
x-cbparentid: 18112710-0021-0000-0000-0000213DB386
Message-Id: <20181127105602.GC16502@rapoport-lnx>
X-Proofpoint-Virus-Version: vendor=fsecure engine=2.50.10434:,, definitions=2018-11-27_09:,,
 signatures=0
X-Proofpoint-Spam-Details: rule=outbound_notspam policy=outbound score=0 priorityscore=1501
 malwarescore=0 suspectscore=0 phishscore=0 bulkscore=0 spamscore=0
 clxscore=1015 lowpriorityscore=0 mlxscore=0 impostorscore=0
 mlxlogscore=999 adultscore=0 classifier=spam adjust=0 reason=mlx
 scancount=1 engine=8.0.1-1810050000 definitions=main-1811270096
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: <linux-kernel.vger.kernel.org>
X-Mailing-List: linux-kernel@vger.kernel.org

On Mon, Nov 26, 2018 at 12:53:51PM -0800, Matthew Wilcox wrote:
> On Mon, Nov 26, 2018 at 11:27:07AM -0800, Hugh Dickins wrote:
> > Waiting on a page migration entry has used wait_on_page_locked() all
> > along since 2006: but you cannot safely wait_on_page_locked() without
> > holding a reference to the page, and that extra reference is enough to
> > make migrate_page_move_mapping() fail with -EAGAIN, when a racing task
> > faults on the entry before migrate_page_move_mapping() gets there.
> > 
> > And that failure is retried nine times, amplifying the pain when
> > trying to migrate a popular page.  With a single persistent faulter,
> > migration sometimes succeeds; with two or three concurrent faulters,
> > success becomes much less likely (and the more the page was mapped,
> > the worse the overhead of unmapping and remapping it on each try).
> > 
> > This is especially a problem for memory offlining, where the outer
> > level retries forever (or until terminated from userspace), because
> > a heavy refault workload can trigger an endless loop of migration
> > failures.  wait_on_page_locked() is the wrong tool for the job.
> > 
> > David Herrmann (but was he the first?) noticed this issue in 2014:
> > https://marc.info/?l=linux-mm&m=140110465608116&w=2
> > 
> > Tim Chen started a thread in August 2017 which appears relevant:
> > https://marc.info/?l=linux-mm&m=150275941014915&w=2
> > where Kan Liang went on to implicate __migration_entry_wait():
> > https://marc.info/?l=linux-mm&m=150300268411980&w=2
> > and the thread ended up with the v4.14 commits:
> > 2554db916586 ("sched/wait: Break up long wake list walk")
> > 11a19c7b099f ("sched/wait: Introduce wakeup boomark in wake_up_page_bit")
> > 
> > Baoquan He reported "Memory hotplug softlock issue" 14 November 2018:
> > https://marc.info/?l=linux-mm&m=154217936431300&w=2
> > 
> > We have all assumed that it is essential to hold a page reference while
> > waiting on a page lock: partly to guarantee that there is still a struct
> > page when MEMORY_HOTREMOVE is configured, but also to protect against
> > reuse of the struct page going to someone who then holds the page locked
> > indefinitely, when the waiter can reasonably expect timely unlocking.
> > 
> > But in fact, so long as wait_on_page_bit_common() does the put_page(),
> > and is careful not to rely on struct page contents thereafter, there is
> > no need to hold a reference to the page while waiting on it.  That does
> > mean that this case cannot go back through the loop: but that's fine for
> > the page migration case, and even if used more widely, is limited by the
> > "Stop walking if it's locked" optimization in wake_page_function().
> > 
> > Add interface put_and_wait_on_page_locked() to do this, using "behavior"
> > enum in place of "lock" arg to wait_on_page_bit_common() to implement it.
> > No interruptible or killable variant needed yet, but they might follow:
> > I have a vague notion that reporting -EINTR should take precedence over
> > return from wait_on_page_bit_common() without knowing the page state,
> > so arrange it accordingly - but that may be nothing but pedantic.
> > 
> > __migration_entry_wait() still has to take a brief reference to the
> > page, prior to calling put_and_wait_on_page_locked(): but now that it
> > is dropped before waiting, the chance of impeding page migration is
> > very much reduced.  Should we perhaps disable preemption across this?
> > 
> > shrink_page_list()'s __ClearPageLocked(): that was a surprise!  This
> > survived a lot of testing before that showed up.  PageWaiters may have
> > been set by wait_on_page_bit_common(), and the reference dropped, just
> > before shrink_page_list() succeeds in freezing its last page reference:
> > in such a case, unlock_page() must be used.  Follow the suggestion from
> > Michal Hocko, just revert a978d6f52106 ("mm: unlockless reclaim") now:
> > that optimization predates PageWaiters, and won't buy much these days;
> > but we can reinstate it for the !PageWaiters case if anyone notices.
> > 
> > It does raise the question: should vmscan.c's is_page_cache_freeable()
> > and __remove_mapping() now treat a PageWaiters page as if an extra
> > reference were held?  Perhaps, but I don't think it matters much, since
> > shrink_page_list() already had to win its trylock_page(), so waiters are
> > not very common there: I noticed no difference when trying the bigger
> > change, and it's surely not needed while put_and_wait_on_page_locked()
> > is only used for page migration.
> > 
> > Reported-and-tested-by: Baoquan He <bhe@redhat.com>
> > Signed-off-by: Hugh Dickins <hughd@google.com>
> > Acked-by: Michal Hocko <mhocko@suse.com>
> > Reviewed-by: Andrea Arcangeli <aarcange@redhat.com>
> > ---
> >  include/linux/pagemap.h |  2 ++
> >  mm/filemap.c            | 77 ++++++++++++++++++++++++++++++++++-------
> >  mm/huge_memory.c        |  6 ++--
> >  mm/migrate.c            | 12 +++----
> >  mm/vmscan.c             | 10 ++----
> >  5 files changed, 74 insertions(+), 33 deletions(-)
> > 
> 
> /**
>  * put_and_wait_on_page_locked - Drop a reference and wait for it to be unlocked

                                                        wait for page ?

>  * @page: The page to wait for.
>  *
>  * The caller should hold a reference on @page.  They expect the page to
>  * become unlocked relatively soon, but do not wish to hold up migration
>  * (for example) by holding the reference while waiting for the page to
>  * come unlocked.  After this function returns, the caller should not
>  * dereference @page.
>  */

How about:
 
They expect the page to become unlocked relatively soon, but they can wait
for the page to come unlocked without holding the reference, to allow
other users of the @page (for example migration) to continue. 

> (improvements gratefully received)
> 
> > +void put_and_wait_on_page_locked(struct page *page)
> > +{
> > +	wait_queue_head_t *q;
> > +
> > +	page = compound_head(page);
> > +	q = page_waitqueue(page);
> > +	wait_on_page_bit_common(q, page, PG_locked, TASK_UNINTERRUPTIBLE, DROP);
> > +}
> > +
> >  /**
> >   * add_page_wait_queue - Add an arbitrary waiter to a page's wait queue
> >   * @page: Page defining the wait queue of interest
> 

-- 
Sincerely yours,
Mike.

