Return-Path: <linux-kernel-owner@vger.kernel.org>
Delivered-To: unknown
Received: from linux.intel.com (10.54.29.200:995) by likexu-workstation with
  POP3-SSL; 02 Dec 2018 19:23:30 -0000
X-Original-To: like.xu@linux.intel.com
Delivered-To: like.xu@linux.intel.com
Received: from orsmga006.jf.intel.com (orsmga006.jf.intel.com [10.7.209.51])
	(using TLSv1.2 with cipher ECDHE-RSA-AES256-GCM-SHA384 (256/256 bits))
	(No client certificate requested)
	by linux.intel.com (Postfix) with ESMTPS id B3402580479;
	Fri, 30 Nov 2018 13:53:20 -0800 (PST)
Received: from fmsmga104.fm.intel.com ([10.1.193.100])
  by orsmga006-1.jf.intel.com with ESMTP/TLS/DHE-RSA-AES256-GCM-SHA384; 30 Nov 2018 13:53:19 -0800
X-SG-BADATTACHMENTNOREPLY: True
IronPort-PHdr: =?us-ascii?q?9a23=3AXSI/aBEOREtIrFi0+CWY0J1GYnF86YWxBRYc798d?=
 =?us-ascii?q?s5kLTJ75o8u5bnLW6fgltlLVR4KTs6sC17KG9fi4EUU7or+5+EgYd5JNUxJXwe?=
 =?us-ascii?q?43pCcHRPC/NEvgMfTxZDY7FskRHHVs/nW8LFQHUJ2mPw6arXK99yMdFQviPgRp?=
 =?us-ascii?q?OOv1BpTSj8Oq3Oyu5pHfeQpFiCa+bL9oMBm6sRjau9ULj4dlNqs/0AbCrGFSe+?=
 =?us-ascii?q?RRy2NoJFaTkAj568yt4pNt8Dletuw4+cJYXqr0Y6o3TbpDDDQ7KG81/9HktQPC?=
 =?us-ascii?q?TQSU+HQRVHgdnwdSDAjE6BH6WYrxsjf/u+Fg1iSWIdH6QLYpUjmk8qxlSgLniD?=
 =?us-ascii?q?0fOjAk8G/ZlMJ+gqFZrxKvqRNwzJLbbo6ONPpmfK7QZs8aSGhbU8pNSyBMGIGx?=
 =?us-ascii?q?Yo0SBOQBJ+ZYqIz9qkMSoBu6GwatC/ngyjlViXDox60xzuovERzG3QM8HNIFrX?=
 =?us-ascii?q?PZo8/xNKgMXuG61q/IwijdYPNMwzv96JLEfQ08ofCMQb1wctHcyU0uFwPDk1WR?=
 =?us-ascii?q?ppbpPzKT1uQRrWeb6/BsWv6oi24isgx8pCWkyMQ0ioTRmI4Z1lTJ+T9kzIs7O9?=
 =?us-ascii?q?G0UlN3bN24HJdKtiyXNZN6Tt4mTm12oio3yr0LtYS7cSQU0pgqyBDSZvqaeIaS?=
 =?us-ascii?q?+B3jTvyeITJgiXJlZr2/gxGy/FC+yu3zSMa0ykxGrilbndnWsHACyRjT5tKASv?=
 =?us-ascii?q?tn8UetwTeP1wbN5eFYOU04i7bXJpo7zrItmJcfr17PEjL1lUnqlqObd0cp9vCt?=
 =?us-ascii?q?6+v9Y7XmopGcN5VzigH7Kqkuns2/AeIlMgkBRmSb+vqz1Kfl/ULnRLVGl/o2k6?=
 =?us-ascii?q?ffsJ/EP8QWvbC5AwBL3YY58Rq/DCmp0M4enXYZKFJJYhWHj5LmO13WOvD3Ee+/?=
 =?us-ascii?q?g0iwkDds3/3GOrzhApbTIXTZn7bhYK1w60pdyAo10NBe6IhYCrAHIPLvREDxsM?=
 =?us-ascii?q?bUAQM+Mwyx2+znEsly1psCWWKTBa+UKKPSvkWJ5uIzOeaMY5UZuDbgK/c/4f7u?=
 =?us-ascii?q?gmQ0mVscfamvwJsWZ2q0HvVgI0WFf3Xshs0NHnsNvgo7VObqkkGNUSZPZ3auWK?=
 =?us-ascii?q?Ix/jM7CIW4AovZRYCth7qB3CG8HpBNYmBGC1aMEWrndomeWvcMbj6SLdFlkjAe?=
 =?us-ascii?q?SbehTIoh3wm0tADm07pnMvbU+ioAuJ35z9h15+rTlRIo+TxuFcud0XqAT2V1nm?=
 =?us-ascii?q?MOWj8307pzoU17ylefz6d4h+ZUGsBU5/NMSg06L4LTz/RmC9DuXQLMZtSJR0yg?=
 =?us-ascii?q?Qtm8BTExT8g+w9kBY0tmH9WijxbD3zelArMPlryLAoA0/bzY33TrO8l9zHPG3r?=
 =?us-ascii?q?E7j1Y6WstPKXGmhqln+gfOHYHJjVuWm7yqdasG2i7N73mMzWyJsEFcUw5wVKHF?=
 =?us-ascii?q?UGsbZkvXq9T5+0zDQ6WvCbQhLgtO18qCJrFWZd3uiFVMXO3jN8jGY2Kth2ewAg?=
 =?us-ascii?q?6Fya6WY4r0ZWoRxiXdB1ICkwAI43mGMxMzBiOgo2LYETxvGkjjY0Lq8elitny7?=
 =?us-ascii?q?SlU4wB2Nb01kz7C14AIaheSAS/MP2bIJoDshqzRxHFa6w9LWC9qBqxB9fKlGZt?=
 =?us-ascii?q?M9+lNH1WPftwxyJZGgK6FihlgDcwV4pU/u1hN3Cplensgutn8l0A1yKaeA2lNb?=
 =?us-ascii?q?azyYxYzwOqHQKmTq5h+vb7DZ217A39eW4KsA8+k4pEj5swGvFUoi9Gtn3sJR03?=
 =?us-ascii?q?ud4JXKEQUTXYjwUkYx6xh1ubXabjMh6IPT0H1mKbO0vSPa29I1GOslzQ6tftdC?=
 =?us-ascii?q?MK+eCAD+CcwbB8i0J+wslFikdRYEPOFU9K4pMMKqbfqG2Ki3POl+mDKql3hI4I?=
 =?us-ascii?q?d40kiU7SpzVvbI34oZw/GfxgaHTTb8g0u7vcDthI9EYiseHmyhxij+BY5df7F9?=
 =?us-ascii?q?cpwPCWizPcK33NJ+h5j2Vn5c9V6jAU4G2cCzdRqTaVz9wRNf1UANrXO7niu4yi?=
 =?us-ascii?q?R+kys1oaqHwCzO3+PieQIHO25KXmVjjU3gIZOpj9AcR0WoawkplB245Uf13aRb?=
 =?us-ascii?q?paJ/L3XNTkdMZST5M2ZiUq6ovLqYf8FP8I8osTlQUOmkY1CVUKT9oxgZ0yPkBW?=
 =?us-ascii?q?de3yo0dzKpupX4mRx1lmSdIW13rHrYf8Fw2Bje6MbdRf5XwjoJWi14hSPLCVi7?=
 =?us-ascii?q?Otmj5c+UmIvbsuCiS2KhUYVecCnxwoOHrie752xqARukkvC3m93nFxU60CDh29?=
 =?us-ascii?q?lrUyXIsAjzYo3x26umNuJne1FiBEXg5MpiBoF+jowwiYkT2XcAh5WZ53oHkXrp?=
 =?us-ascii?q?PtVd1qLzd34NRT8Nw97I7wnpwkxjLnSVx43nUnWR2NduZ96/YmkOwCIy89hKCL?=
 =?us-ascii?q?uI7LxDhSZ1p1u4rQHLbvRnkDYS1+Au6GIEjOETowUi0D+dAr8JEElcPCzskQmI?=
 =?us-ascii?q?7t+koKVWYmavbaa/1E5kkd+9C7GCpxlWWGzldZc6AS9w8sJ/PUrQ0H3074HoYt?=
 =?us-ascii?q?jRYsgVth2JiBfAlOlVJYk1lvoLgypnJG38sWcky+49kRxhw5W6sJKbJGVq+aKz?=
 =?us-ascii?q?GgRYOSHtZ8MP5jHtir5Tkd2M0ICoGpVhBy8HXJ/1Tf+zFDIStPLnNxuBETEmq3?=
 =?us-ascii?q?ebH6bfEhGb6Et8s33PFJWrPWmNJHYF1dViWAWdJEtHjQAWRjo6m4A2FhuwyMz9?=
 =?us-ascii?q?akt55S0R5l3lqhtK0O1oLALyUmPepAeudzc1R4KTLBtQ7gFe+UjVNdaS4f50Hy?=
 =?us-ascii?q?Fd5pehthCCKnSHZwRUCmEEQkyFB1f+Prm3+NnP6e6YCvClL/vJZ7WOpvdTV/OJ?=
 =?us-ascii?q?xZKpz4tn8CyANsSJPnl+EfI73lBPUmx+G8Tcgz8PUTAYlzrRb86Hoxex4i13od?=
 =?us-ascii?q?6+8PToWwLv5JGDC7hIMdVo9BC5n72DN/OLhCtiLTZY15UMxWLHybQF3V4SjT1u?=
 =?us-ascii?q?eCepEbgaqSHNS6fQkLdNDxEHcyNzKNdI76Uk0wZXJM7Ukcn12aB4j/IvD1dFVE?=
 =?us-ascii?q?fsmsWoZcwMPmG8O0nLBEeNNLSaOzLLx9v7br+7Sb1VlO9UrQG/uS6HE0//OTSO?=
 =?us-ascii?q?jyXpVxGqMe1WkC6XJgBRuIGjfRZrEmXjSNPmahumMN54lzE2wLs0hm/UOm4YKz?=
 =?us-ascii?q?Rzb0RNrriI5yNCnvp/A3BB7mZiLeScmyeW9e/YKpMXsfttGit1luJa7248y7ta?=
 =?us-ascii?q?9yxEQP11mC3Prt9huV2mk++PyiZ5XxpKsDpEmIWLvUAxcZneo5BDQXPs+BML8H?=
 =?us-ascii?q?XVBRMXoddsFtzoveZX0NeL3KbyLipSttfR1cgCDsPXbsWdPykPKx3sTRfQARsM?=
 =?us-ascii?q?SzKmLynzml1Wk7nG/3mYvpE8ppX23ppIRqJKX18dEvIcF1QjHdoeLZMxVTQhx+?=
 =?us-ascii?q?3IxPUU7Gaz+UGCDP5RuYrKA6qf?=
X-IronPort-Anti-Spam-Filtered: true
X-IronPort-Anti-Spam-Result: =?us-ascii?q?A0AKAABrsAFch0O0hNFjGwEBAQEDAQEBB?=
 =?us-ascii?q?wMBAQGBUQYBAQELAYNrJ4N5iBhfi1WBPzlolkyBdhEYEwGEOwODOCI0CQ0BAwE?=
 =?us-ascii?q?BAQEBAQIBEwEBAQgNCQgpL4I2IoJlAwMBAiAEUgYJAQEkAiYCAgNEEAcSBYMcg?=
 =?us-ascii?q?gIFpw58M4osgQuLD3qBHIERM4IqB4UJgyqCVwKJLYZDNpAPBwKCIo8tgVuFEIo?=
 =?us-ascii?q?0iHuPYoFGgg0zGiNQgmyCJxcSjiweAQExAQGBAwEBinSCTAEB?=
X-IPAS-Result: =?us-ascii?q?A0AKAABrsAFch0O0hNFjGwEBAQEDAQEBBwMBAQGBUQYBAQE?=
 =?us-ascii?q?LAYNrJ4N5iBhfi1WBPzlolkyBdhEYEwGEOwODOCI0CQ0BAwEBAQEBAQIBEwEBA?=
 =?us-ascii?q?QgNCQgpL4I2IoJlAwMBAiAEUgYJAQEkAiYCAgNEEAcSBYMcggIFpw58M4osgQu?=
 =?us-ascii?q?LD3qBHIERM4IqB4UJgyqCVwKJLYZDNpAPBwKCIo8tgVuFEIo0iHuPYoFGgg0zG?=
 =?us-ascii?q?iNQgmyCJxcSjiweAQExAQGBAwEBinSCTAEB?=
X-IronPort-AV: E=Sophos;i="5.56,300,1539673200"; 
   d="scan'208";a="53384438"
X-Amp-Result: SKIPPED(no attachment in message)
X-Amp-File-Uploaded: False
Received: from vger.kernel.org ([209.132.180.67])
  by mtab.intel.com with ESMTP; 30 Nov 2018 13:53:18 -0800
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
        id S1726950AbeLAJD4 (ORCPT <rfc822;like.xu@linux.intel.com>
        + 23 others); Sat, 1 Dec 2018 04:03:56 -0500
Received: from mga05.intel.com ([192.55.52.43]:60167 "EHLO mga05.intel.com"
        rhost-flags-OK-OK-OK-OK) by vger.kernel.org with ESMTP
        id S1725867AbeLAJD4 (ORCPT <rfc822;linux-kernel@vger.kernel.org>);
        Sat, 1 Dec 2018 04:03:56 -0500
X-Amp-Result: SKIPPED(no attachment in message)
X-Amp-File-Uploaded: False
Received: from orsmga001.jf.intel.com ([10.7.209.18])
  by fmsmga105.fm.intel.com with ESMTP/TLS/DHE-RSA-AES256-GCM-SHA384; 30 Nov 2018 13:53:13 -0800
X-ExtLoop1: 1
X-IronPort-AV: E=Sophos;i="5.56,300,1539673200"; 
   d="scan'208";a="114393781"
Received: from ahduyck-desk1.jf.intel.com (HELO ahduyck-desk1.amr.corp.intel.com) ([10.7.198.76])
  by orsmga001.jf.intel.com with ESMTP; 30 Nov 2018 13:53:13 -0800
Subject: [mm PATCH v6 5/7] mm: Move hot-plug specific memory init into
 separate functions and optimize
From: Alexander Duyck <alexander.h.duyck@linux.intel.com>
To: akpm@linux-foundation.org, linux-mm@kvack.org
Cc: sparclinux@vger.kernel.org, linux-kernel@vger.kernel.org,
        linux-nvdimm@lists.01.org, davem@davemloft.net,
        pavel.tatashin@microsoft.com, mhocko@suse.com, mingo@kernel.org,
        kirill.shutemov@linux.intel.com, dan.j.williams@intel.com,
        dave.jiang@intel.com, alexander.h.duyck@linux.intel.com,
        rppt@linux.vnet.ibm.com, willy@infradead.org, vbabka@suse.cz,
        khalid.aziz@oracle.com, ldufour@linux.vnet.ibm.com,
        mgorman@techsingularity.net, yi.z.zhang@linux.intel.com,
        alexander.h.duyck@linux.intel.com
Date: Fri, 30 Nov 2018 13:53:13 -0800
Message-ID: <154361479366.7497.13916678539146224699.stgit@ahduyck-desk1.amr.corp.intel.com>
In-Reply-To: <154361452447.7497.1348692079883153517.stgit@ahduyck-desk1.amr.corp.intel.com>
References: <154361452447.7497.1348692079883153517.stgit@ahduyck-desk1.amr.corp.intel.com>
User-Agent: StGit/unknown-version
MIME-Version: 1.0
Content-Type: text/plain; charset="utf-8"
Content-Transfer-Encoding: 7bit
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: <linux-kernel.vger.kernel.org>
X-Mailing-List: linux-kernel@vger.kernel.org

Combine the bits in memmap_init_zone and memmap_init_zone_device that are
related to hotplug into a single function called __memmap_init_hotplug.

Also take the opportunity to integrate __init_single_page's functionality
into this function. In doing so we can get rid of some of the redundancy
such as the LRU pointers versus the pgmap.

Reviewed-by: Pavel Tatashin <pasha.tatashin@soleen.com>
Signed-off-by: Alexander Duyck <alexander.h.duyck@linux.intel.com>
---
 mm/page_alloc.c |  208 ++++++++++++++++++++++++++++++++++++-------------------
 1 file changed, 135 insertions(+), 73 deletions(-)

diff --git a/mm/page_alloc.c b/mm/page_alloc.c
index fbd9bd2bc262..416bbb6f05ab 100644
--- a/mm/page_alloc.c
+++ b/mm/page_alloc.c
@@ -1181,8 +1181,9 @@ static void free_one_page(struct zone *zone,
 	spin_unlock(&zone->lock);
 }
 
-static void __meminit __init_single_page(struct page *page, unsigned long pfn,
-				unsigned long zone, int nid)
+static void __meminit __init_struct_page_nolru(struct page *page,
+					       unsigned long pfn,
+					       unsigned long zone, int nid)
 {
 	mm_zero_struct_page(page);
 	set_page_links(page, zone, nid, pfn);
@@ -1191,7 +1192,6 @@ static void __meminit __init_single_page(struct page *page, unsigned long pfn,
 	page_cpupid_reset_last(page);
 	page_kasan_tag_reset(page);
 
-	INIT_LIST_HEAD(&page->lru);
 #ifdef WANT_PAGE_VIRTUAL
 	/* The shift won't overflow because ZONE_NORMAL is below 4G. */
 	if (!is_highmem_idx(zone))
@@ -1199,6 +1199,80 @@ static void __meminit __init_single_page(struct page *page, unsigned long pfn,
 #endif
 }
 
+static void __meminit __init_single_page(struct page *page, unsigned long pfn,
+				unsigned long zone, int nid)
+{
+	__init_struct_page_nolru(page, pfn, zone, nid);
+	INIT_LIST_HEAD(&page->lru);
+}
+
+static void __meminit __init_pageblock(unsigned long start_pfn,
+				       unsigned long nr_pages,
+				       unsigned long zone, int nid,
+				       struct dev_pagemap *pgmap)
+{
+	unsigned long nr_pgmask = pageblock_nr_pages - 1;
+	struct page *start_page = pfn_to_page(start_pfn);
+	unsigned long pfn = start_pfn + nr_pages - 1;
+	struct page *page;
+
+	/*
+	 * Enforce the following requirements:
+	 * size > 0
+	 * size < pageblock_nr_pages
+	 * start_pfn -> pfn does not cross pageblock_nr_pages boundary
+	 */
+	VM_BUG_ON(((start_pfn ^ pfn) | (nr_pages - 1)) > nr_pgmask);
+
+	/*
+	 * Work from highest page to lowest, this way we will still be
+	 * warm in the cache when we call set_pageblock_migratetype
+	 * below.
+	 *
+	 * The loop is based around the page pointer as the main index
+	 * instead of the pfn because pfn is not used inside the loop if
+	 * the section number is not in page flags and WANT_PAGE_VIRTUAL
+	 * is not defined.
+	 */
+	for (page = start_page + nr_pages; page-- != start_page; pfn--) {
+		__init_struct_page_nolru(page, pfn, zone, nid);
+		/*
+		 * Mark page reserved as it will need to wait for onlining
+		 * phase for it to be fully associated with a zone.
+		 *
+		 * We can use the non-atomic __set_bit operation for setting
+		 * the flag as we are still initializing the pages.
+		 */
+		__SetPageReserved(page);
+		/*
+		 * ZONE_DEVICE pages union ->lru with a ->pgmap back
+		 * pointer and hmm_data.  It is a bug if a ZONE_DEVICE
+		 * page is ever freed or placed on a driver-private list.
+		 */
+		page->pgmap = pgmap;
+		if (!pgmap)
+			INIT_LIST_HEAD(&page->lru);
+	}
+
+	/*
+	 * Mark the block movable so that blocks are reserved for
+	 * movable at startup. This will force kernel allocations
+	 * to reserve their blocks rather than leaking throughout
+	 * the address space during boot when many long-lived
+	 * kernel allocations are made.
+	 *
+	 * bitmap is created for zone's valid pfn range. but memmap
+	 * can be created for invalid pages (for alignment)
+	 * check here not to call set_pageblock_migratetype() against
+	 * pfn out of zone.
+	 *
+	 * Please note that MEMMAP_HOTPLUG path doesn't clear memmap
+	 * because this is done early in sparse_add_one_section
+	 */
+	if (!(start_pfn & nr_pgmask))
+		set_pageblock_migratetype(start_page, MIGRATE_MOVABLE);
+}
+
 #ifdef CONFIG_DEFERRED_STRUCT_PAGE_INIT
 static void __meminit init_reserved_page(unsigned long pfn)
 {
@@ -5693,6 +5767,25 @@ overlap_memmap_init(unsigned long zone, unsigned long *pfn)
 	return false;
 }
 
+static void __meminit __memmap_init_hotplug(unsigned long size, int nid,
+					    unsigned long zone,
+					    unsigned long start_pfn,
+					    struct dev_pagemap *pgmap)
+{
+	unsigned long pfn = start_pfn + size;
+
+	while (pfn != start_pfn) {
+		unsigned long stride = pfn;
+
+		pfn = max(ALIGN_DOWN(pfn - 1, pageblock_nr_pages), start_pfn);
+		stride -= pfn;
+
+		__init_pageblock(pfn, stride, zone, nid, pgmap);
+
+		cond_resched();
+	}
+}
+
 /*
  * Initially all pages are reserved - free ones are freed
  * up by memblock_free_all() once the early boot process is
@@ -5703,49 +5796,59 @@ void __meminit memmap_init_zone(unsigned long size, int nid, unsigned long zone,
 		struct vmem_altmap *altmap)
 {
 	unsigned long pfn, end_pfn = start_pfn + size;
-	struct page *page;
 
 	if (highest_memmap_pfn < end_pfn - 1)
 		highest_memmap_pfn = end_pfn - 1;
 
+	if (context == MEMMAP_HOTPLUG) {
 #ifdef CONFIG_ZONE_DEVICE
-	/*
-	 * Honor reservation requested by the driver for this ZONE_DEVICE
-	 * memory. We limit the total number of pages to initialize to just
-	 * those that might contain the memory mapping. We will defer the
-	 * ZONE_DEVICE page initialization until after we have released
-	 * the hotplug lock.
-	 */
-	if (zone == ZONE_DEVICE) {
-		if (!altmap)
-			return;
+		/*
+		 * Honor reservation requested by the driver for this
+		 * ZONE_DEVICE memory. We limit the total number of pages to
+		 * initialize to just those that might contain the memory
+		 * mapping. We will defer the ZONE_DEVICE page initialization
+		 * until after we have released the hotplug lock.
+		 */
+		if (zone == ZONE_DEVICE) {
+			if (!altmap)
+				return;
+
+			if (start_pfn == altmap->base_pfn)
+				start_pfn += altmap->reserve;
+			end_pfn = altmap->base_pfn +
+				  vmem_altmap_offset(altmap);
+		}
+#endif
+		/*
+		 * For these ZONE_DEVICE pages we don't need to record the
+		 * pgmap as they should represent only those pages used to
+		 * store the memory map. The actual ZONE_DEVICE pages will
+		 * be initialized later.
+		 */
+		__memmap_init_hotplug(end_pfn - start_pfn, nid, zone,
+				      start_pfn, NULL);
 
-		if (start_pfn == altmap->base_pfn)
-			start_pfn += altmap->reserve;
-		end_pfn = altmap->base_pfn + vmem_altmap_offset(altmap);
+		return;
 	}
-#endif
 
 	for (pfn = start_pfn; pfn < end_pfn; pfn++) {
+		struct page *page;
+
 		/*
 		 * There can be holes in boot-time mem_map[]s handed to this
 		 * function.  They do not exist on hotplugged memory.
 		 */
-		if (context == MEMMAP_EARLY) {
-			if (!early_pfn_valid(pfn))
-				continue;
-			if (!early_pfn_in_nid(pfn, nid))
-				continue;
-			if (overlap_memmap_init(zone, &pfn))
-				continue;
-			if (defer_init(nid, pfn, end_pfn))
-				break;
-		}
+		if (!early_pfn_valid(pfn))
+			continue;
+		if (!early_pfn_in_nid(pfn, nid))
+			continue;
+		if (overlap_memmap_init(zone, &pfn))
+			continue;
+		if (defer_init(nid, pfn, end_pfn))
+			break;
 
 		page = pfn_to_page(pfn);
 		__init_single_page(page, pfn, zone, nid);
-		if (context == MEMMAP_HOTPLUG)
-			__SetPageReserved(page);
 
 		/*
 		 * Mark the block movable so that blocks are reserved for
@@ -5772,7 +5875,6 @@ void __ref memmap_init_zone_device(struct zone *zone,
 				   unsigned long size,
 				   struct dev_pagemap *pgmap)
 {
-	unsigned long pfn, end_pfn = start_pfn + size;
 	struct pglist_data *pgdat = zone->zone_pgdat;
 	unsigned long zone_idx = zone_idx(zone);
 	unsigned long start = jiffies;
@@ -5788,53 +5890,13 @@ void __ref memmap_init_zone_device(struct zone *zone,
 	 */
 	if (pgmap->altmap_valid) {
 		struct vmem_altmap *altmap = &pgmap->altmap;
+		unsigned long end_pfn = start_pfn + size;
 
 		start_pfn = altmap->base_pfn + vmem_altmap_offset(altmap);
 		size = end_pfn - start_pfn;
 	}
 
-	for (pfn = start_pfn; pfn < end_pfn; pfn++) {
-		struct page *page = pfn_to_page(pfn);
-
-		__init_single_page(page, pfn, zone_idx, nid);
-
-		/*
-		 * Mark page reserved as it will need to wait for onlining
-		 * phase for it to be fully associated with a zone.
-		 *
-		 * We can use the non-atomic __set_bit operation for setting
-		 * the flag as we are still initializing the pages.
-		 */
-		__SetPageReserved(page);
-
-		/*
-		 * ZONE_DEVICE pages union ->lru with a ->pgmap back
-		 * pointer and hmm_data.  It is a bug if a ZONE_DEVICE
-		 * page is ever freed or placed on a driver-private list.
-		 */
-		page->pgmap = pgmap;
-		page->hmm_data = 0;
-
-		/*
-		 * Mark the block movable so that blocks are reserved for
-		 * movable at startup. This will force kernel allocations
-		 * to reserve their blocks rather than leaking throughout
-		 * the address space during boot when many long-lived
-		 * kernel allocations are made.
-		 *
-		 * bitmap is created for zone's valid pfn range. but memmap
-		 * can be created for invalid pages (for alignment)
-		 * check here not to call set_pageblock_migratetype() against
-		 * pfn out of zone.
-		 *
-		 * Please note that MEMMAP_HOTPLUG path doesn't clear memmap
-		 * because this is done early in sparse_add_one_section
-		 */
-		if (!(pfn & (pageblock_nr_pages - 1))) {
-			set_pageblock_migratetype(page, MIGRATE_MOVABLE);
-			cond_resched();
-		}
-	}
+	__memmap_init_hotplug(size, nid, zone_idx, start_pfn, pgmap);
 
 	pr_info("%s initialised, %lu pages in %ums\n", dev_name(pgmap->dev),
 		size, jiffies_to_msecs(jiffies - start));

