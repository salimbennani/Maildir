Return-Path: <linux-kernel-owner@vger.kernel.org>
Delivered-To: unknown
Received: from linux.intel.com (10.54.29.200:995) by likexu-workstation with
  POP3-SSL; 02 Dec 2018 19:23:28 -0000
X-Original-To: like.xu@linux.intel.com
Delivered-To: like.xu@linux.intel.com
Received: from orsmga004.jf.intel.com (orsmga004.jf.intel.com [10.7.209.38])
	(using TLSv1.2 with cipher ECDHE-RSA-AES256-GCM-SHA384 (256/256 bits))
	(No client certificate requested)
	by linux.intel.com (Postfix) with ESMTPS id 9D7FE58054E;
	Fri, 30 Nov 2018 13:53:03 -0800 (PST)
Received: from fmsmga104.fm.intel.com ([10.1.193.100])
  by orsmga004-1.jf.intel.com with ESMTP/TLS/DHE-RSA-AES256-GCM-SHA384; 30 Nov 2018 13:53:02 -0800
X-SG-BADATTACHMENTNOREPLY: True
IronPort-PHdr: =?us-ascii?q?9a23=3Ai8jgNhSNxv4sMHPZRd9xSivmcNpsv+yvbD5Q0YIu?=
 =?us-ascii?q?jvd0So/mwa64YBOAt8tkgFKBZ4jH8fUM07OQ7/iwHzRYqb+681k6OKRWUBEEjc?=
 =?us-ascii?q?hE1ycBO+WiTXPBEfjxciYhF95DXlI2t1uyMExSBdqsLwaK+i764jEdAAjwOhRo?=
 =?us-ascii?q?LerpBIHSk9631+ev8JHPfglEnjWwba9xIRmssQndqtQdjJd/JKo21hbHuGZDdf?=
 =?us-ascii?q?5MxWNvK1KTnhL86dm18ZV+7SleuO8v+tBZX6nicKs2UbJXDDI9M2Ao/8LrrgXM?=
 =?us-ascii?q?TRGO5nQHTGoblAdDDhXf4xH7WpfxtTb6tvZ41SKHM8D6Uaw4VDK/5KptVRTmij?=
 =?us-ascii?q?oINyQh/W/KisJ+kqxVrhGjqBxxzYHbb52aOvVlfqPFf94XXnZBU8RLWiBdHo+x?=
 =?us-ascii?q?dYkCAuwcNuhYtYn9oF4OoAOiCAmoGuzuxSVHhnnr0qIkyeQqDA/I3BEgHt0Ss3?=
 =?us-ascii?q?TfsdL4O70WUe+rw6jH1zPDYO5I1jfn8oTIcgotruyRXbNwbcXRylIiFwfEjlWW?=
 =?us-ascii?q?tIzkMCmZ1uULs2iH8eVgUfijhHIgqwF0uzWiwNonhIrRho8N1FzI6SF0zJwoKd?=
 =?us-ascii?q?C2VkJ3e8OoHZhMuy2ANoZ7QNsuT3xmtSs10LEKpJC2cScQxJg6yRPSauaLf5aH?=
 =?us-ascii?q?7x/lSe2fOy13hGh/d7K6nxuy8Vavyun7VsSszlZKoTRKksPWunAOyRPT8M6HRe?=
 =?us-ascii?q?V5/ku73jaPzQ/T5vlFIUAyi6XbN4YszqAsmpcXq0jPAyH7lFvsgKOLdUgo5vKk?=
 =?us-ascii?q?5uXlb7n+o5+TLY50igXwMqQ0ncy/BPw1MgwPX2id5OS926Tv/U7nT7VQiP05jK?=
 =?us-ascii?q?3ZvIndJcUVoK62HRVV35096xawETimys4UnXoZI1JffhKIkYzpN0vJIPDiAvez?=
 =?us-ascii?q?m06snytzx/DaIr3hBY3ALnzCkLfiY7lx8UFdyBcowNBb5pJUDKwBIf3pVk/wst?=
 =?us-ascii?q?zYEgE2Mwiuz+n7D9V905sUWXiTDa+BLKPSrViI6/ovI+aWZY8VpCzyK/8/6/7u?=
 =?us-ascii?q?kH82g1kdfaay0JsTaXC4GOlmIkqDbXrthNcBDXkFvg4kQOP2j12CVCZZZ2yuUK?=
 =?us-ascii?q?Ik+jE7FIWmAJ/BRoCqnrONxiS7HppQZmBADVCBCnPod4SCW/cRZyOeOM5hkjoY?=
 =?us-ascii?q?Vbe/T48tzw2htAj/y7B/NOrb5jUYtY7/1Nhy/+Dcjwoy9TxzD8SeyW2NVXt7nm?=
 =?us-ascii?q?ETSj8y3aB/p1F9y1iZ3ah5hfxYCcJc5/dTXggmMp7cyvRwC8ruVQLZYteJVFGm?=
 =?us-ascii?q?T82lAT4rSNI92dsOY0dnFNWkgRDOxC6qA74Tl7yWC5046KPc337tJ8ljz3bKzr?=
 =?us-ascii?q?Uuj14jQsFXL22pmrZ/9xTPB47Oi0iWiryldboC0yLX9GeM12yOvFpGXw52VqnF?=
 =?us-ascii?q?WXMfZk7Srdni4kPCTrmuCakoMwdbyM6CLLdKZcPtjVlcWPjjP9HeaXqrm2isHR?=
 =?us-ascii?q?aI2q+MbI3ydmoAxirdFlYLnxoT/XmcMwg+HTmuo2TFATxqFFLvZV7s8OZkpHO6?=
 =?us-ascii?q?SE800x+Fb0l727Wp/R4VgOSWS+kP0bIcpCchtzJ0EU6h39LXDtqAoBZhfKVcYN?=
 =?us-ascii?q?8n/FdLz2XZtxZ5PpyhKaBiiUUTcwB2v0PoyhV2BZ9MkcksrHM20gVyLbiU309G?=
 =?us-ascii?q?dzOdxZrwIKHYKnHu/BCzbK7bwkvR0NKI9aYA9vs5q0/vsxq0FkU/6Xpn1dpV03?=
 =?us-ascii?q?yC5pjRCAoSUJTxUls49hRgprHaZDU96J3Q1XF2Laa0tTrC0cozBOQ50hagY8tf?=
 =?us-ascii?q?MKScGQ7yDs0WHdShJPYrmlipdB0EOu9S+bUwP8OncfuGxaGqMPxhnDKgkWRI/o?=
 =?us-ascii?q?R93liQ+Cp7T+7Cx4wFzO2A3gubSzf8i0+sstr2mY9Yfz4SBHewyS/+CI5XeKJy?=
 =?us-ascii?q?Z4cLBX6yLMKtwtVxmoDiW2Rf9F6lHF4G3M6peRyPb13yxwFQ1EIXoWC5liu81T?=
 =?us-ascii?q?B7jzYprq+H1izU3+vibAYHOnJMRGR6jVbsIJK4jtAAUEizcggpkgCo5UL7x6hd?=
 =?us-ascii?q?uaR+IHPfQUZOfyjqMW5iVrG8uaaFY85K8JkoqzlYUPygYVCGTb7wuxka3Dn5H2?=
 =?us-ascii?q?tdxzA7cCumuo7jkBx5i2KdLXBzo2TfecxrwRff5drcReNe3zYcRSl4jyXXCUa4?=
 =?us-ascii?q?P9Wz4dqUkJLDuPikV229Tp1TbTXrzYSYuSq7/2JqBgezn/Kymt3hCgU61S7719?=
 =?us-ascii?q?93VSTHthr8Y4/r17ikPuJjZEVnGFj8689iEIFkjoQwnI0Q2WQdhpiN/noIi2bz?=
 =?us-ascii?q?Pc9b2aLjdnUNQzELzsXR4Ajk3k1jM32Iy5j4VnWb3stued26bnkK1SI66sBAEL?=
 =?us-ascii?q?2U46BcnStpvlq4qhrcYf18njce0/Qi8nAbjP8SuAox0CqdGKsdEldCPSzjjBmI?=
 =?us-ascii?q?69G+rKNKZGega7Sw1Ux+ncy/A7GGuA1TRHH5epI6Fy9q8sp/KE7M0GH06oz8ZN?=
 =?us-ascii?q?nQatcTugeVkhjaiehVNYkxluELhSd8PWL9vHsly/M0jBB03JG6upSHJHtp/K6j?=
 =?us-ascii?q?HhFYMTj1bdsJ+j7xlaZegtqW34e3E5p6ADoLW5/oTe+yHDIWqPTqLAKOEDw6qn?=
 =?us-ascii?q?eGFrvTBw6f6EF6r33RF5CnLW2YJH4czd96XhmSOFRfgBwIXDU9hpM5FBqlxMn/?=
 =?us-ascii?q?f0di/DwR+kT0qhhRyuJrKhn/VH3QpByzZzcwSZifKgdW7w5Y60fUN8ye8vx8Hy?=
 =?us-ascii?q?VC8pK9qwyNL3SRZx5UAmERRkyEG1fjM6Gu5NnH7uiYH/e+IOHIYbmUsuxeUPGI?=
 =?us-ascii?q?xZ2034ti/jaMMNiPP3Z4A/063EpDQW52G8DDlzoTTCwXkjrHb9SHqxek5i13ss?=
 =?us-ascii?q?e//ezrWA3x5IuPCLhSMdR19xC1m6eDMOGQizhjKTZFzZMB3nvIyLkZ3F4PhCBi?=
 =?us-ascii?q?bTitEbIctSHTSKLcgLNYDxkeaylrLstH87o83hVROc7ckt76zKN4geUvC1hbVV?=
 =?us-ascii?q?3tgMWpZc0RLmG5NVPHAluLNbucKT3KxcH3fb2zSblKgOpIsB2wvC6RE1X/MTSb?=
 =?us-ascii?q?iznpSxevPPlQjCGaORxSop2yfgxxBmjjUt3mbAa2MNt2jT0w3L01iWnGNW8aMT?=
 =?us-ascii?q?hgbUxNqqec4j9fgvV6A2ZB9GZqLfGYmyaF6OnVMpYXvuFtAiRxluJa5mw1yrpV?=
 =?us-ascii?q?7C5eQvx1lzDfrtpvo1Ggj+mOxSBrUBtIqjZXmo2LuV9uNrne9plFCj74+0cE7n?=
 =?us-ascii?q?2VIxALocZ1T9PopqZcw8TOk6S1Ly1Nt5rQ/M0BF43RLeqELnMqMlzuAjGHIhEC?=
 =?us-ascii?q?SGuCMWzPjkpRneva2mCEpZty/pHolYoHTLNWTho1UP8HG09mNNgDJopnGDIijb?=
 =?us-ascii?q?OfysUP4Czt/1HqWMxGs8WfBbqpCvL1JWPBgA=3D=3D?=
X-IronPort-Anti-Spam-Filtered: true
X-IronPort-Anti-Spam-Result: =?us-ascii?q?A0AgAABrsAFch0O0hNFjHAEBAQQBAQcEA?=
 =?us-ascii?q?QGBUQcBAQsBg2sng3mIGF+LVYE/OZI7hHmBcxQYEwGEOwODOCI0CQ0BAwEBAQE?=
 =?us-ascii?q?BAQIBEwEBAQgNCQgpL4I2IoJlAwMBAiBWBgkBASQCJgICA0QQBxIFgxyCAgWnD?=
 =?us-ascii?q?oEviiyBC4sPeoEcgREzimSCVwKJLYZDNpAPBwKCIogMhyGRHyyIT49igUaCDTM?=
 =?us-ascii?q?aI4M8gicXjj4eAQExAQGBAwEBjUABAQ?=
X-IPAS-Result: =?us-ascii?q?A0AgAABrsAFch0O0hNFjHAEBAQQBAQcEAQGBUQcBAQsBg2s?=
 =?us-ascii?q?ng3mIGF+LVYE/OZI7hHmBcxQYEwGEOwODOCI0CQ0BAwEBAQEBAQIBEwEBAQgNC?=
 =?us-ascii?q?QgpL4I2IoJlAwMBAiBWBgkBASQCJgICA0QQBxIFgxyCAgWnDoEviiyBC4sPeoE?=
 =?us-ascii?q?cgREzimSCVwKJLYZDNpAPBwKCIogMhyGRHyyIT49igUaCDTMaI4M8gicXjj4eA?=
 =?us-ascii?q?QExAQGBAwEBjUABAQ?=
X-IronPort-AV: E=Sophos;i="5.56,300,1539673200"; 
   d="scan'208";a="53384409"
X-Amp-Result: SKIPPED(no attachment in message)
X-Amp-File-Uploaded: False
Received: from vger.kernel.org ([209.132.180.67])
  by mtab.intel.com with ESMTP; 30 Nov 2018 13:53:01 -0800
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
        id S1726877AbeLAJDk (ORCPT <rfc822;like.xu@linux.intel.com>
        + 23 others); Sat, 1 Dec 2018 04:03:40 -0500
Received: from mga09.intel.com ([134.134.136.24]:43397 "EHLO mga09.intel.com"
        rhost-flags-OK-OK-OK-OK) by vger.kernel.org with ESMTP
        id S1725749AbeLAJDk (ORCPT <rfc822;linux-kernel@vger.kernel.org>);
        Sat, 1 Dec 2018 04:03:40 -0500
X-Amp-Result: SKIPPED(no attachment in message)
X-Amp-File-Uploaded: False
Received: from orsmga001.jf.intel.com ([10.7.209.18])
  by orsmga102.jf.intel.com with ESMTP/TLS/DHE-RSA-AES256-GCM-SHA384; 30 Nov 2018 13:52:58 -0800
X-ExtLoop1: 1
X-IronPort-AV: E=Sophos;i="5.56,300,1539673200"; 
   d="scan'208";a="114393665"
Received: from ahduyck-desk1.jf.intel.com (HELO ahduyck-desk1.amr.corp.intel.com) ([10.7.198.76])
  by orsmga001.jf.intel.com with ESMTP; 30 Nov 2018 13:52:58 -0800
Subject: [mm PATCH v6 2/7] mm: Drop meminit_pfn_in_nid as it is redundant
From: Alexander Duyck <alexander.h.duyck@linux.intel.com>
To: akpm@linux-foundation.org, linux-mm@kvack.org
Cc: sparclinux@vger.kernel.org, linux-kernel@vger.kernel.org,
        linux-nvdimm@lists.01.org, davem@davemloft.net,
        pavel.tatashin@microsoft.com, mhocko@suse.com, mingo@kernel.org,
        kirill.shutemov@linux.intel.com, dan.j.williams@intel.com,
        dave.jiang@intel.com, alexander.h.duyck@linux.intel.com,
        rppt@linux.vnet.ibm.com, willy@infradead.org, vbabka@suse.cz,
        khalid.aziz@oracle.com, ldufour@linux.vnet.ibm.com,
        mgorman@techsingularity.net, yi.z.zhang@linux.intel.com,
        alexander.h.duyck@linux.intel.com
Date: Fri, 30 Nov 2018 13:52:58 -0800
Message-ID: <154361477830.7497.18073959471440151885.stgit@ahduyck-desk1.amr.corp.intel.com>
In-Reply-To: <154361452447.7497.1348692079883153517.stgit@ahduyck-desk1.amr.corp.intel.com>
References: <154361452447.7497.1348692079883153517.stgit@ahduyck-desk1.amr.corp.intel.com>
User-Agent: StGit/unknown-version
MIME-Version: 1.0
Content-Type: text/plain; charset="utf-8"
Content-Transfer-Encoding: 7bit
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: <linux-kernel.vger.kernel.org>
X-Mailing-List: linux-kernel@vger.kernel.org

As best as I can tell the meminit_pfn_in_nid call is completely redundant.
The deferred memory initialization is already making use of
for_each_free_mem_range which in turn will call into __next_mem_range which
will only return a memory range if it matches the node ID provided assuming
it is not NUMA_NO_NODE.

I am operating on the assumption that there are no zones or pgdata_t
structures that have a NUMA node of NUMA_NO_NODE associated with them. If
that is the case then __next_mem_range will never return a memory range
that doesn't match the zone's node ID and as such the check is redundant.

So one piece I would like to verify on this is if this works for ia64.
Technically it was using a different approach to get the node ID, but it
seems to have the node ID also encoded into the memblock. So I am
assuming this is okay, but would like to get confirmation on that.

On my x86_64 test system with 384GB of memory per node I saw a reduction in
initialization time from 2.80s to 1.85s as a result of this patch.

Reviewed-by: Pavel Tatashin <pavel.tatashin@microsoft.com>
Acked-by: Michal Hocko <mhocko@suse.com>
Signed-off-by: Alexander Duyck <alexander.h.duyck@linux.intel.com>
---
 mm/page_alloc.c |   51 ++++++++++++++-------------------------------------
 1 file changed, 14 insertions(+), 37 deletions(-)

diff --git a/mm/page_alloc.c b/mm/page_alloc.c
index 20e1a8a2e98c..09969619ab48 100644
--- a/mm/page_alloc.c
+++ b/mm/page_alloc.c
@@ -1308,36 +1308,22 @@ int __meminit early_pfn_to_nid(unsigned long pfn)
 #endif
 
 #ifdef CONFIG_NODES_SPAN_OTHER_NODES
-static inline bool __meminit __maybe_unused
-meminit_pfn_in_nid(unsigned long pfn, int node,
-		   struct mminit_pfnnid_cache *state)
+/* Only safe to use early in boot when initialisation is single-threaded */
+static inline bool __meminit early_pfn_in_nid(unsigned long pfn, int node)
 {
 	int nid;
 
-	nid = __early_pfn_to_nid(pfn, state);
+	nid = __early_pfn_to_nid(pfn, &early_pfnnid_cache);
 	if (nid >= 0 && nid != node)
 		return false;
 	return true;
 }
 
-/* Only safe to use early in boot when initialisation is single-threaded */
-static inline bool __meminit early_pfn_in_nid(unsigned long pfn, int node)
-{
-	return meminit_pfn_in_nid(pfn, node, &early_pfnnid_cache);
-}
-
 #else
-
 static inline bool __meminit early_pfn_in_nid(unsigned long pfn, int node)
 {
 	return true;
 }
-static inline bool __meminit  __maybe_unused
-meminit_pfn_in_nid(unsigned long pfn, int node,
-		   struct mminit_pfnnid_cache *state)
-{
-	return true;
-}
 #endif
 
 
@@ -1466,21 +1452,13 @@ static inline void __init pgdat_init_report_one_done(void)
  *
  * Then, we check if a current large page is valid by only checking the validity
  * of the head pfn.
- *
- * Finally, meminit_pfn_in_nid is checked on systems where pfns can interleave
- * within a node: a pfn is between start and end of a node, but does not belong
- * to this memory node.
  */
-static inline bool __init
-deferred_pfn_valid(int nid, unsigned long pfn,
-		   struct mminit_pfnnid_cache *nid_init_state)
+static inline bool __init deferred_pfn_valid(unsigned long pfn)
 {
 	if (!pfn_valid_within(pfn))
 		return false;
 	if (!(pfn & (pageblock_nr_pages - 1)) && !pfn_valid(pfn))
 		return false;
-	if (!meminit_pfn_in_nid(pfn, nid, nid_init_state))
-		return false;
 	return true;
 }
 
@@ -1488,15 +1466,14 @@ deferred_pfn_valid(int nid, unsigned long pfn,
  * Free pages to buddy allocator. Try to free aligned pages in
  * pageblock_nr_pages sizes.
  */
-static void __init deferred_free_pages(int nid, int zid, unsigned long pfn,
+static void __init deferred_free_pages(unsigned long pfn,
 				       unsigned long end_pfn)
 {
-	struct mminit_pfnnid_cache nid_init_state = { };
 	unsigned long nr_pgmask = pageblock_nr_pages - 1;
 	unsigned long nr_free = 0;
 
 	for (; pfn < end_pfn; pfn++) {
-		if (!deferred_pfn_valid(nid, pfn, &nid_init_state)) {
+		if (!deferred_pfn_valid(pfn)) {
 			deferred_free_range(pfn - nr_free, nr_free);
 			nr_free = 0;
 		} else if (!(pfn & nr_pgmask)) {
@@ -1516,17 +1493,18 @@ static void __init deferred_free_pages(int nid, int zid, unsigned long pfn,
  * by performing it only once every pageblock_nr_pages.
  * Return number of pages initialized.
  */
-static unsigned long  __init deferred_init_pages(int nid, int zid,
+static unsigned long  __init deferred_init_pages(struct zone *zone,
 						 unsigned long pfn,
 						 unsigned long end_pfn)
 {
-	struct mminit_pfnnid_cache nid_init_state = { };
 	unsigned long nr_pgmask = pageblock_nr_pages - 1;
+	int nid = zone_to_nid(zone);
 	unsigned long nr_pages = 0;
+	int zid = zone_idx(zone);
 	struct page *page = NULL;
 
 	for (; pfn < end_pfn; pfn++) {
-		if (!deferred_pfn_valid(nid, pfn, &nid_init_state)) {
+		if (!deferred_pfn_valid(pfn)) {
 			page = NULL;
 			continue;
 		} else if (!page || !(pfn & nr_pgmask)) {
@@ -1589,12 +1567,12 @@ static int __init deferred_init_memmap(void *data)
 	for_each_free_mem_range(i, nid, MEMBLOCK_NONE, &spa, &epa, NULL) {
 		spfn = max_t(unsigned long, first_init_pfn, PFN_UP(spa));
 		epfn = min_t(unsigned long, zone_end_pfn(zone), PFN_DOWN(epa));
-		nr_pages += deferred_init_pages(nid, zid, spfn, epfn);
+		nr_pages += deferred_init_pages(zone, spfn, epfn);
 	}
 	for_each_free_mem_range(i, nid, MEMBLOCK_NONE, &spa, &epa, NULL) {
 		spfn = max_t(unsigned long, first_init_pfn, PFN_UP(spa));
 		epfn = min_t(unsigned long, zone_end_pfn(zone), PFN_DOWN(epa));
-		deferred_free_pages(nid, zid, spfn, epfn);
+		deferred_free_pages(spfn, epfn);
 	}
 	pgdat_resize_unlock(pgdat, &flags);
 
@@ -1633,7 +1611,6 @@ static DEFINE_STATIC_KEY_TRUE(deferred_pages);
 static noinline bool __init
 deferred_grow_zone(struct zone *zone, unsigned int order)
 {
-	int zid = zone_idx(zone);
 	int nid = zone_to_nid(zone);
 	pg_data_t *pgdat = NODE_DATA(nid);
 	unsigned long nr_pages_needed = ALIGN(1 << order, PAGES_PER_SECTION);
@@ -1683,7 +1660,7 @@ deferred_grow_zone(struct zone *zone, unsigned int order)
 		while (spfn < epfn && nr_pages < nr_pages_needed) {
 			t = ALIGN(spfn + PAGES_PER_SECTION, PAGES_PER_SECTION);
 			first_deferred_pfn = min(t, epfn);
-			nr_pages += deferred_init_pages(nid, zid, spfn,
+			nr_pages += deferred_init_pages(zone, spfn,
 							first_deferred_pfn);
 			spfn = first_deferred_pfn;
 		}
@@ -1695,7 +1672,7 @@ deferred_grow_zone(struct zone *zone, unsigned int order)
 	for_each_free_mem_range(i, nid, MEMBLOCK_NONE, &spa, &epa, NULL) {
 		spfn = max_t(unsigned long, first_init_pfn, PFN_UP(spa));
 		epfn = min_t(unsigned long, first_deferred_pfn, PFN_DOWN(epa));
-		deferred_free_pages(nid, zid, spfn, epfn);
+		deferred_free_pages(spfn, epfn);
 
 		if (first_deferred_pfn == epfn)
 			break;

