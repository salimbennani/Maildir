Return-Path: <linux-kernel-owner@vger.kernel.org>
Delivered-To: unknown
Received: from linux.intel.com (10.54.29.200:995) by i7-8700 with POP3-SSL;
  13 Dec 2018 08:49:28 -0000
X-Original-To: like.xu@linux.intel.com
Delivered-To: like.xu@linux.intel.com
Received: from orsmga002.jf.intel.com (orsmga002.jf.intel.com [10.7.209.21])
	(using TLSv1.2 with cipher ECDHE-RSA-AES256-GCM-SHA384 (256/256 bits))
	(No client certificate requested)
	by linux.intel.com (Postfix) with ESMTPS id 0DFD958079D;
	Wed, 12 Dec 2018 04:14:07 -0800 (PST)
Received: from fmsmga104.fm.intel.com ([10.1.193.100])
  by orsmga002-1.jf.intel.com with ESMTP/TLS/DHE-RSA-AES256-GCM-SHA384; 12 Dec 2018 04:14:06 -0800
X-SG-BADATTACHMENTNOREPLY: True
IronPort-PHdr: =?us-ascii?q?9a23=3AG4/cLRwihmUYOZ/XCy+O+j09IxM/srCxBDY+r6Qd?=
 =?us-ascii?q?0e4QK/ad9pjvdHbS+e9qxAeQG9mDu7Qc06L/iOPJYSQ4+5GPsXQPItRndiQuro?=
 =?us-ascii?q?EopTEmG9OPEkbhLfTnPGQQFcVGU0J5rTngaRAGUMnxaEfPrXKs8DUcBgvwNRZv?=
 =?us-ascii?q?JuTyB4Xek9m72/q99pHPYAhEniaxba9vJxiqsAvdsdUbj5F/Iagr0BvJpXVIe+?=
 =?us-ascii?q?VSxWx2IF+Yggjx6MSt8pN96ipco/0u+dJOXqX8ZKQ4UKdXDC86PGAv5c3krgfM?=
 =?us-ascii?q?QA2S7XYBSGoWkx5IAw/Y7BHmW5r6ryX3uvZh1CScIMb7Vq4/Vyi84Kh3SR/okC?=
 =?us-ascii?q?YHOCA/8GHLkcx7kaZXrAu8qxBj34LYZYeYP+d8cKzAZ9MXXWRPUMZPWSJcAY28?=
 =?us-ascii?q?YYQAAPYcMulaoYb9vEMOoBmlCAmwGO/i0CNEimPs0KEk1ekqDAHI3BYnH9ILqH?=
 =?us-ascii?q?naq9T1O7sSUe+vyKnD0DfNb/RK1jf+74jDbxcsofSMXbJ3bcXRyk4vGhjGjlqO?=
 =?us-ascii?q?s4zlOS2a1uAXv2ic9epgWvuihmg6oA9yujii3tkghpXNi44P11zJ+zt1zJwoKd?=
 =?us-ascii?q?C7VEJ3e9+pHZlIuy2HM4Z7QtkuT3xmtSs60LEKp4C3cDQQxJg5xxPSZPqKeJWS?=
 =?us-ascii?q?7B35TuaeOzJ4iWpleL2hgxay9lCtyvPzVsaqylZGtClFncfWtnALyRPT7tKLSv?=
 =?us-ascii?q?xn/keuwTqP1gbT5f9YIU0si6bXN5oszqQtmpcdr0jPBDL6lUbqgKOMd0gp+PCk?=
 =?us-ascii?q?6+H9bbXnop+cOZV0igb7Mqk2nsy/AOI4MhUBXmSC+uSzyqfj/UvnT7VOl/E2la?=
 =?us-ascii?q?fYsJbEKsQBvaO5HQBV3Zg56xqlDDepzs4YnX8ZI1JBYh6HiJLpO17WLPDiEfi/?=
 =?us-ascii?q?m0iskCtsx/3eOr3hA5bNIWbZnLbuYLZw8EpcyAs1zdBC6JNYELABIPTvWkDvsN?=
 =?us-ascii?q?zUFAM2Mwuxw+z/EtVyypseWX6TAq+eKK7SsUWH5uMzI+aWY48Zojb9K+U/6P7o?=
 =?us-ascii?q?gn80glsdfaiv3ZsKZ3G0BPVmI0OFYXXyhtcNC3sFvg07TObykl2NTSZTZ2quX6?=
 =?us-ascii?q?I7/jw7CoWmApnZSoCuh7yB2iG7HppNa2BCC1CMF2rodoqeV/cNbiKSPtFukjge?=
 =?us-ascii?q?Wbe9TI8h0AmktBXmxLp/MurU5ioYuIr529hu5+3TkhIy+SZuD8uH0WGAVGV0nm?=
 =?us-ascii?q?IORz8r06Fzu019ylGf0admh/xUD8Bc5/RMUg0iL57T0/R6C8zuWgLGZtqJS0yp?=
 =?us-ascii?q?QtO8DTE1T9I+2dkOY0lmFtWmjxDD2TeqArAPm7yKApw07rzT33zrK8lhzHbG0b?=
 =?us-ascii?q?Erj0M6TctXKW2mmql/+hDOCIHTjUWWibymdaQG0y7L72eM02yOsEZcUA5zVKXF?=
 =?us-ascii?q?WWsSZk/XrdT/+0PDQKWiCbUhMgtd18GCLrFGZcHujVVDXP3jIsjRY3qtm2esAh?=
 =?us-ascii?q?aF3q6DY5D0e2oDxindCFILkwYI/XmYMwgzHSOho2PYDDxzGlPjeULs8e9iqHyl?=
 =?us-ascii?q?Sk841R2Fb0pk17Ct4B4ameScS+8P3rIDoCohtzR0HFO639LKC9qBpxBtfLlGbd?=
 =?us-ascii?q?M6+ldH0WPZtwpyPpG7K6Bih1gecxl4vk/01hV3DJlAntYurH8w0AVyLqeY2ktb?=
 =?us-ascii?q?dzyExZDwJqHXKm7q8R+1b67ZxF7f38iW+6sV8/s4tkjssxuvFkoh9HVnzcJY03?=
 =?us-ascii?q?+d5pXMEQoTXoj9Ukcx9xhmub7aZjMx6J/T1X1pKaO0qCPN28o1BOs5zRatZ9de?=
 =?us-ascii?q?ML6eGADuCcEbBsiuJ/Ysm1imdR8EOOFS9KgpP8KpbfeG2airPPp+kzKil2hI/I?=
 =?us-ascii?q?d90keU/SpmVuHIx4oFw+2f3gafTTf8jUuuvdrtmY9ZYjEeBGy/xjb+BI5Qf6F9?=
 =?us-ascii?q?YZwECWOzLMKp3NV+gJjtVmVc9F6iAVMGxcCodQCTb1z7wQ1fy0AXrWa7liu/yj?=
 =?us-ascii?q?x+iyspobaH3CzS3+TicwIKO25KRGV4jVbgO5O0j80cXEWzawgplR2l5Vv1xqRB?=
 =?us-ascii?q?paR/KXXTTllMfyTsM25iVa6wvKKYY8FT8JMorTlXUOOkbFCYULH9uRga0yDkH2?=
 =?us-ascii?q?dE3zA0bTKqupb4nxx8lm2dKm1+rH7YecF22Bfe68bQRf9X3joaWiZ4jSPbCUS7?=
 =?us-ascii?q?P9ms5d+UjYvMsviiV2K9UZ1eaSnqwpmHtCeh521qABu/kuu3mt3mFwg6zCD628?=
 =?us-ascii?q?NrVSXOsBbzfI3r276mPuJge0liHEX85NZiGoFijoswg4kd2XsAiZWU53YHkXrz?=
 =?us-ascii?q?Ps9d2aLxd3cNQT8Lw9jI4AnqwkFjL3SJx57nWXWZ2Mdue966YmYO0CIn889KEL?=
 =?us-ascii?q?uU7KBDnSZtp1q4rAHRbuJnkjYT1/Qu82IajP8TuAU20CqdGL8SEFJcPSztkRSI?=
 =?us-ascii?q?8t+/oL9WZGapbbi/yk5+kcq9A7GFpwFWQGz5dYs6HS9s8sV/N0rB0GH06oHhYt?=
 =?us-ascii?q?XRbMgcthuJkxfblOhVKYk8lv4LhSphJGL8smcpy+89jRxyw566uJKLJHlq/KK8?=
 =?us-ascii?q?GhRYLCH6Z9sP+jHxiqZTht2Z0JqoHpVlBzUHRp/oTe+zHTIWtPTnMRuOETImpn?=
 =?us-ascii?q?eaH7rfARGQ6EN8o33TFJCrMmmdJGMFwtV6WBmdOEtfjRgWXDogm542CBuqyNb9?=
 =?us-ascii?q?cEtj5TAR+134qgZKyu1yLBnySWPfpAauajcpR5mTNhtW7gde50jLNcyS9P58Hy?=
 =?us-ascii?q?Zd/pe5tgyCNnSbZxhUDWEOQkGFB1fjPqS35dnd6eeYAPCyL+DJYbWIpuxTTPOI?=
 =?us-ascii?q?xZOp0ot78DeALMSPPn9+D/Il3kpPR2x2G8Pcmz8XUSwYizrNb9KHpBe74iB3rt?=
 =?us-ascii?q?6w8PXoWALs5IuDEbhSMc9o+xC5n6iDLfOQhD1iJDZc15MMw2LIybcF0F4TjSFu?=
 =?us-ascii?q?ayeiEbAauSHRS6LQn7ddDwQHZCNrKMtI86U80xFXNs7Gkdz1zKB3j/4vB1dBVF?=
 =?us-ascii?q?zsgcWpZc0MI2GgO1LLHkeLNLKaJTLVx8H7e7+zSbpVjO9MrR2/pS6bE1P/PjSE?=
 =?us-ascii?q?jzTpSxGvMeRWgC6HJhBRpIG9fQhrCWX4SNLmaxu7MMJ4jDEswL00gG/KOnAYMT?=
 =?us-ascii?q?Rmb0xNqbiQ5ztCgvpjA2xB8mZlLe6clieZ9ebYLJMWsfptAitsluNa4G41y71a?=
 =?us-ascii?q?7CxfQPx1mS3SrsNhol28k+mPzCZnXwRKqjpRmI2LukBiau3l8cwKenfe/RYJpU?=
 =?us-ascii?q?zWQy8KusdoD9rx8egEydnVlab3ACxC7s7Z+MwCQc7dLc/RY1Q7Nh+8PT/fDAIB?=
 =?us-ascii?q?BR6sPmLYzxhYkPaZ9Xq9rZUgrJXo3p0URekIBxQOCvoGBxE9T5Q5K5BtU2ZhyO?=
 =?us-ascii?q?bDgQ=3D=3D?=
X-IronPort-Anti-Spam-Filtered: true
X-IronPort-Anti-Spam-Result: =?us-ascii?q?A0ABAAAt+xBch0O0hNFbCBkBAQEBAQEBA?=
 =?us-ascii?q?QEBAQEHAQEBAQEBgVEEAQEBAQELAYNrJ4wUjBKCDRSXP4FzLBMBhzsiNAkNAQM?=
 =?us-ascii?q?BAQEBAQECARMBAQEIDQkIKS+CNiQBgmEBAQEBAgEBAiQTPwUBCQEBChUDCRMSA?=
 =?us-ascii?q?wwFSRMFFoMGgXoIBAGmXDOKMIw8F4FAP4ERgxKEWwGGAAKLMJVcCZFMCxiJdId?=
 =?us-ascii?q?SmwWCDjMaCCgIgyeQXD8yAYEEAQGKMIJMAQE?=
X-IPAS-Result: =?us-ascii?q?A0ABAAAt+xBch0O0hNFbCBkBAQEBAQEBAQEBAQEHAQEBAQE?=
 =?us-ascii?q?BgVEEAQEBAQELAYNrJ4wUjBKCDRSXP4FzLBMBhzsiNAkNAQMBAQEBAQECARMBA?=
 =?us-ascii?q?QEIDQkIKS+CNiQBgmEBAQEBAgEBAiQTPwUBCQEBChUDCRMSAwwFSRMFFoMGgXo?=
 =?us-ascii?q?IBAGmXDOKMIw8F4FAP4ERgxKEWwGGAAKLMJVcCZFMCxiJdIdSmwWCDjMaCCgIg?=
 =?us-ascii?q?yeQXD8yAYEEAQGKMIJMAQE?=
X-IronPort-AV: E=Sophos;i="5.56,344,1539673200"; 
   d="scan'208";a="54862116"
X-Amp-Result: UNKNOWN
X-Amp-Original-Verdict: FILE UNKNOWN
X-Amp-File-Uploaded: False
Received: from vger.kernel.org ([209.132.180.67])
  by mtab.intel.com with ESMTP; 12 Dec 2018 04:14:05 -0800
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
        id S1727383AbeLLMOC (ORCPT <rfc822;like.xu@linux.intel.com>
        + 23 others); Wed, 12 Dec 2018 07:14:02 -0500
Received: from mx2.suse.de ([195.135.220.15]:58594 "EHLO mx1.suse.de"
        rhost-flags-OK-OK-OK-FAIL) by vger.kernel.org with ESMTP
        id S1727067AbeLLMOC (ORCPT <rfc822;linux-kernel@vger.kernel.org>);
        Wed, 12 Dec 2018 07:14:02 -0500
X-Virus-Scanned: by amavisd-new at test-mx.suse.de
Received: from relay2.suse.de (unknown [195.135.220.254])
        by mx1.suse.de (Postfix) with ESMTP id E5A9DAC39;
        Wed, 12 Dec 2018 12:13:59 +0000 (UTC)
Date: Wed, 12 Dec 2018 13:13:58 +0100
From: Michal Hocko <mhocko@kernel.org>
To: "Kirill A. Shutemov" <kirill@shutemov.name>
Cc: Andrew Morton <akpm@linux-foundation.org>,
        Liu Bo <bo.liu@linux.alibaba.com>, Jan Kara <jack@suse.cz>,
        Dave Chinner <david@fromorbit.com>,
        Theodore Ts'o <tytso@mit.edu>,
        Johannes Weiner <hannes@cmpxchg.org>,
        Vladimir Davydov <vdavydov.dev@gmail.com>, linux-mm@kvack.org,
        linux-fsdevel@vger.kernel.org, LKML <linux-kernel@vger.kernel.org>
Subject: Re: [PATCH] mm, memcg: fix reclaim deadlock with writeback
Message-ID: <20181212121358.GR1286@dhcp22.suse.cz>
References: <20181211132645.31053-1-mhocko@kernel.org>
 <20181212115837.zragenml27av3fqm@kshutemo-mobl1>
MIME-Version: 1.0
Content-Type: text/plain; charset=us-ascii
Content-Disposition: inline
In-Reply-To: <20181212115837.zragenml27av3fqm@kshutemo-mobl1>
User-Agent: Mutt/1.10.1 (2018-07-13)
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: <linux-kernel.vger.kernel.org>
X-Mailing-List: linux-kernel@vger.kernel.org

On Wed 12-12-18 14:58:37, Kirill A. Shutemov wrote:
> On Tue, Dec 11, 2018 at 02:26:45PM +0100, Michal Hocko wrote:
> > From: Michal Hocko <mhocko@suse.com>
> > 
> > Liu Bo has experienced a deadlock between memcg (legacy) reclaim and the
> > ext4 writeback
> > task1:
> > [<ffffffff811aaa52>] wait_on_page_bit+0x82/0xa0
> > [<ffffffff811c5777>] shrink_page_list+0x907/0x960
> > [<ffffffff811c6027>] shrink_inactive_list+0x2c7/0x680
> > [<ffffffff811c6ba4>] shrink_node_memcg+0x404/0x830
> > [<ffffffff811c70a8>] shrink_node+0xd8/0x300
> > [<ffffffff811c73dd>] do_try_to_free_pages+0x10d/0x330
> > [<ffffffff811c7865>] try_to_free_mem_cgroup_pages+0xd5/0x1b0
> > [<ffffffff8122df2d>] try_charge+0x14d/0x720
> > [<ffffffff812320cc>] memcg_kmem_charge_memcg+0x3c/0xa0
> > [<ffffffff812321ae>] memcg_kmem_charge+0x7e/0xd0
> > [<ffffffff811b68a8>] __alloc_pages_nodemask+0x178/0x260
> > [<ffffffff8120bff5>] alloc_pages_current+0x95/0x140
> > [<ffffffff81074247>] pte_alloc_one+0x17/0x40
> > [<ffffffff811e34de>] __pte_alloc+0x1e/0x110
> > [<ffffffffa06739de>] alloc_set_pte+0x5fe/0xc20
> > [<ffffffff811e5d93>] do_fault+0x103/0x970
> > [<ffffffff811e6e5e>] handle_mm_fault+0x61e/0xd10
> > [<ffffffff8106ea02>] __do_page_fault+0x252/0x4d0
> > [<ffffffff8106ecb0>] do_page_fault+0x30/0x80
> > [<ffffffff8171bce8>] page_fault+0x28/0x30
> > [<ffffffffffffffff>] 0xffffffffffffffff
> > 
> > task2:
> > [<ffffffff811aadc6>] __lock_page+0x86/0xa0
> > [<ffffffffa02f1e47>] mpage_prepare_extent_to_map+0x2e7/0x310 [ext4]
> > [<ffffffffa08a2689>] ext4_writepages+0x479/0xd60
> > [<ffffffff811bbede>] do_writepages+0x1e/0x30
> > [<ffffffff812725e5>] __writeback_single_inode+0x45/0x320
> > [<ffffffff81272de2>] writeback_sb_inodes+0x272/0x600
> > [<ffffffff81273202>] __writeback_inodes_wb+0x92/0xc0
> > [<ffffffff81273568>] wb_writeback+0x268/0x300
> > [<ffffffff81273d24>] wb_workfn+0xb4/0x390
> > [<ffffffff810a2f19>] process_one_work+0x189/0x420
> > [<ffffffff810a31fe>] worker_thread+0x4e/0x4b0
> > [<ffffffff810a9786>] kthread+0xe6/0x100
> > [<ffffffff8171a9a1>] ret_from_fork+0x41/0x50
> > [<ffffffffffffffff>] 0xffffffffffffffff
> > 
> > He adds
> > : task1 is waiting for the PageWriteback bit of the page that task2 has
> > : collected in mpd->io_submit->io_bio, and tasks2 is waiting for the LOCKED
> > : bit the page which tasks1 has locked.
> > 
> > More precisely task1 is handling a page fault and it has a page locked
> > while it charges a new page table to a memcg. That in turn hits a memory
> > limit reclaim and the memcg reclaim for legacy controller is waiting on
> > the writeback but that is never going to finish because the writeback
> > itself is waiting for the page locked in the #PF path. So this is
> > essentially ABBA deadlock.
> > 
> > Waiting for the writeback in legacy memcg controller is a workaround
> > for pre-mature OOM killer invocations because there is no dirty IO
> > throttling available for the controller. There is no easy way around
> > that unfortunately. Therefore fix this specific issue by pre-allocating
> > the page table outside of the page lock. We have that handy
> > infrastructure for that already so simply reuse the fault-around pattern
> > which already does this.
> > 
> > Reported-and-Debugged-by: Liu Bo <bo.liu@linux.alibaba.com>
> > Signed-off-by: Michal Hocko <mhocko@suse.com>
> > ---
> > Hi,
> > this has been originally reported here [1]. While it could get worked
> > around in the fs, catching the allocation early sounds like a preferable
> > approach. Liu Bo has noted that he is not able to reproduce this anymore
> > because kmem accounting has been disabled in their workload but this
> > should be quite straightforward to review.
> > 
> > There are probably other hidden __GFP_ACCOUNT | GFP_KERNEL allocations
> > from under a fs page locked but they should be really rare. I am not
> > aware of a better solution unfortunately.
> 
> Okay, I have spent some time on the issue and was not able to find a
> better solution too. But I cannot say I like it.

Ohh, I do not like it either. I can make it more targeted by abstracting
sane_reclaim() and using it for the check but I am not sure this is
really more helpful.
 
> I think we need to spend more time on making ->prealloc_pte useful: looks
> like it would help to convert vmf_insert_* helpers to take struct vm_fault
> * as input and propagate it down to pmd population point. Otherwise DAX
> and drivers would alloacate the page table for nothing.

Yes this would be an obvious enahancement.

> Have you considered if we need anything similar for anon path? Is it
> possible to have similar deadlock with swaping rather than writeback?

No, I do not see anon path to allocated under page lock.
-- 
Michal Hocko
SUSE Labs
