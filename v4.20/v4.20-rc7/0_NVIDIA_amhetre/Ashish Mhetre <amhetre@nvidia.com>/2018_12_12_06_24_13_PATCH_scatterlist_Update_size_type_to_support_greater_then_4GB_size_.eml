Return-Path: <linux-kernel-owner@vger.kernel.org>
Delivered-To: unknown
Received: from linux.intel.com (10.54.29.200:995) by i7-8700 with POP3-SSL;
  12 Dec 2018 19:41:57 -0000
X-Original-To: like.xu@linux.intel.com
Delivered-To: like.xu@linux.intel.com
Received: from orsmga005.jf.intel.com (orsmga005.jf.intel.com [10.7.209.41])
	(using TLSv1.2 with cipher ECDHE-RSA-AES256-GCM-SHA384 (256/256 bits))
	(No client certificate requested)
	by linux.intel.com (Postfix) with ESMTPS id 24AF05803DC;
	Tue, 11 Dec 2018 22:26:07 -0800 (PST)
Received: from orsmga101.jf.intel.com ([10.7.208.22])
  by orsmga005-1.jf.intel.com with ESMTP/TLS/DHE-RSA-AES256-GCM-SHA384; 11 Dec 2018 22:26:06 -0800
X-SG-BADATTACHMENTNOREPLY: True
IronPort-PHdr: =?us-ascii?q?9a23=3AbSbn9xLEj+PgCbjhFNmcpTZWNBhigK39O0sv0rFi?=
 =?us-ascii?q?tYgULPj9rarrMEGX3/hxlliBBdydt6oUzbKO+4nbGkU4qa6bt34DdJEeHzQksu?=
 =?us-ascii?q?4x2zIaPcieFEfgJ+TrZSFpVO5LVVti4m3peRMNQJW2aFLduGC94iAPERvjKwV1?=
 =?us-ascii?q?Ov71GonPhMiryuy+4ZLebxlLiTanfb9+MAi9oBnMuMURnYZsMLs6xAHTontPde?=
 =?us-ascii?q?RWxGdoKkyWkh3h+Mq+/4Nt/jpJtf45+MFOTav1f6IjTbxFFzsmKHw65NfqtRbY?=
 =?us-ascii?q?UwSC4GYXX3gMnRpJBwjF6wz6Xov0vyDnuOdxxDWWMMvrRr0yRD+s7bpkSAXwhS?=
 =?us-ascii?q?kHKTA37W/ZhM93gq1UvB2hvAR/zozPbYGJKPZzZL/RcMkGSWZdWMtaSixPApm7?=
 =?us-ascii?q?b4sKF+cMIf1Yr4n8p1sVrRu1GA6iBOPxxT9UnH/5w7Ax3uM7HgHD3AwvAc4OsG?=
 =?us-ascii?q?7Ko9juMqcST+G1w7TJzTrZdf9ZxTD96I3Rfx0nvPqCXqpwfNLPxUUzEw7JlEic?=
 =?us-ascii?q?pIL7Mz+Py+gAsHSX4/BhWO+tk2IrtRx9rzm1yssylIXEhZgZxk3a+Slk2oo5ON?=
 =?us-ascii?q?K1RUB9bNW5CpVfrTuaOJFzQs46Q2FnpiI6yroetJ6lcygF1o4nywTca/OZaYiI?=
 =?us-ascii?q?5AzsVOKLLTd/nnJld6qzhxe08Ue+1u3xTte43EpOoyZfj9XBuG4B2wbO5sWEVv?=
 =?us-ascii?q?dx5Eas1DSX2wDW8O5EIEQ0laTBK54mx749jp4TsUXFHi/rl0T6layWeVs++uiu?=
 =?us-ascii?q?9evnZqzqppiSNo9ylA7+KL8jmtKwAesmKAgCRWub9vqm1L3l40L5RK9Gjvoskq?=
 =?us-ascii?q?nWqJzaP9gUpralAw9J1YYu8xK/Dzal0NsGh3UGI09FdQmDj4joPVHOPf/5Ae2+?=
 =?us-ascii?q?g1SqjDdk2fTGMqf9DZXKK3jJiK3hcqpl605A1AozyshS55JOBbEAPPL8QEjxuM?=
 =?us-ascii?q?bYDh8kKQO0xennBc551oMfX2KPH6CYPLnTsV+O+uIgPe2MaJUJtzb6Lvgv/+Tu?=
 =?us-ascii?q?gmMhmV8BYamp2oMaaHK/Hvt4OUmZYn3sgtEHEWcNpQc+SO3qiFufUT9cfXqyXq?=
 =?us-ascii?q?Q85i0lB4KiF4vMWoetgLmZ1iehApJWfnxGCkyLEXrwbYqEQPcMaCWRIsN7iDwL?=
 =?us-ascii?q?T7qhRpQl1RGvsg/61rVmIvDV+i0eqZLsytx16/fPmhE18Dx+F96d3H2VT2Fogm?=
 =?us-ascii?q?MIQCc73KNlrkx70FuD1al4jOZeFdxc/P5JVgY6NZjBz+11EdzyWwTBfsuXR1ai?=
 =?us-ascii?q?WNmpHTYxTtcpyd8Uf0l9A8mijgzE3yeyHrAajaKLC4Iu/qLcxXfxId19xGjA1K?=
 =?us-ascii?q?Umi1kmQc5PNWm9i6579gjTAZPJkkqDm6arc6QcwDDC9GOZwWWSu0FYVRZ6Ub/Z?=
 =?us-ascii?q?UnAHekvWsdP561vfQLC0F7QoLBFNyc6YJatMcd3mk1NGSeznONTfZWKxhmixCQ?=
 =?us-ascii?q?yJxrOKcIrlZWEd0D/BB0gDlgAZ5WyGOhQmBie9v2LeCyRjFU7uY0Pp9ul+tHO7?=
 =?us-ascii?q?T08uwwGWdUFh0KC1+hoUhfyaRPMexbYEuCYnqzVpE1exxdPWC9ycpwV/eKVQe8?=
 =?us-ascii?q?8y4FBC1WjBrQxyIoSgL7x+hl4Zawl4pUfu2At4C4pekckmtmglzBdvJq2C1lNB?=
 =?us-ascii?q?dDSY3Y7rN73TK2ny+g2vaqHM1lHf1taW5rkA6PAip1r/uwGpE1Io82973NlNz3?=
 =?us-ascii?q?uc+pLKARISUJLsSEo46wJ2prDaYiYn4YPU2mZhMa21sj/ExtIoC/Epyhemf9dD?=
 =?us-ascii?q?LqyEEBX+HNEdB8irMOYqgUSmbgoYPOBO8645J9mmd/qa16GxJuZvgTWmgX5B4I?=
 =?us-ascii?q?9jyEKM9jNwRfLS0JYB3v6XwBGHVzD6jFq6tsD3mIZEZSwdH2alyCjkApJRabN2?=
 =?us-ascii?q?fYoRFWiuJMi3zM1kh5HxQ35Y6EKjB1Qe1c6peBqedVz80RdL1UQKp3yqgi+4zz?=
 =?us-ascii?q?1ykzE0oauTxi3Ow+L+dBUZPm5HXnVtjVDpIYKsldAVQFCobxQ1lBui/Uv6xbJU?=
 =?us-ascii?q?pL58L2nQRkdEZTP2IHthUquzt7qCZdBA6JUzvCVTUeS8Z02aS7Hnrxsb1SPjA3?=
 =?us-ascii?q?VRxDQhez62vZX5mgRwiHiBI3ZrsHrZZcZwyA/f5dPGQv5dxDgGRCh+iTTMAli8?=
 =?us-ascii?q?Pt+p/ciblpvZs+C+UX6hWYNXcSXx0YyAsy6773VwARKjh/CzhsHnEQ8i3C/4zd?=
 =?us-ascii?q?ZqVD/ErBbhYobx0aS6Pvlqfk1pBF/69sp7FZtykoo2hJEMx3cago+Z8mYAkWf2?=
 =?us-ascii?q?Kd9bw77xbGIRRT4XxN7Y+A3l2ExgLn2T3Y74WGuSwtB9Z9akeGMZwTwy79pFCK?=
 =?us-ascii?q?qP6LxEnC11oke3rA7LYPh9mCsdxuUq6HIAn+4Jvw8txD2HAr8OBUlYITDslxOQ?=
 =?us-ascii?q?4tCiq6VXYXyjcLmq20p4gNChF6qCogBHVXb9e5ciGzJw78plPFLN1n3z9p/reN?=
 =?us-ascii?q?3KYd0PsR2Ulg/Kj/JJJ5IpivoKmS1nNHrmsnI/zO47iQFu0Yu+vIiaMGht+KO5?=
 =?us-ascii?q?AhhFNjz6fc8T+zftjbpAkcaSxYygApJhGjATVpvyUf2oCC4StejgNwuWEj0zsH?=
 =?us-ascii?q?KbFqTEHQOF9EdqtXHPE42oN3GKInkW185iSQKZJExehgAUQTo7koQ4FgCs2Mzu?=
 =?us-ascii?q?bkN56ioN6V7/rxtG0vhoOAXnUmfDuAeobS85SZiYLBpL9wFC+l3aMcqE4uJoGC?=
 =?us-ascii?q?FY+JKhoReJKmyaYQRIEG4IVlaFB1DlIrmh+93A//KECeq5KvvEea+OpvBGV/eU?=
 =?us-ascii?q?2ZKv1ZNr/zaSOcWOPXliDPw71lBAXXBjHMTZlCsASzYKlyLWdMOboBa8+itqrs?=
 =?us-ascii?q?Gw6vjrWQTv5ZeRBLtWK9lg5xe2gaKbPe6KmCl5MSpY1o8LxXLQ0rcfwUUdiztw?=
 =?us-ascii?q?eDitC7gAsS/NQbnUmq9WCR4bdixyONFJ76I6wglCJ8rbhsnp2b5/i/4/E01FWk?=
 =?us-ascii?q?D5msG1ecwKJHmwNE/GBEaOLriJOSfHzN33YayiT71dl+FUtxy2uTaGHE7vJDWD?=
 =?us-ascii?q?lz/1Vx+xNeFAlj2UPBtbuIulaBZiFXDjTM76ah28KNJ2jSc5wbsxhnPLM24TKT?=
 =?us-ascii?q?l9c0NXob2W4iNVmfF/G21H7np4IuiIgSeZ7+/EKpkItftnGDh7l+Vf4Cdy97wA?=
 =?us-ascii?q?uCFJXvZ4gjf6odlor1a81OCXwzxuFh1UpXBCmdTP9RFuMLvU87FMUGjJ+RYK43?=
 =?us-ascii?q?nWDRkW8Z8tXtT/sadd4tvCjqT+LHFO8ISQtZ8VC9LVIcTBMGcnLRfzMD/SEAYB?=
 =?us-ascii?q?CzWsMDebzxhAlP/U9nSTtYM9rLDomZwHULgdU0Y6QLdSXkBkGsESZZxtTys4lp?=
 =?us-ascii?q?aFg8MSo3mzth/cQINdpJ+RErrGBfTpNSbci6dBajMMwKjkNsISMIPh0kBvY1U8?=
 =?us-ascii?q?m57FTQ6YCdRMpDBxKww5ukNA9FBgQWApnUHocAWg5DkUD/Hi2lZilAdjZPwk3D?=
 =?us-ascii?q?Hy4ls2LxzBoy5m1AFlnNDsjTyQajP9ILaYW59XByv98UM2N8WobRxyaFibhkxl?=
 =?us-ascii?q?LzeMYrJck6FtPTRijQ/RpYFCMfhCTKFFaVkbwvTBNKZg6khVtijynRwP3uDCE5?=
 =?us-ascii?q?Y3zAY=3D?=
X-IronPort-Anti-Spam-Filtered: true
X-IronPort-Anti-Spam-Result: =?us-ascii?q?A0ARAABmqRBch0O0hNFkHAEBAQQBAQcEA?=
 =?us-ascii?q?QGBUQcBAQsBg2snjBSOM5c+gXYRGBMBhzQiNAkNAQMBAQEBAQECARMBAQEIDQk?=
 =?us-ascii?q?IKSMMgjYigmwCJBkBATcBBQkCHzEDWgEJAQMFBYMcggIFpHaBbDOCdgEBBYEEA?=
 =?us-ascii?q?QGGJQiHfIJ9JoEcF4FAP4ERgmSFCYYBiRmHJI9rVQmKRocNAhaBXIhChyMBiSO?=
 =?us-ascii?q?BBY8MgUaCDjMaCBsVgyeCGwkDF4NKihwBPjgBMYEFAQGJBIJMAQE?=
X-IPAS-Result: =?us-ascii?q?A0ARAABmqRBch0O0hNFkHAEBAQQBAQcEAQGBUQcBAQsBg2s?=
 =?us-ascii?q?njBSOM5c+gXYRGBMBhzQiNAkNAQMBAQEBAQECARMBAQEIDQkIKSMMgjYigmwCJ?=
 =?us-ascii?q?BkBATcBBQkCHzEDWgEJAQMFBYMcggIFpHaBbDOCdgEBBYEEAQGGJQiHfIJ9JoE?=
 =?us-ascii?q?cF4FAP4ERgmSFCYYBiRmHJI9rVQmKRocNAhaBXIhChyMBiSOBBY8MgUaCDjMaC?=
 =?us-ascii?q?BsVgyeCGwkDF4NKihwBPjgBMYEFAQGJBIJMAQE?=
X-IronPort-AV: E=Sophos;i="5.56,343,1539673200"; 
   d="scan'208";a="44608741"
X-Amp-Result: SKIPPED(no attachment in message)
X-Amp-File-Uploaded: False
Received: from vger.kernel.org ([209.132.180.67])
  by mtab.intel.com with ESMTP; 11 Dec 2018 22:25:04 -0800
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
        id S1726491AbeLLGZC (ORCPT <rfc822;like.xu@linux.intel.com>
        + 23 others); Wed, 12 Dec 2018 01:25:02 -0500
Received: from hqemgate14.nvidia.com ([216.228.121.143]:5226 "EHLO
        hqemgate14.nvidia.com" rhost-flags-OK-OK-OK-OK) by vger.kernel.org
        with ESMTP id S1726237AbeLLGZC (ORCPT
        <rfc822;linux-kernel@vger.kernel.org>);
        Wed, 12 Dec 2018 01:25:02 -0500
Received: from hqpgpgate102.nvidia.com (Not Verified[216.228.121.13]) by hqemgate14.nvidia.com (using TLS: TLSv1.2, DES-CBC3-SHA)
        id <B5c10a9b80000>; Tue, 11 Dec 2018 22:24:56 -0800
Received: from hqmail.nvidia.com ([172.20.161.6])
  by hqpgpgate102.nvidia.com (PGP Universal service);
  Tue, 11 Dec 2018 22:24:59 -0800
X-PGP-Universal: processed;
        by hqpgpgate102.nvidia.com on Tue, 11 Dec 2018 22:24:59 -0800
Received: from HQMAIL112.nvidia.com (172.18.146.18) by HQMAIL103.nvidia.com
 (172.20.187.11) with Microsoft SMTP Server (TLS) id 15.0.1395.4; Wed, 12 Dec
 2018 06:24:59 +0000
Received: from HQMAIL104.nvidia.com (172.18.146.11) by HQMAIL112.nvidia.com
 (172.18.146.18) with Microsoft SMTP Server (TLS) id 15.0.1395.4; Wed, 12 Dec
 2018 06:24:58 +0000
Received: from hqnvemgw02.nvidia.com (172.16.227.111) by HQMAIL104.nvidia.com
 (172.18.146.11) with Microsoft SMTP Server (TLS) id 15.0.1395.4 via Frontend
 Transport; Wed, 12 Dec 2018 06:24:58 +0000
Received: from amhetre.nvidia.com (Not Verified[10.24.229.42]) by hqnvemgw02.nvidia.com with Trustwave SEG (v7,5,8,10121)
        id <B5c10a9b60001>; Tue, 11 Dec 2018 22:24:58 -0800
From: Ashish Mhetre <amhetre@nvidia.com>
To: <herbert@gondor.apana.org.au>, <davem@davemloft.net>,
        <axboe@kernel.dk>, <adrian.hunter@intel.com>,
        <ulf.hansson@linaro.org>, <linux-crypto@vger.kernel.org>,
        <linux-nvme@lists.infradead.org>, <linux-kernel@vger.kernel.org>,
        <vdumpa@nvidia.com>, <mmaddireddy@nvidia.com>
CC: <Snikam@nvidia.com>, <linux-tegra@vger.kernel.org>,
        Ashish Mhetre <amhetre@nvidia.com>
Subject: [PATCH] scatterlist: Update size type to support greater then 4GB size.
Date: Wed, 12 Dec 2018 11:54:13 +0530
Message-ID: <1544595853-18492-1-git-send-email-amhetre@nvidia.com>
X-Mailer: git-send-email 2.7.4
X-NVConfidentiality: public
MIME-Version: 1.0
Content-Type: text/plain
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed; d=nvidia.com; s=n1;
        t=1544595896; bh=vhjJbD6OmAKiXHI0SNL6GmN+1jzGNJgpAVsMaqjQFXE=;
        h=X-PGP-Universal:From:To:CC:Subject:Date:Message-ID:X-Mailer:
         X-NVConfidentiality:MIME-Version:Content-Type;
        b=QUv0lsk8ltUbes1XnsulnBGs9FVEQoyPRcoRx3XnRiSQsemg21btLPeUlFHP7nRHo
         T5ZPAR1mlCkB66fswKdCP53VLiUWbRMPOOCz4CwUqJw33tGIH6owL37hw67GxbdQQP
         X6yQaWqp6HEgTDIzDLRPwjpujhyDlah2ucfYcDL9A9vZi9vzT5wTufLNBH8MAPtJs3
         U6hHRBV3UYwBV8Xnm/Payj51iRjkin7rYU205lED9ESDGKWAaWn2Zaw8EKLvn/Fr8T
         vGgfIUktak7l6jwkVHtvWlQx4jXMcSLz6+wn/Yv//0M4oN4f1JsuxJAQCpVAy3qQM8
         vGGQmUAeilgHw==
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: <linux-kernel.vger.kernel.org>
X-Mailing-List: linux-kernel@vger.kernel.org

From: Krishna Reddy <vdumpa@nvidia.com>

In the cases where greater than 4GB allocations are required, current
definition of scatterlist doesn't support it. For example, Tegra devices
have more than 4GB of system memory available. So they are expected to
support larger allocation requests.
This patch updates the type of scatterlist members to support creating
scatterlist for allocations of size greater than 4GB size.
Updated the files that are necessary to fix compilation issues with updated
type of variables.

With definition of scatterlist changed in this patch, size of sg has
increased from 28 bytes to 40 bytes because of which allocations in nvme
driver are crossing order-0( as sizeof(struct scatterlist) is used in nvme
driver allocations ) i.e. they are not able to fit into single page.

Recently a patch to limit the nvme allocations to order-0 is mergerd.
'commit 943e942e6266f22babee5efeb00f8f672fbff5bd ("nvme-pci: limit
max IO size and segments to avoid high order allocations")'
Because of that patch, WARN log is getting printed in our case as
definition of scatterlist has changed. Alloc size of nvme is calculated as
NVME_MAX_SEGS * sizeof(struct scatterlist). As sizeof(struct scatterlist)
has changed from 28 bytes to 40 bytes, so updating NVME_MAX_SEGS from 127
to 88 to correspond to original nvme alloc size value.

Signed-off-by: Krishna Reddy <vdumpa@nvidia.com>
Signed-off-by: Ashish Mhetre <amhetre@nvidia.com>
---
 crypto/shash.c                |  2 +-
 drivers/ata/libata-sff.c      |  2 +-
 drivers/mmc/host/sdhci.c      |  2 +-
 drivers/mmc/host/toshsd.c     |  2 +-
 drivers/mmc/host/usdhi6rol0.c | 14 +++++++-------
 drivers/nvme/host/pci.c       |  8 ++++----
 include/linux/nvme.h          |  2 +-
 include/linux/scatterlist.h   |  8 ++++----
 8 files changed, 20 insertions(+), 20 deletions(-)

diff --git a/crypto/shash.c b/crypto/shash.c
index d21f04d..434970e 100644
--- a/crypto/shash.c
+++ b/crypto/shash.c
@@ -298,7 +298,7 @@ int shash_ahash_digest(struct ahash_request *req, struct shash_desc *desc)
 
 	if (nbytes &&
 	    (sg = req->src, offset = sg->offset,
-	     nbytes < min(sg->length, ((unsigned int)(PAGE_SIZE)) - offset))) {
+	     nbytes < min(sg->length, ((size_t)(PAGE_SIZE)) - offset))) {
 		void *data;
 
 		data = kmap_atomic(sg_page(sg));
diff --git a/drivers/ata/libata-sff.c b/drivers/ata/libata-sff.c
index c5ea0fc..675def6 100644
--- a/drivers/ata/libata-sff.c
+++ b/drivers/ata/libata-sff.c
@@ -810,7 +810,7 @@ static int __atapi_pio_bytes(struct ata_queued_cmd *qc, unsigned int bytes)
 	offset %= PAGE_SIZE;
 
 	/* don't overrun current sg */
-	count = min(sg->length - qc->cursg_ofs, bytes);
+	count = min(sg->length - qc->cursg_ofs, (size_t)bytes);
 
 	/* don't cross page boundaries */
 	count = min(count, (unsigned int)PAGE_SIZE - offset);
diff --git a/drivers/mmc/host/sdhci.c b/drivers/mmc/host/sdhci.c
index 99bdae5..bd84c0c 100644
--- a/drivers/mmc/host/sdhci.c
+++ b/drivers/mmc/host/sdhci.c
@@ -1025,7 +1025,7 @@ static void sdhci_prepare_data(struct sdhci_host *host, struct mmc_command *cmd)
 		if (unlikely(length_mask | offset_mask)) {
 			for_each_sg(data->sg, sg, data->sg_len, i) {
 				if (sg->length & length_mask) {
-					DBG("Reverting to PIO because of transfer size (%d)\n",
+					DBG("Reverting to PIO because of transfer size (%zd)\n",
 					    sg->length);
 					host->flags &= ~SDHCI_REQ_USE_DMA;
 					break;
diff --git a/drivers/mmc/host/toshsd.c b/drivers/mmc/host/toshsd.c
index dd961c5..af00936 100644
--- a/drivers/mmc/host/toshsd.c
+++ b/drivers/mmc/host/toshsd.c
@@ -479,7 +479,7 @@ static void toshsd_start_data(struct toshsd_host *host, struct mmc_data *data)
 {
 	unsigned int flags = SG_MITER_ATOMIC;
 
-	dev_dbg(&host->pdev->dev, "setup data transfer: blocksize %08x  nr_blocks %d, offset: %08x\n",
+	dev_dbg(&host->pdev->dev, "setup data transfer: blocksize %08x  nr_blocks %d, offset: %08lx\n",
 		data->blksz, data->blocks, data->sg->offset);
 
 	host->data = data;
diff --git a/drivers/mmc/host/usdhi6rol0.c b/drivers/mmc/host/usdhi6rol0.c
index cd8b1b9..5fce5ff 100644
--- a/drivers/mmc/host/usdhi6rol0.c
+++ b/drivers/mmc/host/usdhi6rol0.c
@@ -316,7 +316,7 @@ static void usdhi6_blk_bounce(struct usdhi6_host *host,
 	struct mmc_data *data = host->mrq->data;
 	size_t blk_head = host->head_len;
 
-	dev_dbg(mmc_dev(host->mmc), "%s(): CMD%u of %u SG: %ux%u @ 0x%x\n",
+	dev_dbg(mmc_dev(host->mmc), "%s(): CMD%u of %u SG: %ux%u @ 0x%lx\n",
 		__func__, host->mrq->cmd->opcode, data->sg_len,
 		data->blksz, data->blocks, sg->offset);
 
@@ -360,7 +360,7 @@ static void *usdhi6_sg_map(struct usdhi6_host *host)
 
 	WARN(host->pg.page, "%p not properly unmapped!\n", host->pg.page);
 	if (WARN(sg_dma_len(sg) % data->blksz,
-		 "SG size %u isn't a multiple of block size %u\n",
+		 "SG size %zu isn't a multiple of block size %u\n",
 		 sg_dma_len(sg), data->blksz))
 		return NULL;
 
@@ -383,7 +383,7 @@ static void *usdhi6_sg_map(struct usdhi6_host *host)
 	else
 		host->blk_page = host->pg.mapped;
 
-	dev_dbg(mmc_dev(host->mmc), "Mapped %p (%lx) at %p + %u for CMD%u @ 0x%p\n",
+	dev_dbg(mmc_dev(host->mmc), "Mapped %p (%lx) at %p + %lu for CMD%u @ 0x%p\n",
 		host->pg.page, page_to_pfn(host->pg.page), host->pg.mapped,
 		sg->offset, host->mrq->cmd->opcode, host->mrq);
 
@@ -492,7 +492,7 @@ static void usdhi6_sg_advance(struct usdhi6_host *host)
 		host->sg = next;
 
 		if (WARN(next && sg_dma_len(next) % data->blksz,
-			 "SG size %u isn't a multiple of block size %u\n",
+			 "SG size %zu isn't a multiple of block size %u\n",
 			 sg_dma_len(next), data->blksz))
 			data->error = -EINVAL;
 
@@ -1044,7 +1044,7 @@ static int usdhi6_rq_start(struct usdhi6_host *host)
 		    (data->blksz % 4 ||
 		     data->sg->offset % 4))
 			dev_dbg(mmc_dev(host->mmc),
-				"Bad SG of %u: %ux%u @ %u\n", data->sg_len,
+				"Bad SG of %u: %ux%u @ %lu\n", data->sg_len,
 				data->blksz, data->blocks, data->sg->offset);
 
 		/* Enable DMA for USDHI6_MIN_DMA bytes or more */
@@ -1056,7 +1056,7 @@ static int usdhi6_rq_start(struct usdhi6_host *host)
 			usdhi6_write(host, USDHI6_CC_EXT_MODE, USDHI6_CC_EXT_MODE_SDRW);
 
 		dev_dbg(mmc_dev(host->mmc),
-			"%s(): request opcode %u, %u blocks of %u bytes in %u segments, %s %s @+0x%x%s\n",
+			"%s(): request opcode %u, %u blocks of %u bytes in %u segments, %s %s @+0x%lx%s\n",
 			__func__, cmd->opcode, data->blocks, data->blksz,
 			data->sg_len, use_dma ? "DMA" : "PIO",
 			data->flags & MMC_DATA_READ ? "read" : "write",
@@ -1704,7 +1704,7 @@ static void usdhi6_timeout_work(struct work_struct *work)
 	case USDHI6_WAIT_FOR_WRITE:
 		sg = host->sg ?: data->sg;
 		dev_dbg(mmc_dev(host->mmc),
-			"%c: page #%u @ +0x%zx %ux%u in SG%u. Current SG %u bytes @ %u\n",
+			"%c: page #%u @ +0x%zx %ux%u in SG%u. Current SG %zu bytes @ %lu\n",
 			data->flags & MMC_DATA_READ ? 'R' : 'W', host->page_idx,
 			host->offset, data->blocks, data->blksz, data->sg_len,
 			sg_dma_len(sg), sg->offset);
diff --git a/drivers/nvme/host/pci.c b/drivers/nvme/host/pci.c
index d668682..57ef89d 100644
--- a/drivers/nvme/host/pci.c
+++ b/drivers/nvme/host/pci.c
@@ -43,7 +43,7 @@
  * require an sg allocation that needs more than a page of data.
  */
 #define NVME_MAX_KB_SZ	4096
-#define NVME_MAX_SEGS	127
+#define NVME_MAX_SEGS	88
 
 static int use_threaded_interrupts;
 module_param(use_threaded_interrupts, int, 0);
@@ -552,8 +552,8 @@ static void nvme_print_sgl(struct scatterlist *sgl, int nents)
 
 	for_each_sg(sgl, sg, nents, i) {
 		dma_addr_t phys = sg_phys(sg);
-		pr_warn("sg[%d] phys_addr:%pad offset:%d length:%d "
-			"dma_address:%pad dma_length:%d\n",
+		pr_warn("sg[%d] phys_addr:%pad offset:%lu length:%zu "
+			"dma_address:%pad dma_length:%zu\n",
 			i, &phys, sg->offset, sg->length, &sg_dma_address(sg),
 			sg_dma_len(sg));
 	}
@@ -566,7 +566,7 @@ static blk_status_t nvme_pci_setup_prps(struct nvme_dev *dev,
 	struct dma_pool *pool;
 	int length = blk_rq_payload_bytes(req);
 	struct scatterlist *sg = iod->sg;
-	int dma_len = sg_dma_len(sg);
+	u64 dma_len = sg_dma_len(sg);
 	u64 dma_addr = sg_dma_address(sg);
 	u32 page_size = dev->ctrl.page_size;
 	int offset = dma_addr & (page_size - 1);
diff --git a/include/linux/nvme.h b/include/linux/nvme.h
index 68e91ef..0a07a29 100644
--- a/include/linux/nvme.h
+++ b/include/linux/nvme.h
@@ -587,7 +587,7 @@ enum {
 
 struct nvme_sgl_desc {
 	__le64	addr;
-	__le32	length;
+	__le64	length;
 	__u8	rsvd[3];
 	__u8	type;
 };
diff --git a/include/linux/scatterlist.h b/include/linux/scatterlist.h
index 093aa57..f6d3482 100644
--- a/include/linux/scatterlist.h
+++ b/include/linux/scatterlist.h
@@ -10,11 +10,11 @@
 
 struct scatterlist {
 	unsigned long	page_link;
-	unsigned int	offset;
-	unsigned int	length;
+	unsigned long	offset;
+	size_t		length;
 	dma_addr_t	dma_address;
 #ifdef CONFIG_NEED_SG_DMA_LENGTH
-	unsigned int	dma_length;
+	size_t		dma_length;
 #endif
 };
 
@@ -114,7 +114,7 @@ static inline void sg_assign_page(struct scatterlist *sg, struct page *page)
  *
  **/
 static inline void sg_set_page(struct scatterlist *sg, struct page *page,
-			       unsigned int len, unsigned int offset)
+			       size_t len, unsigned long offset)
 {
 	sg_assign_page(sg, page);
 	sg->offset = offset;
-- 
2.7.4

