Return-Path: <qemu-devel-bounces+like.xu=linux.intel.com@nongnu.org>
Delivered-To: unknown
Received: from linux.intel.com (10.54.29.200:995) by i7-8700 with POP3-SSL;
  13 Dec 2018 08:50:53 -0000
X-Original-To: like.xu@linux.intel.com
Delivered-To: like.xu@linux.intel.com
Received: from fmsmga004.fm.intel.com (fmsmga004.fm.intel.com [10.253.24.48])
	(using TLSv1.2 with cipher ECDHE-RSA-AES256-GCM-SHA384 (256/256 bits))
	(No client certificate requested)
	by linux.intel.com (Postfix) with ESMTPS id A4E01580380
	for <like.xu@linux.intel.com>; Wed, 12 Dec 2018 05:57:42 -0800 (PST)
Received: from fmsmga105.fm.intel.com ([10.1.193.10])
  by fmsmga004-1.fm.intel.com with ESMTP/TLS/DHE-RSA-AES256-GCM-SHA384; 12 Dec 2018 05:57:42 -0800
IronPort-PHdr: =?us-ascii?q?9a23=3A1eTSGxSG6j9G96Z7Q+7mK2c2X9psv+yvbD5Q0YIu?=
 =?us-ascii?q?jvd0So/mwa6zYxSN2/xhgRfzUJnB7Loc0qyK6/CmATRIyK3CmUhKSIZLWR4BhJ?=
 =?us-ascii?q?detC0bK+nBN3fGKuX3ZTcxBsVIWQwt1Xi6NU9IBJS2PAWK8TW94jEIBxrwKxd+?=
 =?us-ascii?q?KPjrFY7OlcS30P2594HObwlSizexfbB/IA+qoQnNq8IbnZZsJqEtxxXTv3BGYf?=
 =?us-ascii?q?5WxWRmJVKSmxbz+MK994N9/ipTpvws6ddOXb31cKokQ7NYCi8mM30u683wqRbD?=
 =?us-ascii?q?VwqP6WACXWgQjxFFHhLK7BD+Xpf2ryv6qu9w0zSUMMHqUbw5Xymp4rx1QxH0li?=
 =?us-ascii?q?gIKz858HnWisNuiqJbvAmhrAF7z4LNfY2ZKOZycqbbcNgHR2ROQ9xRWjRPDI28?=
 =?us-ascii?q?cYUBDOgOPehfr4byu1QAogawBRGuCe3txTJEm3H70bEk3OQ6CgzGwA4tEsgSvH?=
 =?us-ascii?q?jIsNn5KqEfWv21wqnSyjXDautb1Cn66IjSdBAuv/WMXbNqfsHMy0cvCh/KjlaN?=
 =?us-ascii?q?ooHiIzyV0eQNs3WH4OpjTu+vkXAopBxxoje12scgkJXGhoUQyl3d8yhy3YU7Jc?=
 =?us-ascii?q?WgRUJlfdKpE4FcuzyHO4Z1WM8uXW9ltSYgxrEbu5O3ZDYGxIgjyhLFdvCKfZaE?=
 =?us-ascii?q?7gj+WOuSLzp0nmxpdbG5ih2v60av0Pf8WdOx0FtSripKjN3MtncV2hzX68iHUe?=
 =?us-ascii?q?d9/ly71TaA0QDT9/tIIUcularUM5Ihw7gwmYQPsUnbACP6hEb7gLWLekk5+eWk?=
 =?us-ascii?q?8frrb7vmq5OGKoN5iBnyMqE0lcy+BeQ4PBIOX2+e+emkzb3s40j5QKhTgvIrjK?=
 =?us-ascii?q?bZro7VJcACqqGiBA9Vz4Aj5AqhADe919gYmXgHLFFbdx6dgInpJknDIPT5Dfe5?=
 =?us-ascii?q?nlStny1nx/HAPr39HJrNKmLPn6vmfbZ48ENczg0zzdZQ55JSF7ENOvXzWlX+tN?=
 =?us-ascii?q?DAFB82LxS0w/r7CNV6zo4eXWOPAqyHP6/Ivl6I+/kiI+2NZI8TpTb8JOIp5//o?=
 =?us-ascii?q?jX8lh1AdebOl0ocQaHC9TbxbJV6Eay/snssZCjVN+Q4/V/DxzluFVzFVejC1Ra?=
 =?us-ascii?q?174zg6DIevC8DEXpysh7qamz62G4ATam1YB1TfLHHzao/RXv4NbD6VcNZslyFB?=
 =?us-ascii?q?WbW/Rotkzxy3qQLh15JhKezb/DBesojsg8No7e/eng1n6DpvEs6G2HuMRWwnom?=
 =?us-ascii?q?RdazYo3aw3gU15xlqF27JxhfAQQdBa+fJFeh03OZ7V06pxDNWkCSzbedLcY1G8?=
 =?us-ascii?q?RNiiADh5bs86wJdaaEF9Bt6hpgrO0yqjH/kekLndV898yb7Vw3Wkf5U18H3Bzq?=
 =?us-ascii?q?R0ygB+GsY=3D?=
X-IronPort-Anti-Spam-Filtered: true
X-IronPort-Anti-Spam-Result: =?us-ascii?q?A0CBAADGEhFcmBHrdtBjGwEBAQEDAQEBB?=
 =?us-ascii?q?wMBAQGBZYExKoIlE4xzizOCDXyYShQYFIc+IjgSAQMBAQEBAQECARMBAQEBAQg?=
 =?us-ascii?q?LCwYbDi+CNgUCAxoBBoJbAQEBAQIBAQI3DAopAwIBAQIGAQEKGCMDCAMBUwYTB?=
 =?us-ascii?q?YMcgXoIAQSnD4VAhG+MPBeBQD+BEYIUSTWCEII6EYYBAok5AYZSkQAJkUwLGIF?=
 =?us-ascii?q?ciA02hyeZP4FdgXczGggbFYMngicXEm0BDo0QQDGBBxyKEwElMIF3AQE?=
X-IPAS-Result: =?us-ascii?q?A0CBAADGEhFcmBHrdtBjGwEBAQEDAQEBBwMBAQGBZYExKoI?=
 =?us-ascii?q?lE4xzizOCDXyYShQYFIc+IjgSAQMBAQEBAQECARMBAQEBAQgLCwYbDi+CNgUCA?=
 =?us-ascii?q?xoBBoJbAQEBAQIBAQI3DAopAwIBAQIGAQEKGCMDCAMBUwYTBYMcgXoIAQSnD4V?=
 =?us-ascii?q?AhG+MPBeBQD+BEYIUSTWCEII6EYYBAok5AYZSkQAJkUwLGIFciA02hyeZP4Fdg?=
 =?us-ascii?q?XczGggbFYMngicXEm0BDo0QQDGBBxyKEwElMIF3AQE?=
X-IronPort-AV: E=Sophos;i="5.56,344,1539673200"; 
   d="scan'208";a="141818123"
X-Amp-Result: SKIPPED(no attachment in message)
X-Amp-File-Uploaded: False
Received: from lists.gnu.org ([208.118.235.17])
  by mtab.intel.com with ESMTP/TLS/AES256-SHA; 12 Dec 2018 05:57:41 -0800
Received: from localhost ([::1]:45083 helo=lists.gnu.org)
	by lists.gnu.org with esmtp (Exim 4.71)
	(envelope-from <qemu-devel-bounces+like.xu=linux.intel.com@nongnu.org>)
	id 1gX51B-0001g6-1t
	for like.xu@linux.intel.com; Wed, 12 Dec 2018 08:57:41 -0500
Received: from eggs.gnu.org ([2001:4830:134:3::10]:50762)
	by lists.gnu.org with esmtp (Exim 4.71)
	(envelope-from <cohuck@redhat.com>) id 1gX4lj-0005Jk-EJ
	for qemu-devel@nongnu.org; Wed, 12 Dec 2018 08:41:44 -0500
Received: from Debian-exim by eggs.gnu.org with spam-scanned (Exim 4.71)
	(envelope-from <cohuck@redhat.com>) id 1gX4li-0002Dt-8l
	for qemu-devel@nongnu.org; Wed, 12 Dec 2018 08:41:43 -0500
Received: from mx1.redhat.com ([209.132.183.28]:33279)
	by eggs.gnu.org with esmtps (TLS1.0:DHE_RSA_AES_256_CBC_SHA1:32)
	(Exim 4.71) (envelope-from <cohuck@redhat.com>)
	id 1gX4li-0002Cy-01; Wed, 12 Dec 2018 08:41:42 -0500
Received: from smtp.corp.redhat.com (int-mx07.intmail.prod.int.phx2.redhat.com
	[10.5.11.22])
	(using TLSv1.2 with cipher AECDH-AES256-SHA (256/256 bits))
	(No client certificate requested)
	by mx1.redhat.com (Postfix) with ESMTPS id 0AC1C30832D1;
	Wed, 12 Dec 2018 13:41:41 +0000 (UTC)
Received: from gondolin (dhcp-192-187.str.redhat.com [10.33.192.187])
	by smtp.corp.redhat.com (Postfix) with ESMTP id 9DAA61054FD3;
	Wed, 12 Dec 2018 13:41:34 +0000 (UTC)
Date: Wed, 12 Dec 2018 14:41:32 +0100
From: Cornelia Huck <cohuck@redhat.com>
To: David Hildenbrand <david@redhat.com>
Message-ID: <20181212144132.41a1409d.cohuck@redhat.com>
In-Reply-To: <5c491972-5210-5ac6-6023-7365fb24dc3f@redhat.com>
References: <1544135058-21380-1-git-send-email-walling@linux.ibm.com>
	<1544135058-21380-3-git-send-email-walling@linux.ibm.com>
	<20181207130853.20506345.cohuck@redhat.com>
	<dbabb43d-01e7-d221-a761-ad5a53fd8f94@linux.ibm.com>
	<aff40d67-9fcb-43fb-beeb-1dbe7a1e22f3@linux.ibm.com>
	<5c491972-5210-5ac6-6023-7365fb24dc3f@redhat.com>
Organization: Red Hat GmbH
MIME-Version: 1.0
Content-Type: text/plain; charset=US-ASCII
Content-Transfer-Encoding: 7bit
X-Scanned-By: MIMEDefang 2.84 on 10.5.11.22
X-Greylist: Sender IP whitelisted, not delayed by milter-greylist-4.5.16
	(mx1.redhat.com [10.5.110.44]);
	Wed, 12 Dec 2018 13:41:41 +0000 (UTC)
X-detected-operating-system: by eggs.gnu.org: GNU/Linux 2.2.x-3.x [generic]
	[fuzzy]
X-Received-From: 209.132.183.28
Subject: Re: [Qemu-devel] [qemu-s390x] [PATCH v2 2/3] s390: cpu feature for
 diagnose 318 andlimit max VCPUs to 247
X-BeenThere: qemu-devel@nongnu.org
X-Mailman-Version: 2.1.21
Precedence: list
List-Id: <qemu-devel.nongnu.org>
List-Unsubscribe: <https://lists.nongnu.org/mailman/options/qemu-devel>,
	<mailto:qemu-devel-request@nongnu.org?subject=unsubscribe>
List-Archive: <http://lists.nongnu.org/archive/html/qemu-devel/>
List-Post: <mailto:qemu-devel@nongnu.org>
List-Help: <mailto:qemu-devel-request@nongnu.org?subject=help>
List-Subscribe: <https://lists.nongnu.org/mailman/listinfo/qemu-devel>,
	<mailto:qemu-devel-request@nongnu.org?subject=subscribe>
Cc: Collin Walling <walling@linux.ibm.com>, thuth@redhat.com,
	qemu-devel@nongnu.org, borntraeger@de.ibm.com,
	qemu-s390x@nongnu.org, rth@twiddle.net
Errors-To: qemu-devel-bounces+like.xu=linux.intel.com@nongnu.org
Sender: "Qemu-devel" <qemu-devel-bounces+like.xu=linux.intel.com@nongnu.org>

On Wed, 12 Dec 2018 12:20:08 +0100
David Hildenbrand <david@redhat.com> wrote:

> On 11.12.18 22:12, Collin Walling wrote:
> > On 12/11/18 11:47 AM, Collin Walling wrote:  
> >> On 12/7/18 7:08 AM, Cornelia Huck wrote:  
> >>> On Thu,  6 Dec 2018 17:24:17 -0500
> >>> Collin Walling <walling@linux.ibm.com> wrote:
> >>>  
> >>>> Diagnose 318 is a new z14.2 CPU feature. Since we are able to emulate
> >>>> it entirely via KVM, we can add guest support for earlier models. A
> >>>> new CPU feature for diagnose 318 (shortened to diag318) will be made
> >>>> available to guests starting with the zEC12-full CPU model.
> >>>>
> >>>> The z14.2 adds a new read SCP info byte (let's call it byte 134) to
> >>>> detect the availability of diag318. Because of this, we have room for
> >>>> one less VCPU and thus limit the max VPUs supported in a configuration
> >>>> to 247 (down from 248).
> >>>>
> >>>> Signed-off-by: Collin Walling <walling@linux.ibm.com>.
> >>>> ---
> >>>>  hw/s390x/sclp.c                 | 2 ++
> >>>>  include/hw/s390x/sclp.h         | 2 ++
> >>>>  target/s390x/cpu.h              | 2 +-
> >>>>  target/s390x/cpu_features.c     | 3 +++
> >>>>  target/s390x/cpu_features.h     | 1 +
> >>>>  target/s390x/cpu_features_def.h | 3 +++
> >>>>  target/s390x/gen-features.c     | 1 +
> >>>>  target/s390x/kvm.c              | 1 +
> >>>>  8 files changed, 14 insertions(+), 1 deletion(-)
> >>>>  
> >>>  
> >>>> diff --git a/target/s390x/cpu.h b/target/s390x/cpu.h
> >>>> index 8c2320e..594b4a4 100644
> >>>> --- a/target/s390x/cpu.h
> >>>> +++ b/target/s390x/cpu.h
> >>>> @@ -52,7 +52,7 @@
> >>>>  
> >>>>  #define MMU_USER_IDX 0
> >>>>  
> >>>> -#define S390_MAX_CPUS 248
> >>>> +#define S390_MAX_CPUS 247  
> >>>
> >>> Isn't that already problematic if you try to migrate from an older QEMU
> >>> with all possible vcpus defined? IOW, don't you really need a way that
> >>> older machines can still run with one more vcpu?
> >>>  
> >>
> >> Good call. I'll run some tests on this and see what happens. I'll report
> >> here on those results.
> >>  
> > 
> > Migrating to a machine that supports less vCPUs will report
> > 
> > error: unsupported configuration: Maximum CPUs greater than specified machine type limit
> > 
> > I revisited the code to see if there's a way to dynamically set the max vcpu count based 
> > on the read scp info size, but it gets really tricky and code looks very complicated.
> > (Having a packed struct contain the CPU entries whose maximum is determined by hardware
> > limitations makes things difficult -- but who said s390 is easy? :) )
> > 
> > In reality, do we often have guests running with 248 or even 247 vcpus? If so, I imagine
> > the performance isn't too significant?  
> Gluing CPU feature availability to machines is plain ugly. This sounds
> like going back to pre-cpu model times ;)
> 
> There are two alternatives:
> 
> a) Don't model it as a CPU feature in QEMU. Glue it completely to the
> QEMU machine. This goes hand-in-hand with the proposal I made in the KVM
> thread, that diag318 is to be handled completely in QEMU, always. The
> KVM setting part is optional (if KVM + HW support it).
> 
> Then we can have two different max_cpus/ReadInfo layouts based on the
> machine type. No need to worry about QEMU cpu features.
> 
> Once we have other SCLP features (eventually requiring KVM/HW support)
> announced in the same feature block, things might get more involved, but
> I guess we could handle it somehow.

Perhaps via a capability to be enabled?

> 
> 
> b) Glue the ReadInfo layout to the CPU feature, we would have to
> default-disable the CPU feature for legacy machines. And bail out if
> more CPUs are used when the feature is enabled. Hairy.
> 
> 
> I guess a) would be the best thing to do. After all this really does not
> sound like a CPU feature but more like a machine feature. But there is
> usually a fine line between them.

a) sounds like the better option to me as well.

