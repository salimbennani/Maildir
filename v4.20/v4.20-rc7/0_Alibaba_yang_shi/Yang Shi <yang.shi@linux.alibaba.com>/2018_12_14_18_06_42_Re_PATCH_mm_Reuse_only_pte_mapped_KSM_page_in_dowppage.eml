Return-Path: <linux-kernel-owner@vger.kernel.org>
Delivered-To: unknown
Received: from linux.intel.com (10.54.29.200:995) by i7-8700 with POP3-SSL;
  15 Dec 2018 13:08:17 -0000
X-Original-To: like.xu@linux.intel.com
Delivered-To: like.xu@linux.intel.com
Received: from orsmga002.jf.intel.com (orsmga002.jf.intel.com [10.7.209.21])
	(using TLSv1.2 with cipher ECDHE-RSA-AES256-GCM-SHA384 (256/256 bits))
	(No client certificate requested)
	by linux.intel.com (Postfix) with ESMTPS id 79E3C58061F;
	Fri, 14 Dec 2018 10:07:07 -0800 (PST)
Received: from orsmga101.jf.intel.com ([10.7.208.22])
  by orsmga002-1.jf.intel.com with ESMTP/TLS/DHE-RSA-AES256-GCM-SHA384; 14 Dec 2018 10:07:07 -0800
X-SG-BADATTACHMENTNOREPLY: True
IronPort-PHdr: =?us-ascii?q?9a23=3Ar2xy1RbavQwIg88N2Zg/lFX/LSx+4OfEezUN459i?=
 =?us-ascii?q?sYplN5qZpcm/YB7h7PlgxGXEQZ/co6odzbaO4+a4ASQp2tWoiDg6aptCVhsI24?=
 =?us-ascii?q?09vjcLJ4q7M3D9N+PgdCcgHc5PBxdP9nC/NlVJSo6lPwWB6nK94iQPFRrhKAF7?=
 =?us-ascii?q?Ovr6GpLIj8Swyuu+54Dfbx9HiTahYr5+Ngm6oRnMvcQKnIVuLbo8xAHUqXVSYe?=
 =?us-ascii?q?RWwm1oJVOXnxni48q74YBu/SdNtf8/7sBMSar1cbg2QrxeFzQmLns65Nb3uhnZ?=
 =?us-ascii?q?TAuA/WUTX2MLmRdVGQfF7RX6XpDssivms+d2xSeXMdHqQb0yRD+v9LlgRgP2hy?=
 =?us-ascii?q?gbNj456GDXhdJ2jKJHuxKquhhzz5fJbI2JKPZye6XQds4YS2VcRMZcTzFPDJ2y?=
 =?us-ascii?q?b4UPDOQPM+hXoIb/qFQSohW+HhGsCeH0xz9UhXL7x7E23/gvHAzE2gErAtIAsG?=
 =?us-ascii?q?7TrNXwLKodU/q6zK/HzT7ecv1W2Tb945XPfxEhu/6MW71wfdDKyUkvFgPIlVGQ?=
 =?us-ascii?q?qY3jPzOI2eUBqXKU7+5hVe20kWEosBt+riKzyccrj4nEn4QYwU3H+yVh2Is5O8?=
 =?us-ascii?q?G0RUphbdK5HpZcqTuWO5Z1T88+WW1luSQ3xqUbtZKmfCUG0okrywDQZvCdfYWE?=
 =?us-ascii?q?/gjvWPufLDp2gn9uZaixiAyo8Ue6z+3xTsm030hOripCitTMqH8N2ALJ6sSdSf?=
 =?us-ascii?q?ty4F2h2TCR2ADX8O1EJlo0laXDJ54gxL4/iIYTvFzdEiPqnEj6lrKae0s69uSy?=
 =?us-ascii?q?9ujqYanqqoWdOoJ2kg3+N74hms27AeQ2KAgOWG2b9Py41L3i+035XbpLguQ1kq?=
 =?us-ascii?q?bHqpDaI9oUpqqgDw9S3Icj7QiwDy293dQGknkIMkhFdAiEj4f3IVHOJu73DfOl?=
 =?us-ascii?q?j1SrijdryOjKPqf9DZXVMnjDjLDhcK55605dywo808pT5p1JCrwaJPLzW0nxtM?=
 =?us-ascii?q?HXDxMjMgy0xfrnB8t51o8ERW2PBaqZOrvIsVCU/uIvP/WMZIgNtTb9Mfcl5uLu?=
 =?us-ascii?q?gmU+mVMHfampwIEYaHa3Hvl9J0WZYHzsgsoOEGsQvwo+SvDqh0OGUTJJe3myWK?=
 =?us-ascii?q?c87CkhCI26FYfDWpytgLuZ0Se5GZ1ZeHpKClOLEXfucYWEXOwBaCaTIs9njzwF?=
 =?us-ascii?q?WqKtS44n1RGyqgD6z6BrIfbT+i0drZjjzsR65/XPlREu8jx5F96S03qNT2FznW?=
 =?us-ascii?q?MEXSU207p9oUFmzleD0K54g+FXFNBJ5vNJVBs6OoDYz+BgF9/yXQfBdM+TSFm6?=
 =?us-ascii?q?WtWmHS0xTtUpzt8NeUl9Hc+ujhTC3yWwBb8VmKeGBJg18qLawnjwKNxxy3fA1K?=
 =?us-ascii?q?k9kVYmRtFDOnGhhq567wLTHZLGk12Fl6a2cqQRxDPC+32dzWWQpk1YUBR/UaPe?=
 =?us-ascii?q?XX8BYEvaqtD55kDHT7+qErknNgpBycifKqpFcNHpjFNGROv9N9TaeW6+h2CwBR?=
 =?us-ascii?q?OQzLOWcIXqY3kd3DnaCEUcjg8c52iGOhYkCiehuW3eCiduGkzpY0739el+qXW7?=
 =?us-ascii?q?TlI7zg2Qbk1h0aa19QARhfCGV/wT2bcEsj87qzpoBFa9w87WC92Yqgp9faVcZN?=
 =?us-ascii?q?Q94EtH1WPZrQB9IoasL6d4hl4acgR3uUzu2g5zCoVBl8gqsXwrwBBzKaKezFNO?=
 =?us-ascii?q?aTeY0YrsNb3QL2n45AqvZLLO2lHCzNaW/b8C5+48q1r9swCmCEoj/2983NlIzn?=
 =?us-ascii?q?ST/JPKDAkVUZLvSUs38xl6p7fHYigy/Y/U1HtsMbWqvT/Gwd4mGOwlyhO4dddF?=
 =?us-ascii?q?LKyEDBPyE9EdB8W2KO0qhkKlYQ4eMOFT9K47JcWmd/Sd1a6vPeZgmi+mjGtd7I?=
 =?us-ascii?q?B81EKM6zRzSurS05kZxPGY2xONVy3gg1e5rsD3hYdEaCkIHmq+1SfrHpRRabB1?=
 =?us-ascii?q?fYoRD2ehPde3xtRni5HxQXFY8EOsCE0c2M+ufxqfdFj93QxW1UQKrn2rgyq4zz?=
 =?us-ascii?q?pokz43qqqTxjDBw+PndBAfIG5EWHFijUvwIYizl90bXEmoYxIplRe//kb62q5b?=
 =?us-ascii?q?qb97L2nSR0dIYif3I3tjUqu2qrqNfcpP5Ik0viVQVeS2eUqaRaLloxsGzyPjGH?=
 =?us-ascii?q?NTxDIheDGwuZX5nBt6hHiGLHlpr3rZesBwxRHB69zaXvNR2jsGRC9liTjYHFS8?=
 =?us-ascii?q?Pt+p/cmKmJfHqOyxS2WhVphLeynx0YyArDe75XFtARCnn/G8gNrnHRI40S/60d?=
 =?us-ascii?q?lnTiHIrBf6Yon22KW2K+Nnfk90BFDi78p2AJ1xkow1hJsIw3gVmo2V/WYbkWf0?=
 =?us-ascii?q?Kdhb2rjxbHsXST4L3t7a+g7l2EJ4I3KNxoL5UGidw8R7a9m7ZGMWxjwy78RQBK?=
 =?us-ascii?q?iI67xEmDN/okCkogLJffh9gjAdxOMr6H4bgOEGohAhzyuDDbAJAUlXIzbsmA+W?=
 =?us-ascii?q?4NCko6Vaf2Kvcbm21EpjktGtFrCCogdAWHnnfpcuBzN/7sJ6MFjUyn389pnkeM?=
 =?us-ascii?q?XMbdIUrhCUjxDAj+1PJJMwjPUKgzdnOXnmvX0k0OM7iR1u3ZenvImIMWlt/aS5?=
 =?us-ascii?q?AgJGOT3xfc8c5jbtjaNGlMaMw4+vBolhGikMXJbwVv2nCjUStfD6NwqUFD08t2?=
 =?us-ascii?q?yWGb7eHQ+Z9UdnoGjDE5GtN3GLOnYZyc9uSwWaJExamAoURik1noYlFgC2w8zs?=
 =?us-ascii?q?aEV56SoU5lHmsRtA0P5oOwP8UmfCpweodzE0R4KELBdN6gFC5kHVMdGR7+5pHi?=
 =?us-ascii?q?FY+IGhoxKJKmCBewtICmQJUFSeB1//Jrmu+cXA8++AC+u+KPvOfKyOqfFEWPeO?=
 =?us-ascii?q?356vyYxm/zCDNsiUOnliDvs72ldMXHxjGsTZnSkPRDITly7Xc8GboxK88DVtrs?=
 =?us-ascii?q?+j6PTrRB7v5YyXBrtSL9pv+hO2gaSCN+KKhyZ5MzFY1pwSyn/S1bgfx0UfiyVv?=
 =?us-ascii?q?dzmrDLQBujTBTKPWmq9LEREbbzl/O9dP76I5xgNNI9LUisvp1r5kif44E01KVU?=
 =?us-ascii?q?H6lcGze8MLI3uxNFfGBEuQMLSGJDvLw9z4YK+mSL1QivlUuAO0uTqBD0DjOTGD?=
 =?us-ascii?q?nSHzVx+zKeFMkD2bPBtGtYGhcxZtDHLvQ878ZhKnMN94kzs2zKYwhnPLM24cLD?=
 =?us-ascii?q?d9f1lMrr2W8SNXnPF/F3Zd4XpiKOmOgzyZ4PXAKpYKrftrBTx5luJA73Q8zrtV?=
 =?us-ascii?q?7SdES+R0mSvStNFupV6mn/KLyjpmVhpOtzlKiJiKvUVkJaXW6J1AVWzY8xIK6G?=
 =?us-ascii?q?XDQygN8vhkENzrv+hsydjGleqnKytB89vV1dUdHdTJL9CVNzwqNh+/XHbdDxMA?=
 =?us-ascii?q?ZTqqM3zPwkJajfee/2GUqZ58rYLj3NINS6VaUFgdDfMHFklgG8JEJp5yU3dska?=
 =?us-ascii?q?OUjMIg6n25ox3cAs5du9SPX/uICvzpJzuxl7RIZxIUh7j/KNc9LIr+jn1rbFYy?=
 =?us-ascii?q?p4TLUx7BVNZC5DZhbycwoUNQ4D53Smw50kjsLAiq5SlARraPghcqh14mMqwW/z?=
 =?us-ascii?q?D27gJyfwKSqQ=3D=3D?=
X-IronPort-Anti-Spam-Filtered: true
X-IronPort-Anti-Spam-Result: =?us-ascii?q?A0CuAQAD8RNch0O0hNFlHAEBAQQBAQcEA?=
 =?us-ascii?q?QGBZYNsJ4N8lBGBYAglFJk2LBMBh0ciOBIBAwEBAQEBAQIBEwEBAQgNCQgpL4I?=
 =?us-ascii?q?2JAGCYQEBAQECAQECIAQLAQVBBgkBAQgCDgoCAiYCAgNUBgEMBgIBAQGDHIF5B?=
 =?us-ascii?q?wEFilGbUnwzhUCEaYELizOBVz+BEScMgl+IB4JXAokehyyQTgcCgiQEjywGGIF?=
 =?us-ascii?q?dhRyCeodfLIkPkgOBdzMaI4M8gicXjj4eMwGBBAEBjS4BAQ?=
X-IPAS-Result: =?us-ascii?q?A0CuAQAD8RNch0O0hNFlHAEBAQQBAQcEAQGBZYNsJ4N8lBG?=
 =?us-ascii?q?BYAglFJk2LBMBh0ciOBIBAwEBAQEBAQIBEwEBAQgNCQgpL4I2JAGCYQEBAQECA?=
 =?us-ascii?q?QECIAQLAQVBBgkBAQgCDgoCAiYCAgNUBgEMBgIBAQGDHIF5BwEFilGbUnwzhUC?=
 =?us-ascii?q?EaYELizOBVz+BEScMgl+IB4JXAokehyyQTgcCgiQEjywGGIFdhRyCeodfLIkPk?=
 =?us-ascii?q?gOBdzMaI4M8gicXjj4eMwGBBAEBjS4BAQ?=
X-IronPort-AV: E=Sophos;i="5.56,353,1539673200"; 
   d="scan'208";a="45022144"
X-Amp-Result: SKIPPED(no attachment in message)
X-Amp-File-Uploaded: False
Received: from vger.kernel.org ([209.132.180.67])
  by mtab.intel.com with ESMTP; 14 Dec 2018 10:07:05 -0800
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
        id S1730496AbeLNSHD (ORCPT <rfc822;like.xu@linux.intel.com>
        + 23 others); Fri, 14 Dec 2018 13:07:03 -0500
Received: from out30-133.freemail.mail.aliyun.com ([115.124.30.133]:33315 "EHLO
        out30-133.freemail.mail.aliyun.com" rhost-flags-OK-OK-OK-OK)
        by vger.kernel.org with ESMTP id S1730457AbeLNSHB (ORCPT
        <rfc822;linux-kernel@vger.kernel.org>);
        Fri, 14 Dec 2018 13:07:01 -0500
X-Alimail-AntiSpam: AC=PASS;BC=-1|-1;BR=01201311R111e4;CH=green;FP=0|-1|-1|-1|0|-1|-1|-1;HT=e01e04400;MF=yang.shi@linux.alibaba.com;NM=1;PH=DS;RN=12;SR=0;TI=SMTPD_---0TFhbeja_1544810804;
Received: from US-143344MP.local(mailfrom:yang.shi@linux.alibaba.com fp:SMTPD_---0TFhbeja_1544810804)
          by smtp.aliyun-inc.com(127.0.0.1);
          Sat, 15 Dec 2018 02:06:47 +0800
Subject: Re: [PATCH] mm: Reuse only-pte-mapped KSM page in do_wp_page()
To: Kirill Tkhai <ktkhai@virtuozzo.com>, akpm@linux-foundation.org,
        kirill@shutemov.name, hughd@google.com, aarcange@redhat.com
Cc: christian.koenig@amd.com, imbrenda@linux.vnet.ibm.com,
        riel@surriel.com, ying.huang@intel.com, minchan@kernel.org,
        linux-kernel@vger.kernel.org, linux-mm@kvack.org
References: <154471491016.31352.1168978849911555609.stgit@localhost.localdomain>
 <5d5bfbd2-8411-e707-1628-18bde66a6793@linux.alibaba.com>
 <a394a604-20d6-e261-1735-bc225e39f2a2@virtuozzo.com>
From: Yang Shi <yang.shi@linux.alibaba.com>
Message-ID: <00af5cd2-e226-89e3-3506-de5e6de05060@linux.alibaba.com>
Date: Fri, 14 Dec 2018 10:06:42 -0800
User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10.12; rv:52.0)
 Gecko/20100101 Thunderbird/52.7.0
MIME-Version: 1.0
In-Reply-To: <a394a604-20d6-e261-1735-bc225e39f2a2@virtuozzo.com>
Content-Type: text/plain; charset=utf-8; format=flowed
Content-Transfer-Encoding: 8bit
Content-Language: en-US
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: <linux-kernel.vger.kernel.org>
X-Mailing-List: linux-kernel@vger.kernel.org



On 12/14/18 1:26 AM, Kirill Tkhai wrote:
> On 13.12.2018 22:15, Yang Shi wrote:
>>
>> On 12/13/18 7:29 AM, Kirill Tkhai wrote:
>>> This patch adds an optimization for KSM pages almost
>>> in the same way, that we have for ordinary anonymous
>>> pages. If there is a write fault in a page, which is
>>> mapped to an only pte, and it is not related to swap
>>> cache; the page may be reused without copying its
>>> content.
>>>
>>> [Note, that we do not consider PageSwapCache() pages
>>>    at least for now, since we don't want to complicate
>>>    __get_ksm_page(), which has nice optimization based
>>>    on this (for the migration case). Currenly it is
>>>    spinning on PageSwapCache() pages, waiting for when
>>>    they have unfreezed counters (i.e., for the migration
>>>    finish). But we don't want to make it also spinning
>>>    on swap cache pages, which we try to reuse, since
>>>    there is not a very high probability to reuse them.
>>>    So, for now we do not consider PageSwapCache() pages
>>>    at all.]
>>>
>>> So, in reuse_ksm_page() we check for 1)PageSwapCache()
>>> and 2)page_stable_node(), to skip a page, which KSM
>>> is currently trying to link to stable tree. Then we
>>> do page_ref_freeze() to prohibit KSM to merge one more
>>> page into the page, we are reusing. After that, nobody
>>> can refer to the reusing page: KSM skips !PageSwapCache()
>>> pages with zero refcount; and the protection against
>>> of all other participants is the same as for reused
>>> ordinary anon pages pte lock, page lock and mmap_sem.
>>>
>>> Signed-off-by: Kirill Tkhai <ktkhai@virtuozzo.com>
>>> ---
>>>    include/linux/ksm.h |    7 +++++++
>>>    mm/ksm.c            |   25 +++++++++++++++++++++++--
>>>    mm/memory.c         |   16 ++++++++++++++--
>>>    3 files changed, 44 insertions(+), 4 deletions(-)
>>>
>>> diff --git a/include/linux/ksm.h b/include/linux/ksm.h
>>> index 161e8164abcf..e48b1e453ff5 100644
>>> --- a/include/linux/ksm.h
>>> +++ b/include/linux/ksm.h
>>> @@ -53,6 +53,8 @@ struct page *ksm_might_need_to_copy(struct page *page,
>>>      void rmap_walk_ksm(struct page *page, struct rmap_walk_control *rwc);
>>>    void ksm_migrate_page(struct page *newpage, struct page *oldpage);
>>> +bool reuse_ksm_page(struct page *page,
>>> +            struct vm_area_struct *vma, unsigned long address);
>>>      #else  /* !CONFIG_KSM */
>>>    @@ -86,6 +88,11 @@ static inline void rmap_walk_ksm(struct page *page,
>>>    static inline void ksm_migrate_page(struct page *newpage, struct page *oldpage)
>>>    {
>>>    }
>>> +static inline bool reuse_ksm_page(struct page *page,
>>> +            struct vm_area_struct *vma, unsigned long address)
>>> +{
>>> +    return false;
>>> +}
>>>    #endif /* CONFIG_MMU */
>>>    #endif /* !CONFIG_KSM */
>>>    diff --git a/mm/ksm.c b/mm/ksm.c
>>> index 383f961e577a..fbd14264d784 100644
>>> --- a/mm/ksm.c
>>> +++ b/mm/ksm.c
>>> @@ -707,8 +707,9 @@ static struct page *__get_ksm_page(struct stable_node *stable_node,
>>>         * case this node is no longer referenced, and should be freed;
>>>         * however, it might mean that the page is under page_ref_freeze().
>>>         * The __remove_mapping() case is easy, again the node is now stale;
>>> -     * but if page is swapcache in migrate_page_move_mapping(), it might
>>> -     * still be our page, in which case it's essential to keep the node.
>>> +     * the same is in reuse_ksm_page() case; but if page is swapcache
>>> +     * in migrate_page_move_mapping(), it might still be our page,
>>> +     * in which case it's essential to keep the node.
>>>         */
>>>        while (!get_page_unless_zero(page)) {
>>>            /*
>>> @@ -2666,6 +2667,26 @@ void rmap_walk_ksm(struct page *page, struct rmap_walk_control *rwc)
>>>            goto again;
>>>    }
>>>    +bool reuse_ksm_page(struct page *page,
>>> +            struct vm_area_struct *vma,
>>> +            unsigned long address)
>>> +{
>>> +    VM_BUG_ON_PAGE(is_zero_pfn(page_to_pfn(page)), page);
>>> +    VM_BUG_ON_PAGE(!page_mapped(page), page);
>>> +    VM_BUG_ON_PAGE(!PageLocked(page), page);
>>> +
>>> +    if (PageSwapCache(page) || !page_stable_node(page))
>>> +        return false;
>>> +    /* Prohibit parallel get_ksm_page() */
>>> +    if (!page_ref_freeze(page, 1))
>>> +        return false;
>>> +
>>> +    page_move_anon_rmap(page, vma);
>> Once the mapping is changed, it is not KSM mapping anymore. It looks later get_ksm_page() would always fail on this page. Is this expected?
> Yes, this is the thing that the patch makes. Let's look at the actions,
> we have without the patch, when there is a writing to an only-pte-mapped
> KSM page.
>
> We enter to do_wp_page() with page_count() == 1, since KSM page is mapped
> in only pte (and we do not get extra reference to a page, when we add it
> to KSM stable tree). Then:
>
>    do_wp_page()
>      get_page(vmf->page) <- page_count() is 2
>      wp_page_copy()
>        ..
>        cow_user_page() /* Copy user page to a new one */
>        ..
>        put_page(vmf->page) <- page_count() is 1
>        put_page(vmf->page) <- page_count() is 0
>
> Second put_page() frees the page (and also zeroes page->mapping),
> and since that it's not a PageKsm() page anymore. Further
> __get_ksm_page() calls will fail on this page (since the mapping
> was zeroed), and its node will be unlinked from ksm stable tree:
>
> __get_ksm_page()
> {
> 	/* page->mapping == NULL, expected_mapping != NULL */
> 	if (READ_ONCE(page->mapping) != expected_mapping)
> 		goto stale;
> 	.......
> stale:
> 	remove_node_from_stable_tree(stable_node);
> }
>
>
> The patch optimizes do_wp_page(), and makes it to avoid the copying
> (like we have for ordinary anon pages). Since KSM page is freed anyway,
> after we dropped the last reference to it; we reuse it instead of this.
> So, the thing will now work in this way:
>
> do_wp_page()
>    lock_page(vmf->page)
>    reuse_ksm_page()
>      check PageSwapCache() and page_stable_node()
>      page_ref_freeze(page, 1) <- Freeze the page to make parallel
>                                  __get_ksm_page() (if any) waiting
>      page_move_anon_rmap()    <- Write new mapping, so __get_ksm_page()
>                                  sees this is not a KSM page anymore,
>                                  and it removes stable node.
>
> So, the result is the same, but after the patch we achieve it faster :)
>
> Also, note, that in the most probably case, do_wp_page() does not cross
> with __get_ksm_page() (the race window is very small; __get_ksm_page()
> is spinning, only when reuse_ksm_page() is between page_ref_freeze()
> and page_move_anon_rmap(), which are on neighboring lines).
>
> So, this is the idea. Please, let me know in case of something is unclear
> for you.

Thanks for elaborating this. It sounds reasonable. You can add 
Reviewed-by: Yang Shi <yang.shi@linux.alibaba.com>

>
> Kirill

