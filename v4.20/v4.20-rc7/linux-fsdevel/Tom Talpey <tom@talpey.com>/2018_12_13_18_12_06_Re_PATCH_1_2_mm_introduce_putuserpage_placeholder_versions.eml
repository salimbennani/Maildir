Return-Path: <linux-kernel-owner@vger.kernel.org>
Delivered-To: unknown
Received: from linux.intel.com (10.54.29.200:995) by i7-8700 with POP3-SSL;
  14 Dec 2018 08:40:19 -0000
X-Original-To: like.xu@linux.intel.com
Delivered-To: like.xu@linux.intel.com
Received: from fmsmga008.fm.intel.com (fmsmga008.fm.intel.com [10.253.24.58])
	(using TLSv1.2 with cipher ECDHE-RSA-AES256-GCM-SHA384 (256/256 bits))
	(No client certificate requested)
	by linux.intel.com (Postfix) with ESMTPS id DBD4D58079D;
	Thu, 13 Dec 2018 10:12:19 -0800 (PST)
Received: from fmsmga104.fm.intel.com ([10.1.193.100])
  by fmsmga008-1.fm.intel.com with ESMTP/TLS/DHE-RSA-AES256-GCM-SHA384; 13 Dec 2018 10:12:19 -0800
X-SG-BADATTACHMENTNOREPLY: True
IronPort-PHdr: =?us-ascii?q?9a23=3Adc34GhJoFRUC/5FaVdmcpTZWNBhigK39O0sv0rFi?=
 =?us-ascii?q?tYgULv/+rarrMEGX3/hxlliBBdydt6oUzbKO+4nbGkU4qa6bt34DdJEeHzQksu?=
 =?us-ascii?q?4x2zIaPcieFEfgJ+TrZSFpVO5LVVti4m3peRMNQJW2aFLduGC94iAPERvjKwV1?=
 =?us-ascii?q?Ov71GonPhMiryuy+4ZLebxlLiTanfb9+MAi9oBnMuMURnYZsMLs6xAHTontPde?=
 =?us-ascii?q?RWxGdoKkyWkh3h+Mq+/4Nt/jpJtf45+MFOTav1f6IjTbxFFzsmKHw65NfqtRbY?=
 =?us-ascii?q?UwSC4GYXX3gMnRpJBwjF6wz6Xov0vyDnuOdxxDWWMMvrRr0vRz+s87lkRwPpiC?=
 =?us-ascii?q?cfNj427mfXitBrjKlGpB6tvgFzz5LIbI2QMvd1Y6HTcs4ARWdZQ8hfSSJBDIO/?=
 =?us-ascii?q?YYUBAeUOMuRXoJXyqVsVtRuzBxKhBP/sxzJSmnP6waM33uYnHArb3AIgBdUOsH?=
 =?us-ascii?q?HModvrM6cSVP2+wrfSwjXHd/NZxzf845XPfxA9pvGMWKl9cdbLxkkrDwPKkFWR?=
 =?us-ascii?q?pZb5MDOS0+QAqm6W5PdjW+K3k2MrtR19rzy1yssxhITFmJgZxk3H+Cll2oo4JN?=
 =?us-ascii?q?+1RFZlbdOrCpdcqTyWOohsTs8/QGxkpjw2xqAJtJO0eiUB1Y4pyATFa/OddoiF?=
 =?us-ascii?q?+hLjW/iVITd/nH9lZr2/iAio8US6ye3zSNO00FBUoSpBiNXMsWoN1xPL5siGTP?=
 =?us-ascii?q?ty4Fuh1C6R2wzP7uxIO104mKTFJ5I737I9lYYfvV7CEyL0gEn2ibWZdkQg+uim?=
 =?us-ascii?q?8eTnZbDmq4eYN491jAH+L6svltW8AesmKAgOWXaU+eCl2L3k80z5RqtFjuctn6?=
 =?us-ascii?q?nHv5DVO94bqrS6AwBLyIYj7QiwDzO83NQfh3kHI0pJeAibgIjxJ1HOPPf4AO+7?=
 =?us-ascii?q?g1Stkzdk2erKP7L8ApjWKnjDkbHhfaty6kJGyQozy8xf6IxQCr0bPP3zXUrxvs?=
 =?us-ascii?q?TCDhAlKwy03/rnCNJl24MeQ22PA7OZP7nVsVOS5uIvPvODZIkauDvmL/gl5vju?=
 =?us-ascii?q?jWI2mFMHfKmp24cXZ268Hvh8P0qZZn/siM8bEWgWpgo+UPDqiFqaXD5RYHa9Qb?=
 =?us-ascii?q?gw5jI8CIKgC4fDQZuggLiA3Ce9A51XaXpKClGKEXf0aYqEX+0AZz6VIs9kijYE?=
 =?us-ascii?q?T6SuS5c91RGysw/306BoLvHU+i0ftpLvzsJ16PfRlRwp8Tx0DsKd03yCTm1un2?=
 =?us-ascii?q?MIQSM20757oUBn1liD1q14ieRCFdNP//NJThs6NZnEwux5Ed/yXBjNftOISFm8?=
 =?us-ascii?q?RNWmDio8TtYww98IfkZ8FM+ujhHF3yq2HbAVk6aHC4Az8qLZx3LxPdpyy27a1K?=
 =?us-ascii?q?k9iFkrWtZAOne4hqFh7QTTB5TGk0OCl6m0c6QQ2yrN9GSGzWqKp0xYVA9wUaPY?=
 =?us-ascii?q?XXEQfEfWrNL55l/cQL+qE7goLgxBycuaIKtQdtLplUlGROvkONnGfm2+gXmwCg?=
 =?us-ascii?q?iSyrOMdoXqfX4d0zvbCEUflwAT/HCGNRUxByu7omLeCiBuGkzrY0/27eZ+r3a7?=
 =?us-ascii?q?RFcuzw6Wd01hy6a1+hkNiPyASvMT27UEuDshqzR0Blq9w8jaC92apwplfaVcZ9?=
 =?us-ascii?q?w97UxD1WLYsQx9I5OhI7pjhl4YbwR4oUfu2w9rBYVHlMggtGkqwxZqKaKEzFNB?=
 =?us-ascii?q?cCuV0or0OrLJJWj94hCuZ7TN1VHDzdmZ4KEP6Pc/q1X9pwypEksi83N609hayX?=
 =?us-ascii?q?ec55PKDBYMXpL1SEo46x96p7TCaCkn+4zUzWFsMbWzsjLa29MpGfEpxQq6c9Ze?=
 =?us-ascii?q?MKOLDgnyE8IBCsiqKewqnUWpbx0eMOBT8q40I92pd/+c1KG3O+ZgmSqsjX5b74?=
 =?us-ascii?q?BlzkKM6y18R/bS35YE3/6XxBGHWCr7jFu7tMD4h5pEZTALEmWj0yfkAJNeabNo?=
 =?us-ascii?q?fYYMD2ejOMm3xtR4h57wVH9U7l+jB1Ua2MC3fRqedUDy3QpV1U4Pu3yohTO4zy?=
 =?us-ascii?q?BokzEutqee3C3Oz/7idRYdIW5LWW9igEzoIYi1idAaQUepYxIolBuj+Ub12axb?=
 =?us-ascii?q?qL5jIGnUREdCZzL2IH16UqusqrqCZNZC6JEyviVNU+S8YleaRqTmoxQA0CPjHG?=
 =?us-ascii?q?pexDYleDGsoZj5mx16iGSALHd8tnbZeMdwxQvB69zYX/Jewj0GRCxggznNGle8?=
 =?us-ascii?q?J8Wp/cmTl5rbsuGxTWWhWodRcSnqy4ONry+75WxsAR2ikPG/gNznEQ4m0SDl09?=
 =?us-ascii?q?lmTznHrBH5YoPzzaS1LfpnflV0BF/788d6GZtxkooqiJEQxHgVnJOV/XUcnGf3?=
 =?us-ascii?q?MNVb37/+bXUXST4Kxd7V/Bbq2El5In2VwIL5U22XwtF9aNmifmMWxiU94thPCK?=
 =?us-ascii?q?eV77xLhzF5o1SmogLKffhygC0dxuAw534AjOEEow4tziSbArAPEkhUJy3slxKU?=
 =?us-ascii?q?79+gqKVbfnqgcb+11EBmh9CuEKmCoh1AWHb+YpoiAShw7sBlPFPNynLz7JzkeM?=
 =?us-ascii?q?LLbdISrRCUlxbAj+5IKJM+jPYKhCxnOX7jsn0h0eI0kRtu3ZSitoidN2pt5L65?=
 =?us-ascii?q?AgJfNjDtfMwc4DbtjaJDnsqM24CvA45sGjEKXJvuUPKpHygetfXhNwaSDjI8rm?=
 =?us-ascii?q?2XFqbYHQ+a8E1mtW7AE4i3N3GLI3kU1ddiSwOYJENBmwAYRik6koQ6FgC3x8zh?=
 =?us-ascii?q?bUF56SoK5lPjrhtMy+RoNwTwU2vFpQeobCs0R4abLBZM8g5C4ELVO9SE7u1vBy?=
 =?us-ascii?q?FY4oGhrAuVJ22bYARIEHgJWlGeCFDlJLWu/t7A8+6XBuelK/vOYLOOqfFRVvuS?=
 =?us-ascii?q?xJKv1Jdm8CiINsmVInZiCPg70FJZXX9lA8TZhykPSysPmiLNccGbpRS8+i52rs?=
 =?us-ascii?q?yl8/TrQgXv5YSRBLtILNVv4Au7gaOCN+6WmSZ4JixU1pIKxX/U1rcf2EQehD1p?=
 =?us-ascii?q?dzmoCb4ArzLCTLrMmq9LCB4Wczl8NNZT4KImwAZMOdTXitf01rNjiv41ClFFVU?=
 =?us-ascii?q?Hum82zZMwKJX29O03DBEqRKLuGIjjLydntYaygUb1QkPlUtxqotDaHEk/jOy6P?=
 =?us-ascii?q?mCXzWx+zMeFDkiebMQdauIG8dBZtFGfiQMjnah29LN94kzk2zacoiXPNMG4WKS?=
 =?us-ascii?q?J8fF9Vrr2M8SNYhe1yGmxb4XpjKOmEmiCZ4PHZK5YWq/RrBCt0mvle4HQ7zbtV?=
 =?us-ascii?q?8S5FSOZ0mCvUst5hvVWmnvOTxTpgVRod4gpM0aCGp0JnNO328phbQnuMqBAC6W?=
 =?us-ascii?q?SLEBkivdZpCtTz/atXz46curj0LWJ+9NecwcIYH8XFYJabN38JLRPtADPFSgAC?=
 =?us-ascii?q?SGj4Zinkm0VBnaTKpTWupZ8gp82pwcJWRw=3D=3D?=
X-IronPort-Anti-Spam-Filtered: true
X-IronPort-Anti-Spam-Result: =?us-ascii?q?A0D8AAB4oBJch0O0hNFkGwEBAQEDAQEBB?=
 =?us-ascii?q?wMBAQGBZYFbgRJ/g2Q/lCyBYAglFGiZCgGBG4YqIjgSAQMBAQEBAQECARMBAQE?=
 =?us-ascii?q?IDQkIKS+CNiQBgmEBAQEBAgEBAgkXDwEFQQYJAQEIAg4KAgImAgIDVAYKAwgBA?=
 =?us-ascii?q?QEWgjtLgXkIBY0Lm1CBL4VAhHSBC4sxF4F/gRABJwyCKjWEPS6DGoJXAok7ATG?=
 =?us-ascii?q?BRYUTkEoJgiiPKwYYgVyFHIMEh04skjOGXIFrgXdNIxWDKIImF447IoE3AQGMP?=
 =?us-ascii?q?wMBAQ?=
X-IPAS-Result: =?us-ascii?q?A0D8AAB4oBJch0O0hNFkGwEBAQEDAQEBBwMBAQGBZYFbgRJ?=
 =?us-ascii?q?/g2Q/lCyBYAglFGiZCgGBG4YqIjgSAQMBAQEBAQECARMBAQEIDQkIKS+CNiQBg?=
 =?us-ascii?q?mEBAQEBAgEBAgkXDwEFQQYJAQEIAg4KAgImAgIDVAYKAwgBAQEWgjtLgXkIBY0?=
 =?us-ascii?q?Lm1CBL4VAhHSBC4sxF4F/gRABJwyCKjWEPS6DGoJXAok7ATGBRYUTkEoJgiiPK?=
 =?us-ascii?q?wYYgVyFHIMEh04skjOGXIFrgXdNIxWDKIImF447IoE3AQGMPwMBAQ?=
X-IronPort-AV: E=Sophos;i="5.56,349,1539673200"; 
   d="scan'208";a="55079465"
X-Amp-Result: SKIPPED(no attachment in message)
X-Amp-File-Uploaded: False
Received: from vger.kernel.org ([209.132.180.67])
  by mtab.intel.com with ESMTP; 13 Dec 2018 10:12:18 -0800
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
        id S1728788AbeLMSMO (ORCPT <rfc822;like.xu@linux.intel.com>
        + 23 others); Thu, 13 Dec 2018 13:12:14 -0500
Received: from p3plsmtpa07-06.prod.phx3.secureserver.net ([173.201.192.235]:57675
        "EHLO p3plsmtpa07-06.prod.phx3.secureserver.net" rhost-flags-OK-OK-OK-OK)
        by vger.kernel.org with ESMTP id S1729071AbeLMSML (ORCPT
        <rfc822;linux-kernel@vger.kernel.org>);
        Thu, 13 Dec 2018 13:12:11 -0500
Received: from [192.168.0.55] ([24.218.182.144])
        by :SMTPAUTH: with ESMTPSA
        id XVSxguL6iPCUFXVSygJo9O; Thu, 13 Dec 2018 11:12:10 -0700
Subject: Re: [PATCH 1/2] mm: introduce put_user_page*(), placeholder versions
To: Jerome Glisse <jglisse@redhat.com>
Cc: Jason Gunthorpe <jgg@ziepe.ca>,
        Dan Williams <dan.j.williams@intel.com>,
        Jan Kara <jack@suse.cz>, John Hubbard <jhubbard@nvidia.com>,
        Matthew Wilcox <willy@infradead.org>,
        John Hubbard <john.hubbard@gmail.com>,
        Andrew Morton <akpm@linux-foundation.org>,
        Linux MM <linux-mm@kvack.org>,
        Al Viro <viro@zeniv.linux.org.uk>, benve@cisco.com,
        Christoph Hellwig <hch@infradead.org>,
        Christopher Lameter <cl@linux.com>,
        "Dalessandro, Dennis" <dennis.dalessandro@intel.com>,
        Doug Ledford <dledford@redhat.com>,
        Michal Hocko <mhocko@kernel.org>,
        Mike Marciniszyn <mike.marciniszyn@intel.com>,
        rcampbell@nvidia.com,
        Linux Kernel Mailing List <linux-kernel@vger.kernel.org>,
        linux-fsdevel <linux-fsdevel@vger.kernel.org>,
        "Weiny, Ira" <ira.weiny@intel.com>
References: <20181212213005.GE5037@redhat.com>
 <CAPcyv4gJHeFjEgna1S-2uE4KxkSUgkc=e=2E5oqfoirec84C-w@mail.gmail.com>
 <20181212215348.GF5037@redhat.com> <20181212233703.GB2947@ziepe.ca>
 <20181213000109.GK5037@redhat.com> <20181213032043.GA3204@ziepe.ca>
 <20181213124325.GA3186@redhat.com>
 <81a731bb-6a8a-a554-cf99-5d0588b0a21f@talpey.com>
 <20181213141838.GB3186@redhat.com>
 <0b75a9a6-3907-ea88-6352-256bc2954f4a@talpey.com>
 <20181213151839.GC3186@redhat.com>
From: Tom Talpey <tom@talpey.com>
Message-ID: <a6c25182-9691-d9f9-b3b5-a42b2b5d6f7f@talpey.com>
Date: Thu, 13 Dec 2018 13:12:06 -0500
User-Agent: Mozilla/5.0 (Windows NT 10.0; WOW64; rv:60.0) Gecko/20100101
 Thunderbird/60.3.3
MIME-Version: 1.0
In-Reply-To: <20181213151839.GC3186@redhat.com>
Content-Type: text/plain; charset=utf-8; format=flowed
Content-Language: en-US
Content-Transfer-Encoding: 8bit
X-CMAE-Envelope: MS4wfLHqUliG4fv6mCutCeGoEY0OhEHhxQvV4kQgrdK4DW/IVAm3qjqDs0xsVrJsXg47v5gpmv3gg38y1NZOYb1weHD7jFyEL3vKK/xRk5gB27zuox+HLMrr
 2b/nZocyShjJ3YxEkfcheXp3nzRMNqbtcMc58j/n7DH2NptlZ/4M+VkgQ7Gz0wj4LiW7EdOYINxkW+NR8GIbJdTtV+nqvsW4wPymXBMndrcqKFoTchRVdHVp
 w2Q4NftIDuLurWoHWf+I3iJwC/g1opjKwunpEb+dARt4PEYQdM+z1zuFjmHfPYt5casaEi1P8ucZMuhA9Po8apDGIdKItda0BHmMmP+YiR5zGpoC9ICP3jwG
 +e4ly+CpRdCpS4jMzKYzCvFhJpTdhIIjAVpOIsI6+DjnaVXRSmYcgE51SL8q7qbgXnuN0empkyQMk06+NW7S6QfSFKpzOErT7c++A5zuH28s2hwfXvbKj5Sc
 WYn8nrgKnCmK7wBjBL/yhvs220O1+F60W6/C17RWX0gNZzHbeCR7vNV0lCCYgZY9CFoT7fFD9iRbrypD74oph2T1D12MepOhIQaXqJzH2XR+glMvIbxm3b/1
 Fux4BXXkJmivYdamqGcZ4zMZRuDi+PdBD8sPgWe3sPO7/TEqdW7zfb4cj5QJLJR7HeprxG5dqaWplPFyII7WkPHB3tGo04tZQkkaCzdBALdYqCcpbicnYpe3
 CRe7TdubQFeATqIJkUy8NbHG6OAv3c4ST+zg/QlFNXfCdJOFO0cyB1FwbWkSb/mM6Lob5Pvb+lrvHykhR/DaYZKWVb5TfyGD
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: <linux-kernel.vger.kernel.org>
X-Mailing-List: linux-kernel@vger.kernel.org

On 12/13/2018 10:18 AM, Jerome Glisse wrote:
> On Thu, Dec 13, 2018 at 09:51:18AM -0500, Tom Talpey wrote:
>> On 12/13/2018 9:18 AM, Jerome Glisse wrote:
>>> On Thu, Dec 13, 2018 at 08:40:49AM -0500, Tom Talpey wrote:
>>>> On 12/13/2018 7:43 AM, Jerome Glisse wrote:
>>>>> On Wed, Dec 12, 2018 at 08:20:43PM -0700, Jason Gunthorpe wrote:
>>>>>> On Wed, Dec 12, 2018 at 07:01:09PM -0500, Jerome Glisse wrote:
>>>>>>> On Wed, Dec 12, 2018 at 04:37:03PM -0700, Jason Gunthorpe wrote:
>>>>>>>> On Wed, Dec 12, 2018 at 04:53:49PM -0500, Jerome Glisse wrote:
>>>>>>>>>> Almost, we need some safety around assuming that DMA is complete the
>>>>>>>>>> page, so the notification would need to go all to way to userspace
>>>>>>>>>> with something like a file lease notification. It would also need to
>>>>>>>>>> be backstopped by an IOMMU in the case where the hardware does not /
>>>>>>>>>> can not stop in-flight DMA.
>>>>>>>>>
>>>>>>>>> You can always reprogram the hardware right away it will redirect
>>>>>>>>> any dma to the crappy page.
>>>>>>>>
>>>>>>>> That causes silent data corruption for RDMA users - we can't do that.
>>>>>>>>
>>>>>>>> The only way out for current hardware is to forcibly terminate the
>>>>>>>> RDMA activity somehow (and I'm not even sure this is possible, at
>>>>>>>> least it would be driver specific)
>>>>>>>>
>>>>>>>> Even the IOMMU idea probably doesn't work, I doubt all current
>>>>>>>> hardware can handle a PCI-E error TLP properly.
>>>>>>>
>>>>>>> What i saying is reprogram hardware to crappy page ie valid page
>>>>>>> dma map but that just has random content as a last resort to allow
>>>>>>> filesystem to reuse block. So their should be no PCIE error unless
>>>>>>> hardware freak out to see its page table reprogram randomly.
>>>>>>
>>>>>> No, that isn't an option. You can't silently provide corrupted data
>>>>>> for RDMA to transfer out onto the network, or silently discard data
>>>>>> coming in!!
>>>>>>
>>>>>> Think of the consequences of that - I have a fileserver process and
>>>>>> someone does ftruncate and now my clients receive corrupted data??
>>>>>
>>>>> This is what happens _today_ ie today someone do GUP on page file
>>>>> and then someone else do truncate the first GUP is effectively
>>>>> streaming _random_ data to network as the page does not correspond
>>>>> to anything anymore and once the RDMA MR goes aways and release
>>>>> the page the page content will be lost. So i am not changing anything
>>>>> here, what i proposed was to make it explicit to device driver at
>>>>> least that they were streaming random data. Right now this is all
>>>>> silent but this is what is happening wether you like it or not :)
>>>>>
>>>>> Note that  i am saying do that only for truncate to allow to be
>>>>> nice to fs. But again i am fine with whatever solution but you can
>>>>> not please everyone here. Either block truncate and fs folks will
>>>>> hate you or make it clear to device driver that you are streaming
>>>>> random things and RDMA people hates you.
>>>>>
>>>>>
>>>>>> The only option is to prevent the RDMA transfer from ever happening,
>>>>>> and we just don't have hardware support (beyond destroy everything) to
>>>>>> do that.
>>>>>>
>>>>>>> The question is who do you want to punish ? RDMA user that pin stuff
>>>>>>> and expect thing to work forever without worrying for other fs
>>>>>>> activities ? Or filesystem to pin block forever :)
>>>>>>
>>>>>> I don't want to punish everyone, I want both sides to have complete
>>>>>> data integrity as the USER has deliberately decided to combine DAX and
>>>>>> RDMA. So either stop it at the front end (ie get_user_pages_longterm)
>>>>>> or make it work in a way that guarantees integrity for both.
>>>>>>
>>>>>>>        S2: notify userspace program through device/sub-system
>>>>>>>            specific API and delay ftruncate. After a while if there
>>>>>>>            is no answer just be mean and force hardware to use
>>>>>>>            crappy page as anyway this is what happens today
>>>>>>
>>>>>> I don't think this happens today (outside of DAX).. Does it?
>>>>>
>>>>> It does it is just silent, i don't remember anything in the code
>>>>> that would stop a truncate to happen because of elevated refcount.
>>>>> This does not happen with ODP mlx5 as it does abide by _all_ mmu
>>>>> notifier. This is for anything that does ODP without support for
>>>>> mmu notifier.
>>>>
>>>> Wait - is it expected that the MMU notifier upcall is handled
>>>> synchronously? That is, the page DMA mapping must be torn down
>>>> immediately, and before returning?
>>>
>>> Yes you must torn down mapping before returning from mmu notifier
>>> call back. Any time after is too late. You obviously need hardware
>>> that can support that. In the infiniband sub-system AFAIK only the
>>> mlx5 hardware can do that. In the GPU sub-system everyone is fine.
>>
>> I'm skeptical that MLX5 can actually make this guarantee. But we
>> can take that offline in linux-rdma.
> 
> It does unless the code lies about what the hardware do :) See umem_odp.c
> in core and odp.c in mlx5 directories.

Ok, I did look and there are numerous error returns from these calls.
Some are related to resource shortages (including the rather ominous-
sounding "emergency_pages" in odp.c), others related to the generic
RDMA behaviors such as posting work requests and reaping their
completion status.

So I'd ask - what is the backup plan from the mmu notifier if the
unmap fails? Which it certainly will, in many real-world situations.

Tom.

>> I'm also skeptical that NVMe can do this.
>>
>>> Dunno about other sub-systems.
>>>
>>>
>>>> That's simply not possible, since the hardware needs to get control
>>>> to do this. Even if there were an IOMMU that could intercept the
>>>> DMA, reprogramming it will require a flush, which cannot be guaranteed
>>>> to occur "inline".
>>>
>>> If hardware can not do that then hardware should not use GUP, at
>>> least not on file back page. I advocated in favor of forbiding GUP
>>> for device that can not do that as right now this silently breaks
>>> in few cases (truncate, mremap, splice, reflink, ...). So the device
>>> in those cases can end up with GUPed pages that do not correspond
>>> to anything anymore ie they do not correspond to the memory backing
>>> the virtual address they were GUP against, nor they correspond to
>>> the file content at the given offset anymore. It is just random
>>> data as far as the kernel or filesystem is concern.
>>>
>>> Of course for this to happen you need an application that do stupid
>>> thing like create an MR in one thread on the mmap of a file and
>>> truncate that same file in another thread (or from the same thread).
>>>
>>> So this is unlikely to happen in sane program. It does not mean it
>>> will not happen.
>>
>> Completely agree. In other words, this is the responsibility of the
>> DAX (or g-u-p) consumer, which is nt necessarily the program itself,
>> it could be an upper layer.
>>
>> In SMB3 and NFSv4, which I've been focused on, we envision using the
>> existing protocol leases to protect this. When requesting a DAX mapping,
>> the server may requires an exclusive lease. If this mapping needs to
>> change, because of another conflicting mapping, the lease would be
>> recalled and the mapping dropped. This is a normal and well-established
>> filesystem requirement.
>>
>> The twist here is that the platform itself can initiate such an event.
>> It's my belief that this plumbing must flow to the *top* of the stack,
>> i.e. the entity that took the mapping (e.g. filesystem), and not
>> depend on the MMU notifier at the very bottom.
> 
> So this patchset is about mm plumbings, what fs does before mm code
> gets call is a fs discussion. Note also that GUP is always against
> a virtual address of a process. GUP is use by few driver to allow
> the device direct access to some portion of process address space.
> 
> The issues is that some of those device have designed an API that
> fully ignore things like munmap, splice, truncate, ... and as such
> they open the door for undefined behavior. I believe the original
> intention in all the cases was that the user would not do stupid
> thing like setup the device mapping through device specific API and
> then munmap or truncate or anything that would affect the range of
> virtual address.
> 
> Thing is from kernel point of view we should not and can not assume
> that userspace will behave properly. So we have to brace for the
> worst. Which is what this patchset is trying to do ie fix some of
> issues and make the rest of them explicit to device driver so that
> they can decide what to do about it.
> 
> My advice is for each of those sub-system/device to fail loudly
> when such thing happens so that the user knows he is doing something
> stupid or illegal.
> 
> 
>>> The second set of issue at to deals with set_page_dirty happening
>>> long time after page_release did happens and thus the fs dirty
>>> page callback will see page in bad state and will BUG() and you
>>> will have an oops and loose any data your device might have written
>>> to the page. This is highly filesystem dependend and also timing
>>> dependend and link to thing like memory pressure so it might not
>>> happen that often but again it can happen.
>>>
>>>
>>>>>> .. and the remedy here is to kill the process, not provide corrupt
>>>>>> data. Kill the process is likely to not go over well with any real
>>>>>> users that want this combination.
>>>>>>
>>>>>> Think Samba serving files over RDMA - you can't have random unpriv
>>>>>> users calling ftruncate and causing smbd to be killed or serve corrupt
>>>>>> data.
>>>>>
>>>>> So what i am saying is there is a choice and it would be better to
>>>>> decide something than let the existing status quo where we just keep
>>>>> streaming random data after truncate to a GUPed page.
>>>>
>>>> Let's also remember that any torn-down DMA mapping can't be recycled
>>>> until all uses of the old DMA addresses are destroyed. The whole
>>>> thing screams for reference counting all the way down, to me.
>>>
>>> I am not saying reuse the DMA address in the emergency_mean_callback
>>> the idea was:
>>>
>>>       gup_page_emergency_revoke(device, page)
>>>       {
>>>           crapy_page = alloc_page();
>>>           dma_addr = dma_map(crappy_page, device, ...);
>>>           mydevice_page_table_update(device, crappy_page, dma_addr);
>>>           mydevice_tlb_flush(device);
>>>           mydevice_wait_pending_dma(device)
>>>
>>>           // at this point the original GUPed page is not access by hw
>>>
>>>           dma_unmap(page);
>>>           put_user_page(page);
>>>       }
>>
>> Ok, but my concern was also that the old DMA address then becomes
>> unused and may be grabbed by a new i/o. If the hardware still has
>> reads or writes in flight, and they arrive after the old address
>> becomes valid, well, oops.
> 
> In above code at the comment point the driver garanty the hardware
> will never use the old dma address any more ie that all in flight
> dma are done. I know this can be done for some devices. It might
> very well not work for all and this is why this need to be a sub-
> system/device discussion.
> 
> Cheers,
> Jérôme
> 
> 
