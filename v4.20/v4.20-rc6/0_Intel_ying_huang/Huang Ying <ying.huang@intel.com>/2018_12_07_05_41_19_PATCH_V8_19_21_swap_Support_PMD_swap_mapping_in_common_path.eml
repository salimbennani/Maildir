Return-Path: <linux-kernel-owner@vger.kernel.org>
Delivered-To: unknown
Received: from linux.intel.com (10.54.29.200:995) by likexu-workstation with
  POP3-SSL; 07 Dec 2018 16:18:05 -0000
X-Original-To: like.xu@linux.intel.com
Delivered-To: like.xu@linux.intel.com
Received: from fmsmga001.fm.intel.com (fmsmga001.fm.intel.com [10.253.24.23])
	(using TLSv1.2 with cipher ECDHE-RSA-AES256-GCM-SHA384 (256/256 bits))
	(No client certificate requested)
	by linux.intel.com (Postfix) with ESMTPS id 6710058042F;
	Thu,  6 Dec 2018 21:42:42 -0800 (PST)
Received: from orsmga101.jf.intel.com ([10.7.208.22])
  by fmsmga001-1.fm.intel.com with ESMTP/TLS/DHE-RSA-AES256-GCM-SHA384; 06 Dec 2018 21:42:41 -0800
X-SG-BADATTACHMENTNOREPLY: True
IronPort-PHdr: =?us-ascii?q?9a23=3AGI8BxRJG6zfgvUPL6tmcpTZWNBhigK39O0sv0rFi?=
 =?us-ascii?q?tYgULvn7rarrMEGX3/hxlliBBdydt6oUzbKO+4nbGkU4qa6bt34DdJEeHzQksu?=
 =?us-ascii?q?4x2zIaPcieFEfgJ+TrZSFpVO5LVVti4m3peRMNQJW2aFLduGC94iAPERvjKwV1?=
 =?us-ascii?q?Ov71GonPhMiryuy+4ZLebxlLiTanfb9+MAi9oBnMuMURnYZsMLs6xAHTontPde?=
 =?us-ascii?q?RWxGdoKkyWkh3h+Mq+/4Nt/jpJtf45+MFOTav1f6IjTbxFFzsmKHw65NfqtRbY?=
 =?us-ascii?q?UwSC4GYXX3gMnRpJBwjF6wz6Xov0vyDnuOdxxDWWMMvrRr0vRz+s87lkRwPpiC?=
 =?us-ascii?q?cfNj427mfXitBrjKlGpB6tvgFzz5LIbI2QMvd1Y6HTcs4ARWdZXshfSTFPDI2/?=
 =?us-ascii?q?YYUIDeUBM/1Yr5H/qlYVsReyGROhCP/1xzNUmnP727Ax3eQ7EQHB2QwtB9AAsG?=
 =?us-ascii?q?nOo9XzO6cZTOK6zKjOzTXMcvhb3jf86InOchAuu/2MXa9wftDXyUkgDA7Fj1OQ?=
 =?us-ascii?q?qZD7MDORzOgCr2+b7+95WO+plmUpqBlxryCxysswjoTFnJ8Zx17a+Slj3Yo4Js?=
 =?us-ascii?q?G0RFR6bNOmCJdcqiWXO5VsTs4iQ2xkoiY3xqMctZO4fyUHzoksyQTFZPydaYeI?=
 =?us-ascii?q?5wruVOaPLjd8g3JoYKy/hxms/ki60OH8Vde70ExMriVbltnArHcN1wbc6sSfS/?=
 =?us-ascii?q?t9+Fmu2SqX2gzN9u1JJVo4mbfVJpI/2LI8i5kevVjZEiL3mkj6lKqWeV8l+uis?=
 =?us-ascii?q?5eTneLLmppqEOo9wiwH+NLkum8OmDeQ7LAcORW6b9vq41LH6+k34TrNKgeMskq?=
 =?us-ascii?q?TCrpDaKtoUprSjDw9WzIkj8RC/ACmi0NgCmnkHNl1FdAqdj4f1I1HOPOz4DfCn?=
 =?us-ascii?q?jlSokTdrxO7JMqfuA5XQNXXDlLbhfbBg609T0gYzzNZf545KBbEFOv78RkjxtN?=
 =?us-ascii?q?nABB8jLwO02/rnCMl61o4GWWKAGK6ZML/Ivl+P/O4vI/SMa5UTuDbyMPUl4//u?=
 =?us-ascii?q?jXkkmV4SZ6Wp3J0XaGymEfRiOUmWfX3sgtIZG2cQogU+VPDqiEGFUTNLZXayWL?=
 =?us-ascii?q?wz6is4CIKhC4fDQIetjaeF3Ce6GJ1We29HBkqNEXfua4WLRfMMZDiOLc9mlzwO?=
 =?us-ascii?q?TaKhRJM51RGyqA/6zKJqIfDP+i0YspLj18J55/fJmhEw7jF0C8Wd02eQT2B7hG?=
 =?us-ascii?q?8IRjk23Lxhrkx50FuMza94g/lAH9xJ+/xJShs6NYLbz+FiCND9QATBcs2NSFan?=
 =?us-ascii?q?WNqmBz4xQ8k1w98PZUZ9BtqjggrC3yqsH78aibiLCIYo/aLb2nj7P9x9xGre1K?=
 =?us-ascii?q?k9k1kmRdNCOnC8ia5h6QffHY7JnF+fl6axa6sc2inB9GOAzWqLuEFVSwpwUaTD?=
 =?us-ascii?q?XXACaUrat9X55kXeT7CwDbQrKBdOycmHKqFScN3mkU1GROv/ONTZe2++hn2/BQ?=
 =?us-ascii?q?iWyb+WbIrlYWMd3D7DB0gCiA0T+XeGNQ4jBiauuW7eDTpuFU7xbEPo6+VxtHS7?=
 =?us-ascii?q?TkosxQGQc0Jhz6a1+gIShfGEV/MT37cEuCA9qzV0HFexxc7WB8CHpwp7eKVcYN?=
 =?us-ascii?q?U94Fhc2GLdtgx9OIGgLq94il4fdQR3o13h1xFtBopclsgqqWsgzBBuJqKAzFNB?=
 =?us-ascii?q?azSY0IjqNb3TNGbz8w6gaq7M1l7FzdaZ570A6PI7q1XkogGkDU4i83Rh09lI3H?=
 =?us-ascii?q?qQ/JTKDAwOUZ3vVkY77QR1p7bfYiMl/YPbyWVsMbWosj/Fw98oBPYlxgy8cNtF?=
 =?us-ascii?q?MaKEFBX9E8sVB8W1LOwqml6pbg8LPexI9a40Od+meOWC2KKxIOlgmzemh3xd4I?=
 =?us-ascii?q?9hykKM6zZ8SunQ0pYfwvGXwhGIVy3hg1emqMz3n55LZSsTHmam1SfrHopRabBs?=
 =?us-ascii?q?coYRDmeuJda6xtF/h57rRn5Z+0SvB1IA2M+1ZxWSa0bx0hFX1UQSuXangze3zy?=
 =?us-ascii?q?RokzE1qaqSxCzPw+X4eBsHIGJLX3RijVH3LIiwjtAaWlWobgczmBuk40b627ZU?=
 =?us-ascii?q?pKBlI2bPRkdIejD8L3t+XauoqrqCf8lP5YsqsSpNSuS8YlOaSrnnrxsBySzjHG?=
 =?us-ascii?q?hexDE9dz60vJX0hBh6iGObLHZuo3vVY8BwxRHD5NPCQf5dxCYJRC59iTPPHFiz?=
 =?us-ascii?q?I8Gp/cmIl5fEqu2/V3iuVppJfSnpzIOAsjC25WlrAR25gvCylcfrEQk80S/nyd?=
 =?us-ascii?q?ZqUT/Eowr7Yonuz666K/5oflF0BF/g7Mp3AoJ+nZExhJ0K2Xgam4+a/XwIkWro?=
 =?us-ascii?q?NdVb2KT+bGcCRDIRwt7V5hTl11NnLn6T2435UXCdyNN7Z9amemMWxj4978dSBa?=
 =?us-ascii?q?eR7bxEnjF6rkC2rA3Pevh9gikSyeE153EEmeEJtxEgziGcArAUAElZMjbglxWO?=
 =?us-ascii?q?79CisqpXYHyjfqS31Ep7hdqhFq2NohlAWHblfZcvBTNw7sJ6MF7W0Xz88IfkeM?=
 =?us-ascii?q?TLbdIItx2ZiBPAj+lTKJIsmfsGnytnOWThvXI7z+43lwBh3Za/vIKfMWVi4Lq5?=
 =?us-ascii?q?AgJENj3yf84c4SvijaFansaLxYyvGohhFy4PXJvpS/KoDT0Tue7mNwaIDD0ztH?=
 =?us-ascii?q?ObFaDDEg+Y7Udst2jPHIyzN3GLOHkZys1vRBuHK0xang8URy82noIjGgCp2czh?=
 =?us-ascii?q?c1p55jYL6V7jsRZMzuNoNx/iUmbQvguoazE0SISBIxpS9A1N+0DVMcmG5OJpAy?=
 =?us-ascii?q?5Y5oGhrBCKKmGDZwVICnwJWlWZB1/5OLmi/8LA8++eBuqxNPbOZbSOqepDV/aH?=
 =?us-ascii?q?356v041m/yqSOcWLJHVtE/o72k9bV3BjB8vZgykPSzAQly/Vb86Uuha8+i50rs?=
 =?us-ascii?q?C+6vjrWxjv5YyAC7RMK9Vv5gu2jLyHN+6RgiZ5NDlZ2okNxX/O1LgQwloShzty?=
 =?us-ascii?q?eDmqFLQKrTTNQ77Imq9LEx4bbDt+O9FV760nxAlCJ87ahsnx1r55lfM1D1ZFVV?=
 =?us-ascii?q?r8msCmf8AKIme9NE/ZC0aPLriJOTrLw8Tva6OmVbJQlPlUtwG3uTuDD0/jPzGD?=
 =?us-ascii?q?myP1WBy1Le5MjD+UPBpFtYG5cxZtD3XjTd38Zh26Nt93kSM5wbkuinzWMm4cNC?=
 =?us-ascii?q?B2c1lRob2I8SNYnvJ/FnRB73V/K+mEnieZ7+/AJZcXsftkGCJ0l+1B7XQ+yrtV?=
 =?us-ascii?q?6jxERfNvlCvTqN5uv0+pku2VxjV7VxpOr2UDuIXelENuI6jGvrxHQ2rD+lpZ5G?=
 =?us-ascii?q?aIDjwOpt14GpjhvL1WxtHTlaX1bjBY/ISH09EbAp30NcuBPzIQMBzmUGrFDQ0K?=
 =?us-ascii?q?Cz62PGfQr01bjPyWsHaSq85p+dDXhJMSR+oDBxQOHfQABxEgRYRaLQ=3D=3D?=
X-IronPort-Anti-Spam-Filtered: true
X-IronPort-Anti-Spam-Result: =?us-ascii?q?A0ALAAAwBwpch0O0hNFjHAEBAQQBAQcEA?=
 =?us-ascii?q?QGBUQcBAQsBg2snjBOOMZc7gSQDTBQYEwGHVyI0CQ0BAwEBAQEBAQIBEwEBAQg?=
 =?us-ascii?q?NCQgpL4I2JAGCYgMDAQIkUgYJAQEYOANUBhMFgxyCAgWmdTOKMIdwhC+CFoN1i?=
 =?us-ascii?q?woCiTaBb4UPkC4HApE/CxhffYg8hx0BmRqBRmyBITMaI4M8gicXjioyAQExAYE?=
 =?us-ascii?q?EAQGKPwEB?=
X-IPAS-Result: =?us-ascii?q?A0ALAAAwBwpch0O0hNFjHAEBAQQBAQcEAQGBUQcBAQsBg2s?=
 =?us-ascii?q?njBOOMZc7gSQDTBQYEwGHVyI0CQ0BAwEBAQEBAQIBEwEBAQgNCQgpL4I2JAGCY?=
 =?us-ascii?q?gMDAQIkUgYJAQEYOANUBhMFgxyCAgWmdTOKMIdwhC+CFoN1iwoCiTaBb4UPkC4?=
 =?us-ascii?q?HApE/CxhffYg8hx0BmRqBRmyBITMaI4M8gicXjioyAQExAYEEAQGKPwEB?=
X-IronPort-AV: E=Sophos;i="5.56,324,1539673200"; 
   d="scan'208";a="43967312"
X-Amp-Result: SKIPPED(no attachment in message)
X-Amp-File-Uploaded: False
Received: from vger.kernel.org ([209.132.180.67])
  by mtab.intel.com with ESMTP; 06 Dec 2018 21:42:40 -0800
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
        id S1726291AbeLGFmY (ORCPT <rfc822;like.xu@linux.intel.com>
        + 23 others); Fri, 7 Dec 2018 00:42:24 -0500
Received: from mga01.intel.com ([192.55.52.88]:55177 "EHLO mga01.intel.com"
        rhost-flags-OK-OK-OK-OK) by vger.kernel.org with ESMTP
        id S1726277AbeLGFmW (ORCPT <rfc822;linux-kernel@vger.kernel.org>);
        Fri, 7 Dec 2018 00:42:22 -0500
X-Amp-Result: SKIPPED(no attachment in message)
X-Amp-File-Uploaded: False
Received: from fmsmga007.fm.intel.com ([10.253.24.52])
  by fmsmga101.fm.intel.com with ESMTP/TLS/DHE-RSA-AES256-GCM-SHA384; 06 Dec 2018 21:42:21 -0800
X-ExtLoop1: 1
X-IronPort-AV: E=Sophos;i="5.56,324,1539673200"; 
   d="scan'208";a="105567346"
Received: from yhuang-mobile.sh.intel.com ([10.239.196.133])
  by fmsmga007.fm.intel.com with ESMTP; 06 Dec 2018 21:42:18 -0800
From: Huang Ying <ying.huang@intel.com>
To: Andrew Morton <akpm@linux-foundation.org>
Cc: linux-mm@kvack.org, linux-kernel@vger.kernel.org,
        Huang Ying <ying.huang@intel.com>,
        "Kirill A. Shutemov" <kirill.shutemov@linux.intel.com>,
        Andrea Arcangeli <aarcange@redhat.com>,
        Michal Hocko <mhocko@kernel.org>,
        Johannes Weiner <hannes@cmpxchg.org>,
        Shaohua Li <shli@kernel.org>, Hugh Dickins <hughd@google.com>,
        Minchan Kim <minchan@kernel.org>,
        Rik van Riel <riel@redhat.com>,
        Dave Hansen <dave.hansen@linux.intel.com>,
        Naoya Horiguchi <n-horiguchi@ah.jp.nec.com>,
        Zi Yan <zi.yan@cs.rutgers.edu>,
        Daniel Jordan <daniel.m.jordan@oracle.com>
Subject: [PATCH -V8 19/21] swap: Support PMD swap mapping in common path
Date: Fri,  7 Dec 2018 13:41:19 +0800
Message-Id: <20181207054122.27822-20-ying.huang@intel.com>
X-Mailer: git-send-email 2.18.1
In-Reply-To: <20181207054122.27822-1-ying.huang@intel.com>
References: <20181207054122.27822-1-ying.huang@intel.com>
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: <linux-kernel.vger.kernel.org>
X-Mailing-List: linux-kernel@vger.kernel.org

Original code is only for PMD migration entry, it is revised to
support PMD swap mapping.

Signed-off-by: "Huang, Ying" <ying.huang@intel.com>
Cc: "Kirill A. Shutemov" <kirill.shutemov@linux.intel.com>
Cc: Andrea Arcangeli <aarcange@redhat.com>
Cc: Michal Hocko <mhocko@kernel.org>
Cc: Johannes Weiner <hannes@cmpxchg.org>
Cc: Shaohua Li <shli@kernel.org>
Cc: Hugh Dickins <hughd@google.com>
Cc: Minchan Kim <minchan@kernel.org>
Cc: Rik van Riel <riel@redhat.com>
Cc: Dave Hansen <dave.hansen@linux.intel.com>
Cc: Naoya Horiguchi <n-horiguchi@ah.jp.nec.com>
Cc: Zi Yan <zi.yan@cs.rutgers.edu>
Cc: Daniel Jordan <daniel.m.jordan@oracle.com>
---
 fs/proc/task_mmu.c | 12 +++++-------
 mm/gup.c           | 36 ++++++++++++++++++++++++------------
 mm/huge_memory.c   |  7 ++++---
 mm/mempolicy.c     |  2 +-
 4 files changed, 34 insertions(+), 23 deletions(-)

diff --git a/fs/proc/task_mmu.c b/fs/proc/task_mmu.c
index 39e96a21366e..0e65233f2cc2 100644
--- a/fs/proc/task_mmu.c
+++ b/fs/proc/task_mmu.c
@@ -986,7 +986,7 @@ static inline void clear_soft_dirty_pmd(struct vm_area_struct *vma,
 		pmd = pmd_clear_soft_dirty(pmd);
 
 		set_pmd_at(vma->vm_mm, addr, pmdp, pmd);
-	} else if (is_migration_entry(pmd_to_swp_entry(pmd))) {
+	} else if (is_swap_pmd(pmd)) {
 		pmd = pmd_swp_clear_soft_dirty(pmd);
 		set_pmd_at(vma->vm_mm, addr, pmdp, pmd);
 	}
@@ -1316,9 +1316,8 @@ static int pagemap_pmd_range(pmd_t *pmdp, unsigned long addr, unsigned long end,
 			if (pm->show_pfn)
 				frame = pmd_pfn(pmd) +
 					((addr & ~PMD_MASK) >> PAGE_SHIFT);
-		}
-#ifdef CONFIG_ARCH_ENABLE_THP_MIGRATION
-		else if (is_swap_pmd(pmd)) {
+		} else if (IS_ENABLED(CONFIG_HAVE_PMD_SWAP_ENTRY) &&
+			   is_swap_pmd(pmd)) {
 			swp_entry_t entry = pmd_to_swp_entry(pmd);
 			unsigned long offset;
 
@@ -1331,10 +1330,9 @@ static int pagemap_pmd_range(pmd_t *pmdp, unsigned long addr, unsigned long end,
 			flags |= PM_SWAP;
 			if (pmd_swp_soft_dirty(pmd))
 				flags |= PM_SOFT_DIRTY;
-			VM_BUG_ON(!is_pmd_migration_entry(pmd));
-			page = migration_entry_to_page(entry);
+			if (is_pmd_migration_entry(pmd))
+				page = migration_entry_to_page(entry);
 		}
-#endif
 
 		if (page && page_mapcount(page) == 1)
 			flags |= PM_MMAP_EXCLUSIVE;
diff --git a/mm/gup.c b/mm/gup.c
index 6dd33e16a806..460565825ef0 100644
--- a/mm/gup.c
+++ b/mm/gup.c
@@ -215,6 +215,7 @@ static struct page *follow_pmd_mask(struct vm_area_struct *vma,
 	spinlock_t *ptl;
 	struct page *page;
 	struct mm_struct *mm = vma->vm_mm;
+	swp_entry_t entry;
 
 	pmd = pmd_offset(pudp, address);
 	/*
@@ -242,18 +243,22 @@ static struct page *follow_pmd_mask(struct vm_area_struct *vma,
 	if (!pmd_present(pmdval)) {
 		if (likely(!(flags & FOLL_MIGRATION)))
 			return no_page_table(vma, flags);
-		VM_BUG_ON(thp_migration_supported() &&
-				  !is_pmd_migration_entry(pmdval));
-		if (is_pmd_migration_entry(pmdval))
+		entry = pmd_to_swp_entry(pmdval);
+		if (thp_migration_supported() && is_migration_entry(entry)) {
 			pmd_migration_entry_wait(mm, pmd);
-		pmdval = READ_ONCE(*pmd);
-		/*
-		 * MADV_DONTNEED may convert the pmd to null because
-		 * mmap_sem is held in read mode
-		 */
-		if (pmd_none(pmdval))
+			pmdval = READ_ONCE(*pmd);
+			/*
+			 * MADV_DONTNEED may convert the pmd to null because
+			 * mmap_sem is held in read mode
+			 */
+			if (pmd_none(pmdval))
+				return no_page_table(vma, flags);
+			goto retry;
+		}
+		if (IS_ENABLED(CONFIG_THP_SWAP) && !non_swap_entry(entry))
 			return no_page_table(vma, flags);
-		goto retry;
+		WARN_ON(1);
+		return no_page_table(vma, flags);
 	}
 	if (pmd_devmap(pmdval)) {
 		ptl = pmd_lock(mm, pmd);
@@ -275,11 +280,18 @@ static struct page *follow_pmd_mask(struct vm_area_struct *vma,
 		return no_page_table(vma, flags);
 	}
 	if (unlikely(!pmd_present(*pmd))) {
+		entry = pmd_to_swp_entry(*pmd);
 		spin_unlock(ptl);
 		if (likely(!(flags & FOLL_MIGRATION)))
 			return no_page_table(vma, flags);
-		pmd_migration_entry_wait(mm, pmd);
-		goto retry_locked;
+		if (thp_migration_supported() && is_migration_entry(entry)) {
+			pmd_migration_entry_wait(mm, pmd);
+			goto retry_locked;
+		}
+		if (IS_ENABLED(CONFIG_THP_SWAP) && !non_swap_entry(entry))
+			return no_page_table(vma, flags);
+		WARN_ON(1);
+		return no_page_table(vma, flags);
 	}
 	if (unlikely(!pmd_trans_huge(*pmd))) {
 		spin_unlock(ptl);
diff --git a/mm/huge_memory.c b/mm/huge_memory.c
index 5b2eb7871cd7..b75af88c505a 100644
--- a/mm/huge_memory.c
+++ b/mm/huge_memory.c
@@ -2138,7 +2138,7 @@ static inline int pmd_move_must_withdraw(spinlock_t *new_pmd_ptl,
 static pmd_t move_soft_dirty_pmd(pmd_t pmd)
 {
 #ifdef CONFIG_MEM_SOFT_DIRTY
-	if (unlikely(is_pmd_migration_entry(pmd)))
+	if (unlikely(is_swap_pmd(pmd)))
 		pmd = pmd_swp_mksoft_dirty(pmd);
 	else if (pmd_present(pmd))
 		pmd = pmd_mksoft_dirty(pmd);
@@ -2222,11 +2222,12 @@ int change_huge_pmd(struct vm_area_struct *vma, pmd_t *pmd,
 	preserve_write = prot_numa && pmd_write(*pmd);
 	ret = 1;
 
-#ifdef CONFIG_ARCH_ENABLE_THP_MIGRATION
+#if defined(CONFIG_ARCH_ENABLE_THP_MIGRATION) || defined(CONFIG_THP_SWAP)
 	if (is_swap_pmd(*pmd)) {
 		swp_entry_t entry = pmd_to_swp_entry(*pmd);
 
-		VM_BUG_ON(!is_pmd_migration_entry(*pmd));
+		VM_BUG_ON(!IS_ENABLED(CONFIG_THP_SWAP) &&
+			  !is_migration_entry(entry));
 		if (is_write_migration_entry(entry)) {
 			pmd_t newpmd;
 			/*
diff --git a/mm/mempolicy.c b/mm/mempolicy.c
index e4f8248822c1..39335bf99169 100644
--- a/mm/mempolicy.c
+++ b/mm/mempolicy.c
@@ -436,7 +436,7 @@ static int queue_pages_pmd(pmd_t *pmd, spinlock_t *ptl, unsigned long addr,
 	struct queue_pages *qp = walk->private;
 	unsigned long flags;
 
-	if (unlikely(is_pmd_migration_entry(*pmd))) {
+	if (unlikely(is_swap_pmd(*pmd))) {
 		ret = 1;
 		goto unlock;
 	}
-- 
2.18.1

