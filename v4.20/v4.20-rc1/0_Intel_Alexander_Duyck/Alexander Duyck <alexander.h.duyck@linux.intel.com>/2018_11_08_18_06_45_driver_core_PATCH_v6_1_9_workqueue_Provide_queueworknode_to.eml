Return-Path: <linux-kernel-owner@vger.kernel.org>
Delivered-To: unknown
Received: from pop3.zju.edu.cn (124.160.105.205:110) by
  likexu-MOBL1.ccr.corp.intel.com with POP3; 09 Nov 2018 00:37:06 -0000
Received: from icoremail.net (unknown [209.85.215.180])
	by mail-app2 (Coremail) with SMTP id by_KCgDnX9Nle+RbDclhAQ--.29591S3;
	Fri, 09 Nov 2018 02:07:34 +0800 (CST)
Received: from mail-pg1-f180.google.com (unknown [209.85.215.180])
	by mx2.icoremail.net (Coremail) with SMTP id AQAAfwCXbDhje+RbzAYeAA--.896S3;
	Fri, 09 Nov 2018 02:07:31 +0800 (CST)
Received: by mail-pg1-f180.google.com with SMTP id w3-v6so9172894pgs.11
        for <xuliker@zju.edu.cn>; Thu, 08 Nov 2018 10:07:31 -0800 (PST)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20161025;
        h=x-original-authentication-results:x-gm-message-state:delivered-to
         :subject:from:to:cc:date:message-id:in-reply-to:references
         :user-agent:mime-version:content-transfer-encoding:sender:precedence
         :list-id;
        bh=ss+c7ROLFKBLxQhNGGk6fZFm7tNGapUpbuH0YO8eONM=;
        b=HXW6sK7xzU0zvthpZcSO812iJn8h/f7374Qf8eh9we2UwD3wkQbeFseHGRuV8q912H
         RQA9E5yDfaJuDIplT7vW1GPV+pBLIqr/I3spiWLg6ktpEO7Drz7YtrtoeCtDK8jkzlpe
         TwbjOLoJNGzcIWooPCBknNziS9bBoV/e+Bm9ovFEu/wMlYXE/O+fvOmDDNMLWmpeiZMf
         KQJxZuCIeE4CiqSaLXrEb1dlclBL+R3KBagxppDcZAHGQYbSs2HUcbE9Ql75lzSZlTXn
         sTnnQK8L/uuHMVsKtAb8y4mXLZXazT+KluC/yxnNbDd8Zk9wcEtjMF6LWSZsNA8VFnEF
         pWZQ==
X-Original-Authentication-Results: mx.google.com;       spf=pass (google.com: best guess record for domain of linux-kernel-owner@vger.kernel.org designates 209.132.180.67 as permitted sender) smtp.mailfrom=linux-kernel-owner@vger.kernel.org;       dmarc=fail (p=NONE sp=NONE dis=NONE) header.from=intel.com
X-Gm-Message-State: AGRZ1gLtxm+rdwyxeqyY1sW3CLvLYjQvQavEbd1uvld7aM2YwTuDWOhE
	XYzwokHEGMFfoYqdYF+jD6l6bQxv+9rs4gWZhcHkelxOHE7jZkblQw==
X-Received: by 2002:a63:9402:: with SMTP id m2mr4405444pge.93.1541700450970;
        Thu, 08 Nov 2018 10:07:30 -0800 (PST)
X-Forwarded-To: xuliker@zju.edu.cn
X-Forwarded-For: liker.xu@gmail.com xuliker@zju.edu.cn
Delivered-To: liker.xu@gmail.com
Received: by 2002:a17:90a:c304:0:0:0:0 with SMTP id g4-v6csp529002pjt;
        Thu, 8 Nov 2018 10:07:30 -0800 (PST)
X-Google-Smtp-Source: AJdET5cMPTICTwBFW64Pn/7NKjDgulGhtM+mllJnyuG3bHQGuEZTz2iiTSKpsoRjlEvjC28xIxTa
X-Received: by 2002:a63:c942:: with SMTP id y2mr4545266pgg.331.1541700450000;
        Thu, 08 Nov 2018 10:07:30 -0800 (PST)
ARC-Seal: i=1; a=rsa-sha256; t=1541700449; cv=none;
        d=google.com; s=arc-20160816;
        b=JPn9SvMlIb2mvArdxvJKBub0t0x+Ft05LUTE7zejkezd8+TlvDgn6IKPn+zHpKsPVf
         ouXAjcPy4CUJRHmJH/vMltaXJbR/+TV4GGhch079+y436734CZNApO4ppw6MB9ktbYnG
         bw9J+l40l5vTcymtbTONkAziTQbwt34VC2XIowSla543eWuBWmhLYC03nkgPoGTSvejb
         Vb87W4t0ey8vWZx5rCOJgMLfndoQSqwCFLtKTTcp6aOskVRdZwo57DmF5Uyrp6Fis2FQ
         8smHP8zkcptr/ke2Ke7nG69M5kaMlyFakLAl09fLWX4CwtgmxNXwqStYdHCL9ZQd0cWm
         225w==
ARC-Message-Signature: i=1; a=rsa-sha256; c=relaxed/relaxed; d=google.com; s=arc-20160816;
        h=list-id:precedence:sender:content-transfer-encoding:mime-version
         :user-agent:references:in-reply-to:message-id:date:cc:to:from
         :subject;
        bh=ss+c7ROLFKBLxQhNGGk6fZFm7tNGapUpbuH0YO8eONM=;
        b=NmdPXWdZp/jFjIBh6bJN6dLPVH4eu7JDh+A4+WVkA5S9xXk7X28g01gjjjgUivW4zA
         uMZg4Ul8t5i53fQ7rdQXOUBoFUKPjTijHdctzhtZ53qPohP9sfDsdocZJm6G2AS2Ubui
         F5bEl3oVZf8K5fZNHJn0Vv5ll4OELnycDO97hn4xhe5PY3zpKZ8Enmx4/Wp17/RNzP11
         jhcaAh1o5DW3LWTjCNm2CtOXBMINQYMPc60uMMR+w3VRADNgLEo9Zos7UxS77QshNP4C
         +wfMAWIU8/zrIohgieAeAkALVHnIMJMW+KjeGYs5RUItWnLpp7KANseNbP1Kyy+cR08s
         WlfA==
ARC-Authentication-Results: i=1; mx.google.com;
       spf=pass (google.com: best guess record for domain of linux-kernel-owner@vger.kernel.org designates 209.132.180.67 as permitted sender) smtp.mailfrom=linux-kernel-owner@vger.kernel.org;
       dmarc=fail (p=NONE sp=NONE dis=NONE) header.from=intel.com
Received: from vger.kernel.org (vger.kernel.org. [209.132.180.67])
        by mx.google.com with ESMTP id f7-v6si4213443pgh.159.2018.11.08.10.07.08;
        Thu, 08 Nov 2018 10:07:29 -0800 (PST)
Received-SPF: pass (google.com: best guess record for domain of linux-kernel-owner@vger.kernel.org designates 209.132.180.67 as permitted sender) client-ip=209.132.180.67;
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
        id S1727390AbeKIDn0 (ORCPT <rfc822;ankurbansal210989@gmail.com>
        + 99 others); Thu, 8 Nov 2018 22:43:26 -0500
Received: from mga11.intel.com ([192.55.52.93]:3631 "EHLO mga11.intel.com"
        rhost-flags-OK-OK-OK-OK) by vger.kernel.org with ESMTP
        id S1726684AbeKIDn0 (ORCPT <rfc822;linux-kernel@vger.kernel.org>);
        Thu, 8 Nov 2018 22:43:26 -0500
X-Amp-Result: SKIPPED(no attachment in message)
X-Amp-File-Uploaded: False
Received: from orsmga007.jf.intel.com ([10.7.209.58])
  by fmsmga102.fm.intel.com with ESMTP/TLS/DHE-RSA-AES256-GCM-SHA384; 08 Nov 2018 10:06:45 -0800
X-ExtLoop1: 1
X-IronPort-AV: E=Sophos;i="5.54,480,1534834800"; 
   d="scan'208";a="87734982"
Received: from ahduyck-desk1.jf.intel.com ([10.7.198.76])
  by orsmga007.jf.intel.com with ESMTP; 08 Nov 2018 10:06:45 -0800
Subject: [driver-core PATCH v6 1/9] workqueue: Provide queue_work_node to
 queue work near a given NUMA node
From: Alexander Duyck <alexander.h.duyck@linux.intel.com>
To: linux-kernel@vger.kernel.org, gregkh@linuxfoundation.org
Cc: linux-nvdimm@lists.01.org, tj@kernel.org,
        akpm@linux-foundation.org, linux-pm@vger.kernel.org,
        jiangshanlai@gmail.com, rafael@kernel.org, len.brown@intel.com,
        pavel@ucw.cz, zwisler@kernel.org, dan.j.williams@intel.com,
        dave.jiang@intel.com, bvanassche@acm.org,
        alexander.h.duyck@linux.intel.com
Date: Thu, 08 Nov 2018 10:06:45 -0800
Message-ID: <154170040562.12967.17831655390715808287.stgit@ahduyck-desk1.jf.intel.com>
In-Reply-To: <154170028986.12967.2108024712555179678.stgit@ahduyck-desk1.jf.intel.com>
References: <154170028986.12967.2108024712555179678.stgit@ahduyck-desk1.jf.intel.com>
User-Agent: StGit/unknown-version
MIME-Version: 1.0
Content-Type: text/plain; charset="utf-8"
Content-Transfer-Encoding: 7bit
Sender: liker.xu+caf_=xuliker=zju.edu.cn@gmail.com
Precedence: bulk
List-ID: <linux-kernel.vger.kernel.org>
X-Mailing-List: linux-kernel@vger.kernel.org
X-CM-TRANSID: AQAAfwCXbDhje+RbzAYeAA--.896S3
Authentication-Results: mail-app2; spf=pass smtp.mail=liker.xu+caf_=xu
	liker=zju.edu.cn@gmail.com;
X-Coremail-Antispam: 1UD129KBjvJXoW3WF1xAF4rZr4xAr1Dtw1rXrb_yoW7GryDpF
	WYka9xtw4ktFW7K3s3Xw48Jr1agw48WrsrJw1fA3sYyrWYqr1kXw1ktFy3ZFyUGrWku3W2
	vFWDt398K3WjyFDanT9S1TB71UUUUUUqnTZGkaVYY2UrUUUUjbIjqfuFe4nvWSU8nxnvy2
	9KBjDU0xBIdaVrnRJUUUPSb7Iv0xC_KF4lb4IE77IF4wAFF20E14v26r1j6r4UM7CIcVAF
	z4kK6r1j6r18M28lY4IEw2IIxxk0rwA2F7IY1VAKz4vEj48ve4kI8wA2z4x0Y4vE2Ix0cI
	8IcVAFwI0_Ar0_tr1l84ACjcxK6xIIjxv20xvEc7CjxVAFwI0_Cr0_Gr1UM28EF7xvwVC2
	z280aVAFwI0_Gr1j6F4UJwA2z4x0Y4vEx4A2jsIEc7CjxVAFwI0_Gr1j6F4UJwAS0I0E0x
	vYzxvE52x082IY62kv0487Mc02F40EFcxC0VAKzVAqx4xG6I80ewAv7VC0I7IYx2IY67AK
	xVWUJVWUGwAv7VC2z280aVAFwI0_Jr0_Gr1lOx8S6xCaFVCjc4AY6r1j6r4UM4x0Y48IcV
	AKI48JMx02cVCv0xWlc7CjxVAKzI0EY4vE52x082I5MxkFs20EY4vE44CYbxCE4x80FwCY
	02Avz4vEIxC_XwCY0x0Ix7I2Y4AK64vIr41lcIIF0xvE2Ix0cI8IcVAFwI0_Xr0_Ar1lcI
	IF0xvE2Ix0cI8IcVCY1x0267AKxVW8JVWxJwCYIxAIcVC2z280aVAFwI0_Gr1j6F4UJwCY
	IxAIcVC2z280aVCY1x0267AKxVW8Jr0_Cr1UMxAIw28IcxkI7VAKI48JMxAIw28IcVAKzI
	0EY4vE52x082I5MxCjnVCjjxCrMxC20s026xCaFVCjc4AY6r1j6r4UMI8I3I0E5I8CrVAF
	wI0_Jr0_Jr4lx2IqxVCjr7xvwVAFwI0_JrI_JrWlx4CE17CEb7AF67AKxVW8ZVWrXwCIc4
	0Y0x0EwIxGrwCI42IY6xAIw20EY4v20xvaj40_Jr0_JF7vcSsGvfC2KfnxnUUI43ZEXa7I
	U5wBMtUUUUU==

Provide a new function, queue_work_node, which is meant to schedule work on
a "random" CPU of the requested NUMA node. The main motivation for this is
to help assist asynchronous init to better improve boot times for devices
that are local to a specific node.

For now we just default to the first CPU that is in the intersection of the
cpumask of the node and the online cpumask. The only exception is if the
CPU is local to the node we will just use the current CPU. This should work
for our purposes as we are currently only using this for unbound work so
the CPU will be translated to a node anyway instead of being directly used.

As we are only using the first CPU to represent the NUMA node for now I am
limiting the scope of the function so that it can only be used with unbound
workqueues.

Acked-by: Tejun Heo <tj@kernel.org>
Reviewed-by: Bart Van Assche <bvanassche@acm.org>
Signed-off-by: Alexander Duyck <alexander.h.duyck@linux.intel.com>
---
 include/linux/workqueue.h |    2 +
 kernel/workqueue.c        |   84 +++++++++++++++++++++++++++++++++++++++++++++
 2 files changed, 86 insertions(+)

diff --git a/include/linux/workqueue.h b/include/linux/workqueue.h
index 60d673e15632..1f50c1e586e7 100644
--- a/include/linux/workqueue.h
+++ b/include/linux/workqueue.h
@@ -463,6 +463,8 @@ int workqueue_set_unbound_cpumask(cpumask_var_t cpumask);
 
 extern bool queue_work_on(int cpu, struct workqueue_struct *wq,
 			struct work_struct *work);
+extern bool queue_work_node(int node, struct workqueue_struct *wq,
+			    struct work_struct *work);
 extern bool queue_delayed_work_on(int cpu, struct workqueue_struct *wq,
 			struct delayed_work *work, unsigned long delay);
 extern bool mod_delayed_work_on(int cpu, struct workqueue_struct *wq,
diff --git a/kernel/workqueue.c b/kernel/workqueue.c
index 0280deac392e..5df1a0ef6f90 100644
--- a/kernel/workqueue.c
+++ b/kernel/workqueue.c
@@ -1492,6 +1492,90 @@ bool queue_work_on(int cpu, struct workqueue_struct *wq,
 }
 EXPORT_SYMBOL(queue_work_on);
 
+/**
+ * workqueue_select_cpu_near - Select a CPU based on NUMA node
+ * @node: NUMA node ID that we want to select a CPU from
+ *
+ * This function will attempt to find a "random" cpu available on a given
+ * node. If there are no CPUs available on the given node it will return
+ * WORK_CPU_UNBOUND indicating that we should just schedule to any
+ * available CPU if we need to schedule this work.
+ */
+static int workqueue_select_cpu_near(int node)
+{
+	int cpu;
+
+	/* No point in doing this if NUMA isn't enabled for workqueues */
+	if (!wq_numa_enabled)
+		return WORK_CPU_UNBOUND;
+
+	/* Delay binding to CPU if node is not valid or online */
+	if (node < 0 || node >= MAX_NUMNODES || !node_online(node))
+		return WORK_CPU_UNBOUND;
+
+	/* Use local node/cpu if we are already there */
+	cpu = raw_smp_processor_id();
+	if (node == cpu_to_node(cpu))
+		return cpu;
+
+	/* Use "random" otherwise know as "first" online CPU of node */
+	cpu = cpumask_any_and(cpumask_of_node(node), cpu_online_mask);
+
+	/* If CPU is valid return that, otherwise just defer */
+	return cpu < nr_cpu_ids ? cpu : WORK_CPU_UNBOUND;
+}
+
+/**
+ * queue_work_node - queue work on a "random" cpu for a given NUMA node
+ * @node: NUMA node that we are targeting the work for
+ * @wq: workqueue to use
+ * @work: work to queue
+ *
+ * We queue the work to a "random" CPU within a given NUMA node. The basic
+ * idea here is to provide a way to somehow associate work with a given
+ * NUMA node.
+ *
+ * This function will only make a best effort attempt at getting this onto
+ * the right NUMA node. If no node is requested or the requested node is
+ * offline then we just fall back to standard queue_work behavior.
+ *
+ * Currently the "random" CPU ends up being the first available CPU in the
+ * intersection of cpu_online_mask and the cpumask of the node, unless we
+ * are running on the node. In that case we just use the current CPU.
+ *
+ * Return: %false if @work was already on a queue, %true otherwise.
+ */
+bool queue_work_node(int node, struct workqueue_struct *wq,
+		     struct work_struct *work)
+{
+	unsigned long flags;
+	bool ret = false;
+
+	/*
+	 * This current implementation is specific to unbound workqueues.
+	 * Specifically we only return the first available CPU for a given
+	 * node instead of cycling through individual CPUs within the node.
+	 *
+	 * If this is used with a per-cpu workqueue then the logic in
+	 * workqueue_select_cpu_near would need to be updated to allow for
+	 * some round robin type logic.
+	 */
+	WARN_ON_ONCE(!(wq->flags & WQ_UNBOUND));
+
+	local_irq_save(flags);
+
+	if (!test_and_set_bit(WORK_STRUCT_PENDING_BIT, work_data_bits(work))) {
+		int cpu = workqueue_select_cpu_near(node);
+
+		__queue_work(cpu, wq, work);
+		ret = true;
+	}
+
+	local_irq_restore(flags);
+	return ret;
+}
+EXPORT_SYMBOL_GPL(queue_work_node);
+
 void delayed_work_timer_fn(struct timer_list *t)
 {
 	struct delayed_work *dwork = from_timer(dwork, t, timer);
