Return-Path: <linux-kernel-owner@vger.kernel.org>
Delivered-To: unknown
Received: from pop3.zju.edu.cn (61.164.42.155:110) by
  likexu-MOBL1.ccr.corp.intel.com with POP3; 08 Nov 2018 10:29:38 -0000
Received: from icoremail.net (unknown [209.85.210.174])
	by mail-app2 (Coremail) with SMTP id by_KCgDHH7aTCuRbUihfAQ--.28806S3;
	Thu, 08 Nov 2018 18:06:12 +0800 (CST)
Received: from mail-pf1-f174.google.com (unknown [209.85.210.174])
	by mx2.icoremail.net (Coremail) with SMTP id AQAAfwCHXzuRCuRbVCwcAA--.857S3;
	Thu, 08 Nov 2018 18:06:09 +0800 (CST)
Received: by mail-pf1-f174.google.com with SMTP id x2-v6so5010883pfm.7
        for <xuliker@zju.edu.cn>; Thu, 08 Nov 2018 02:06:09 -0800 (PST)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20161025;
        h=x-original-authentication-results:x-gm-message-state:delivered-to
         :from:to:cc:subject:date:message-id:mime-version
         :content-transfer-encoding:sender:precedence:list-id;
        bh=JlDKuVCSX6yv23TxsZ5ehMOWoWzxvwzQ7wGwAhD6cf8=;
        b=qNWXUa6kfXq6No8LS/Ko5pKf31eyjHDljuF4s5FOmnn8gTYWIBIwuR1wSscB6xjrNy
         8/z/PlzW/tH28OVnglNfk70vwA/QvoH+uO3q2p4Cqo2dzexjlUrfVW85qJQV9OPRSsBF
         EbQ4FTQqi6F+KKSCXpH6NN/nTHMxhierR5yycb/6EZhvDfossAAnqGHs2Q+aUmD10j3i
         ljEt3TLmCFbwtFhcOWppeYeIwbv+hXF+fmn/2Lz7RmiHwR0nFdO1HXGfvhrQrG+qAzko
         0SzgDo1BMu8h23+SKWrXvcojGfJJhlU4JcJxof4YXGKeTgLr9dNfdaHZuZdOiocaD6Uf
         VSWQ==
X-Original-Authentication-Results: mx.google.com;       spf=pass (google.com: best guess record for domain of linux-kernel-owner@vger.kernel.org designates 209.132.180.67 as permitted sender) smtp.mailfrom=linux-kernel-owner@vger.kernel.org;       dmarc=fail (p=NONE sp=NONE dis=NONE) header.from=kernel.org
X-Gm-Message-State: AGRZ1gJWxJGcGNvhbFYJfdxdQb6OGzb8JWmi1NW67MlAKa3lIjPBYGOX
	quNKJwxmck7wRH7CH9hGuPQe9ltQT/Iiut63TNsBuOtirFEI3d1VhQ==
X-Received: by 2002:a65:66ce:: with SMTP id c14mr3261736pgw.450.1541671569555;
        Thu, 08 Nov 2018 02:06:09 -0800 (PST)
X-Forwarded-To: xuliker@zju.edu.cn
X-Forwarded-For: liker.xu@gmail.com xuliker@zju.edu.cn
Delivered-To: liker.xu@gmail.com
Received: by 2002:a17:90a:c304:0:0:0:0 with SMTP id g4-v6csp317643pjt;
        Thu, 8 Nov 2018 02:06:08 -0800 (PST)
X-Google-Smtp-Source: AJdET5f8GLLDdH7NKf7BP/hGiUzwCoamHHMHwVt8aqT6+q4YIwwaAnYCA/FAAy2Y2PBm6LgerKZh
X-Received: by 2002:a63:ae4d:: with SMTP id e13-v6mr3287293pgp.315.1541671568759;
        Thu, 08 Nov 2018 02:06:08 -0800 (PST)
ARC-Seal: i=1; a=rsa-sha256; t=1541671568; cv=none;
        d=google.com; s=arc-20160816;
        b=GTUXeNdTd7AJglMd8JdioklURoIda7/mmrL72P5FYGgA6pJ1o9+AXgj29LhmPgIj6x
         kQ9uZVglGr/mN05yRML4XdiIohc2mC4iNat4CPjlKzLjM6p6cTUsOqeqRMtbHjsSSsc7
         9K67zu1uFbqREQsvrG7UmoPKiytS7SPOIrBF7nGzDt2duwJZ+deCAYn8Cw2gZknbVUaN
         wSRC4RO6M8NsQdGTiYspv+ZJFFKbBCXtwJu4YnYHu44z5FOTRWpCrtxCDjMu9hXny2cI
         aBPHgdM0oFpYZkyR/v8zo+O1KGV8ZefyPkIHs/4QXwbNDTbl7t8Y09VDpX2mZBKt2FlT
         qJyQ==
ARC-Message-Signature: i=1; a=rsa-sha256; c=relaxed/relaxed; d=google.com; s=arc-20160816;
        h=list-id:precedence:sender:content-transfer-encoding:mime-version
         :message-id:date:subject:cc:to:from;
        bh=JlDKuVCSX6yv23TxsZ5ehMOWoWzxvwzQ7wGwAhD6cf8=;
        b=Hq6Rbfaf5ficKen2v9b5b/IcA1ArKHeBoPR/ntEw+z1qNUz1jGVkLkBrsCTPFaVnT6
         vjzdu3XJM6VTeyS/F8StrJR2ZQ+jLgS4aY48K4E3dFVetzlOa9j5NHoBJ4WsozjNJax/
         a2aEivCgVqjo85hxuEjNGSpFggEb1ZNlBkKz0LgZJkJmc0bbIkpprf5aRBZ1qGhV+uEm
         MjKZG8HuPqvwmdImy9y6DOKkfb2ULQDuRI4gOkO1D19oQzl/Tq/IAG1JaR4Py9JlN9+X
         rq4lwZRdd7PcFjOL8zqJOv/8cajHr90oTqmmM+IGsVCTwzs/CPk+2UY+5GVenyrZidT5
         7gdw==
ARC-Authentication-Results: i=1; mx.google.com;
       spf=pass (google.com: best guess record for domain of linux-kernel-owner@vger.kernel.org designates 209.132.180.67 as permitted sender) smtp.mailfrom=linux-kernel-owner@vger.kernel.org;
       dmarc=fail (p=NONE sp=NONE dis=NONE) header.from=kernel.org
Received: from vger.kernel.org (vger.kernel.org. [209.132.180.67])
        by mx.google.com with ESMTP id e9-v6si3377289pgo.567.2018.11.08.02.05.52;
        Thu, 08 Nov 2018 02:06:08 -0800 (PST)
Received-SPF: pass (google.com: best guess record for domain of linux-kernel-owner@vger.kernel.org designates 209.132.180.67 as permitted sender) client-ip=209.132.180.67;
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
        id S1726975AbeKHTjR (ORCPT <rfc822;lumpython@gmail.com> + 99 others);
        Thu, 8 Nov 2018 14:39:17 -0500
Received: from mail-ed1-f68.google.com ([209.85.208.68]:45819 "EHLO
        mail-ed1-f68.google.com" rhost-flags-OK-OK-OK-OK) by vger.kernel.org
        with ESMTP id S1726283AbeKHTjR (ORCPT
        <rfc822;linux-kernel@vger.kernel.org>);
        Thu, 8 Nov 2018 14:39:17 -0500
Received: by mail-ed1-f68.google.com with SMTP id w39-v6so11465631edw.12
        for <linux-kernel@vger.kernel.org>; Thu, 08 Nov 2018 02:04:32 -0800 (PST)
X-Received: by 2002:a50:f285:: with SMTP id f5-v6mr3153856edm.77.1541671471575;
        Thu, 08 Nov 2018 02:04:31 -0800 (PST)
Received: from tiehlicka.suse.cz (prg-ext-pat.suse.com. [213.151.95.130])
        by smtp.gmail.com with ESMTPSA id z11-v6sm932788edh.6.2018.11.08.02.04.30
        (version=TLS1_2 cipher=ECDHE-RSA-AES128-GCM-SHA256 bits=128/128);
        Thu, 08 Nov 2018 02:04:30 -0800 (PST)
From: Michal Hocko <mhocko@kernel.org>
To: <linux-mm@kvack.org>
Cc: Andrew Morton <akpm@linux-foundation.org>,
        Oscar Salvador <OSalvador@suse.com>,
        LKML <linux-kernel@vger.kernel.org>,
        Michal Hocko <mhocko@suse.com>,
        Wen Congyang <tangchen@cn.fujitsu.com>,
        Tang Chen <wency@cn.fujitsu.com>,
        Miroslav Benes <mbenes@suse.cz>,
        Vlastimil Babka <vbabka@suse.cz>
Subject: [RFC PATCH] mm, memory_hotplug: do not clear numa_node association after hot_remove
Date: Thu,  8 Nov 2018 11:04:13 +0100
Message-Id: <20181108100413.966-1-mhocko@kernel.org>
X-Mailer: git-send-email 2.19.1
MIME-Version: 1.0
Content-Transfer-Encoding: 8bit
Sender: liker.xu+caf_=xuliker=zju.edu.cn@gmail.com
Precedence: bulk
List-ID: <linux-kernel.vger.kernel.org>
X-Mailing-List: linux-kernel@vger.kernel.org
X-CM-TRANSID: AQAAfwCHXzuRCuRbVCwcAA--.857S3
Authentication-Results: mail-app2; spf=pass smtp.mail=liker.xu+caf_=xu
	liker=zju.edu.cn@gmail.com;
X-Coremail-Antispam: 1UD129KBjvJXoWxtw4kCryDJrWUGryUurWfXwb_yoW7tr4rpr
	4UG345Cr4ktr1UGr18trW5JryUJr4xAa17Jw1xuF1kZF15Gr18Ar18tr4UWryDJrWrXF17
	Jrs8Ja1Iqa45AaDanT9S1TB71UUUUUUqnTZGkaVYY2UrUUUU0bIjqfuFe4nvWSU8nxnvy2
	9KBjDU0xBIdaVrnRJUUUPIb7Iv0xC_Kw4lb4IE77IF4wAFF20E14v26r1j6r4UM7CIcVAF
	z4kK6r1j6r18M28lY4IEw2IIxxk0rwA2F7IY1VAKz4vEj48ve4kI8wA2z4x0Y4vE2Ix0cI
	8IcVAFwI0_Xr0_Ar1l84ACjcxK6xIIjxv20xvEc7CjxVAFwI0_Gr0_Cr1l84ACjcxK6I8E
	87Iv67AKxVW0oVCq3wA2z4x0Y4vEx4A2jsIEc7CjxVAFwI0_GcCE3s1le2I262IYc4CY6c
	8Ij28IcVAaY2xG8wAqx4xG64xvF2IEw4CE5I8CrVC2j2WlYx0E2Ix0cI8IcVAFwI0_JrI_
	JrylYx0Ex4A2jsIE14v26r4j6F4UMcvjeVCFs4IE7xkEbVWUJVW8JwACjcxG0xvY0x0EwI
	xGrwCjxxvEa2IrMxkF7I0Ew4C26cxK6c8Ij28IcwCY1Ik26cxK6xAEc7vF6xCjj44lc2xS
	Y4AK6IIF6r4DMxkI7II2jI8vz4vEwIxGrwCYIxAIcVC0I7IYx2IY67AKxVW8JVW5JwCYIx
	AIcVC0I7IYx2IY6xkF7I0E14v26r4j6F4UMxvI42IY6I8E87Iv67AKxVWxJr0_GcWlcIIF
	0xvEx4A2jsIEc7CjxVAFwI0_Cr1j6rxdMxAIw28IcxkI7VAKI48JMxAIw28IcVAKzI0EY4
	vE52x082I5MxCjnVCjjxCrMxC20s026xCaFVCjc4AY6r1j6r4UMI8I3I0E5I8CrVAFwI0_
	Jr0_Jr4lx2IqxVCjr7xvwVAFwI0_JrI_JrWlx4CE17CEb7AF67AKxVWUtVW8ZwCIc40Y0x
	0EwIxGrwCI42IY6xAIw20EY4v20xvaj40_Zr0_Wr1UYxBIdaVFxhVjvjDU0xZFpf9x07bm
	T5LUUUUU=

From: Michal Hocko <mhocko@suse.com>

Per-cpu numa_node provides a default node for each possible cpu. The
association gets initialized during the boot when the architecture
specific code explores cpu->NUMA affinity. When the whole NUMA node is
removed though we are clearing this association

try_offline_node
  check_and_unmap_cpu_on_node
    unmap_cpu_on_node
      numa_clear_node
        numa_set_node(cpu, NUMA_NO_NODE)

This means that whoever calls cpu_to_node for a cpu associated with such
a node will get NUMA_NO_NODE. This is problematic for two reasons. First
it is fragile because __alloc_pages_node would simply blow up on an
out-of-bound access. We have encountered this when loading kvm module
BUG: unable to handle kernel paging request at 00000000000021c0
IP: [<ffffffff8119ccb3>] __alloc_pages_nodemask+0x93/0xb70
PGD 800000ffe853e067 PUD 7336bbc067 PMD 0
Oops: 0000 [#1] SMP
[...]
CPU: 88 PID: 1223749 Comm: modprobe Tainted: G        W          4.4.156-94.64-default #1
task: ffff88727eff1880 ti: ffff887354490000 task.ti: ffff887354490000
RIP: 0010:[<ffffffff8119ccb3>]  [<ffffffff8119ccb3>] __alloc_pages_nodemask+0x93/0xb70
RSP: 0018:ffff887354493b40  EFLAGS: 00010202
RAX: 00000000000021c0 RBX: 0000000000000000 RCX: 0000000000000000
RDX: 0000000000000000 RSI: 0000000000000002 RDI: 00000000014000c0
RBP: 00000000014000c0 R08: ffffffffffffffff R09: 0000000000000000
R10: ffff88fffc89e790 R11: 0000000000014000 R12: 0000000000000101
R13: ffffffffa0772cd4 R14: ffffffffa0769ac0 R15: 0000000000000000
FS:  00007fdf2f2f1700(0000) GS:ffff88fffc880000(0000) knlGS:0000000000000000
CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033
CR2: 00000000000021c0 CR3: 00000077205ee000 CR4: 0000000000360670
DR0: 0000000000000000 DR1: 0000000000000000 DR2: 0000000000000000
DR3: 0000000000000000 DR6: 00000000fffe0ff0 DR7: 0000000000000400
Stack:
 0000000000000086 014000c014d20400 ffff887354493bb8 ffff882614d20f4c
 0000000000000000 0000000000000046 0000000000000046 ffffffff810ac0c9
 ffff88ffe78c0000 ffffffff0000009f ffffe8ffe82d3500 ffff88ff8ac55000
Call Trace:
 [<ffffffffa07476cd>] alloc_vmcs_cpu+0x3d/0x90 [kvm_intel]
 [<ffffffffa0772c0c>] hardware_setup+0x781/0x849 [kvm_intel]
 [<ffffffffa04a1c58>] kvm_arch_hardware_setup+0x28/0x190 [kvm]
 [<ffffffffa04856fc>] kvm_init+0x7c/0x2d0 [kvm]
 [<ffffffffa0772cf2>] vmx_init+0x1e/0x32c [kvm_intel]
 [<ffffffff8100213a>] do_one_initcall+0xca/0x1f0
 [<ffffffff81193886>] do_init_module+0x5a/0x1d7
 [<ffffffff81112083>] load_module+0x1393/0x1c90
 [<ffffffff81112b30>] SYSC_finit_module+0x70/0xa0
 [<ffffffff8161cbc3>] entry_SYSCALL_64_fastpath+0x1e/0xb7
DWARF2 unwinder stuck at entry_SYSCALL_64_fastpath+0x1e/0xb7

on an older kernel but the code is basically the same in the current
Linus tree as well. alloc_vmcs_cpu could use alloc_pages_nodemask which
would recognize NUMA_NO_NODE and use alloc_pages_node which would translate
it to numa_mem_id but that is wrong as well because it would use a cpu
affinity of the local CPU which might be quite far from the original node.
It is also reasonable to expect that cpu_to_node will provide a sane value
and there might be many more callers like that.

The second problem is that __register_one_node relies on cpu_to_node
to properly associate cpus back to the node when it is onlined. We do
not want to lose that link as there is no arch independent way to get it
from the early boot time AFAICS.

Drop the whole check_and_unmap_cpu_on_node machinery and keep the
association to fix both issues. The NODE_DATA(nid) is not deallocated
so it will stay in place and if anybody wants to allocate from that node
then a fallback node will be used.

Thanks to Vlastimil Babka for his live system debugging skills that
helped debugging the issue.

Debugged-by: Vlastimil Babka <vbabka@suse.cz>
Reported-by: Miroslav Benes <mbenes@suse.cz>
Fixes: e13fe8695c57 ("cpu-hotplug,memory-hotplug: clear cpu_to_node() when offlining the node")
Cc: Wen Congyang <tangchen@cn.fujitsu.com>
Cc: Tang Chen <wency@cn.fujitsu.com>
Signed-off-by: Michal Hocko <mhocko@suse.com>
---

Hi,
please note that I am sending this as an RFC even though this has been
confirmed to fix the oops in kvm_intel module because I cannot simply
tell that there are no other side effect that I do not see from the code
reading. I would appreciate some background from people who have
introduced this code e13fe8695c57 ("cpu-hotplug,memory-hotplug: clear
cpu_to_node() when offlining the node") because the changelog doesn't
really explain the motivation much.

 mm/memory_hotplug.c | 30 +-----------------------------
 1 file changed, 1 insertion(+), 29 deletions(-)

diff --git a/mm/memory_hotplug.c b/mm/memory_hotplug.c
index 2b2b3ccbbfb5..87aeafac54ee 100644
--- a/mm/memory_hotplug.c
+++ b/mm/memory_hotplug.c
@@ -1753,34 +1753,6 @@ static int check_cpu_on_node(pg_data_t *pgdat)
 	return 0;
 }
 
-static void unmap_cpu_on_node(pg_data_t *pgdat)
-{
-#ifdef CONFIG_ACPI_NUMA
-	int cpu;
-
-	for_each_possible_cpu(cpu)
-		if (cpu_to_node(cpu) == pgdat->node_id)
-			numa_clear_node(cpu);
-#endif
-}
-
-static int check_and_unmap_cpu_on_node(pg_data_t *pgdat)
-{
-	int ret;
-
-	ret = check_cpu_on_node(pgdat);
-	if (ret)
-		return ret;
-
-	/*
-	 * the node will be offlined when we come here, so we can clear
-	 * the cpu_to_node() now.
-	 */
-
-	unmap_cpu_on_node(pgdat);
-	return 0;
-}
-
 /**
  * try_offline_node
  * @nid: the node ID
@@ -1813,7 +1785,7 @@ void try_offline_node(int nid)
 		return;
 	}
 
-	if (check_and_unmap_cpu_on_node(pgdat))
+	if (check_cpu_on_node(pgdat))
 		return;
 
 	/*
-- 
2.19.1
