Return-Path: <linux-kernel-owner@vger.kernel.org>
Delivered-To: unknown
Received: from linux.intel.com (10.54.29.200:995) by i7-8700 with POP3-SSL;
  20 Dec 2018 19:16:06 -0000
X-Original-To: like.xu@linux.intel.com
Delivered-To: like.xu@linux.intel.com
Received: from orsmga003.jf.intel.com (orsmga003.jf.intel.com [10.7.209.27])
	(using TLSv1.2 with cipher ECDHE-RSA-AES256-GCM-SHA384 (256/256 bits))
	(No client certificate requested)
	by linux.intel.com (Postfix) with ESMTPS id E791E580522;
	Thu, 20 Dec 2018 02:54:56 -0800 (PST)
Received: from orsmga101.jf.intel.com ([10.7.208.22])
  by orsmga003-1.jf.intel.com with ESMTP/TLS/DHE-RSA-AES256-GCM-SHA384; 20 Dec 2018 02:54:56 -0800
X-SG-BADATTACHMENTNOREPLY: True
IronPort-PHdr: =?us-ascii?q?9a23=3ATfulLRapkiDGeZaRvdYA5Az/LSx+4OfEezUN459i?=
 =?us-ascii?q?sYplN5qZpci5bR7h7PlgxGXEQZ/co6odzbaO4+a4ASQp2tWoiDg6aptCVhsI24?=
 =?us-ascii?q?09vjcLJ4q7M3D9N+PgdCcgHc5PBxdP9nC/NlVJSo6lPwWB6nK94iQPFRrhKAF7?=
 =?us-ascii?q?Ovr6GpLIj8Swyuu+54Dfbx9HiTahYr5+Ngm6oRnMvcQKnIVuLbo8xAHUqXVSYe?=
 =?us-ascii?q?RWwm1oJVOXnxni48q74YBu/SdNtf8/7sBMSar1cbg2QrxeFzQmLns65Nb3uhnZ?=
 =?us-ascii?q?TAuA/WUTX2MLmRdVGQfF7RX6XpDssivms+d2xSeXMdHqQb0yRD+v9LlgRgP2hy?=
 =?us-ascii?q?gbNj456GDXhdJ2jKJHuxKquhhzz5fJbI2JKPZye6XQds4YS2VcRMZcTzFPDJ2y?=
 =?us-ascii?q?b4UPDOQPM+hXoIb/qFsPsRSwChKsBPvtxzJTmn/737c33/g9HQzI3gEtGc8Fvn?=
 =?us-ascii?q?TOrNXyMacfSeS7zK7IzTXFcvhY2yr955PTfR87u/GDQK97fM3TyUkvCgPKlU6f?=
 =?us-ascii?q?ppb/PzyIzekNtXab7+t9WuKukWErsR1+oj+qxso1jITCm4Ebykjc+Cln3Io4Ic?=
 =?us-ascii?q?e0RFN1bNK6CpdcqiKXO5dsTs4jQWxkoDs2xqEctZKmYiQHx44rywPFZ/GHa4SE?=
 =?us-ascii?q?/A/vWeeLLTtmmn5oe6iziwus/US90OHxV8m53VBXpSRfiNbMrGoC1xnL58iHVP?=
 =?us-ascii?q?R9+kCh1C6R1wDc9O5EO1o4lanFJJ47xL4/iJ4TvV7EHi/sl0X6lK6WdkM69ei0?=
 =?us-ascii?q?8+nrfKnqq5uGO4NphAzyLL4iltG8DOgkKAQDXmqW9fy51LL5/E35RLtKjucxkq?=
 =?us-ascii?q?ncqJ3aIcUbpqikAw5ay4oj6AiwDy2g0NsGmXkLNVVFeRyBj4f3IVHDO+74Dfih?=
 =?us-ascii?q?jFS2ijtrxO7JPqfnAprTKnjPirDhfaxy60JE0go80chf545ICrEGOP/zXk7xtN?=
 =?us-ascii?q?/GARMjPA203v3qCNF81oMYRGKODbWVMKLUsV+U+O0vJ/OAa5MSuDb4M/Il/eLh?=
 =?us-ascii?q?jWclmV8BeqmkxZsXZ2q5HvR6OUqZZmDggtccEWgQuAo+Q/fniFmDUT5VenazUL?=
 =?us-ascii?q?gw5jA9CIK6E4jDQpqhj6CG3Ce+BpdWfHxJCkiQEXf0cIWJQ+0DaDmSIs9mkTwI?=
 =?us-ascii?q?T6KhRJUj1Ry1sA/6yrxnLvfb+yECtJLj0sR16PPXlR0o6TN0CMGd2XmXT25ohm?=
 =?us-ascii?q?MIWyM23KdnrEx+0FiD17J0g/hZFdNJ4fNJXRw3NZrdz+x8FtDzVRjNftaPSFa6?=
 =?us-ascii?q?XNqmBSs9Qc42w98Le0x9Acmtjgjf3yq2BL8Yj6GEC4Yq8q3CxXTxJ9xyy3Dd1K?=
 =?us-ascii?q?Y/iVkqRc9PNW6jhq577AXTA4/Jk0OEl6elb6gc3SjN9HudwmqKpk1XTAlwUaDd?=
 =?us-ascii?q?V3AFekTWtcj55l/FT7K2FLsoKBVBxtCYJqtKcNLpi05GS+nlONnFZ2KxmmGwBQ?=
 =?us-ascii?q?uHx7+WbYrqfXkd0zvZCEQejw8T+nOGPxAkBii9u2LeECBuFVX3bkPw8Ol+rXS7?=
 =?us-ascii?q?TlM0zwCKdUFhy6C5+hkPhfyYSvMT2L0EtTwlqzV1Gla9wt3XB8CBpwpnYKVTf9?=
 =?us-ascii?q?c97E1b2mLesgx3JoagILx6hl4CbwR3uFvj2A9zCopensklsnMrwBBpJqKFzVxO?=
 =?us-ascii?q?bTWY3ZP3Or3JMWTy+BGva6jL2lDRytqW+6EP6OgmpFXnpg2mCk0i83B/2dlPz3?=
 =?us-ascii?q?Sc/onKDBYVUZ/pUkc36gJ2qK3Abig854Pbz3tsMaavvz/G2tIpAvYlyxm6c9de?=
 =?us-ascii?q?NqOECBH9E8kAC8eyL+wqnkCjbggYM+BK6K40I8SmeuOc2K6qIOlvhiimgnlA4I?=
 =?us-ascii?q?xn1EKD6TB8Su/R05kZ2f6Y2haIWCnmjFemtMD6goREZTAUHmqixinoHo9RZqtu?=
 =?us-ascii?q?fYkVDWeiOdG4xtJ7h5T1QX5X6EajB08a2M+uYReTb1390RdQ1EgNunynhC24wi?=
 =?us-ascii?q?dwkzEoqKqfwSPPz/7jdBoBJm5EWm1igU3wLoizitAQRFKoYBQxlBu5+Ub6wLBW?=
 =?us-ascii?q?pKZlIGnJQkdIfC/2I3t5UqSqtbqCYM9P6JU2viVRS+m8ZVGaSrjgoxoVyS/jHm?=
 =?us-ascii?q?1exCwleDGuoJn2gxt6iGeFJnZpsHXZYd1wxQvY5NHERf9exD0GSDN6iTnWAFix?=
 =?us-ascii?q?JN2p/dSSl5feveGyTWOhVptPcSb1yYOMrje05WpvARenhfC8hsXnERQm0S/8z9?=
 =?us-ascii?q?RqVj/HrBfmbonryqS1K+RnfkZzCV/46sp6HJx+k4QqiJER33gamoua/X4dnWjv?=
 =?us-ascii?q?NtVb3Lr0bGARSj4T397V/A/l1VVmLnKIxIL2TG+Rw8V/aNmhfmMZxDg94NtUB6?=
 =?us-ascii?q?eO47xJhi91olu+rQLMbvlxhDYdyf0y6HEEh+EFohYiziKYAroKB0lXITTslwiU?=
 =?us-ascii?q?79C5tKhXeGGvcb2q2Et/h9+hCqyCohpHWHb4YZoiGS5w7sNiMFPDynHz64fkeM?=
 =?us-ascii?q?XOYtIXrBGbjxDAj+1NIpIrivUKnTZnOX76vXA90OE0lxtu3ZWnvISdL2Vt4bm0?=
 =?us-ascii?q?AhpZNj3zesMS9SvhjadYnsaKwY+vGo9tFSkMXJvtVfioCi4dtez7NwaSFz0xsn?=
 =?us-ascii?q?WbFqDaHQCB80dqtW7PH4qoN3GKJ3kZ0NNiSwOGJEFEhAAUXTM6noM2Fwywxczh?=
 =?us-ascii?q?dlt56S4V5lLithRMzedoPQHlUmjDvAeodis0SJ+HIRtW6QFC+l7VMdGE4eJ1BS?=
 =?us-ascii?q?1Y5ZqhrAqCKmGAYwRIDGcJWlGLBlz5P7mu48XA/PacBuakM/TOZrCOo/REV/iU?=
 =?us-ascii?q?3ZKvzpdm/zGUO8WPIHZiDv472klCXXxjGMTZgTIPSyMJmCLXcs6bvwyx+il2rs?=
 =?us-ascii?q?C57fTqVxjj5YqJC7tOL9pv/wq6jruEN+6VnCx5MypX1osQxX/Uz7gSxEQdizx1?=
 =?us-ascii?q?eDm3D7sBtTTBTKbRmqJMCx4baiVzNNZH7q4m3wlNP9Lbhc3x1rJikvE1DFJFX0?=
 =?us-ascii?q?T7ms61fcwKP329NFTfCUaXNbSGICfHzN3tbaygSb1fkuNUuga0uTaaFU/jIzuC?=
 =?us-ascii?q?myPoVxCpLeFDkiWbMAZCt4G6dxZnEXLjQ87+ah2nLN93iiU7wL0uiXPMMG4cMD?=
 =?us-ascii?q?58fFtMr72Q9yxYhPp/FndF7npkK+mEhimY4/PZKpYQrftkHCB0m/hG73Q9zrsG?=
 =?us-ascii?q?pB1DEd58nmPxp8Rn6wWkm+KM4iF6SxcIoSQdwMqpsF9lPKiR2Z1BQm3JtEYP4m?=
 =?us-ascii?q?GREA8Hj8FoBt3mp+Zbzd2Zx4zpLzIX0dXU+4M8GsLeIdiLeC4jMQfjEjfOACMD?=
 =?us-ascii?q?Uz+nNGiZjEtYxqLBvkaJp4Q3/8C/0KEFTaVWARlsTqsX?=
X-IronPort-Anti-Spam-Filtered: true
X-IronPort-Anti-Spam-Result: =?us-ascii?q?A0B6AAAIdBtch0O0hNFjGwEBAQEDAQEBB?=
 =?us-ascii?q?wMBAQGBZYNsJwqDc5QVgWAIJRSZUSsBhy0iOBIBAwEBAQEBAQIBEwEBAQgNCQg?=
 =?us-ascii?q?pIwyCNiQBgmIBAgMBAiAEGQEBNwEFCQEBCg4KAgImAgIDRBAGAQwBBwEBARaDB?=
 =?us-ascii?q?4ICBaZscHwzgnYBAQWCQ4RkCIELihiBHBeBQD+BEScMgl+ICYJXi0SEYjeQYgm?=
 =?us-ascii?q?RXwYYgV+IKiaHLSyJIJA/gV2BdzMaCBsVgyeCGwwXg0qKdB8BMYEFAQGMQYEfA?=
 =?us-ascii?q?QE?=
X-IPAS-Result: =?us-ascii?q?A0B6AAAIdBtch0O0hNFjGwEBAQEDAQEBBwMBAQGBZYNsJwq?=
 =?us-ascii?q?Dc5QVgWAIJRSZUSsBhy0iOBIBAwEBAQEBAQIBEwEBAQgNCQgpIwyCNiQBgmIBA?=
 =?us-ascii?q?gMBAiAEGQEBNwEFCQEBCg4KAgImAgIDRBAGAQwBBwEBARaDB4ICBaZscHwzgnY?=
 =?us-ascii?q?BAQWCQ4RkCIELihiBHBeBQD+BEScMgl+ICYJXi0SEYjeQYgmRXwYYgV+IKiaHL?=
 =?us-ascii?q?SyJIJA/gV2BdzMaCBsVgyeCGwwXg0qKdB8BMYEFAQGMQYEfAQE?=
X-IronPort-AV: E=Sophos;i="5.56,376,1539673200"; 
   d="scan'208";a="45786529"
X-Amp-Result: SKIPPED(no attachment in message)
X-Amp-File-Uploaded: False
Received: from vger.kernel.org ([209.132.180.67])
  by mtab.intel.com with ESMTP; 20 Dec 2018 02:54:55 -0800
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
        id S1731324AbeLTKyx (ORCPT <rfc822;like.xu@linux.intel.com>
        + 22 others); Thu, 20 Dec 2018 05:54:53 -0500
Received: from hqemgate16.nvidia.com ([216.228.121.65]:11171 "EHLO
        hqemgate16.nvidia.com" rhost-flags-OK-OK-OK-OK) by vger.kernel.org
        with ESMTP id S1731299AbeLTKyw (ORCPT
        <rfc822;linux-kernel@vger.kernel.org>);
        Thu, 20 Dec 2018 05:54:52 -0500
Received: from hqpgpgate102.nvidia.com (Not Verified[216.228.121.13]) by hqemgate16.nvidia.com (using TLS: TLSv1.2, DES-CBC3-SHA)
        id <B5c1b74f00000>; Thu, 20 Dec 2018 02:54:40 -0800
Received: from hqmail.nvidia.com ([172.20.161.6])
  by hqpgpgate102.nvidia.com (PGP Universal service);
  Thu, 20 Dec 2018 02:54:50 -0800
X-PGP-Universal: processed;
        by hqpgpgate102.nvidia.com on Thu, 20 Dec 2018 02:54:50 -0800
Received: from [10.2.167.233] (10.124.1.5) by HQMAIL101.nvidia.com
 (172.20.187.10) with Microsoft SMTP Server (TLS) id 15.0.1395.4; Thu, 20 Dec
 2018 10:54:50 +0000
Subject: Re: [PATCH 1/2] mm: introduce put_user_page*(), placeholder versions
To: Jan Kara <jack@suse.cz>, Jerome Glisse <jglisse@redhat.com>
CC: Matthew Wilcox <willy@infradead.org>,
        Dave Chinner <david@fromorbit.com>,
        Dan Williams <dan.j.williams@intel.com>,
        John Hubbard <john.hubbard@gmail.com>,
        Andrew Morton <akpm@linux-foundation.org>,
        Linux MM <linux-mm@kvack.org>, <tom@talpey.com>,
        Al Viro <viro@zeniv.linux.org.uk>, <benve@cisco.com>,
        Christoph Hellwig <hch@infradead.org>,
        Christopher Lameter <cl@linux.com>,
        "Dalessandro, Dennis" <dennis.dalessandro@intel.com>,
        Doug Ledford <dledford@redhat.com>,
        Jason Gunthorpe <jgg@ziepe.ca>,
        Michal Hocko <mhocko@kernel.org>, <mike.marciniszyn@intel.com>,
        <rcampbell@nvidia.com>,
        Linux Kernel Mailing List <linux-kernel@vger.kernel.org>,
        linux-fsdevel <linux-fsdevel@vger.kernel.org>
References: <20181210102846.GC29289@quack2.suse.cz>
 <20181212150319.GA3432@redhat.com> <20181212214641.GB29416@dastard>
 <20181214154321.GF8896@quack2.suse.cz> <20181216215819.GC10644@dastard>
 <20181217181148.GA3341@redhat.com>
 <20181217183443.GO10600@bombadil.infradead.org>
 <20181218093017.GB18032@quack2.suse.cz>
 <9f43d124-2386-7bfd-d90b-4d0417f51ccd@nvidia.com>
 <20181219020723.GD4347@redhat.com> <20181219110856.GA18345@quack2.suse.cz>
X-Nvconfidentiality: public
From: John Hubbard <jhubbard@nvidia.com>
Message-ID: <8e98d553-7675-8fa1-3a60-4211fc836ed9@nvidia.com>
Date: Thu, 20 Dec 2018 02:54:49 -0800
User-Agent: Mozilla/5.0 (X11; Linux x86_64; rv:60.0) Gecko/20100101
 Thunderbird/60.3.2
MIME-Version: 1.0
In-Reply-To: <20181219110856.GA18345@quack2.suse.cz>
X-Originating-IP: [10.124.1.5]
X-ClientProxiedBy: HQMAIL101.nvidia.com (172.20.187.10) To
 HQMAIL101.nvidia.com (172.20.187.10)
Content-Type: text/plain; charset="utf-8"
Content-Language: en-US
Content-Transfer-Encoding: 7bit
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed; d=nvidia.com; s=n1;
        t=1545303280; bh=gUB33G4I8Kn0nCUd1t/wdYqHhzS834HZBOXF/wjwMGw=;
        h=X-PGP-Universal:Subject:To:CC:References:X-Nvconfidentiality:From:
         Message-ID:Date:User-Agent:MIME-Version:In-Reply-To:
         X-Originating-IP:X-ClientProxiedBy:Content-Type:Content-Language:
         Content-Transfer-Encoding;
        b=Usjgz8dydyIWquetSS0VR7eqhrfalgnjXEpcHJu/+pctTBq8ZlQgtBcRPMVoVMGp5
         pndIUPe1yllJ6TYB7qnNZWKLr+eNoK+pMakdcn0TXYKq+u8bO1kGA+mBugPkPWibhV
         vUEWdNTTy7TQ6OoxFnZ5zVZMBF+PZolAToKB1FTZBMVnGKg//pdi3ZDSQhzt6HGYd2
         AMKLivBOKLzE6Wzm7ruWSQEhDu66eexGksoIBit2XfG1HUmFqmEFQEPD7He8nWtYlm
         ISNEkrFUe4T/MkArDPSxjovRv4wk0f80IMyNzZeFDLBWRE0mWpTYnOAWx8NEsmsHGl
         rZBqt1LGEul2w==
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: <linux-kernel.vger.kernel.org>
X-Mailing-List: linux-kernel@vger.kernel.org

On 12/19/18 3:08 AM, Jan Kara wrote:
> On Tue 18-12-18 21:07:24, Jerome Glisse wrote:
>> On Tue, Dec 18, 2018 at 03:29:34PM -0800, John Hubbard wrote:
>>> OK, so let's take another look at Jerome's _mapcount idea all by itself (using
>>> *only* the tracking pinned pages aspect), given that it is the lightest weight
>>> solution for that.  
>>>
>>> So as I understand it, this would use page->_mapcount to store both the real
>>> mapcount, and the dma pinned count (simply added together), but only do so for
>>> file-backed (non-anonymous) pages:
>>>
>>>
>>> __get_user_pages()
>>> {
>>> 	...
>>> 	get_page(page);
>>>
>>> 	if (!PageAnon)
>>> 		atomic_inc(page->_mapcount);
>>> 	...
>>> }
>>>
>>> put_user_page(struct page *page)
>>> {
>>> 	...
>>> 	if (!PageAnon)
>>> 		atomic_dec(&page->_mapcount);
>>>
>>> 	put_page(page);
>>> 	...
>>> }
>>>
>>> ...and then in the various consumers of the DMA pinned count, we use page_mapped(page)
>>> to see if any mapcount remains, and if so, we treat it as DMA pinned. Is that what you 
>>> had in mind?
>>
>> Mostly, with the extra two observations:
>>     [1] We only need to know the pin count when a write back kicks in
>>     [2] We need to protect GUP code with wait_for_write_back() in case
>>         GUP is racing with a write back that might not the see the
>>         elevated mapcount in time.
>>
>> So for [2]
>>
>> __get_user_pages()
>> {
>>     get_page(page);
>>
>>     if (!PageAnon) {
>>         atomic_inc(page->_mapcount);
>> +       if (PageWriteback(page)) {
>> +           // Assume we are racing and curent write back will not see
>> +           // the elevated mapcount so wait for current write back and
>> +           // force page fault
>> +           wait_on_page_writeback(page);
>> +           // force slow path that will fault again
>> +       }
>>     }
>> }
> 
> This is not needed AFAICT. __get_user_pages() gets page reference (and it
> should also increment page->_mapcount) under PTE lock. So at that point we
> are sure we have writeable PTE nobody can change. So page_mkclean() has to
> block on PTE lock to make PTE read-only and only after going through all
> PTEs like this, it can check page->_mapcount. So the PTE lock provides
> enough synchronization.
> 
>> For [1] only needing pin count during write back turns page_mkclean into
>> the perfect spot to check for that so:
>>
>> int page_mkclean(struct page *page)
>> {
>>     int cleaned = 0;
>> +   int real_mapcount = 0;
>>     struct address_space *mapping;
>>     struct rmap_walk_control rwc = {
>>         .arg = (void *)&cleaned,
>>         .rmap_one = page_mkclean_one,
>>         .invalid_vma = invalid_mkclean_vma,
>> +       .mapcount = &real_mapcount,
>>     };
>>
>>     BUG_ON(!PageLocked(page));
>>
>>     if (!page_mapped(page))
>>         return 0;
>>
>>     mapping = page_mapping(page);
>>     if (!mapping)
>>         return 0;
>>
>>     // rmap_walk need to change to count mapping and return value
>>     // in .mapcount easy one
>>     rmap_walk(page, &rwc);
>>
>>     // Big fat comment to explain what is going on
>> +   if ((page_mapcount(page) - real_mapcount) > 0) {
>> +       SetPageDMAPined(page);
>> +   } else {
>> +       ClearPageDMAPined(page);
>> +   }
> 
> This is the detail I'm not sure about: Why cannot rmap_walk_file() race
> with e.g. zap_pte_range() which decrements page->_mapcount and thus the
> check we do in page_mkclean() is wrong?

Right. This looks like a dead end, after all. We can't lock a whole chunk 
of "all these are mapped, hold still while we count you" pages. It's not
designed to allow that at all.

IMHO, we are now back to something like dynamic_page, which provides an
independent dma pinned count. 

-- 
thanks,
John Hubbard
NVIDIA
