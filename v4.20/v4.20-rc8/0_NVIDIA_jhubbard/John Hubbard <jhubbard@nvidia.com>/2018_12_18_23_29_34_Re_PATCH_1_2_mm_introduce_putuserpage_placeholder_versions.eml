Return-Path: <linux-kernel-owner@vger.kernel.org>
Delivered-To: unknown
Received: from linux.intel.com (10.54.29.200:995) by i7-8700 with POP3-SSL;
  19 Dec 2018 08:45:27 -0000
X-Original-To: like.xu@linux.intel.com
Delivered-To: like.xu@linux.intel.com
Received: from fmsmga002.fm.intel.com (fmsmga002.fm.intel.com [10.253.24.26])
	(using TLSv1.2 with cipher ECDHE-RSA-AES256-GCM-SHA384 (256/256 bits))
	(No client certificate requested)
	by linux.intel.com (Postfix) with ESMTPS id EBBC858055F;
	Tue, 18 Dec 2018 15:32:42 -0800 (PST)
Received: from orsmga102-1.jf.intel.com (HELO mga09.intel.com) ([10.7.208.27])
  by fmsmga002-1.fm.intel.com with ESMTP; 18 Dec 2018 15:32:42 -0800
X-SG-BADATTACHMENTNOREPLY: True
IronPort-PHdr: =?us-ascii?q?9a23=3AMkJCARSsbes5AKGVX0cu+3PISNpsv+yvbD5Q0YIu?=
 =?us-ascii?q?jvd0So/mwa64YRCOt8tkgFKBZ4jH8fUM07OQ7/iwHzRYqb+681k6OKRWUBEEjc?=
 =?us-ascii?q?hE1ycBO+WiTXPBEfjxciYhF95DXlI2t1uyMExSBdqsLwaK+i764jEdAAjwOhRo?=
 =?us-ascii?q?LerpBIHSk9631+ev8JHPfglEnjWwba9xIRmssQndqtQdjJd/JKo21hbHuGZDdf?=
 =?us-ascii?q?5MxWNvK1KTnhL86dm18ZV+7SleuO8v+tBZX6nicKs2UbJXDDI9M2Ao/8LrrgXM?=
 =?us-ascii?q?TRGO5nQHTGoblAdDDhXf4xH7WpfxtTb6tvZ41SKHM8D6Uaw4VDK/5KpwVhTmlD?=
 =?us-ascii?q?kIOCI48GHPi8x/kqRboA66pxdix4LYeZyZOOZicq/Ye94RWGhPUdtLVyFZH42y?=
 =?us-ascii?q?cYUPAeoCM+hWoYbyqFkBrRqiCgejH+Pv0j1Fi2Tq3aA4yektDR3K0QIiEt8IrX?=
 =?us-ascii?q?/arM/1NKAXUe2tyKfIyjXDb/VL0jn/9YjHaQsuruuWXb1tbMHczksvFwPYjlqL?=
 =?us-ascii?q?soPqJSmV2fkWvmid8epgVP+gi289pA1rvjevwcIsh5DPi4kIxF7E8iB5z5w0Jd?=
 =?us-ascii?q?2+UEN7YsCrEIFWty6EM4t6WMQiQ3tnuCs817YIuoa7cTAUxJg7wxPTceGLfoaW?=
 =?us-ascii?q?7h75SeqcIit0iGhkdb+9nxq+7EqtxvPmWsWqzFpGtDdJn9fWun0D0xHf8taLRu?=
 =?us-ascii?q?Z880u7xzqDyQPe5vtZLUwqiKbXMZ8sz742m5EOq0rMBDX2l1/zjKKOdkUr5Oyo?=
 =?us-ascii?q?6+P/b7X4qZ+TKZV0hhv9MqswgMy/B/o3MgwUU2ic4+S826Xv/Uz/QLpUkv07ir?=
 =?us-ascii?q?fVvIzeKMgBu6K0DRFZ3pw+5xu8EzuqytUVkHsfIFJAYh2HjozpO1/UIPD/CPey?=
 =?us-ascii?q?m1CskDZtx/DbMbztG5bNIWbZkLfnY7l971dQyA09zNBZ+Z1UEKoMIOz8WkDvrt?=
 =?us-ascii?q?zUFBw5PBKuw+bhFtp90pkSWWWVAq+WKK/Sq0OH5vozI+mQY48YoDL9K/km5/Hw?=
 =?us-ascii?q?l3M4lkIdcLKt3ZsWbnC4A/tnL1+YYXrqntcOD2MKshAiQ+ztjV2ISSRTaGqqX6?=
 =?us-ascii?q?Ig+jE7D5qrDYfZSYCsnLyOxiC7EodWZmBbEF+MF3joep6AW/cNbiKSP8BgniYF?=
 =?us-ascii?q?VbinV48uyxWuuBXmxLpgK+re4jcYuo771Nhp++3Tkgk/9T5zD8uDyW2NTGZ0nm?=
 =?us-ascii?q?UORz8xx61/pU19ylGe0al3mfBYFNpT5+9XXQc+L5LT0+t6C9XqUALbYtiJUEqm?=
 =?us-ascii?q?QsmhATwpVN0x2N8OY0F+G9m4lBDMxSiqDqQRl7yKApw0763d02LwJ8Z713bJyq?=
 =?us-ascii?q?0hg0M6TctIMG2snrR/+BTLB47Vj0WZkL6ndacG0y7L7muDyWuOs1teUA5/SqjF?=
 =?us-ascii?q?WXEfZk3LrdX2/E/CTrmuCag5PQtF08KNNqxKatjxh1VcWPjjIMjeY362m2qoGB?=
 =?us-ascii?q?mH3K2MY5Twd2UdxirdDlMEnB4V/XqBMQg+BSKho2bFATxqFFLvZV7s8OZkpHO6?=
 =?us-ascii?q?SE800x+Fb0l727Wp/R4VgOSWS+kP0bIcpCchtzJ0EU6g0N3MFdqPuRBtfKVGbt?=
 =?us-ascii?q?M7+1dIy2TZuhd5PpyhKaBim1Effx52v0PoyxV4FIFAndI2o3MtyQp4MbiY309Z?=
 =?us-ascii?q?dzOEwZDwPaXaKnXz/BCqbK7WxlHe0daM9qcT8vg4rE/jvAWoFkok/HVqyN1V03?=
 =?us-ascii?q?qa5pXXAwseS5PxUkAr9xdko7HWeDUy54TR1Xd0K6m7rifC2841BOsi0huvZdNf?=
 =?us-ascii?q?P72LFQDsE8wWHdOhKPE3lFezaBIEP+dS9LAvMsOidvuG3rOrPel6kDKni2RH/J?=
 =?us-ascii?q?5y0kaW+yVgTe7I2o4Pw+uE0QufSzf8kFChv9j3mIBZfz0dAnCzyCnkBIFLYK1y?=
 =?us-ascii?q?cp0GCWOvI82x29V/iIThW39e9F6/GVwG3NWldgaVb1z4xQdQz1gYoWS7mSukyD?=
 =?us-ascii?q?x5iysprquD0yPU2eTtaR0HNnRNRGZ8l1fsIJG4gMwAU0iscgcmigGl5UH8x6VA?=
 =?us-ascii?q?oKR/Lm/TQVpHfiTsLmFiVLewuaSGY8JV9JwotiBXWvymYV+GUr79vwca0yT7Em?=
 =?us-ascii?q?pexTA3bTGrto/inxxnjmKQN3JzrHvfecFtyhbT/t3cRfhN3jUYQCl0kyXYBl+5?=
 =?us-ascii?q?P9Ox59Wbi4/DsvyiV2KmTpBTczPkzZmDtCu44m1mGwa/kOqwmt3kEAg61zH019?=
 =?us-ascii?q?9xWCXMrRb8ZJTr1qugPeJmeEloGEHz685gFo5ilYswgYka2WIGiZWN4XoHjWDz?=
 =?us-ascii?q?PM1b2K3ka3oBXzwLw9/T4AX+3E1jL3SJx5/2V3mHw8thYcW6bX0S2i4n889KD6?=
 =?us-ascii?q?KU5qRenSRpulq4sR7RYf9lkzce0/Qu6WQWg+EUuAU3yCWdDasfHU1ZPSzqihSJ?=
 =?us-ascii?q?4MqyrKRRZGazb7ew0FByksymDLGHugtcQmr2eo8+HS9s6cVyKFfM0Hzw6o7+Yt?=
 =?us-ascii?q?XRY8wctgaIkxjelehaM4w+luAFhSd8PWL9vHsly/M0jBB03JG6upSHJHtp/K6j?=
 =?us-ascii?q?HhFYMTj1bdsJ+j7xlaZegtqW34e3E5V9HTULWYHkTPOyHzIUqPTnLB2OEDwnp3?=
 =?us-ascii?q?efGLrfGxKf6Uh8o3LOFZCrK2+YJH0Dwdp+QxmdIVRVgBoIUzUigp45CgeqydT6?=
 =?us-ascii?q?f0hj4TAR4kP4pgFIyuJ1LBT/VmbfpAG1ajY7UpSfLRxW7h1c6EfRK8CR8uVzHy?=
 =?us-ascii?q?RA9J27sAONMnCbZxhPDWwRWEyLHVXjMae15dXa7+iUHOm+L+bNYbWTr+xRTeyI?=
 =?us-ascii?q?yImr0otn+TaMK8qOMmNjD/09xkpMQ3R5F97FlDUITiwdjzjNYNKDpBeg5i13qd?=
 =?us-ascii?q?iy8fTsWALy/IuPFqFdMdN19xCthqeDMeGQiT19KTZZ0JMM2HDJxKIe3F4UlyFh?=
 =?us-ascii?q?aT2tHa4cui7KSaLagrVXAAIDayNvKMtI6Lox3glTNs7aidP11b94guQ2C1dfUl?=
 =?us-ascii?q?zhld+mZdYXI2GmL17HAEeLNLKbJTzE2c33YKW8SaFOg+VQrRG/pTGbE0r7NDSZ?=
 =?us-ascii?q?izbpTwyvMf1LjCyDJhNepZqycgxzBmnjVt7mbhy7PcRzjT03x700m3zLOXQdMT?=
 =?us-ascii?q?h6b0NCsLmQ4TlEjfV4HmxL9mBlIvWcmyaF8+nYLY4bsedqAiRxje5V/G42xKdV?=
 =?us-ascii?q?7C5aQvx4gy/Srt9oo1G7neiD0DtnUBxSqjlVgIKHp1ltOaLc9pNYQ3bL4AoN7X?=
 =?us-ascii?q?mMCxQNv9ZkCsfgu6ZVytjOkqL8MDZD89LO8ssaCMjZM8aHMHsnMRr0Fz/YFgoF?=
 =?us-ascii?q?TTi3NW7Bg0xRiu2d9nqQrstylp+5upMIApxSTlV9QvETAUdNB8EZLdF8TGVg2Z?=
 =?us-ascii?q?uSkNII6GX2kxjVT8JK9sTYV/aWEN3uLjiDhLVJbhdOxqn3e9c9LIr+jm5lal8y?=
 =?us-ascii?q?vJnAEUPKUZgZoC18ZAU9ukll9mZ/Qmw6nUnib1X+szcoCfeok0tu2UNFauM3+W?=
 =?us-ascii?q?Kpug9vKw=3D=3D?=
X-IronPort-Anti-Spam-Filtered: true
X-IronPort-Anti-Spam-Result: =?us-ascii?q?A0ApAABjghlch0O0hNFaChoBAQEBAQIBA?=
 =?us-ascii?q?QEBBwIBAQEBgWWBW4EPSzcnCoNzlBWBYAglFJk5FRgNBgGHHSI4EgEDAQEBAQE?=
 =?us-ascii?q?BAgETAQEBCgsJCCkjDII2JAGCYgECAwECIAQZAQE3AQUJAQEKDgoCAiYCAgNEE?=
 =?us-ascii?q?AYBDAEFAgEBARaCPEsBggAFCqYccHwzgnYBAQWBMAGBEoRmAwWBC4oYgRwXgUA?=
 =?us-ascii?q?/gTgMgl+DBYFRF4McgleLPYReN5BUCYcPgQqJQQYYgV2IKodQLIkYhHeLOIFdg?=
 =?us-ascii?q?XczGggbFTuCbBIBgggMF4NKhRSFYB8BMQEBgQMBAYsUgS2BHwEB?=
X-IPAS-Result: =?us-ascii?q?A0ApAABjghlch0O0hNFaChoBAQEBAQIBAQEBBwIBAQEBgWW?=
 =?us-ascii?q?BW4EPSzcnCoNzlBWBYAglFJk5FRgNBgGHHSI4EgEDAQEBAQEBAgETAQEBCgsJC?=
 =?us-ascii?q?CkjDII2JAGCYgECAwECIAQZAQE3AQUJAQEKDgoCAiYCAgNEEAYBDAEFAgEBARa?=
 =?us-ascii?q?CPEsBggAFCqYccHwzgnYBAQWBMAGBEoRmAwWBC4oYgRwXgUA/gTgMgl+DBYFRF?=
 =?us-ascii?q?4McgleLPYReN5BUCYcPgQqJQQYYgV2IKodQLIkYhHeLOIFdgXczGggbFTuCbBI?=
 =?us-ascii?q?BgggMF4NKhRSFYB8BMQEBgQMBAYsUgS2BHwEB?=
X-IronPort-AV: E=Sophos;i="5.56,370,1539673200"; 
   d="scan'208";a="58041653"
X-Amp-Result: SKIPPED(no attachment in message)
X-Amp-File-Uploaded: False
Received: from vger.kernel.org ([209.132.180.67])
  by mtab.intel.com with ESMTP; 18 Dec 2018 15:32:40 -0800
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
        id S1728029AbeLRX3h (ORCPT <rfc822;like.xu@linux.intel.com>
        + 23 others); Tue, 18 Dec 2018 18:29:37 -0500
Received: from hqemgate16.nvidia.com ([216.228.121.65]:18683 "EHLO
        hqemgate16.nvidia.com" rhost-flags-OK-OK-OK-OK) by vger.kernel.org
        with ESMTP id S1727505AbeLRX3h (ORCPT
        <rfc822;linux-kernel@vger.kernel.org>);
        Tue, 18 Dec 2018 18:29:37 -0500
Received: from hqpgpgate101.nvidia.com (Not Verified[216.228.121.13]) by hqemgate16.nvidia.com (using TLS: TLSv1.2, DES-CBC3-SHA)
        id <B5c1982d60000>; Tue, 18 Dec 2018 15:29:26 -0800
Received: from hqmail.nvidia.com ([172.20.161.6])
  by hqpgpgate101.nvidia.com (PGP Universal service);
  Tue, 18 Dec 2018 15:29:35 -0800
X-PGP-Universal: processed;
        by hqpgpgate101.nvidia.com on Tue, 18 Dec 2018 15:29:35 -0800
Received: from [10.2.165.33] (172.20.13.39) by HQMAIL101.nvidia.com
 (172.20.187.10) with Microsoft SMTP Server (TLS) id 15.0.1395.4; Tue, 18 Dec
 2018 23:29:34 +0000
Subject: Re: [PATCH 1/2] mm: introduce put_user_page*(), placeholder versions
To: Jan Kara <jack@suse.cz>, Matthew Wilcox <willy@infradead.org>
CC: Jerome Glisse <jglisse@redhat.com>,
        Dave Chinner <david@fromorbit.com>,
        Dan Williams <dan.j.williams@intel.com>,
        John Hubbard <john.hubbard@gmail.com>,
        Andrew Morton <akpm@linux-foundation.org>,
        Linux MM <linux-mm@kvack.org>, <tom@talpey.com>,
        Al Viro <viro@zeniv.linux.org.uk>, <benve@cisco.com>,
        Christoph Hellwig <hch@infradead.org>,
        Christopher Lameter <cl@linux.com>,
        "Dalessandro, Dennis" <dennis.dalessandro@intel.com>,
        Doug Ledford <dledford@redhat.com>,
        Jason Gunthorpe <jgg@ziepe.ca>,
        Michal Hocko <mhocko@kernel.org>, <mike.marciniszyn@intel.com>,
        <rcampbell@nvidia.com>,
        Linux Kernel Mailing List <linux-kernel@vger.kernel.org>,
        linux-fsdevel <linux-fsdevel@vger.kernel.org>
References: <20181207191620.GD3293@redhat.com>
 <3c4d46c0-aced-f96f-1bf3-725d02f11b60@nvidia.com>
 <20181208022445.GA7024@redhat.com> <20181210102846.GC29289@quack2.suse.cz>
 <20181212150319.GA3432@redhat.com> <20181212214641.GB29416@dastard>
 <20181214154321.GF8896@quack2.suse.cz> <20181216215819.GC10644@dastard>
 <20181217181148.GA3341@redhat.com>
 <20181217183443.GO10600@bombadil.infradead.org>
 <20181218093017.GB18032@quack2.suse.cz>
From: John Hubbard <jhubbard@nvidia.com>
X-Nvconfidentiality: public
Message-ID: <9f43d124-2386-7bfd-d90b-4d0417f51ccd@nvidia.com>
Date: Tue, 18 Dec 2018 15:29:34 -0800
User-Agent: Mozilla/5.0 (X11; Linux x86_64; rv:60.0) Gecko/20100101
 Thunderbird/60.3.2
MIME-Version: 1.0
In-Reply-To: <20181218093017.GB18032@quack2.suse.cz>
X-Originating-IP: [172.20.13.39]
X-ClientProxiedBy: HQMAIL103.nvidia.com (172.20.187.11) To
 HQMAIL101.nvidia.com (172.20.187.10)
Content-Type: text/plain; charset="utf-8"
Content-Language: en-US
Content-Transfer-Encoding: 7bit
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed; d=nvidia.com; s=n1;
        t=1545175766; bh=2TfDXwNT47vgNfw8MvfnpjdCFl0Z+qp69nHDp3I2aOY=;
        h=X-PGP-Universal:Subject:To:CC:References:From:X-Nvconfidentiality:
         Message-ID:Date:User-Agent:MIME-Version:In-Reply-To:
         X-Originating-IP:X-ClientProxiedBy:Content-Type:Content-Language:
         Content-Transfer-Encoding;
        b=dSUi+k5T3gQFPL/MBmnEJ0P6Mx6jwC8E1nn5j2ExlEL1xQwHUcn5NeTQgdOgBFapa
         X2ikwz1UqGs2Ceyo7ShKm5Idda/j5J9tlNyfSBMhrPWaiz2I/cLIetjgiUJv0hmBZD
         rKvC/a+iYvB8pg1b6+OQkuGxYDmBkBdvmkPZTFAk+sg//ZCWpd+T3k1HN+MA1SxkMl
         GBIIwG2aGleT6Bm8ODrcokuXsNlGc+eT3vAZSfefoq/jviBMJ+T1gaxzOOeXE+S1yV
         tMKGWOJTkuBYEvxNuBbUJoGbQSl7TMrJJy1hybQm3OwVyFEv6RTfgfKtOzqn4byVrz
         gkSWBFAXDdfbg==
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: <linux-kernel.vger.kernel.org>
X-Mailing-List: linux-kernel@vger.kernel.org

On 12/18/18 1:30 AM, Jan Kara wrote:
> On Mon 17-12-18 10:34:43, Matthew Wilcox wrote:
>> On Mon, Dec 17, 2018 at 01:11:50PM -0500, Jerome Glisse wrote:
>>> On Mon, Dec 17, 2018 at 08:58:19AM +1100, Dave Chinner wrote:
>>>> Sure, that's a possibility, but that doesn't close off any race
>>>> conditions because there can be DMA into the page in progress while
>>>> the page is being bounced, right? AFAICT this ext3+DIF/DIX case is
>>>> different in that there is no 3rd-party access to the page while it
>>>> is under IO (ext3 arbitrates all access to it's metadata), and so
>>>> nothing can actually race for modification of the page between
>>>> submission and bouncing at the block layer.
>>>>
>>>> In this case, the moment the page is unlocked, anyone else can map
>>>> it and start (R)DMA on it, and that can happen before the bio is
>>>> bounced by the block layer. So AFAICT, block layer bouncing doesn't
>>>> solve the problem of racing writeback and DMA direct to the page we
>>>> are doing IO on. Yes, it reduces the race window substantially, but
>>>> it doesn't get rid of it.
>>>
>>> So the event flow is:
>>>     - userspace create object that match a range of virtual address
>>>       against a given kernel sub-system (let's say infiniband) and
>>>       let's assume that the range is an mmap() of a regular file
>>>     - device driver do GUP on the range (let's assume it is a write
>>>       GUP) so if the page is not already map with write permission
>>>       in the page table than a page fault is trigger and page_mkwrite
>>>       happens
>>>     - Once GUP return the page to the device driver and once the
>>>       device driver as updated the hardware states to allow access
>>>       to this page then from that point on hardware can write to the
>>>       page at _any_ time, it is fully disconnected from any fs event
>>>       like write back, it fully ignore things like page_mkclean
>>>
>>> This is how it is to day, we allowed people to push upstream such
>>> users of GUP. This is a fact we have to live with, we can not stop
>>> hardware access to the page, we can not force the hardware to follow
>>> page_mkclean and force a page_mkwrite once write back ends. This is
>>> the situation we are inheriting (and i am personnaly not happy with
>>> that).
>>>
>>> >From my point of view we are left with 2 choices:
>>>     [C1] break all drivers that do not abide by the page_mkclean and
>>>          page_mkwrite
>>>     [C2] mitigate as much as possible the issue
>>>
>>> For [C2] the idea is to keep track of GUP per page so we know if we
>>> can expect the page to be written to at any time. Here is the event
>>> flow:
>>>     - driver GUP the page and program the hardware, page is mark as
>>>       GUPed
>>>     ...
>>>     - write back kicks in on the dirty page, lock the page and every
>>>       thing as usual , sees it is GUPed and inform the block layer to
>>>       use a bounce page
>>
>> No.  The solution John, Dan & I have been looking at is to take the
>> dirty page off the LRU while it is pinned by GUP.  It will never be
>> found for writeback.
>>
>> That's not the end of the story though.  Other parts of the kernel (eg
>> msync) also need to be taught to stay away from pages which are pinned
>> by GUP.  But the idea is that no page gets written back to storage while
>> it's pinned by GUP.  Only when the last GUP ends is the page returned
>> to the list of dirty pages.
> 
> We've been through this in:
> 
> https://lore.kernel.org/lkml/20180709194740.rymbt2fzohbdmpye@quack2.suse.cz/
> 
> back in July. You cannot just skip pages for fsync(2). So as I wrote above -
> memory cleaning writeback can skip pinned pages. Data integrity writeback
> must be able to write pinned pages. And bouncing is one reasonable way how
> to do that.
> 
> This writeback decision is pretty much independent from the mechanism by
> which we are going to identify pinned pages. Whether that's going to be
> separate counter in struct page, using page->_mapcount, or separately
> allocated data structure as you know promote.
> 
> I currently like the most the _mapcount suggestion from Jerome but I'm not
> really attached to any solution as long as it performs reasonably and
> someone can make it working :) as I don't have time to implement it at
> least till January.
> 

OK, so let's take another look at Jerome's _mapcount idea all by itself (using
*only* the tracking pinned pages aspect), given that it is the lightest weight
solution for that.  

So as I understand it, this would use page->_mapcount to store both the real
mapcount, and the dma pinned count (simply added together), but only do so for
file-backed (non-anonymous) pages:


__get_user_pages()
{
	...
	get_page(page);

	if (!PageAnon)
		atomic_inc(page->_mapcount);
	...
}

put_user_page(struct page *page)
{
	...
	if (!PageAnon)
		atomic_dec(&page->_mapcount);

	put_page(page);
	...
}

...and then in the various consumers of the DMA pinned count, we use page_mapped(page)
to see if any mapcount remains, and if so, we treat it as DMA pinned. Is that what you 
had in mind?


-- 
thanks,
John Hubbard
NVIDIA
