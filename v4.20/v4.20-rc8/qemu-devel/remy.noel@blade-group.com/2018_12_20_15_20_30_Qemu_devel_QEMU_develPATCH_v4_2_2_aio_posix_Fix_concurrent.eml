Return-Path: <qemu-devel-bounces+like.xu=linux.intel.com@nongnu.org>
Delivered-To: unknown
Received: from linux.intel.com (10.54.29.200:995) by i7-8700 with POP3-SSL;
  24 Dec 2018 15:37:36 -0000
X-Original-To: like.xu@linux.intel.com
Delivered-To: like.xu@linux.intel.com
Received: from orsmga004.jf.intel.com (orsmga004.jf.intel.com [10.7.209.38])
	(using TLSv1.2 with cipher ECDHE-RSA-AES256-GCM-SHA384 (256/256 bits))
	(No client certificate requested)
	by linux.intel.com (Postfix) with ESMTPS id 2511258050C
	for <like.xu@linux.intel.com>; Thu, 20 Dec 2018 07:22:54 -0800 (PST)
Received: from orsmga103.jf.intel.com ([10.7.208.35])
  by orsmga004-1.jf.intel.com with ESMTP/TLS/DHE-RSA-AES256-GCM-SHA384; 20 Dec 2018 07:22:53 -0800
IronPort-PHdr: =?us-ascii?q?9a23=3ATSKJPB820oA3Tf9uRHKM819IXTAuvvDOBiVQ1KB2?=
 =?us-ascii?q?0e0cTK2v8tzYMVDF4r011RmVBdWds6oMotGVmpioYXYH75eFvSJKW713fDhBt/?=
 =?us-ascii?q?8rmRc9CtWOE0zxIa2iRSU7GMNfSA0tpCnjYgBaF8nkelLdvGC54yIMFRXjLwp1?=
 =?us-ascii?q?Ifn+FpLPg8it2O2+557ebx9UiDahfLh/MAi4oQLNu8cMnIBsMLwxyhzHontJf+?=
 =?us-ascii?q?RZ22ZlLk+Nkhj/+8m94odt/zxftPw9+cFAV776f7kjQrxDEDsmKWE169b1uhTF?=
 =?us-ascii?q?UACC+2ETUmQSkhpPHgjF8BT3VYr/vyfmquZw3jSRMNboRr4oRzut86ZrSAfpiC?=
 =?us-ascii?q?gZMT457HrXgdF0gK5CvR6tuwBzz4vSbYqINvRxY7ndcMsaS2RfUMhfVCtPDYGy?=
 =?us-ascii?q?b4QAAOQPIP5Yoov/qVYBsBezCxWgC/30yjJTmnP73rc33/g7HA3awAAtGc8Fvn?=
 =?us-ascii?q?TOrNXyMacfSfq1w7fNzTTDdf9W3zD955bMch06uv6MWah/ftfPxkU2GAPFlFKQ?=
 =?us-ascii?q?qZH9Pz+PyusNtG2b4ux9Xuysk24qsx99riSsy8s2l4XFm4EYxkra+Sh3wIs5P8?=
 =?us-ascii?q?C0RUxjbdK5EpZdtDuWO5VqTs4hWW1kpSc3xqcItJKleiUB1Y4pyATFa/OddoiF?=
 =?us-ascii?q?+hLjW/iVITd/nH9lfLO/hw2u8Ui70OH8Wc+00EtQoipCiNnMuWgB1x3V6seZVv?=
 =?us-ascii?q?tw5lmt1SqM2gzJ9+1IPEM5mbDFJ5MvwrM8jIcfvEbbEi/zgkr2jauWdks++uiv?=
 =?us-ascii?q?7uTqeqzmqYGZN49pkw3xL7ohmtKhDuQ8KwQBRG+b+fm61LL/40L5W7JGjvk3kq?=
 =?us-ascii?q?narp/WP8saprOhDg9R04Yj7Qu/Dji83NQZm3kHMExKeBadg4f1PFHOJev1DfG4?=
 =?us-ascii?q?g1Sqnzdrwe3GMqfmApXXIXjPiK3hcqpl605A1AozyshS55ZVCrECPv3/QEDwtM?=
 =?us-ascii?q?HDAx89Mgy0xfvnCdpn2oMfX2KPHrGWMKfIvVCU4eIvJrrEWYkOpTyoK+Q5/+W8?=
 =?us-ascii?q?yjg9mEQBZu+v2p0Ybm3+Ge5pZECQYH7pi9FGFn8Wvw04V6vzhVifFDJeeXu2DJ?=
 =?us-ascii?q?86/SwxXYevDIPfQdK0jbmcmSu2AJBSI3pLE02BCmvAcYKCVPERLiWILZh6jzYG?=
 =?us-ascii?q?WLO9HpInzgykrwTgyrBqfdbTrzQVsI+m2NVr6un7kxY0+jppScOH3DKjVWZxy3?=
 =?us-ascii?q?kFQi5w2qdypWR3zl6P3O13mftFDZpY4PYaAU8BKZfAwrkiWJjJUQXbc4LMEQ7+?=
 =?us-ascii?q?Tw=3D=3D?=
X-IronPort-Anti-Spam-Filtered: true
X-IronPort-Anti-Spam-Result: =?us-ascii?q?A0AkAADtshtchxHrdtBkHgEGBwaBUQkLA?=
 =?us-ascii?q?YEwKoEPgSmMdYscgg2XXYFzEwEBGAMRhy4iNAkNAQMBAQEBAQECARMBAQEKCwk?=
 =?us-ascii?q?IGw4jDII2BQIDGgEGglwDAwECJAsBDQEBBAopAQIDAQIGAQEfKQgDATABBQEcG?=
 =?us-ascii?q?QWCUksBggEBAwGcCzyKKYFsM4J2AQEFhX6BJAgSh2yBfYEogRyCFoERhheHW4l?=
 =?us-ascii?q?JBIF3lXsHAocRg0WHAySBX4gZN4cuLIonjxMCBAIEBQIFDyGBJYIOcFCCbAmCE?=
 =?us-ascii?q?gwXEoM4gQSJUHGBBAOLaYF3AQE?=
X-IPAS-Result: =?us-ascii?q?A0AkAADtshtchxHrdtBkHgEGBwaBUQkLAYEwKoEPgSmMdYs?=
 =?us-ascii?q?cgg2XXYFzEwEBGAMRhy4iNAkNAQMBAQEBAQECARMBAQEKCwkIGw4jDII2BQIDG?=
 =?us-ascii?q?gEGglwDAwECJAsBDQEBBAopAQIDAQIGAQEfKQgDATABBQEcGQWCUksBggEBAwG?=
 =?us-ascii?q?cCzyKKYFsM4J2AQEFhX6BJAgSh2yBfYEogRyCFoERhheHW4lJBIF3lXsHAocRg?=
 =?us-ascii?q?0WHAySBX4gZN4cuLIonjxMCBAIEBQIFDyGBJYIOcFCCbAmCEgwXEoM4gQSJUHG?=
 =?us-ascii?q?BBAOLaYF3AQE?=
X-IronPort-AV: E=Sophos;i="5.56,377,1539673200"; 
   d="scan'208";a="57188121"
X-Amp-Result: SKIPPED(no attachment in message)
X-Amp-File-Uploaded: False
Received: from lists.gnu.org ([208.118.235.17])
  by mtab.intel.com with ESMTP/TLS/AES256-SHA; 20 Dec 2018 07:22:52 -0800
Received: from localhost ([::1]:38177 helo=lists.gnu.org)
	by lists.gnu.org with esmtp (Exim 4.71)
	(envelope-from <qemu-devel-bounces+like.xu=linux.intel.com@nongnu.org>)
	id 1ga0A0-00081c-6Z
	for like.xu@linux.intel.com; Thu, 20 Dec 2018 10:22:52 -0500
Received: from eggs.gnu.org ([2001:4830:134:3::10]:53451)
	by lists.gnu.org with esmtp (Exim 4.71)
	(envelope-from <remy.noel@blade-group.com>) id 1ga07w-0006uC-US
	for qemu-devel@nongnu.org; Thu, 20 Dec 2018 10:20:45 -0500
Received: from Debian-exim by eggs.gnu.org with spam-scanned (Exim 4.71)
	(envelope-from <remy.noel@blade-group.com>) id 1ga07u-0006Co-HW
	for qemu-devel@nongnu.org; Thu, 20 Dec 2018 10:20:44 -0500
Received: from mail-ed1-x542.google.com ([2a00:1450:4864:20::542]:37654)
	by eggs.gnu.org with esmtps (TLS1.0:RSA_AES_128_CBC_SHA1:16)
	(Exim 4.71) (envelope-from <remy.noel@blade-group.com>)
	id 1ga07u-0006AX-2x
	for qemu-devel@nongnu.org; Thu, 20 Dec 2018 10:20:42 -0500
Received: by mail-ed1-x542.google.com with SMTP id h15so2074504edb.4
	for <qemu-devel@nongnu.org>; Thu, 20 Dec 2018 07:20:42 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
	d=blade-group.com; s=google;
	h=from:to:cc:subject:date:message-id:in-reply-to:references
	:mime-version:content-transfer-encoding;
	bh=zCq6nee5gwuX8otONPJPEMJ8Rq9leEgwkcinfqKCUXM=;
	b=MvKiOF97OYFaHjeRDzNgRnWyGWw+qQsJEcT/FdsijqjAEM3tr63u/4hh74cGupr0dd
	bYWir23wusavZeE7rW0WRKE65mfSoAhk18LM724HmNDzseH1N+FCJytAS4pHB8uPK+kJ
	SHfw+J3Nq3AoGd2WFZNtz/L5SjDaDimdc96HEeZyuDm80MoZeUqtBdCUbcKjVuVU3O2X
	9PJqYqyt3dytLo/nqi110IjtXp+MQP7xppmYnz9M9w9TWV5VbLXgMp7bVQE6IHioLqeX
	N3QGCejyJyigN6qGUDYV42bCcmctwcxxp0+F+Wa3a6NcpsHJysaY3lr5GTium29hpOtH
	sTJA==
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
	d=1e100.net; s=20161025;
	h=x-gm-message-state:from:to:cc:subject:date:message-id:in-reply-to
	:references:mime-version:content-transfer-encoding;
	bh=zCq6nee5gwuX8otONPJPEMJ8Rq9leEgwkcinfqKCUXM=;
	b=bUzvVfwJpUmP4+LzWIvz2VynVUalyJzEoNkq5QXLjcQ9YLTLv5aigFa2V7Ci8eUjj0
	srhHGUjefN81KYy+LgNfYUrezdIEzEUiAVX23H6ApMw4DjBux5rwXA5OhUVd3S13rgFr
	ohpjT/XXnl/qOlrOs2jjVBmDEW6TmVvrAOsqBItHmqKeCLz6zOLRjs9A7NB1BfiZLTkr
	46gff+1CMxox75dg2NG+IDrUeJ7Y/i+hI1ClzRCE3q6oKMrbs3I7PWKxFGLS5MrTgo4I
	8o27XGlRFUOWfpE/SARph2giLqtL85o+j4x7jDyg8rqHmQ5O0i5MZALkYdPRabIkqddv
	nFTA==
X-Gm-Message-State: AA+aEWYKeFC8WBX/P0w5uLVa6vuAx+TOlfdOGvxY/O+YqgZs0aiKQhNo
	g+vJZkQ3LROfxhnzPkfKBICBYlK5Hlhtvw==
X-Google-Smtp-Source: AFSGD/V7WoM+I3U/pUg2uzn37+unSLgtmUuBKvqw+PO0f5w6Eq93Ro+tPYzmlCXzLRHDqZ7k3DR+TA==
X-Received: by 2002:a17:906:cd2:: with SMTP id
	l18-v6mr19243859ejh.97.1545319239788; 
	Thu, 20 Dec 2018 07:20:39 -0800 (PST)
Received: from mocramis-ultrabook.localdomain ([178.208.16.32])
	by smtp.gmail.com with ESMTPSA id
	f35sm6606853edd.80.2018.12.20.07.20.38
	(version=TLS1_2 cipher=ECDHE-RSA-AES128-GCM-SHA256 bits=128/128);
	Thu, 20 Dec 2018 07:20:38 -0800 (PST)
From: remy.noel@blade-group.com
To: qemu-devel@nongnu.org
Date: Thu, 20 Dec 2018 16:20:30 +0100
Message-Id: <20181220152030.28035-3-remy.noel@blade-group.com>
X-Mailer: git-send-email 2.19.2
In-Reply-To: <20181220152030.28035-1-remy.noel@blade-group.com>
References: <20181220152030.28035-1-remy.noel@blade-group.com>
MIME-Version: 1.0
Content-Transfer-Encoding: 8bit
X-detected-operating-system: by eggs.gnu.org: Genre and OS details not
	recognized.
X-Received-From: 2a00:1450:4864:20::542
Subject: [Qemu-devel] [QEMU-devel][PATCH v4 2/2] aio-posix: Fix concurrent
 aio_poll/set_fd_handler.
X-BeenThere: qemu-devel@nongnu.org
X-Mailman-Version: 2.1.21
Precedence: list
List-Id: <qemu-devel.nongnu.org>
List-Unsubscribe: <https://lists.nongnu.org/mailman/options/qemu-devel>,
	<mailto:qemu-devel-request@nongnu.org?subject=unsubscribe>
List-Archive: <http://lists.nongnu.org/archive/html/qemu-devel/>
List-Post: <mailto:qemu-devel@nongnu.org>
List-Help: <mailto:qemu-devel-request@nongnu.org?subject=help>
List-Subscribe: <https://lists.nongnu.org/mailman/listinfo/qemu-devel>,
	<mailto:qemu-devel-request@nongnu.org?subject=subscribe>
Cc: Fam Zheng <famz@redhat.com>,
	"open list:Block I/O path" <qemu-block@nongnu.org>,
	Stefan Weil <sw@weilnetz.de>, Remy Noel <remy.noel@blade-group.com>,
	Stefan Hajnoczi <stefanha@redhat.com>, Paolo Bonzini <pbonzini@redhat.com>
Errors-To: qemu-devel-bounces+like.xu=linux.intel.com@nongnu.org
Sender: "Qemu-devel" <qemu-devel-bounces+like.xu=linux.intel.com@nongnu.org>

From: Remy Noel <remy.noel@blade-group.com>

It is possible for an io_poll callback to be concurrently executed along
with an aio_set_fd_handlers. This can cause all sorts of problems, like
a NULL callback or a bad opaque pointer.

This changes set_fd_handlers so that it no longer modify existing handlers
entries and instead, always insert those after having proper initialisation.

Tested-by: Stefan Hajnoczi <stefanha@redhat.com>
Signed-off-by: Remy Noel <remy.noel@blade-group.com>
---
 util/aio-posix.c | 89 ++++++++++++++++++++++++++++--------------------
 util/aio-win32.c | 67 ++++++++++++++++--------------------
 2 files changed, 82 insertions(+), 74 deletions(-)

diff --git a/util/aio-posix.c b/util/aio-posix.c
index a927319d2c..8640dfde9f 100644
--- a/util/aio-posix.c
+++ b/util/aio-posix.c
@@ -200,6 +200,31 @@ static AioHandler *find_aio_handler(AioContext *ctx, int fd)
     return NULL;
 }
 
+static bool aio_remove_fd_handler(AioContext *ctx, AioHandler *node)
+{
+    /* If the GSource is in the process of being destroyed then
+     * g_source_remove_poll() causes an assertion failure.  Skip
+     * removal in that case, because glib cleans up its state during
+     * destruction anyway.
+     */
+    if (!g_source_is_destroyed(&ctx->source)) {
+        g_source_remove_poll(&ctx->source, &node->pfd);
+    }
+
+    /* If a read is in progress, just mark the node as deleted */
+    if (qemu_lockcnt_count(&ctx->list_lock)) {
+        node->deleted = 1;
+        node->pfd.revents = 0;
+        return false;
+    }
+    /* Otherwise, delete it for real.  We can't just mark it as
+     * deleted because deleted nodes are only cleaned up while
+     * no one is walking the handlers list.
+     */
+    QLIST_REMOVE(node, node);
+    return true;
+}
+
 void aio_set_fd_handler(AioContext *ctx,
                         int fd,
                         bool is_external,
@@ -209,6 +234,7 @@ void aio_set_fd_handler(AioContext *ctx,
                         void *opaque)
 {
     AioHandler *node;
+    AioHandler *new_node = NULL;
     bool is_new = false;
     bool deleted = false;
     int poll_disable_change;
@@ -223,28 +249,6 @@ void aio_set_fd_handler(AioContext *ctx,
             qemu_lockcnt_unlock(&ctx->list_lock);
             return;
         }
-
-        /* If the GSource is in the process of being destroyed then
-         * g_source_remove_poll() causes an assertion failure.  Skip
-         * removal in that case, because glib cleans up its state during
-         * destruction anyway.
-         */
-        if (!g_source_is_destroyed(&ctx->source)) {
-            g_source_remove_poll(&ctx->source, &node->pfd);
-        }
-
-        /* If a read is in progress, just mark the node as deleted */
-        if (qemu_lockcnt_count(&ctx->list_lock)) {
-            node->deleted = 1;
-            node->pfd.revents = 0;
-        } else {
-            /* Otherwise, delete it for real.  We can't just mark it as
-             * deleted because deleted nodes are only cleaned up while
-             * no one is walking the handlers list.
-             */
-            QLIST_REMOVE(node, node);
-            deleted = true;
-        }
         /* Clean events in order to unregister fd from the ctx epoll. */
         node->pfd.events = 0;
 
@@ -252,24 +256,32 @@ void aio_set_fd_handler(AioContext *ctx,
     } else {
         poll_disable_change = !io_poll - (node && !node->io_poll);
         if (node == NULL) {
-            /* Alloc and insert if it's not already there */
-            node = g_new0(AioHandler, 1);
-            node->pfd.fd = fd;
-            QLIST_INSERT_HEAD_RCU(&ctx->aio_handlers, node, node);
-
-            g_source_add_poll(&ctx->source, &node->pfd);
             is_new = true;
         }
+        /* Alloc and insert if it's not already there */
+        new_node = g_new0(AioHandler, 1);
 
         /* Update handler with latest information */
-        node->io_read = io_read;
-        node->io_write = io_write;
-        node->io_poll = io_poll;
-        node->opaque = opaque;
-        node->is_external = is_external;
+        new_node->io_read = io_read;
+        new_node->io_write = io_write;
+        new_node->io_poll = io_poll;
+        new_node->opaque = opaque;
+        new_node->is_external = is_external;
+
+        if (is_new) {
+            new_node->pfd.fd = fd;
+        } else {
+            new_node->pfd = node->pfd;
+        }
+        g_source_add_poll(&ctx->source, &new_node->pfd);
+
+        new_node->pfd.events = (io_read ? G_IO_IN | G_IO_HUP | G_IO_ERR : 0);
+        new_node->pfd.events |= (io_write ? G_IO_OUT | G_IO_ERR : 0);
 
-        node->pfd.events = (io_read ? G_IO_IN | G_IO_HUP | G_IO_ERR : 0);
-        node->pfd.events |= (io_write ? G_IO_OUT | G_IO_ERR : 0);
+        QLIST_INSERT_HEAD_RCU(&ctx->aio_handlers, new_node, node);
+    }
+    if (node) {
+        deleted = aio_remove_fd_handler(ctx, node);
     }
 
     /* No need to order poll_disable_cnt writes against other updates;
@@ -281,7 +293,12 @@ void aio_set_fd_handler(AioContext *ctx,
     atomic_set(&ctx->poll_disable_cnt,
                atomic_read(&ctx->poll_disable_cnt) + poll_disable_change);
 
-    aio_epoll_update(ctx, node, is_new);
+    if (new_node) {
+        aio_epoll_update(ctx, new_node, is_new);
+    } else if (node) {
+        /* Unregister deleted fd_handler */
+        aio_epoll_update(ctx, node, false);
+    }
     qemu_lockcnt_unlock(&ctx->list_lock);
     aio_notify(ctx);
 
diff --git a/util/aio-win32.c b/util/aio-win32.c
index c58957cc4b..a23b9c364d 100644
--- a/util/aio-win32.c
+++ b/util/aio-win32.c
@@ -35,6 +35,22 @@ struct AioHandler {
     QLIST_ENTRY(AioHandler) node;
 };
 
+static void aio_remove_fd_handler(AioContext *ctx, AioHandler *node)
+{
+    /* If aio_poll is in progress, just mark the node as deleted */
+    if (qemu_lockcnt_count(&ctx->list_lock)) {
+        node->deleted = 1;
+        node->pfd.revents = 0;
+    } else {
+        /* Otherwise, delete it for real.  We can't just mark it as
+         * deleted because deleted nodes are only cleaned up after
+         * releasing the list_lock.
+         */
+        QLIST_REMOVE(node, node);
+        g_free(node);
+    }
+}
+
 void aio_set_fd_handler(AioContext *ctx,
                         int fd,
                         bool is_external,
@@ -44,41 +60,23 @@ void aio_set_fd_handler(AioContext *ctx,
                         void *opaque)
 {
     /* fd is a SOCKET in our case */
-    AioHandler *node;
+    AioHandler *old_node;
+    AioHandler *node = NULL;
 
     qemu_lockcnt_lock(&ctx->list_lock);
-    QLIST_FOREACH(node, &ctx->aio_handlers, node) {
-        if (node->pfd.fd == fd && !node->deleted) {
+    QLIST_FOREACH(old_node, &ctx->aio_handlers, node) {
+        if (old_node->pfd.fd == fd && !old_node->deleted) {
             break;
         }
     }
 
-    /* Are we deleting the fd handler? */
-    if (!io_read && !io_write) {
-        if (node) {
-            /* If aio_poll is in progress, just mark the node as deleted */
-            if (qemu_lockcnt_count(&ctx->list_lock)) {
-                node->deleted = 1;
-                node->pfd.revents = 0;
-            } else {
-                /* Otherwise, delete it for real.  We can't just mark it as
-                 * deleted because deleted nodes are only cleaned up after
-                 * releasing the list_lock.
-                 */
-                QLIST_REMOVE(node, node);
-                g_free(node);
-            }
-        }
-    } else {
+    if (io_read || io_write) {
         HANDLE event;
         long bitmask = 0;
 
-        if (node == NULL) {
-            /* Alloc and insert if it's not already there */
-            node = g_new0(AioHandler, 1);
-            node->pfd.fd = fd;
-            QLIST_INSERT_HEAD_RCU(&ctx->aio_handlers, node, node);
-        }
+        /* Alloc and insert if it's not already there */
+        node = g_new0(AioHandler, 1);
+        node->pfd.fd = fd;
 
         node->pfd.events = 0;
         if (node->io_read) {
@@ -104,9 +102,13 @@ void aio_set_fd_handler(AioContext *ctx,
             bitmask |= FD_WRITE | FD_CONNECT;
         }
 
+        QLIST_INSERT_HEAD_RCU(&ctx->aio_handlers, node, node);
         event = event_notifier_get_handle(&ctx->notifier);
         WSAEventSelect(node->pfd.fd, event, bitmask);
     }
+    if (old_node) {
+        aio_remove_fd_handler(ctx, old_node);
+    }
 
     qemu_lockcnt_unlock(&ctx->list_lock);
     aio_notify(ctx);
@@ -139,18 +141,7 @@ void aio_set_event_notifier(AioContext *ctx,
         if (node) {
             g_source_remove_poll(&ctx->source, &node->pfd);
 
-            /* aio_poll is in progress, just mark the node as deleted */
-            if (qemu_lockcnt_count(&ctx->list_lock)) {
-                node->deleted = 1;
-                node->pfd.revents = 0;
-            } else {
-                /* Otherwise, delete it for real.  We can't just mark it as
-                 * deleted because deleted nodes are only cleaned up after
-                 * releasing the list_lock.
-                 */
-                QLIST_REMOVE(node, node);
-                g_free(node);
-            }
+            aio_remove_fd_handler(ctx, node);
         }
     } else {
         if (node == NULL) {
-- 
2.19.2


