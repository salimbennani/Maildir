Return-Path: <linux-kernel-owner@vger.kernel.org>
Delivered-To: unknown
Received: from linux.intel.com (10.54.29.200:995) by i7-8700 with POP3-SSL;
  20 Dec 2018 19:14:16 -0000
X-Original-To: like.xu@linux.intel.com
Delivered-To: like.xu@linux.intel.com
Received: from fmsmga004.fm.intel.com (fmsmga004.fm.intel.com [10.253.24.48])
	(using TLSv1.2 with cipher ECDHE-RSA-AES256-GCM-SHA384 (256/256 bits))
	(No client certificate requested)
	by linux.intel.com (Postfix) with ESMTPS id 8AA55580522;
	Thu, 20 Dec 2018 01:27:45 -0800 (PST)
Received: from fmsmga105.fm.intel.com ([10.1.193.10])
  by fmsmga004-1.fm.intel.com with ESMTP/TLS/DHE-RSA-AES256-GCM-SHA384; 20 Dec 2018 01:27:45 -0800
X-SG-BADATTACHMENTNOREPLY: True
IronPort-PHdr: =?us-ascii?q?9a23=3AtRgtshxJC1fIPU/XCy+O+j09IxM/srCxBDY+r6Qd?=
 =?us-ascii?q?0e4TI/ad9pjvdHbS+e9qxAeQG9mDu7Qc06L/iOPJYSQ4+5GPsXQPItRndiQuro?=
 =?us-ascii?q?EopTEmG9OPEkbhLfTnPGQQFcVGU0J5rTngaRAGUMnxaEfPrXKs8DUcBgvwNRZv?=
 =?us-ascii?q?JuTyB4Xek9m72/q99pHPYAhEniaxba9vJxiqsAvdsdUbj5F/Iagr0BvJpXVIe+?=
 =?us-ascii?q?VSxWx2IF+Yggjx6MSt8pN96ipco/0u+dJOXqX8ZKQ4UKdXDC86PGAv5c3krgfM?=
 =?us-ascii?q?QA2S7XYBSGoWkx5IAw/Y7BHmW5r6ryX3uvZh1CScIMb7Vq4/Vyi84Kh3SR/okC?=
 =?us-ascii?q?YHOCA/8GHLkcx7kaZXrAu8qxBj34LYZYeYP+d8cKzAZ9MXXWpPUNhMWSJPAY2y?=
 =?us-ascii?q?aIkAD+QPMulXs4bzqEAOrQO8CAS3GOPiyTFFimPs0KAg0eksFxzN0gw6H9IJtX?=
 =?us-ascii?q?TZtNT7NL0MXuC60aLGyC/Db/RM1jf98YTGcAouoeuQXbJ1a8XRz1QkGgTKjlWK?=
 =?us-ascii?q?t4PlMDCV1uQWvmif7upgU/+vimEpqwF2vzivwNojhZPVhoIUzVDE8z91wIEvJd?=
 =?us-ascii?q?23UUN2Z8OvHpVXtyGfLYR2Q8UiTnlruCkk0L0Gv4C0fCwQxJQg3R7fZPqKeJWL?=
 =?us-ascii?q?7BL7TOudPyt0iXZ/dL6iiRu+71KsxvD/W8WoylpHryhInsHPu30DzRDe6cmKRu?=
 =?us-ascii?q?F+80qlwzqDyhzf5+NCLEspj6TUMYQhzaQ1lpcLsUTMACv2mELuga+IeUUr5PKo?=
 =?us-ascii?q?5/7kYrr4vJ+cMZF7igXkPqQpgMy/Dvw0MgkIX2eF5eSxzKPv8VH9TblQk/E7nL?=
 =?us-ascii?q?fVvIrHKckYuqK1GQ5Y34Q75xa6FTim0dAYnXcdLFJCfRKKl4zpO1DIIPDlAvaz?=
 =?us-ascii?q?mlesnylxx/DAILLhBozBLn/NkbfnY7l98VVRyBQ8zd9B/ZJYELIBL+zpWk/3qt?=
 =?us-ascii?q?PYCgU1Mwuuw+boENl9zJ8RWXqTAq+FN6PfqVuI5uMsI+aSfoMUtyv9JuMh5/7v?=
 =?us-ascii?q?i385hFAccbOo3ZsRdHC3APBmL1+Fbnrrh9cLCX0KsRYmTOz2lF2CViZeZ3aoUK?=
 =?us-ascii?q?I9+jE0EoWmAZ3DRoCwmrOB2ii7E4ZSZmBHDFCMDHjpe5+FW/cKdCKdPMthniYY?=
 =?us-ascii?q?WrimTo8rzQuuuxPiy7p7MurU/TUVuoj41Nh14O3Tlgs+9SZuAMSfyGyNS2B0nm?=
 =?us-ascii?q?UVRz45xqx/oEp9ykud3qh8mfBXCdtT5/ZRWAcgKZHc1/B6C8z1Wg/ZfdeGUlCm?=
 =?us-ascii?q?Ts+iATEwVN0xxdAObl15G9WjiBDDwiWrD6UUl7yNGJw77Kbc02LtKMZ6znbMzL?=
 =?us-ascii?q?MhgEU+QstTKW2mgbZy+BXJCI7XjUqVjaaqer4a3C7W6miDy22CvEVbUA51VaXI?=
 =?us-ascii?q?RnQfZkrQrdTk6ULOVb6uCbI7MgRfzc6OMLdFatrsjV9eXvfsJMzeY36tm2e3HR?=
 =?us-ascii?q?uH26mDbJT0dGkH3CXSEk4EkxsN8naALgU+Aiaho2TDDD1hD17vYkXs8fVgp3O/?=
 =?us-ascii?q?VEM70waKb0h53bqv5hEVneCcS+8U3r8cpCchqjB0HFGh39LWC9uMvRZhcL9bYd?=
 =?us-ascii?q?Mn5FdH1GTZtwNmM5ykLqBigEMecgtts0Pv0RV3FptPkcwwoHw2ywpyLLqS0Eld?=
 =?us-ascii?q?eDOAwZDwJrrXJ3Ho8xCrdaHX1U/R0daM9qgU9fQ3tk/svAeqFkol7XVqyN1V03?=
 =?us-ascii?q?qa5pXXAwseS5PxUkAr9xdko7HWeDUy54TR1Xd0K6m7rifC2841BOsi0huhf8pf?=
 =?us-ascii?q?PLmYGwPoEswaB9KhKOolm1WyahIEPeZS9LM7Ps+8dvuG3rKrM/hknD68kWtH54?=
 =?us-ascii?q?V92FqW9yVgUu7Iw4oFw/aA0wudVjfzkE2ustrqloBDfz0SGHSwyTLlBIJIeqJ9?=
 =?us-ascii?q?Z4ILBnqwLM2twdV+gYXgW3pZ9F6lGlMH19WleRuUb1zhwwJQ0V4brmCgmSu91z?=
 =?us-ascii?q?Z0iS0mrrKD3CzSxOTvbBoGOm9RSGhil1vsOpW0j9YBUUisbggpkgal5Engy6ha?=
 =?us-ascii?q?oqR/M3fcQUNScyfqKGFiV7O6tqCebM5X9JMorSJXXfy+YV+AUL79oBga0yT5E2?=
 =?us-ascii?q?tF3j87dDKqupT/nxNkjmKQN3JzrHvfecFtyhbT/t3cRfhN3jUYQCl0kyXYBl+5?=
 =?us-ascii?q?P9Ox59Wbi4/DsvyiV2KmTpBScTPkzYSauCu55G1qBwayn/Symt3hDAg73jX319?=
 =?us-ascii?q?hsVSXUshn8ZpPn2Li9MeJiZkNoHkPz69JmGoFilYs9nJIQ1mIbhpmP/XoHjH38?=
 =?us-ascii?q?MdNU2a/laHoNRDgLw8Pa4QT/2U1jKG6JyJz9VnmH3sRhYNy6aHsM2i0h98BKFL?=
 =?us-ascii?q?uU7LtckCtwo1q4rhjebeJznzgD0vsu9GAVg/sStwUz1CWdDasfHU1ZPSzqihSJ?=
 =?us-ascii?q?4MqyrKRRZGazb7ew0FByksymDLGHugtcQmr2eo8+HS9s6cVyKE7M0Hr26o3+ed?=
 =?us-ascii?q?jfd9QTtgCPkxfbjuhYM5YxlvsMhSp6NmPxp3wly+gnjRNw2ZG2ppSIK2Jo/Kih?=
 =?us-ascii?q?GB5XKiX1Z98P+jHqlatRhdyZ34erHpV8ADkLWIboQOmsEDITs/TnKgmPHCc9qn?=
 =?us-ascii?q?edBbrQAwuf5F16oHLIFpChL2uXK2UBzdV+WBmdI1RSgAIOUzU/gJE5DRqmxND7?=
 =?us-ascii?q?fEd6+zAR5UP4qh1WxeJzLBT/VmbfpAG1ajY7UpSfLRxW7h1c6EfRK8CR8uVzHy?=
 =?us-ascii?q?RA9J27sAONMnCbZxhPDWwRWk2EAE3jPqCz5dba9eiUHPG+L/zIYbWBsuFeU/aI?=
 =?us-ascii?q?xZSy0opp5TqMN8OPPmV8AP0/wEZMQXd5G8HBkTUVVyMXjz7Nb9KcpBqk+i14sM?=
 =?us-ascii?q?G/8PfoWALu/4ePCKFSMdJg+x+om6eDKvWQiT19KTZZ0JMM2HDJxKIe3F4UlyFh?=
 =?us-ascii?q?aT2tHa4cui7KSaLagrVXAAIDayNvKMtI6Lox0RNQOcHAkNP6yL55guQxC1dETl?=
 =?us-ascii?q?HhnsCpZcoXI2CyLl/HBUCLNKiYKj3P2c34faS8SbhIhuVOqxKwoSqbE1PkPjmb?=
 =?us-ascii?q?iznpVhWvPftQgy2BIBNeuJ+ychB2BGjnTdLmbAC7MdBtgT03x700mm3FNWoGPT?=
 =?us-ascii?q?dgdENNq6Wa7TlEjfVnB2xB8n1lIPGEmimD6enYL5cWsf1zDSV1l+JV+nI6y7RO?=
 =?us-ascii?q?4SFARfx1njbSr9F0r1GnlOmP1iRoUB5UpjlXg4KLuBYqBaKM8phGRGaB/x8X62?=
 =?us-ascii?q?iUIwoFqsEjCdD1va1UjN/Vm/HdMjBHpv3O8MRUJNLTIcLCEHM7LR/gHnaAAxEI?=
 =?us-ascii?q?Qj2rHWXegVFNnvaP8HGcspk9rN7rgpVYGewTb0A8Cv5PUhctJ9cFOpoiG2p8yb?=
 =?us-ascii?q?M=3D?=
X-IronPort-Anti-Spam-Filtered: true
X-IronPort-Anti-Spam-Result: =?us-ascii?q?A0ANAAA9YBtch0O0hNFbCBwBAQEEAQEHB?=
 =?us-ascii?q?AEBgVEHAQELAYJpgQIng32IGV+LHYIhl0mBcxUYCwgBhy0iNAkNAQMBAQEBAQE?=
 =?us-ascii?q?CARMBAQEIDQkIKSMMgjYkAYJiAwMBAiAECwENAQE3AQUJAQEkAgUhAgIDDEgZB?=
 =?us-ascii?q?YMdAYIBBAEKpmVwfAwngnYBAQWBMAGFdgMFgQuGc4MlgRwXgX+IbRKDLYJXiSk?=
 =?us-ascii?q?kgXeVIQ9LCYcRikgkgV+FH4pejkeLRIFGgg4zGggoCIMnE4IIDBeIXoVAPzIBA?=
 =?us-ascii?q?YEAAwEBIROKX4JNAQE?=
X-IPAS-Result: =?us-ascii?q?A0ANAAA9YBtch0O0hNFbCBwBAQEEAQEHBAEBgVEHAQELAYJ?=
 =?us-ascii?q?pgQIng32IGV+LHYIhl0mBcxUYCwgBhy0iNAkNAQMBAQEBAQECARMBAQEIDQkIK?=
 =?us-ascii?q?SMMgjYkAYJiAwMBAiAECwENAQE3AQUJAQEkAgUhAgIDDEgZBYMdAYIBBAEKpmV?=
 =?us-ascii?q?wfAwngnYBAQWBMAGFdgMFgQuGc4MlgRwXgX+IbRKDLYJXiSkkgXeVIQ9LCYcRi?=
 =?us-ascii?q?kgkgV+FH4pejkeLRIFGgg4zGggoCIMnE4IIDBeIXoVAPzIBAYEAAwEBIROKX4J?=
 =?us-ascii?q?NAQE?=
X-IronPort-AV: E=Sophos;i="5.56,376,1539673200"; 
   d="scan'208";a="142904630"
X-Amp-Result: SKIPPED(no attachment in message)
X-Amp-File-Uploaded: False
Received: from vger.kernel.org ([209.132.180.67])
  by mtab.intel.com with ESMTP; 20 Dec 2018 01:27:44 -0800
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
        id S1732365AbeLTJ1n (ORCPT <rfc822;like.xu@linux.intel.com>
        + 22 others); Thu, 20 Dec 2018 04:27:43 -0500
Received: from mail.kernel.org ([198.145.29.99]:38760 "EHLO mail.kernel.org"
        rhost-flags-OK-OK-OK-OK) by vger.kernel.org with ESMTP
        id S1732356AbeLTJ1j (ORCPT <rfc822;linux-kernel@vger.kernel.org>);
        Thu, 20 Dec 2018 04:27:39 -0500
Received: from localhost (5356596B.cm-6-7b.dynamic.ziggo.nl [83.86.89.107])
        (using TLSv1.2 with cipher ECDHE-RSA-AES256-GCM-SHA384 (256/256 bits))
        (No client certificate requested)
        by mail.kernel.org (Postfix) with ESMTPSA id 3E8AC20989;
        Thu, 20 Dec 2018 09:27:38 +0000 (UTC)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/simple; d=kernel.org;
        s=default; t=1545298058;
        bh=UiwCqWgSU+8bKuP7DfjiuKqALszd7vV7YyWaLcT4jmw=;
        h=From:To:Cc:Subject:Date:In-Reply-To:References:From;
        b=0jxy/mCDa9Iegf5I7hLAnoZn7PE4I21Sl8MZflBGvu2SbEC1eynLRwEbthuL5Xo67
         k9sULQHUK62Vn6EpIHcOCoFTe+6e/Ro0s7UBjnUeVM2tPqSwifcztPKvvAHbFHPZZ7
         fi8VYRKNOvxIAUOcBWtdnPd+de2Uz1L3q2zxxy2w=
From: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
To: linux-kernel@vger.kernel.org
Cc: Greg Kroah-Hartman <gregkh@linuxfoundation.org>,
        stable@vger.kernel.org, Will Deacon <will.deacon@arm.com>,
        Thomas Gleixner <tglx@linutronix.de>,
        "Peter Zijlstra (Intel)" <peterz@infradead.org>,
        Linus Torvalds <torvalds@linux-foundation.org>,
        andrea.parri@amarulasolutions.com, longman@redhat.com,
        Ingo Molnar <mingo@kernel.org>,
        Sebastian Andrzej Siewior <bigeasy@linutronix.de>,
        Sasha Levin <sashal@kernel.org>
Subject: [PATCH 4.14 29/72] locking/qspinlock, x86: Provide liveness guarantee
Date: Thu, 20 Dec 2018 10:18:28 +0100
Message-Id: <20181220085923.488666294@linuxfoundation.org>
X-Mailer: git-send-email 2.20.1
In-Reply-To: <20181220085922.332225035@linuxfoundation.org>
References: <20181220085922.332225035@linuxfoundation.org>
User-Agent: quilt/0.65
X-stable: review
X-Patchwork-Hint: ignore
MIME-Version: 1.0
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: 8bit
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: <linux-kernel.vger.kernel.org>
X-Mailing-List: linux-kernel@vger.kernel.org

4.14-stable review patch.  If anyone has any objections, please let me know.

------------------

commit 7aa54be2976550f17c11a1c3e3630002dea39303 upstream.

On x86 we cannot do fetch_or() with a single instruction and thus end up
using a cmpxchg loop, this reduces determinism. Replace the fetch_or()
with a composite operation: tas-pending + load.

Using two instructions of course opens a window we previously did not
have. Consider the scenario:

	CPU0		CPU1		CPU2

 1)	lock
	  trylock -> (0,0,1)

 2)			lock
			  trylock /* fail */

 3)	unlock -> (0,0,0)

 4)					lock
					  trylock -> (0,0,1)

 5)			  tas-pending -> (0,1,1)
			  load-val <- (0,1,0) from 3

 6)			  clear-pending-set-locked -> (0,0,1)

			  FAIL: _2_ owners

where 5) is our new composite operation. When we consider each part of
the qspinlock state as a separate variable (as we can when
_Q_PENDING_BITS == 8) then the above is entirely possible, because
tas-pending will only RmW the pending byte, so the later load is able
to observe prior tail and lock state (but not earlier than its own
trylock, which operates on the whole word, due to coherence).

To avoid this we need 2 things:

 - the load must come after the tas-pending (obviously, otherwise it
   can trivially observe prior state).

 - the tas-pending must be a full word RmW instruction, it cannot be an XCHGB for
   example, such that we cannot observe other state prior to setting
   pending.

On x86 we can realize this by using "LOCK BTS m32, r32" for
tas-pending followed by a regular load.

Note that observing later state is not a problem:

 - if we fail to observe a later unlock, we'll simply spin-wait for
   that store to become visible.

 - if we observe a later xchg_tail(), there is no difference from that
   xchg_tail() having taken place before the tas-pending.

Suggested-by: Will Deacon <will.deacon@arm.com>
Reported-by: Thomas Gleixner <tglx@linutronix.de>
Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
Reviewed-by: Will Deacon <will.deacon@arm.com>
Cc: Linus Torvalds <torvalds@linux-foundation.org>
Cc: Peter Zijlstra <peterz@infradead.org>
Cc: andrea.parri@amarulasolutions.com
Cc: longman@redhat.com
Fixes: 59fb586b4a07 ("locking/qspinlock: Remove unbounded cmpxchg() loop from locking slowpath")
Link: https://lkml.kernel.org/r/20181003130957.183726335@infradead.org
Signed-off-by: Ingo Molnar <mingo@kernel.org>
[bigeasy: GEN_BINARY_RMWcc macro redo]
Signed-off-by: Sebastian Andrzej Siewior <bigeasy@linutronix.de>
Signed-off-by: Sasha Levin <sashal@kernel.org>
---
 arch/x86/include/asm/qspinlock.h | 21 +++++++++++++++++++++
 kernel/locking/qspinlock.c       | 17 ++++++++++++++++-
 2 files changed, 37 insertions(+), 1 deletion(-)

diff --git a/arch/x86/include/asm/qspinlock.h b/arch/x86/include/asm/qspinlock.h
index 2cb6624acaec..f784b95e44df 100644
--- a/arch/x86/include/asm/qspinlock.h
+++ b/arch/x86/include/asm/qspinlock.h
@@ -5,9 +5,30 @@
 #include <asm/cpufeature.h>
 #include <asm-generic/qspinlock_types.h>
 #include <asm/paravirt.h>
+#include <asm/rmwcc.h>
 
 #define _Q_PENDING_LOOPS	(1 << 9)
 
+#define queued_fetch_set_pending_acquire queued_fetch_set_pending_acquire
+
+static __always_inline bool __queued_RMW_btsl(struct qspinlock *lock)
+{
+	GEN_BINARY_RMWcc(LOCK_PREFIX "btsl", lock->val.counter,
+			 "I", _Q_PENDING_OFFSET, "%0", c);
+}
+
+static __always_inline u32 queued_fetch_set_pending_acquire(struct qspinlock *lock)
+{
+	u32 val = 0;
+
+	if (__queued_RMW_btsl(lock))
+		val |= _Q_PENDING_VAL;
+
+	val |= atomic_read(&lock->val) & ~_Q_PENDING_MASK;
+
+	return val;
+}
+
 #define	queued_spin_unlock queued_spin_unlock
 /**
  * queued_spin_unlock - release a queued spinlock
diff --git a/kernel/locking/qspinlock.c b/kernel/locking/qspinlock.c
index 9ffc2f9af8b8..1011a1b292ac 100644
--- a/kernel/locking/qspinlock.c
+++ b/kernel/locking/qspinlock.c
@@ -225,6 +225,20 @@ static __always_inline u32 xchg_tail(struct qspinlock *lock, u32 tail)
 }
 #endif /* _Q_PENDING_BITS == 8 */
 
+/**
+ * queued_fetch_set_pending_acquire - fetch the whole lock value and set pending
+ * @lock : Pointer to queued spinlock structure
+ * Return: The previous lock value
+ *
+ * *,*,* -> *,1,*
+ */
+#ifndef queued_fetch_set_pending_acquire
+static __always_inline u32 queued_fetch_set_pending_acquire(struct qspinlock *lock)
+{
+	return atomic_fetch_or_acquire(_Q_PENDING_VAL, &lock->val);
+}
+#endif
+
 /**
  * set_locked - Set the lock bit and own the lock
  * @lock: Pointer to queued spinlock structure
@@ -323,7 +337,8 @@ void queued_spin_lock_slowpath(struct qspinlock *lock, u32 val)
 	 * 0,0,0 -> 0,0,1 ; trylock
 	 * 0,0,1 -> 0,1,1 ; pending
 	 */
-	val = atomic_fetch_or_acquire(_Q_PENDING_VAL, &lock->val);
+	val = queued_fetch_set_pending_acquire(lock);
+
 	/*
 	 * If we observe any contention; undo and queue.
 	 */
-- 
2.19.1



