Return-Path: <linux-kernel-owner@vger.kernel.org>
Delivered-To: unknown
Received: from linux.intel.com (10.54.29.200:995) by i7-8700 with POP3-SSL;
  24 Dec 2018 15:38:42 -0000
X-Original-To: like.xu@linux.intel.com
Delivered-To: like.xu@linux.intel.com
Received: from orsmga007.jf.intel.com (orsmga007.jf.intel.com [10.7.209.58])
	(using TLSv1.2 with cipher ECDHE-RSA-AES256-GCM-SHA384 (256/256 bits))
	(No client certificate requested)
	by linux.intel.com (Postfix) with ESMTPS id A6C245805F0;
	Thu, 20 Dec 2018 09:00:39 -0800 (PST)
Received: from orsmga103.jf.intel.com ([10.7.208.35])
  by orsmga007-1.jf.intel.com with ESMTP/TLS/DHE-RSA-AES256-GCM-SHA384; 20 Dec 2018 09:00:39 -0800
X-SG-BADATTACHMENTNOREPLY: True
IronPort-PHdr: =?us-ascii?q?9a23=3A9HdNsBDI+rcXdXCH5QPFUyQJP3N1i/DPJgcQr6Af?=
 =?us-ascii?q?oPdwSP74rsWwAkXT6L1XgUPTWs2DsrQY07qQ6/iocFdDyK7JiGoFfp1IWk1Nou?=
 =?us-ascii?q?QttCtkPvS4D1bmJuXhdS0wEZcKflZk+3amLRodQ56mNBXdrXKo8DEdBAj0OxZr?=
 =?us-ascii?q?KeTpAI7SiNm82/yv95HJbAhEmDmwbaluIBmqsA7cqtQYjYx+J6gr1xDHuGFIe+?=
 =?us-ascii?q?NYxWNpIVKcgRPx7dqu8ZBg7ipdpesv+9ZPXqvmcas4S6dYDCk9PGAu+MLrrxjD?=
 =?us-ascii?q?QhCR6XYaT24bjwBHAwnB7BH9Q5fxri73vfdz1SWGIcH7S60/VC+85Kl3VhDnlC?=
 =?us-ascii?q?YHNyY48G7JjMxwkLlbqw+lqxBm3oLYfJ2ZOP94c6jAf90VWHBBU95eWCxPAIyy?=
 =?us-ascii?q?b4UBAekcM+hGs4b9vEMOoBmlCAmwGO/i0CNEimPq0aA41ekqDAHI3BYnH9ILqH?=
 =?us-ascii?q?naos/6NKEPWu+1zanIyTHDb/JM1jf484jDbxcsruyWUrJ2a8bRy1MjFg3EjlWU?=
 =?us-ascii?q?rYzlPima1uEWs2WA7upgU/6vhHAjqw1rvjevwcIsh5DPi4kIyV7E7T10zJgpKd?=
 =?us-ascii?q?C8UkJ3fNCpHIVKuy2HNIZ6XtkuTmBqtSoi1LEKpZq2cDIJxZkn3RLTdeGLf5SS?=
 =?us-ascii?q?7h/iV+ucJypzimh/d7KlnRmy9FCtyu3iWcmw11ZHtjRFktbSuXAXzRDT6daISu?=
 =?us-ascii?q?F7/ki/3TaDzQfT6vtLIUwslKrbLYAuwqIom5YNrUjOGjX6lFj4gaOIbEko5+ul?=
 =?us-ascii?q?5/j9brjnpJKQL4p0hRv/MqQqlMy/G+M4Mg0WUmif+OS80qDj/ELgTLVJkPI2iK?=
 =?us-ascii?q?/Zv47eJcgCoa64DQlV3Zg56xukETem38oXnWMdIFJGZh2HlY7pNE/KIPziCve/?=
 =?us-ascii?q?mVusnC9xx//aJr3hHonNLn/bnbflfLZ96FBTxBA8zNBC/J9UDrABIPTuWk7+rt?=
 =?us-ascii?q?DYDxk5MxCqzObjEtlyyoQeWWeXCK+DLKzSqUOI5v4oI+SUZI8aojf9K+Q/6P7p?=
 =?us-ascii?q?l3M5mUIdcrOv3ZsYc324GvVmI0OEYXvjmNsBEGEKvhYgQ+zuklGNTTlTZ3OqVa?=
 =?us-ascii?q?Im+j47EJ6mDZvERo21mrOBxye7HppVZmxcEFCDC3Xoep6AW/cNbiKSP8BgniYF?=
 =?us-ascii?q?VbinV48uyxWuuBXmxLpgK+re4jcYuo771Nhp++3Tkgk/9T9uAMSbyW2NS2B0kX?=
 =?us-ascii?q?kORz85x61/pU19ylGe0al3mfBYFNpT5+9XXQc+L5LT0+t6C9XqUALbYtiJUEqm?=
 =?us-ascii?q?QsmhATwpU90+2cEObFhnF9WilB/D2TGqDKETl7CMAJw08afc33zqKsZ5ynbG0r?=
 =?us-ascii?q?QhjlY8TstOM22mmrBw9wzJC4HVlEWZkr6gdb4A0y7V6GeD0W2OsVlFXwFqT6XK?=
 =?us-ascii?q?Q2oTZkvMotT//UPNUbmuBK8jMgtAz86CN6RLZsfojVVAWPfsJtDeb3itlGe3AB?=
 =?us-ascii?q?aC3qmMY5bye2UBwCXdD1AJkxwS/XaDMgg+GiehomLEADxyD17vZFns8e1/qHO9?=
 =?us-ascii?q?QU851AWKb0xn17qo9R8Zn/2cS/UP3r0avCctsSl7HFG439jOEdqPuxJhfLlAYd?=
 =?us-ascii?q?M6+FpIz2bZuBJyP5O+L6FunEURcxlqsEz00RV3CYJAkdYxoXMuzQpyL7+Y0Vxb?=
 =?us-ascii?q?ezOZ25DwJqPYKm3o8B+zbK7W30nU0MyK9acX9PQ4t1LjsRmpF0o/6Xloz8NZ0n?=
 =?us-ascii?q?qc5prQCgoSXon8UkI29xh8urHbbTMx54LS1X1wL6a0tiXO1M4uBOsg0hygZctQ?=
 =?us-ascii?q?MLuYFA/uFM0XH9KuKO02lFezdBILIedS+LQyP8y4bfuG2benM/p6kzKikGtI/p?=
 =?us-ascii?q?p90kWK9ydnTu7I3pAFw+yX3wedVjf8ikuhvd7zmYxeeT4SGW+/wzD+BIFNfq1y?=
 =?us-ascii?q?YZoLCWC2Lsy3x9VynZ7sV2RD9F6+AVMLw8upeRuUb1zg0gxcz0UXoXq7mSSmyz?=
 =?us-ascii?q?x4iS0mrq2a3CbW2eTtaAIHOnJXRGlllVrsI5K7j8oZXEiraAgljgCl6lz5x6hY?=
 =?us-ascii?q?paR/KXfcQUFTcijyLmFiVLawt7WYb85O7pMorTtYUOCmbV+GTb79pgMQ0zn/EG?=
 =?us-ascii?q?tG2DA7azaqt435nhNgj2KRNnRzrHvfecxrwRff5drcReNe3zYcRSl4jyXXCUa4?=
 =?us-ascii?q?P9Wz4dqUkJLDuPikV229Tp1TbTXrzYSYuSu4/2JqAAezn/CumtL9Fwg63jT219?=
 =?us-ascii?q?1rVSXOsRb9bZPn16W8MeJ7YEZoAEXw5NZ9GoF7ioEwno0f2WAGhpWJ+noKiWLz?=
 =?us-ascii?q?MdRY2a3kdnYMSyAEw8XJ4Af7wk1sNWyGx5j2VniGxsthZt+6Yn4Z2y4n7sBKDr?=
 =?us-ascii?q?uU46JAnSdvvlW4qgfRa+BnnjgB0fsu9GIag+YRtQoxySWdB6oeHEhCMizqihSI?=
 =?us-ascii?q?9Mu+rKRMaWarcLiw0ld+nN+7ALGDpAFcRGj2epM4ESBs6cV/NUrG0Gfv5YH8ZN?=
 =?us-ascii?q?nQcdUTuwWPnBjaiOhVLI8xmuAOhSp6Im/9uXwly+gmjR1hx526vY6HK3lz86K9?=
 =?us-ascii?q?GBJXKjr1Z8YL8DH3kalehtqW35yoHph5GDUERp7oQuyzED4IqfTrLQWOECA/qn?=
 =?us-ascii?q?eGH7rQBxSf5Vxir3LOFZCrKn6WKGMYzdVkWBmSOkhfjBoIUzU9m54zDhqqy9D5?=
 =?us-ascii?q?cEdl+jAR4Ub1qxtLyuJ1Lhn/T33QpAGyZjcvT5ifKhVW4xpG50fUN8ye8+1yEz?=
 =?us-ascii?q?tZ/p2nsAyCNGibax5UAmEOX0yOH0rjMaW25dnc7+iYAfKzL/vQbrWPquxeVPaI?=
 =?us-ascii?q?yYis0ot8+DaMOduAPmN/D/0gwUdDWXF5G8LEmzQAUSAXliTNb9KFqxe44CF4ss?=
 =?us-ascii?q?e/8PHzUgL1+YSPE6dSMclo+x2um6iDKvWfhDxnJjdYzJ8MwX7IxaMb3F4TjSFu?=
 =?us-ascii?q?ajasHa4BtS7LUKLfhKtXAwQHZCN0MctC97g80RVVOc7HltP10aZ1juI0C1dAT1?=
 =?us-ascii?q?DuhtulatAKI26jMlPKH0KLNLWAJT3WzMD7e6K8SbtMjOpKsx28oyqUE0jmPj6b?=
 =?us-ascii?q?jTnmSwivMf1QjCGcJBFfuJuychBoCWjiStLpchy6MN9tgj0wzr05nXfKNW8aMT?=
 =?us-ascii?q?hhfEJBtLyQ7SVEgvphH2xN9GZqLe6Bm3XR0+6NCJsMtv5mSgtwlvlB7TxuybRR?=
 =?us-ascii?q?7TpfSdRvlSfSp8IoqFajxLqh0D1iBTZHrH50hYaPvExnIu2N+pBGH3SC4xMJ6W?=
 =?us-ascii?q?SZDg8ipt15B9mpsKdVnIuc3JnvIStPpoqHtfAXANLZfYfeaCIs?=
X-IronPort-Anti-Spam-Filtered: true
X-IronPort-Anti-Spam-Result: =?us-ascii?q?A0DhAgDMyRtch0O0hNFlHQEBBQEHBQGBZ?=
 =?us-ascii?q?YNsJ4N9lBQpgUIFHRSYbQNMLRMBhy4iOBIBAwEBAQEBAQIBEwEBAQgNCQgpIwy?=
 =?us-ascii?q?CNiQBgmEBAQEBAgEBAiAEGQEBNwEEAQkBAQoLAwoCAiYCAgMfEgEFARwGEwUDE?=
 =?us-ascii?q?4MHgXoIBZwRPIopcHwzgnYBAQWHIQgSeYs0eoEcgRGDEogJgleLRIUZhUOLHwc?=
 =?us-ascii?q?CgimPPBiBX4UfgzGHLiyZUjCBPIF3TSOBAQaCNYIbDBeDSop0HjMBgQQBAY1gA?=
 =?us-ascii?q?QE?=
X-IPAS-Result: =?us-ascii?q?A0DhAgDMyRtch0O0hNFlHQEBBQEHBQGBZYNsJ4N9lBQpgUI?=
 =?us-ascii?q?FHRSYbQNMLRMBhy4iOBIBAwEBAQEBAQIBEwEBAQgNCQgpIwyCNiQBgmEBAQEBA?=
 =?us-ascii?q?gEBAiAEGQEBNwEEAQkBAQoLAwoCAiYCAgMfEgEFARwGEwUDE4MHgXoIBZwRPIo?=
 =?us-ascii?q?pcHwzgnYBAQWHIQgSeYs0eoEcgRGDEogJgleLRIUZhUOLHwcCgimPPBiBX4Ufg?=
 =?us-ascii?q?zGHLiyZUjCBPIF3TSOBAQaCNYIbDBeDSop0HjMBgQQBAY1gAQE?=
X-IronPort-AV: E=Sophos;i="5.56,377,1539673200"; 
   d="scan'208";a="57203530"
X-Amp-Result: SKIPPED(no attachment in message)
X-Amp-File-Uploaded: False
Received: from vger.kernel.org ([209.132.180.67])
  by mtab.intel.com with ESMTP; 20 Dec 2018 09:00:37 -0800
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
        id S1732785AbeLTQ5e (ORCPT <rfc822;like.xu@linux.intel.com>
        + 22 others); Thu, 20 Dec 2018 11:57:34 -0500
Received: from mail-ot1-f68.google.com ([209.85.210.68]:42440 "EHLO
        mail-ot1-f68.google.com" rhost-flags-OK-OK-OK-OK) by vger.kernel.org
        with ESMTP id S1732385AbeLTQ5e (ORCPT
        <rfc822;linux-kernel@vger.kernel.org>);
        Thu, 20 Dec 2018 11:57:34 -0500
Received: by mail-ot1-f68.google.com with SMTP id v23so2525934otk.9
        for <linux-kernel@vger.kernel.org>; Thu, 20 Dec 2018 08:57:33 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=intel-com.20150623.gappssmtp.com; s=20150623;
        h=mime-version:references:in-reply-to:from:date:message-id:subject:to
         :cc;
        bh=DYRCP9UN9luBBsvCXHDTrjPXPPJREpwyogy2A14Q3wo=;
        b=BF+jxDWaMphjdbIE5m6BbKM9lClqGRJRTGaKWB+fCVLJe/SZocmVMCJD9ohNMiKav/
         fKjZMPDcyFwY4po1ZMBzgMblTjmN+TPwnUxY2SdRGpvulfuWnU1i+PCPMtABqCWwoJDM
         hywlsMQbC3hdF49+lKUceJFYCBs5t4l9jhhNJGv2IsCgfEQjTPskI0P3ilo/dLoijyEV
         d7vLnDReV2sow+LkSc1wsys6szTsQO/mDObZaf33ul6um9Y1CG/XbO4WSQ/KJat2nrfX
         6GLtiSiO75c0SNylDl/mgdoprBeTZ6XoSMOxeBzmQuQLqzlhwGobIar+ZH3uHOPSC5W3
         +qIA==
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20161025;
        h=x-gm-message-state:mime-version:references:in-reply-to:from:date
         :message-id:subject:to:cc;
        bh=DYRCP9UN9luBBsvCXHDTrjPXPPJREpwyogy2A14Q3wo=;
        b=MJf5/DWNSHm4dWfxCv+qwL8gH19vK9XdNQhR3Dy/ldmqwOZ3xXq8NXlUNVIs/lSF2J
         FgaaesjNSMMniz/c8/ywE74plHCX1e7QEovE8gVuP66Gf+S+kudD5G5s2L+WfadK4LyY
         nF1N4i7zlEqjYZ/9bYYueV2ABLH0wwbqr2MDwCZR0lkOkKRkTAm4vBLMmDkB9fTDW7EX
         zttCON2RsJze98U4fjaYz7wIwrV2SI1v9E+QnCd0Z52mX0irZpRPi6qMXr0d8VuLHg2N
         hXVhjKO86q0RXVpjgat+OD91a23004UzcvqGFTD1xx5ZHRJk9l7zjzrrMNRNakwtbxmq
         4zng==
X-Gm-Message-State: AA+aEWYHkvuOQfXDSE3ZPGarljfycKMsKJejnrw+6mdVvOKIU+mevS2j
        c5HR2CMY6qUs1HkFRGmQuAiUQ+CzrXTEfngObJQn3Q==
X-Google-Smtp-Source: AFSGD/WCi156/s0upT+G+UTmXWfUxt4iIsjfeMe4jWUZi3yb6/MuVgIfvwzU8+4eUgIMppvOx9oFlGJzJjhJevVoKeQ=
X-Received: by 2002:a9d:6a50:: with SMTP id h16mr17529610otn.95.1545325053044;
 Thu, 20 Dec 2018 08:57:33 -0800 (PST)
MIME-Version: 1.0
References: <20181212214641.GB29416@dastard> <20181214154321.GF8896@quack2.suse.cz>
 <20181216215819.GC10644@dastard> <20181217181148.GA3341@redhat.com>
 <20181217183443.GO10600@bombadil.infradead.org> <20181218093017.GB18032@quack2.suse.cz>
 <9f43d124-2386-7bfd-d90b-4d0417f51ccd@nvidia.com> <20181219020723.GD4347@redhat.com>
 <20181219110856.GA18345@quack2.suse.cz> <8e98d553-7675-8fa1-3a60-4211fc836ed9@nvidia.com>
 <20181220165030.GC3963@redhat.com>
In-Reply-To: <20181220165030.GC3963@redhat.com>
From: Dan Williams <dan.j.williams@intel.com>
Date: Thu, 20 Dec 2018 08:57:22 -0800
Message-ID: <CAPcyv4iDdOGh6wCug9sZsrPdby1Sv1jG5aRUA5PjL0dDW7eNNA@mail.gmail.com>
Subject: Re: [PATCH 1/2] mm: introduce put_user_page*(), placeholder versions
To: Jerome Glisse <jglisse@redhat.com>
Cc: John Hubbard <jhubbard@nvidia.com>, Jan Kara <jack@suse.cz>,
        Matthew Wilcox <willy@infradead.org>,
        Dave Chinner <david@fromorbit.com>,
        John Hubbard <john.hubbard@gmail.com>,
        Andrew Morton <akpm@linux-foundation.org>,
        Linux MM <linux-mm@kvack.org>, tom@talpey.com,
        Al Viro <viro@zeniv.linux.org.uk>, benve@cisco.com,
        Christoph Hellwig <hch@infradead.org>,
        Christopher Lameter <cl@linux.com>,
        "Dalessandro, Dennis" <dennis.dalessandro@intel.com>,
        Doug Ledford <dledford@redhat.com>,
        Jason Gunthorpe <jgg@ziepe.ca>,
        Michal Hocko <mhocko@kernel.org>,
        Mike Marciniszyn <mike.marciniszyn@intel.com>,
        rcampbell@nvidia.com,
        Linux Kernel Mailing List <linux-kernel@vger.kernel.org>,
        linux-fsdevel <linux-fsdevel@vger.kernel.org>
Content-Type: text/plain; charset="UTF-8"
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: <linux-kernel.vger.kernel.org>
X-Mailing-List: linux-kernel@vger.kernel.org

On Thu, Dec 20, 2018 at 8:50 AM Jerome Glisse <jglisse@redhat.com> wrote:
>
> On Thu, Dec 20, 2018 at 02:54:49AM -0800, John Hubbard wrote:
> > On 12/19/18 3:08 AM, Jan Kara wrote:
> > > On Tue 18-12-18 21:07:24, Jerome Glisse wrote:
> > >> On Tue, Dec 18, 2018 at 03:29:34PM -0800, John Hubbard wrote:
> > >>> OK, so let's take another look at Jerome's _mapcount idea all by itself (using
> > >>> *only* the tracking pinned pages aspect), given that it is the lightest weight
> > >>> solution for that.
> > >>>
> > >>> So as I understand it, this would use page->_mapcount to store both the real
> > >>> mapcount, and the dma pinned count (simply added together), but only do so for
> > >>> file-backed (non-anonymous) pages:
> > >>>
> > >>>
> > >>> __get_user_pages()
> > >>> {
> > >>>   ...
> > >>>   get_page(page);
> > >>>
> > >>>   if (!PageAnon)
> > >>>           atomic_inc(page->_mapcount);
> > >>>   ...
> > >>> }
> > >>>
> > >>> put_user_page(struct page *page)
> > >>> {
> > >>>   ...
> > >>>   if (!PageAnon)
> > >>>           atomic_dec(&page->_mapcount);
> > >>>
> > >>>   put_page(page);
> > >>>   ...
> > >>> }
> > >>>
> > >>> ...and then in the various consumers of the DMA pinned count, we use page_mapped(page)
> > >>> to see if any mapcount remains, and if so, we treat it as DMA pinned. Is that what you
> > >>> had in mind?
> > >>
> > >> Mostly, with the extra two observations:
> > >>     [1] We only need to know the pin count when a write back kicks in
> > >>     [2] We need to protect GUP code with wait_for_write_back() in case
> > >>         GUP is racing with a write back that might not the see the
> > >>         elevated mapcount in time.
> > >>
> > >> So for [2]
> > >>
> > >> __get_user_pages()
> > >> {
> > >>     get_page(page);
> > >>
> > >>     if (!PageAnon) {
> > >>         atomic_inc(page->_mapcount);
> > >> +       if (PageWriteback(page)) {
> > >> +           // Assume we are racing and curent write back will not see
> > >> +           // the elevated mapcount so wait for current write back and
> > >> +           // force page fault
> > >> +           wait_on_page_writeback(page);
> > >> +           // force slow path that will fault again
> > >> +       }
> > >>     }
> > >> }
> > >
> > > This is not needed AFAICT. __get_user_pages() gets page reference (and it
> > > should also increment page->_mapcount) under PTE lock. So at that point we
> > > are sure we have writeable PTE nobody can change. So page_mkclean() has to
> > > block on PTE lock to make PTE read-only and only after going through all
> > > PTEs like this, it can check page->_mapcount. So the PTE lock provides
> > > enough synchronization.
> > >
> > >> For [1] only needing pin count during write back turns page_mkclean into
> > >> the perfect spot to check for that so:
> > >>
> > >> int page_mkclean(struct page *page)
> > >> {
> > >>     int cleaned = 0;
> > >> +   int real_mapcount = 0;
> > >>     struct address_space *mapping;
> > >>     struct rmap_walk_control rwc = {
> > >>         .arg = (void *)&cleaned,
> > >>         .rmap_one = page_mkclean_one,
> > >>         .invalid_vma = invalid_mkclean_vma,
> > >> +       .mapcount = &real_mapcount,
> > >>     };
> > >>
> > >>     BUG_ON(!PageLocked(page));
> > >>
> > >>     if (!page_mapped(page))
> > >>         return 0;
> > >>
> > >>     mapping = page_mapping(page);
> > >>     if (!mapping)
> > >>         return 0;
> > >>
> > >>     // rmap_walk need to change to count mapping and return value
> > >>     // in .mapcount easy one
> > >>     rmap_walk(page, &rwc);
> > >>
> > >>     // Big fat comment to explain what is going on
> > >> +   if ((page_mapcount(page) - real_mapcount) > 0) {
> > >> +       SetPageDMAPined(page);
> > >> +   } else {
> > >> +       ClearPageDMAPined(page);
> > >> +   }
> > >
> > > This is the detail I'm not sure about: Why cannot rmap_walk_file() race
> > > with e.g. zap_pte_range() which decrements page->_mapcount and thus the
> > > check we do in page_mkclean() is wrong?
> >
> > Right. This looks like a dead end, after all. We can't lock a whole chunk
> > of "all these are mapped, hold still while we count you" pages. It's not
> > designed to allow that at all.
> >
> > IMHO, we are now back to something like dynamic_page, which provides an
> > independent dma pinned count.
>
> I will keep looking because allocating a structure for every GUP is
> insane to me they are user out there that are GUPin GigaBytes of data

This is not the common case.

> and it gonna waste tons of memory just to fix crappy hardware.

This is the common case.

Please refrain from the hyperbolic assessments.
