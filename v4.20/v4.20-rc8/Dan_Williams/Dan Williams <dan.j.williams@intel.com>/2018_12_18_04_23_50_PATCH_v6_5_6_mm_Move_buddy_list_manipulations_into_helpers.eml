Return-Path: <linux-kernel-owner@vger.kernel.org>
Delivered-To: unknown
Received: from linux.intel.com (10.54.29.200:995) by i7-8700 with POP3-SSL;
  18 Dec 2018 18:07:21 -0000
X-Original-To: like.xu@linux.intel.com
Delivered-To: like.xu@linux.intel.com
Received: from orsmga005.jf.intel.com (orsmga005.jf.intel.com [10.7.209.41])
	(using TLSv1.2 with cipher ECDHE-RSA-AES256-GCM-SHA384 (256/256 bits))
	(No client certificate requested)
	by linux.intel.com (Postfix) with ESMTPS id 2FE345805AD;
	Mon, 17 Dec 2018 20:36:48 -0800 (PST)
Received: from fmsmga102.fm.intel.com ([10.1.193.69])
  by orsmga005-1.jf.intel.com with ESMTP/TLS/DHE-RSA-AES256-GCM-SHA384; 17 Dec 2018 20:36:47 -0800
X-SG-BADATTACHMENTNOREPLY: True
IronPort-PHdr: =?us-ascii?q?9a23=3AUZTXtxM7nxhwoqEIrAkl6mtUPXoX/o7sNwtQ0KIM?=
 =?us-ascii?q?zox0KPj+r8bcNUDSrc9gkEXOFd2Cra4c26yO6+jJYi8p2d65qncMcZhBBVcuqP?=
 =?us-ascii?q?49uEgeOvODElDxN/XwbiY3T4xoXV5h+GynYwAOQJ6tL1LdrWev4jEMBx7xKRR6?=
 =?us-ascii?q?JvjvGo7Vks+7y/2+94fcbglUhzexe69+IAmrpgjNq8cahpdvJLwswRXTuHtIfO?=
 =?us-ascii?q?pWxWJsJV2Nmhv3+9m98p1+/SlOovwt78FPX7n0cKQ+VrxYES8pM3sp683xtBnM?=
 =?us-ascii?q?VhWA630BWWgLiBVIAgzF7BbnXpfttybxq+Rw1DWGMcDwULs5Qiqp4bt1RxD0iS?=
 =?us-ascii?q?cHLz85/3/Risxsl6JQvRatqwViz4LIfI2ZMfxzdb7fc9wHX2pMRttfWSxfDI2y?=
 =?us-ascii?q?bIUADeQBMuhXoIbhqFUOtgO+CAu3CePzyDJFnGP60bEg3ukjFwzNwQwuH8gJsH?=
 =?us-ascii?q?TRtNj7Or0dUeaox6bIzDXDa/dW2Tbn54jNaRAqvPaBUq9qfsrX00UvFRnJj1uR?=
 =?us-ascii?q?qYzhOzOV1/4Cs22A7+d7VOKvjXInpB91ojS12sgsjYzJi5sTx1vZ9it52J44Kc?=
 =?us-ascii?q?OkREN/e9KoDZVduz+AO4drQc4uX3tktSc4x7EepJK2eDYGxI4nyhPfcfCKc5aE?=
 =?us-ascii?q?7gjnWeufJzpzmWhrd6ilhxmo9Eit0u38Wdew0FZNtidFjNbMuW4X1xDJ6ciIVO?=
 =?us-ascii?q?F9/kG/1jaLzQzT7ftEIU8smaraLZ4u3KIwm4INvUjfGiL6glj6gaGIekk+5+Sl?=
 =?us-ascii?q?6Pjrbq/nq5KeL4N0jxvxMqUqmsyxG+Q4NQ0OUnCf+eS90r3j4EL4TKxJjvIoiK?=
 =?us-ascii?q?nZto7VJcACqq6+DQ5V1Jgs6wykAje439QXg2MHIEhGeB2ZlYjpPU/BIPTiAfe4?=
 =?us-ascii?q?mVSsny9nx+raMb35HpXNMn/Dna/lfbZ86E5T1hA/zN9C559PDrEBIfTzWlL+td?=
 =?us-ascii?q?DCDx85NRC0zPjjCNlnyoweXmePCLeDMKzOqV+I+v4vI+6UaY8Vojn9KuQl6OTp?=
 =?us-ascii?q?jXMjmV8dYLOm3Z0YaH2jGvRmIkOZYWfjg9sbEGcKuBY+Q/LuiFGYTTFTYHOyVb?=
 =?us-ascii?q?om5j4nEIKmEZvDRoe1jbyD2ye0AIdaZmNBClCKF3focJ6JW/MNaCKUP89gnSYI?=
 =?us-ascii?q?VbmnS489yx6usBX2xKZgLurR4icYr47s1MBp5+3PkhE/7SZ7D9+d02GKTGF4hH?=
 =?us-ascii?q?kISCU03K1kpUx9y1GD0bV3gvBCFNxT4e9JXRk+NZLG0+N6DNXyUBrbftiVUFam?=
 =?us-ascii?q?XsmmATYpQ9Iy2dAOZVxxG9Gjjh/Z2SqqDKQYl7iKBJwy76Ld0GL9J8d7y3bayq?=
 =?us-ascii?q?Yhi0MqTddINW2jnqR/7RTcB5bVk0WFkKanbbkT0zTT9Gid12aOvFtXUAhrUarb?=
 =?us-ascii?q?W3ATYU/Wrdf85kPGVLKuDbUnMg1cyc+NMKdKa9vpjUlYS/fnItjRf2Wxm2KoDx?=
 =?us-ascii?q?aS2ryMdJbqe3ka3CjFFUcLiR4T8micOQg+HCihpXneAyJoFV/0Z0Ps8O9+qG60?=
 =?us-ascii?q?T0MuzgGKaVFh2KSx+hIPmfOcTPYT1KoeuCg9szV0AEq939XOBtqcpgpheaJcYc?=
 =?us-ascii?q?894FZHz27ZqxZxPpu6L6Bmh14edQt3sljq1xV2DIVAjMcroGkrzAp0NaKXzldB?=
 =?us-ascii?q?eymE0pD3P73dMnPy8wy3a67KxlHe186b9b0L6PsmpFTsogGoGlA5/HV6ztZayX?=
 =?us-ascii?q?2c5pbNDAoMSp/xVkc39x5np7DVeCU95oXU1WFyPqmwqDPNx9UpBO49wBa6Y9hf?=
 =?us-ascii?q?KL+EFBP1E8ACB8muNfYmlESzYhMFPOBd7qg0P8y9evuC2a6rOvtgnT28gWRG5o?=
 =?us-ascii?q?B9zlyD9y5mRuHU2JYFxumS3hGbWDfkkFehrsf3lJheZTETAmWw0zLkC5NWZqFo?=
 =?us-ascii?q?e4YEF32uI8yuytpinZHtX2NX+0C5B1MB3s+kYh6Sb1373Q1N2kUbu32nmS2kzz?=
 =?us-ascii?q?NqlzEltLaQ3CvLw+76bhoIJnZLRHV+jVfrOYW1j9EaUFKobgQzjxul+ED6yrNf?=
 =?us-ascii?q?pKR+KWnTXEhJczL3L2FkTqu/qL6Cb9RT55MvtCVdSP68bkyCSr7hvxsa1DvuH2?=
 =?us-ascii?q?lEyzAhdDGquZL5kwZhiG2HL3Zzr3vZecduyhfZ/9HcQf9R3jwbRCh3kzXXB168?=
 =?us-ascii?q?P8W38tWQjZvMrue+V2e5XJ1JbSbr1Z+AtDe85WByARywhfezlsflEQg71y/2zN?=
 =?us-ascii?q?1qVSTOrBbhbYjnzaW6MeR7fkZ2AF/w8dZ1GoZ7koEonpEfxWAahomJ/XoAiWrz?=
 =?us-ascii?q?Ms9U2aPkYHoNWD4E2djV4Af+1U1nL3KJwZ/5V3qHzstgYdm6fn0Z2iYn489WD6?=
 =?us-ascii?q?eU6aROnTFprVqgsQLRff99ky8Yyfsv634VmfsFuQQzwSWGHrAdA1NYMjfymBSS?=
 =?us-ascii?q?4NCzt6FXZGepcbit20tyh9GhDLeeog5CXHb1YIstHSh17s9nKlLDzGXz6p34eN?=
 =?us-ascii?q?nXdd8TqhqUkxLag+lUMp0xkOcKhTF8OWL8pnAlz+87jRpz3ZC1poSHKmNt/L6n?=
 =?us-ascii?q?DR5cLDH6e8QT+jT1h6ZEgsmWx5yvHolmGjgTR5TnV/WoEDYPtfj9MwaODSYxqn?=
 =?us-ascii?q?OaGbrZAA+e511qr3PJE5C3KX6XIGMVwsllRBmYPEZfmhwbXC0mnp4lEQCn3M7h?=
 =?us-ascii?q?f1185j8P/V70sAdMxvhrNxniUWffuQGoZS0vSJWEKBpW7wdC51raMMCE7+JzGT?=
 =?us-ascii?q?1Y8YOlrACXNmObYAFIB3kTWkOYH1DjIqWu5d7Y/umYAeq+MuLOYaiUpuxYTfuI?=
 =?us-ascii?q?3pWv0o1p/zuXMsWPP39iD+A020ZZXHB5HdjZlCsLSyANiy3NaMubrg+m+iJrts?=
 =?us-ascii?q?C/7OjrWAX36IuPFbRSMNZv+xO3gauZNO6QniF5KTlG2ZMW2H/I06MS3FoTiyFo?=
 =?us-ascii?q?ajmsHq4MtS/LTKLMhKBXCwQXZD90NMtN96g8xBVCOdbHitPp0b51luQ6C0peWl?=
 =?us-ascii?q?z7hM6oZdYGI2W8NF7cAEaLNbKGJSDEws3tYKO8T6FQg/tQtxGqpTmbFErjNCyZ?=
 =?us-ascii?q?lzb1TxCvLf1MjCaDMRxCuYG9dwxhBnT5QN36ah20Ltl3gCYywb01gHPKKGEdPS?=
 =?us-ascii?q?J9c0NLsr2f8ydYju9jFGxG63pvNfOElDqB7+nENpYWtuNmAyRumOJc5XQ6yr1V?=
 =?us-ascii?q?4zlFRfx1giTSqNFurkqikumOzDpnTRVPpixKhIKNoUVtJ6HZ+oNcVnbD+RJepV?=
 =?us-ascii?q?mXXh0Jv95NDtzpprAVxN/Skq76NDZF9ZTT58RPKdLTLZerOXxpDhvtHD/dCRBN?=
 =?us-ascii?q?GTKiMyfdwVNclPWT/3iOhpk8tpXo3pEJT+kIBxQOCvoGBxE9T5Q5K5BtU2ZhyO?=
 =?us-ascii?q?bDgQ=3D=3D?=
X-IronPort-Anti-Spam-Filtered: true
X-IronPort-Anti-Spam-Result: =?us-ascii?q?A0AeAAAYeRhch0O0hNFkHAEBAQQBAQcEA?=
 =?us-ascii?q?QGBUQcBAQsBg1kSJ4N8iBlfixopgT85gzGUE4F2BA4YEwGEOwODGCI0CQ0BAwE?=
 =?us-ascii?q?BAQEBAQIBEwEBAQoLCQgpL4I2JAGCYgMDAQIgBFIGCQEBJAImAgIDRBAZBYMdg?=
 =?us-ascii?q?gEFpmiBLnwzijqBC4szeoEcgUSCMYg3glcCiUOGUjeFK4sjBwKCKIglhyWLU4V?=
 =?us-ascii?q?/mWWBRoIOTSNQgmyCJxeOPh4BATEBgQQBAY4IAQE?=
X-IPAS-Result: =?us-ascii?q?A0AeAAAYeRhch0O0hNFkHAEBAQQBAQcEAQGBUQcBAQsBg1k?=
 =?us-ascii?q?SJ4N8iBlfixopgT85gzGUE4F2BA4YEwGEOwODGCI0CQ0BAwEBAQEBAQIBEwEBA?=
 =?us-ascii?q?QoLCQgpL4I2JAGCYgMDAQIgBFIGCQEBJAImAgIDRBAZBYMdggEFpmiBLnwzijq?=
 =?us-ascii?q?BC4szeoEcgUSCMYg3glcCiUOGUjeFK4sjBwKCKIglhyWLU4V/mWWBRoIOTSNQg?=
 =?us-ascii?q?myCJxeOPh4BATEBgQQBAY4IAQE?=
X-IronPort-AV: E=Sophos;i="5.56,367,1539673200"; 
   d="scan'208";a="57291171"
X-Amp-Result: SKIPPED(no attachment in message)
X-Amp-File-Uploaded: False
Received: from vger.kernel.org ([209.132.180.67])
  by mtab.intel.com with ESMTP; 17 Dec 2018 20:36:30 -0800
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
        id S1726730AbeLREg2 (ORCPT <rfc822;like.xu@linux.intel.com>
        + 23 others); Mon, 17 Dec 2018 23:36:28 -0500
Received: from mga11.intel.com ([192.55.52.93]:41673 "EHLO mga11.intel.com"
        rhost-flags-OK-OK-OK-OK) by vger.kernel.org with ESMTP
        id S1726305AbeLREg1 (ORCPT <rfc822;linux-kernel@vger.kernel.org>);
        Mon, 17 Dec 2018 23:36:27 -0500
X-Amp-Result: SKIPPED(no attachment in message)
X-Amp-File-Uploaded: False
Received: from fmsmga002.fm.intel.com ([10.253.24.26])
  by fmsmga102.fm.intel.com with ESMTP/TLS/DHE-RSA-AES256-GCM-SHA384; 17 Dec 2018 20:36:26 -0800
X-ExtLoop1: 1
X-IronPort-AV: E=Sophos;i="5.56,367,1539673200"; 
   d="scan'208";a="126871776"
Received: from dwillia2-desk3.jf.intel.com (HELO dwillia2-desk3.amr.corp.intel.com) ([10.54.39.16])
  by fmsmga002.fm.intel.com with ESMTP; 17 Dec 2018 20:36:25 -0800
Subject: [PATCH v6 5/6] mm: Move buddy list manipulations into helpers
From: Dan Williams <dan.j.williams@intel.com>
To: akpm@linux-foundation.org
Cc: Michal Hocko <mhocko@suse.com>,
        Dave Hansen <dave.hansen@linux.intel.com>,
        peterz@infradead.org, linux-mm@kvack.org, x86@kernel.org,
        linux-kernel@vger.kernel.org, mgorman@suse.de
Date: Mon, 17 Dec 2018 20:23:50 -0800
Message-ID: <154510703002.1941238.13463167622846312555.stgit@dwillia2-desk3.amr.corp.intel.com>
In-Reply-To: <154510700291.1941238.817190985966612531.stgit@dwillia2-desk3.amr.corp.intel.com>
References: <154510700291.1941238.817190985966612531.stgit@dwillia2-desk3.amr.corp.intel.com>
User-Agent: StGit/0.18-2-gc94f
MIME-Version: 1.0
Content-Type: text/plain; charset="utf-8"
Content-Transfer-Encoding: 7bit
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: <linux-kernel.vger.kernel.org>
X-Mailing-List: linux-kernel@vger.kernel.org

In preparation for runtime randomization of the zone lists, take all
(well, most of) the list_*() functions in the buddy allocator and put
them in helper functions. Provide a common control point for injecting
additional behavior when freeing pages.

Cc: Michal Hocko <mhocko@suse.com>
Cc: Dave Hansen <dave.hansen@linux.intel.com>
Signed-off-by: Dan Williams <dan.j.williams@intel.com>
---
 include/linux/mm.h       |    3 --
 include/linux/mm_types.h |    3 ++
 include/linux/mmzone.h   |   51 ++++++++++++++++++++++++++++++++++
 mm/compaction.c          |    4 +--
 mm/page_alloc.c          |   70 ++++++++++++++++++----------------------------
 5 files changed, 84 insertions(+), 47 deletions(-)

diff --git a/include/linux/mm.h b/include/linux/mm.h
index 5411de93a363..e1d23f80d3ba 100644
--- a/include/linux/mm.h
+++ b/include/linux/mm.h
@@ -473,9 +473,6 @@ static inline void vma_set_anonymous(struct vm_area_struct *vma)
 struct mmu_gather;
 struct inode;
 
-#define page_private(page)		((page)->private)
-#define set_page_private(page, v)	((page)->private = (v))
-
 #if !defined(__HAVE_ARCH_PTE_DEVMAP) || !defined(CONFIG_TRANSPARENT_HUGEPAGE)
 static inline int pmd_devmap(pmd_t pmd)
 {
diff --git a/include/linux/mm_types.h b/include/linux/mm_types.h
index 5ed8f6292a53..72f37ea6dedb 100644
--- a/include/linux/mm_types.h
+++ b/include/linux/mm_types.h
@@ -209,6 +209,9 @@ struct page {
 #define PAGE_FRAG_CACHE_MAX_SIZE	__ALIGN_MASK(32768, ~PAGE_MASK)
 #define PAGE_FRAG_CACHE_MAX_ORDER	get_order(PAGE_FRAG_CACHE_MAX_SIZE)
 
+#define page_private(page)		((page)->private)
+#define set_page_private(page, v)	((page)->private = (v))
+
 struct page_frag_cache {
 	void * va;
 #if (PAGE_SIZE < PAGE_FRAG_CACHE_MAX_SIZE)
diff --git a/include/linux/mmzone.h b/include/linux/mmzone.h
index eafa66d66232..35cc33af87f2 100644
--- a/include/linux/mmzone.h
+++ b/include/linux/mmzone.h
@@ -18,6 +18,8 @@
 #include <linux/pageblock-flags.h>
 #include <linux/page-flags-layout.h>
 #include <linux/atomic.h>
+#include <linux/mm_types.h>
+#include <linux/page-flags.h>
 #include <asm/page.h>
 
 /* Free memory management - zoned buddy allocator.  */
@@ -98,6 +100,55 @@ struct free_area {
 	unsigned long		nr_free;
 };
 
+/* Used for pages not on another list */
+static inline void add_to_free_area(struct page *page, struct free_area *area,
+			     int migratetype)
+{
+	list_add(&page->lru, &area->free_list[migratetype]);
+	area->nr_free++;
+}
+
+/* Used for pages not on another list */
+static inline void add_to_free_area_tail(struct page *page, struct free_area *area,
+				  int migratetype)
+{
+	list_add_tail(&page->lru, &area->free_list[migratetype]);
+	area->nr_free++;
+}
+
+/* Used for pages which are on another list */
+static inline void move_to_free_area(struct page *page, struct free_area *area,
+			     int migratetype)
+{
+	list_move(&page->lru, &area->free_list[migratetype]);
+}
+
+static inline struct page *get_page_from_free_area(struct free_area *area,
+					    int migratetype)
+{
+	return list_first_entry_or_null(&area->free_list[migratetype],
+					struct page, lru);
+}
+
+static inline void rmv_page_order(struct page *page)
+{
+	__ClearPageBuddy(page);
+	set_page_private(page, 0);
+}
+
+static inline void del_page_from_free_area(struct page *page,
+		struct free_area *area, int migratetype)
+{
+	list_del(&page->lru);
+	rmv_page_order(page);
+	area->nr_free--;
+}
+
+static inline bool free_area_empty(struct free_area *area, int migratetype)
+{
+	return list_empty(&area->free_list[migratetype]);
+}
+
 struct pglist_data;
 
 /*
diff --git a/mm/compaction.c b/mm/compaction.c
index 7c607479de4a..44adbfa073b3 100644
--- a/mm/compaction.c
+++ b/mm/compaction.c
@@ -1359,13 +1359,13 @@ static enum compact_result __compact_finished(struct zone *zone,
 		bool can_steal;
 
 		/* Job done if page is free of the right migratetype */
-		if (!list_empty(&area->free_list[migratetype]))
+		if (!free_area_empty(area, migratetype))
 			return COMPACT_SUCCESS;
 
 #ifdef CONFIG_CMA
 		/* MIGRATE_MOVABLE can fallback on MIGRATE_CMA */
 		if (migratetype == MIGRATE_MOVABLE &&
-			!list_empty(&area->free_list[MIGRATE_CMA]))
+			!free_area_empty(area, MIGRATE_CMA))
 			return COMPACT_SUCCESS;
 #endif
 		/*
diff --git a/mm/page_alloc.c b/mm/page_alloc.c
index eaa9a012d6ae..de8b5eb78d13 100644
--- a/mm/page_alloc.c
+++ b/mm/page_alloc.c
@@ -705,12 +705,6 @@ static inline void set_page_order(struct page *page, unsigned int order)
 	__SetPageBuddy(page);
 }
 
-static inline void rmv_page_order(struct page *page)
-{
-	__ClearPageBuddy(page);
-	set_page_private(page, 0);
-}
-
 /*
  * This function checks whether a page is free && is the buddy
  * we can coalesce a page and its buddy if
@@ -811,13 +805,11 @@ static inline void __free_one_page(struct page *page,
 		 * Our buddy is free or it is CONFIG_DEBUG_PAGEALLOC guard page,
 		 * merge with it and move up one order.
 		 */
-		if (page_is_guard(buddy)) {
+		if (page_is_guard(buddy))
 			clear_page_guard(zone, buddy, order, migratetype);
-		} else {
-			list_del(&buddy->lru);
-			zone->free_area[order].nr_free--;
-			rmv_page_order(buddy);
-		}
+		else
+			del_page_from_free_area(buddy, &zone->free_area[order],
+					migratetype);
 		combined_pfn = buddy_pfn & pfn;
 		page = page + (combined_pfn - pfn);
 		pfn = combined_pfn;
@@ -867,15 +859,13 @@ static inline void __free_one_page(struct page *page,
 		higher_buddy = higher_page + (buddy_pfn - combined_pfn);
 		if (pfn_valid_within(buddy_pfn) &&
 		    page_is_buddy(higher_page, higher_buddy, order + 1)) {
-			list_add_tail(&page->lru,
-				&zone->free_area[order].free_list[migratetype]);
-			goto out;
+			add_to_free_area_tail(page, &zone->free_area[order],
+					      migratetype);
+			return;
 		}
 	}
 
-	list_add(&page->lru, &zone->free_area[order].free_list[migratetype]);
-out:
-	zone->free_area[order].nr_free++;
+	add_to_free_area(page, &zone->free_area[order], migratetype);
 }
 
 /*
@@ -1820,7 +1810,7 @@ static inline void expand(struct zone *zone, struct page *page,
 		if (set_page_guard(zone, &page[size], high, migratetype))
 			continue;
 
-		list_add(&page[size].lru, &area->free_list[migratetype]);
+		add_to_free_area(&page[size], area, migratetype);
 		area->nr_free++;
 		set_page_order(&page[size], high);
 	}
@@ -1962,13 +1952,10 @@ struct page *__rmqueue_smallest(struct zone *zone, unsigned int order,
 	/* Find a page of the appropriate size in the preferred list */
 	for (current_order = order; current_order < MAX_ORDER; ++current_order) {
 		area = &(zone->free_area[current_order]);
-		page = list_first_entry_or_null(&area->free_list[migratetype],
-							struct page, lru);
+		page = get_page_from_free_area(area, migratetype);
 		if (!page)
 			continue;
-		list_del(&page->lru);
-		rmv_page_order(page);
-		area->nr_free--;
+		del_page_from_free_area(page, area, migratetype);
 		expand(zone, page, order, current_order, area, migratetype);
 		set_pcppage_migratetype(page, migratetype);
 		return page;
@@ -2054,8 +2041,7 @@ static int move_freepages(struct zone *zone,
 		}
 
 		order = page_order(page);
-		list_move(&page->lru,
-			  &zone->free_area[order].free_list[migratetype]);
+		move_to_free_area(page, &zone->free_area[order], migratetype);
 		page += 1 << order;
 		pages_moved += 1 << order;
 	}
@@ -2207,7 +2193,7 @@ static void steal_suitable_fallback(struct zone *zone, struct page *page,
 
 single_page:
 	area = &zone->free_area[current_order];
-	list_move(&page->lru, &area->free_list[start_type]);
+	move_to_free_area(page, area, start_type);
 }
 
 /*
@@ -2231,7 +2217,7 @@ int find_suitable_fallback(struct free_area *area, unsigned int order,
 		if (fallback_mt == MIGRATE_TYPES)
 			break;
 
-		if (list_empty(&area->free_list[fallback_mt]))
+		if (free_area_empty(area, fallback_mt))
 			continue;
 
 		if (can_steal_fallback(order, migratetype))
@@ -2318,9 +2304,7 @@ static bool unreserve_highatomic_pageblock(const struct alloc_context *ac,
 		for (order = 0; order < MAX_ORDER; order++) {
 			struct free_area *area = &(zone->free_area[order]);
 
-			page = list_first_entry_or_null(
-					&area->free_list[MIGRATE_HIGHATOMIC],
-					struct page, lru);
+			page = get_page_from_free_area(area, MIGRATE_HIGHATOMIC);
 			if (!page)
 				continue;
 
@@ -2433,8 +2417,7 @@ __rmqueue_fallback(struct zone *zone, int order, int start_migratetype)
 	VM_BUG_ON(current_order == MAX_ORDER);
 
 do_steal:
-	page = list_first_entry(&area->free_list[fallback_mt],
-							struct page, lru);
+	page = get_page_from_free_area(area, fallback_mt);
 
 	steal_suitable_fallback(zone, page, start_migratetype, can_steal);
 
@@ -2861,6 +2844,7 @@ EXPORT_SYMBOL_GPL(split_page);
 
 int __isolate_free_page(struct page *page, unsigned int order)
 {
+	struct free_area *area = &page_zone(page)->free_area[order];
 	unsigned long watermark;
 	struct zone *zone;
 	int mt;
@@ -2885,9 +2869,8 @@ int __isolate_free_page(struct page *page, unsigned int order)
 	}
 
 	/* Remove page from free list */
-	list_del(&page->lru);
-	zone->free_area[order].nr_free--;
-	rmv_page_order(page);
+
+	del_page_from_free_area(page, area, mt);
 
 	/*
 	 * Set the pageblock if the isolated page is at least half of a
@@ -3181,13 +3164,13 @@ bool __zone_watermark_ok(struct zone *z, unsigned int order, unsigned long mark,
 			continue;
 
 		for (mt = 0; mt < MIGRATE_PCPTYPES; mt++) {
-			if (!list_empty(&area->free_list[mt]))
+			if (!free_area_empty(area, mt))
 				return true;
 		}
 
 #ifdef CONFIG_CMA
 		if ((alloc_flags & ALLOC_CMA) &&
-		    !list_empty(&area->free_list[MIGRATE_CMA])) {
+		    !free_area_empty(area, MIGRATE_CMA)) {
 			return true;
 		}
 #endif
@@ -5020,7 +5003,7 @@ void show_free_areas(unsigned int filter, nodemask_t *nodemask)
 
 			types[order] = 0;
 			for (type = 0; type < MIGRATE_TYPES; type++) {
-				if (!list_empty(&area->free_list[type]))
+				if (!free_area_empty(area, type))
 					types[order] |= 1 << type;
 			}
 		}
@@ -8145,6 +8128,9 @@ __offline_isolated_pages(unsigned long start_pfn, unsigned long end_pfn)
 	spin_lock_irqsave(&zone->lock, flags);
 	pfn = start_pfn;
 	while (pfn < end_pfn) {
+		struct free_area *area;
+		int mt;
+
 		if (!pfn_valid(pfn)) {
 			pfn++;
 			continue;
@@ -8163,13 +8149,13 @@ __offline_isolated_pages(unsigned long start_pfn, unsigned long end_pfn)
 		BUG_ON(page_count(page));
 		BUG_ON(!PageBuddy(page));
 		order = page_order(page);
+		area = &zone->free_area[order];
 #ifdef CONFIG_DEBUG_VM
 		pr_info("remove from free list %lx %d %lx\n",
 			pfn, 1 << order, end_pfn);
 #endif
-		list_del(&page->lru);
-		rmv_page_order(page);
-		zone->free_area[order].nr_free--;
+		mt = get_pageblock_migratetype(page);
+		del_page_from_free_area(page, area, mt);
 		for (i = 0; i < (1 << order); i++)
 			SetPageReserved((page+i));
 		pfn += (1 << order);

