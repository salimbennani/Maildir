Return-Path: <qemu-devel-bounces+like.xu=linux.intel.com@nongnu.org>
Delivered-To: unknown
Received: from linux.intel.com (10.54.29.200:995) by i7-8700 with POP3-SSL;
  19 Dec 2018 21:31:02 -0000
X-Original-To: like.xu@linux.intel.com
Delivered-To: like.xu@linux.intel.com
Received: from fmsmga001.fm.intel.com (fmsmga001.fm.intel.com [10.253.24.23])
	(using TLSv1.2 with cipher ECDHE-RSA-AES256-GCM-SHA384 (256/256 bits))
	(No client certificate requested)
	by linux.intel.com (Postfix) with ESMTPS id DE3BB5805F0
	for <like.xu@linux.intel.com>; Tue, 18 Dec 2018 22:46:43 -0800 (PST)
Received: from orsmga103.jf.intel.com ([10.7.208.35])
  by fmsmga001-1.fm.intel.com with ESMTP/TLS/DHE-RSA-AES256-GCM-SHA384; 18 Dec 2018 22:46:43 -0800
IronPort-PHdr: =?us-ascii?q?9a23=3AAwpa2RzKHf2L5tPXCy+O+j09IxM/srCxBDY+r6Qd?=
 =?us-ascii?q?2uweIJqq85mqBkHD//Il1AaPAd2Lraocw8Pt8InYEVQa5piAtH1QOLdtbDQizf?=
 =?us-ascii?q?ssogo7HcSeAlf6JvO5JwYzHcBFSUM3tyrjaRsdF8nxfUDdrWOv5jAOBBr/KRB1?=
 =?us-ascii?q?JuPoEYLOksi7ze+/94HQbglSmDaxfa55IQmrownWqsQYm5ZpJLwryhvOrHtIeu?=
 =?us-ascii?q?BWyn1tKFmOgRvy5dq+8YB6/ShItP0v68BPUaPhf6QlVrNYFygpM3o05MLwqxbO?=
 =?us-ascii?q?SxaE62YGXWUXlhpIBBXF7A3/U5zsvCb2qvZx1S+HNsDtU7s6RSqt4LtqSB/wiS?=
 =?us-ascii?q?cIKTg58H3MisdtiK5XuQ+tqwBjz4LRZoyeKfhwcb7Hfd4CW2RBUMZfWS9PDIyy?=
 =?us-ascii?q?YIQADfYOM+lFoYnlpVYArxSzCRSiCe/z1DBInWT73bEj0+k7DQ3KwAItEtIIvX?=
 =?us-ascii?q?/JrNv1LqASUeWtwaTW1zLMculW2Tbh54fQdB4uv+mDU7N3ccXL1UkgCRnFhUiX?=
 =?us-ascii?q?pIP5OzOV2f8As2uB4OpnSO2jkWknqxt+ojW2wMonl4rHhpoNx1za6Sl0w5w5Kc?=
 =?us-ascii?q?ClREN4e9KoDpVduiGAO4drQM4uW2VltDogxrAFvZO3ZjUGxZAmyhLFdvCLbpSE?=
 =?us-ascii?q?7xT+X+iLOzh4nmhqeLenihay70egzur8W9Gw0FZLtSpFjsLMumoC1xzV98iLUP?=
 =?us-ascii?q?x9/l2u2TqX1gDT7P9LIVwsmKbFN5IswaQ8mocOvUnABCP6hkv7ga+Mekk5+OWk?=
 =?us-ascii?q?8+Hnba/npp+YOY90kAb+MqE2l8ymH+s4NxUOU3GG9uuiyr3s40n5TKxRgf0xj6?=
 =?us-ascii?q?nZtozVKtoApqK+Bw9V04Uj5AilAzapzdQVhX0HLFNDeBKagInlIVDOIPbkDfih?=
 =?us-ascii?q?h1Sgiitkx/fDPrD6BJXNKX7DkLjnfbZg8UJczxAzzd9H65JOFr4BOO7zWlP2tN?=
 =?us-ascii?q?HACh85Mg+0zPj9BNRyy4MTQmaPAq6fMKPPvl6E/OMvI++QZIALvDbxMeQq5/nr?=
 =?us-ascii?q?jSxxpFkGYKP83YcLcGvqWbNiIl6FejzqhdEOF3pMuRAxC+njiVmHWDgUYG6uXq?=
 =?us-ascii?q?U6/XYiBYe7SIvOWI2p04GHxzqxS5hfZ2RaDQKVHHL1MomJRfoILTifO9JsiSAs?=
 =?us-ascii?q?U7+nRIk8kxa0u1jh1rBlI+HIrzAero/pz9Nv5ufexi01oBB9EcWRm06MRXpzmC?=
 =?us-ascii?q?tcSzYo3axXrk130VCFl6RihORSGNVJofJFFA4nY83y1et/XvtzVhjAdeCtRWGJ?=
 =?us-ascii?q?Rdy6DCt5Gtk1zPcNakFxXdK4gUaQjGKRH7YJmunTV9QP+aXG0i20fp4lxg=3D?=
 =?us-ascii?q?=3D?=
X-IronPort-Anti-Spam-Filtered: true
X-IronPort-Anti-Spam-Result: =?us-ascii?q?A0AJAAAj6BlchxHrdtBkGwEBAQEDAQEBB?=
 =?us-ascii?q?wMBAQGBUQYBAQELAYEwKoI4jBZfix2BYC18lmAUgVsZGBSEQIJmIjQJDQEDAQE?=
 =?us-ascii?q?BAQEBAgETAQEBCgsJCBsOL4I2BQIDGgEGglwBAgMBAiQfCikDAwECBgEBChgcC?=
 =?us-ascii?q?ggDATkaBg0GAgEBAYJSS4ICAQMBpzUzhUCDZIENjD8RBoF/gREngjY1hGoXhV8?=
 =?us-ascii?q?CiUgulzkJkVsGGJFWmXyBRoIOTTAIgyeCACcXEo4McYEEA4tpgXcBAQ?=
X-IPAS-Result: =?us-ascii?q?A0AJAAAj6BlchxHrdtBkGwEBAQEDAQEBBwMBAQGBUQYBAQE?=
 =?us-ascii?q?LAYEwKoI4jBZfix2BYC18lmAUgVsZGBSEQIJmIjQJDQEDAQEBAQEBAgETAQEBC?=
 =?us-ascii?q?gsJCBsOL4I2BQIDGgEGglwBAgMBAiQfCikDAwECBgEBChgcCggDATkaBg0GAgE?=
 =?us-ascii?q?BAYJSS4ICAQMBpzUzhUCDZIENjD8RBoF/gREngjY1hGoXhV8CiUgulzkJkVsGG?=
 =?us-ascii?q?JFWmXyBRoIOTTAIgyeCACcXEo4McYEEA4tpgXcBAQ?=
X-IronPort-AV: E=Sophos;i="5.56,371,1539673200"; 
   d="scan'208";a="56952173"
X-Amp-Result: SKIPPED(no attachment in message)
X-Amp-File-Uploaded: False
Received: from lists.gnu.org ([208.118.235.17])
  by mtab.intel.com with ESMTP/TLS/AES256-SHA; 18 Dec 2018 22:46:42 -0800
Received: from localhost ([::1]:57888 helo=lists.gnu.org)
	by lists.gnu.org with esmtp (Exim 4.71)
	(envelope-from <qemu-devel-bounces+like.xu=linux.intel.com@nongnu.org>)
	id 1gZVcv-0002zN-DX
	for like.xu@linux.intel.com; Wed, 19 Dec 2018 01:46:41 -0500
Received: from eggs.gnu.org ([2001:4830:134:3::10]:52550)
	by lists.gnu.org with esmtp (Exim 4.71)
	(envelope-from <clg@kaod.org>) id 1gZVcS-0002uu-Tc
	for qemu-devel@nongnu.org; Wed, 19 Dec 2018 01:46:14 -0500
Received: from Debian-exim by eggs.gnu.org with spam-scanned (Exim 4.71)
	(envelope-from <clg@kaod.org>) id 1gZVcP-0006Po-MP
	for qemu-devel@nongnu.org; Wed, 19 Dec 2018 01:46:12 -0500
Received: from 5.mo178.mail-out.ovh.net ([46.105.51.53]:36752)
	by eggs.gnu.org with esmtps (TLS1.0:DHE_RSA_AES_256_CBC_SHA1:32)
	(Exim 4.71) (envelope-from <clg@kaod.org>) id 1gZVcP-0006P6-CZ
	for qemu-devel@nongnu.org; Wed, 19 Dec 2018 01:46:09 -0500
Received: from player771.ha.ovh.net (unknown [10.109.143.189])
	by mo178.mail-out.ovh.net (Postfix) with ESMTP id A54CF439A4
	for <qemu-devel@nongnu.org>; Wed, 19 Dec 2018 07:46:07 +0100 (CET)
Received: from kaod.org (lfbn-1-10605-110.w90-89.abo.wanadoo.fr
	[90.89.196.110]) (Authenticated sender: clg@kaod.org)
	by player771.ha.ovh.net (Postfix) with ESMTPSA id 3C141F8F326;
	Wed, 19 Dec 2018 06:46:02 +0000 (UTC)
To: David Gibson <david@gibson.dropbear.id.au>
References: <20181218213803.14587-1-clg@kaod.org>
	<20181219045340.GC30570@umbus.fritz.box>
From: =?UTF-8?Q?C=c3=a9dric_Le_Goater?= <clg@kaod.org>
Message-ID: <67d119ed-dca7-c4cf-3b54-14e97cee104f@kaod.org>
Date: Wed, 19 Dec 2018 07:46:01 +0100
User-Agent: Mozilla/5.0 (X11; Linux x86_64; rv:60.0) Gecko/20100101
	Thunderbird/60.3.1
MIME-Version: 1.0
In-Reply-To: <20181219045340.GC30570@umbus.fritz.box>
Content-Type: text/plain; charset=windows-1252
Content-Language: en-US
X-Ovh-Tracer-Id: 16802648737794526016
X-VR-SPAMSTATE: OK
X-VR-SPAMSCORE: -100
X-VR-SPAMCAUSE: gggruggvucftvghtrhhoucdtuddrgedtkedrudeiledgjedtucetufdoteggodetrfdotffvucfrrhhofhhilhgvmecuqfggjfdpvefjgfevmfevgfenuceurghilhhouhhtmecuhedttdenucesvcftvggtihhpihgvnhhtshculddquddttddm
Content-Transfer-Encoding: quoted-printable
X-detected-operating-system: by eggs.gnu.org: GNU/Linux 2.2.x-3.x [generic]
	[fuzzy]
X-Received-From: 46.105.51.53
Subject: Re: [Qemu-devel] [PATCH] ppc/xive: introduce helpers to access the
 XIVE structures
X-BeenThere: qemu-devel@nongnu.org
X-Mailman-Version: 2.1.21
Precedence: list
List-Id: <qemu-devel.nongnu.org>
List-Unsubscribe: <https://lists.nongnu.org/mailman/options/qemu-devel>,
	<mailto:qemu-devel-request@nongnu.org?subject=unsubscribe>
List-Archive: <http://lists.nongnu.org/archive/html/qemu-devel/>
List-Post: <mailto:qemu-devel@nongnu.org>
List-Help: <mailto:qemu-devel-request@nongnu.org?subject=help>
List-Subscribe: <https://lists.nongnu.org/mailman/listinfo/qemu-devel>,
	<mailto:qemu-devel-request@nongnu.org?subject=subscribe>
Cc: qemu-ppc@nongnu.org, qemu-devel@nongnu.org
Errors-To: qemu-devel-bounces+like.xu=linux.intel.com@nongnu.org
Sender: "Qemu-devel" <qemu-devel-bounces+like.xu=linux.intel.com@nongnu.org>

On 12/19/18 5:53 AM, David Gibson wrote:
> On Tue, Dec 18, 2018 at 10:38:03PM +0100, C=E9dric Le Goater wrote:
>> The XIVE internal structures (EAS, END, NVT) are architected to be Big
>> Endian. The XIVE models, today, access the different fields of these
>> structures using wrappers around the GETFIELD/SETFIELD macros. The
>> definitions of these macros depend on the host which seems unnecessary
>> for guest only values.
>>
>> Remove GETFIELD/SETFIELD and replace them with explicit XIVE handlers
>> doing the endianess conversion.
>>
>> Signed-off-by: C=E9dric Le Goater <clg@kaod.org>
>=20
> So, rather than applying this as is, I've distributed its pieces and
> folded them into the existing XIVE patches, so as not to break
> bisection.  I've also eliminated the existing GETFIELD and SETFIELD
> macros.

Yes that is better.=20

We will need similar routine for the PHB models, so we might introduce
a common set when time comes.=20

Thanks,

C.=20

>> ---
>>  include/hw/ppc/xive_regs.h | 28 +++++++++++++---
>>  target/ppc/cpu.h           | 12 -------
>>  hw/intc/spapr_xive.c       | 48 +++++++++++++--------------
>>  hw/intc/xive.c             | 68 +++++++++++++++++++------------------=
-
>>  4 files changed, 82 insertions(+), 74 deletions(-)
>>
>> diff --git a/include/hw/ppc/xive_regs.h b/include/hw/ppc/xive_regs.h
>> index 85557e730cd8..78875b156980 100644
>> --- a/include/hw/ppc/xive_regs.h
>> +++ b/include/hw/ppc/xive_regs.h
>> @@ -126,8 +126,18 @@ typedef struct XiveEAS {
>>  #define xive_eas_is_valid(eas)   (be64_to_cpu((eas)->w) & EAS_VALID)
>>  #define xive_eas_is_masked(eas)  (be64_to_cpu((eas)->w) & EAS_MASKED)
>> =20
>> -#define GETFIELD_BE64(m, v)      GETFIELD(m, be64_to_cpu(v))
>> -#define SETFIELD_BE64(m, v, val) cpu_to_be64(SETFIELD(m, be64_to_cpu(=
v), val))
>> +static inline uint64_t xive_get_field64(uint64_t mask, uint64_t word)
>> +{
>> +    return (be64_to_cpu(word) & mask) >> ctz64(mask);
>> +}
>> +
>> +static inline uint64_t xive_set_field64(uint64_t mask, uint64_t word,
>> +                                        uint64_t value)
>> +{
>> +    uint64_t tmp =3D
>> +        (be64_to_cpu(word) & ~mask) | ((value << ctz64(mask)) & mask)=
;
>> +    return cpu_to_be64(tmp);
>> +}
>> =20
>>  /* Event Notification Descriptor (END) */
>>  typedef struct XiveEND {
>> @@ -183,8 +193,18 @@ typedef struct XiveEND {
>>  #define xive_end_is_backlog(end)  (be32_to_cpu((end)->w0) & END_W0_BA=
CKLOG)
>>  #define xive_end_is_escalate(end) (be32_to_cpu((end)->w0) & END_W0_ES=
CALATE_CTL)
>> =20
>> -#define GETFIELD_BE32(m, v)       GETFIELD(m, be32_to_cpu(v))
>> -#define SETFIELD_BE32(m, v, val)  cpu_to_be32(SETFIELD(m, be32_to_cpu=
(v), val))
>> +static inline uint32_t xive_get_field32(uint32_t mask, uint32_t word)
>> +{
>> +    return (be32_to_cpu(word) & mask) >> ctz32(mask);
>> +}
>> +
>> +static inline uint32_t xive_set_field32(uint32_t mask, uint32_t word,
>> +                                        uint32_t value)
>> +{
>> +    uint32_t tmp =3D
>> +        (be32_to_cpu(word) & ~mask) | ((value << ctz32(mask)) & mask)=
;
>> +    return cpu_to_be32(tmp);
>> +}
>> =20
>>  /* Notification Virtual Target (NVT) */
>>  typedef struct XiveNVT {
>> diff --git a/target/ppc/cpu.h b/target/ppc/cpu.h
>> index 527181c0f09f..d5f99f1fc7b9 100644
>> --- a/target/ppc/cpu.h
>> +++ b/target/ppc/cpu.h
>> @@ -78,18 +78,6 @@
>>                                   PPC_BIT32(bs))
>>  #define PPC_BITMASK8(bs, be)    ((PPC_BIT8(bs) - PPC_BIT8(be)) | PPC_=
BIT8(bs))
>> =20
>> -#if HOST_LONG_BITS =3D=3D 32
>> -# define MASK_TO_LSH(m)          (__builtin_ffsll(m) - 1)
>> -#elif HOST_LONG_BITS =3D=3D 64
>> -# define MASK_TO_LSH(m)          (__builtin_ffsl(m) - 1)
>> -#else
>> -# error Unknown sizeof long
>> -#endif
>> -
>> -#define GETFIELD(m, v)          (((v) & (m)) >> MASK_TO_LSH(m))
>> -#define SETFIELD(m, v, val)                             \
>> -        (((v) & ~(m)) | ((((typeof(v))(val)) << MASK_TO_LSH(m)) & (m)=
))
>> -
>>  /********************************************************************=
*********/
>>  /* Exception vectors definitions                                     =
        */
>>  enum {
>> diff --git a/hw/intc/spapr_xive.c b/hw/intc/spapr_xive.c
>> index 3ceabe668b16..87424de26c1c 100644
>> --- a/hw/intc/spapr_xive.c
>> +++ b/hw/intc/spapr_xive.c
>> @@ -119,12 +119,12 @@ static int spapr_xive_target_to_end(uint32_t tar=
get, uint8_t prio,
>>  static void spapr_xive_end_pic_print_info(sPAPRXive *xive, XiveEND *e=
nd,
>>                                            Monitor *mon)
>>  {
>> -    uint32_t qindex =3D GETFIELD_BE32(END_W1_PAGE_OFF, end->w1);
>> -    uint32_t qgen =3D GETFIELD_BE32(END_W1_GENERATION, end->w1);
>> -    uint32_t qsize =3D GETFIELD_BE32(END_W0_QSIZE, end->w0);
>> +    uint32_t qindex =3D xive_get_field32(END_W1_PAGE_OFF, end->w1);
>> +    uint32_t qgen =3D xive_get_field32(END_W1_GENERATION, end->w1);
>> +    uint32_t qsize =3D xive_get_field32(END_W0_QSIZE, end->w0);
>>      uint32_t qentries =3D 1 << (qsize + 10);
>> -    uint32_t nvt =3D GETFIELD_BE32(END_W6_NVT_INDEX, end->w6);
>> -    uint8_t priority =3D GETFIELD_BE32(END_W7_F0_PRIORITY, end->w7);
>> +    uint32_t nvt =3D xive_get_field32(END_W6_NVT_INDEX, end->w6);
>> +    uint8_t priority =3D xive_get_field32(END_W7_F0_PRIORITY, end->w7=
);
>> =20
>>      monitor_printf(mon, "%3d/%d % 6d/%5d ^%d",
>>                     spapr_xive_nvt_to_target(0, nvt),
>> @@ -155,10 +155,10 @@ void spapr_xive_pic_print_info(sPAPRXive *xive, =
Monitor *mon)
>>                         pq & XIVE_ESB_VAL_Q ? 'Q' : '-',
>>                         xsrc->status[i] & XIVE_STATUS_ASSERTED ? 'A' :=
 ' ',
>>                         xive_eas_is_masked(eas) ? "M" : " ",
>> -                       (int) GETFIELD_BE64(EAS_END_DATA, eas->w));
>> +                       (int) xive_get_field64(EAS_END_DATA, eas->w));
>> =20
>>          if (!xive_eas_is_masked(eas)) {
>> -            uint32_t end_idx =3D GETFIELD_BE64(EAS_END_INDEX, eas->w)=
;
>> +            uint32_t end_idx =3D xive_get_field64(EAS_END_INDEX, eas-=
>w);
>>              XiveEND *end;
>> =20
>>              assert(end_idx < xive->nr_ends);
>> @@ -741,11 +741,11 @@ static target_ulong h_int_set_source_config(Powe=
rPCCPU *cpu,
>>          return H_P3;
>>      }
>> =20
>> -    new_eas.w =3D SETFIELD_BE64(EAS_END_BLOCK, new_eas.w, end_blk);
>> -    new_eas.w =3D SETFIELD_BE64(EAS_END_INDEX, new_eas.w, end_idx);
>> +    new_eas.w =3D xive_set_field64(EAS_END_BLOCK, new_eas.w, end_blk)=
;
>> +    new_eas.w =3D xive_set_field64(EAS_END_INDEX, new_eas.w, end_idx)=
;
>> =20
>>      if (flags & SPAPR_XIVE_SRC_SET_EISN) {
>> -        new_eas.w =3D SETFIELD_BE64(EAS_END_DATA, new_eas.w, eisn);
>> +        new_eas.w =3D xive_set_field64(EAS_END_DATA, new_eas.w, eisn)=
;
>>      }
>> =20
>>  out:
>> @@ -810,22 +810,22 @@ static target_ulong h_int_get_source_config(Powe=
rPCCPU *cpu,
>>      }
>> =20
>>      /* EAS_END_BLOCK is unused on sPAPR */
>> -    end_idx =3D GETFIELD_BE64(EAS_END_INDEX, eas.w);
>> +    end_idx =3D xive_get_field64(EAS_END_INDEX, eas.w);
>> =20
>>      assert(end_idx < xive->nr_ends);
>>      end =3D &xive->endt[end_idx];
>> =20
>> -    nvt_blk =3D GETFIELD_BE32(END_W6_NVT_BLOCK, end->w6);
>> -    nvt_idx =3D GETFIELD_BE32(END_W6_NVT_INDEX, end->w6);
>> +    nvt_blk =3D xive_get_field32(END_W6_NVT_BLOCK, end->w6);
>> +    nvt_idx =3D xive_get_field32(END_W6_NVT_INDEX, end->w6);
>>      args[0] =3D spapr_xive_nvt_to_target(nvt_blk, nvt_idx);
>> =20
>>      if (xive_eas_is_masked(&eas)) {
>>          args[1] =3D 0xff;
>>      } else {
>> -        args[1] =3D GETFIELD_BE32(END_W7_F0_PRIORITY, end->w7);
>> +        args[1] =3D xive_get_field32(END_W7_F0_PRIORITY, end->w7);
>>      }
>> =20
>> -    args[2] =3D GETFIELD_BE64(EAS_END_DATA, eas.w);
>> +    args[2] =3D xive_get_field64(EAS_END_DATA, eas.w);
>> =20
>>      return H_SUCCESS;
>>  }
>> @@ -894,7 +894,7 @@ static target_ulong h_int_get_queue_info(PowerPCCP=
U *cpu,
>> =20
>>      args[0] =3D xive->end_base + (1ull << (end_xsrc->esb_shift + 1)) =
* end_idx;
>>      if (xive_end_is_enqueue(end)) {
>> -        args[1] =3D GETFIELD_BE32(END_W0_QSIZE, end->w0) + 12;
>> +        args[1] =3D xive_get_field32(END_W0_QSIZE, end->w0) + 12;
>>      } else {
>>          args[1] =3D 0;
>>      }
>> @@ -987,7 +987,7 @@ static target_ulong h_int_set_queue_config(PowerPC=
CPU *cpu,
>>          end.w2 =3D cpu_to_be32((qpage >> 32) & 0x0fffffff);
>>          end.w3 =3D cpu_to_be32(qpage & 0xffffffff);
>>          end.w0 |=3D cpu_to_be32(END_W0_ENQUEUE);
>> -        end.w0 =3D SETFIELD_BE32(END_W0_QSIZE, end.w0, qsize - 12);
>> +        end.w0 =3D xive_set_field32(END_W0_QSIZE, end.w0, qsize - 12)=
;
>>          break;
>>      case 0:
>>          /* reset queue and disable queueing */
>> @@ -1026,9 +1026,9 @@ static target_ulong h_int_set_queue_config(Power=
PCCPU *cpu,
>>      /* Ensure the priority and target are correctly set (they will no=
t
>>       * be right after allocation)
>>       */
>> -    end.w6 =3D SETFIELD_BE32(END_W6_NVT_BLOCK, 0ul, nvt_blk) |
>> -        SETFIELD_BE32(END_W6_NVT_INDEX, 0ul, nvt_idx);
>> -    end.w7 =3D SETFIELD_BE32(END_W7_F0_PRIORITY, 0ul, priority);
>> +    end.w6 =3D xive_set_field32(END_W6_NVT_BLOCK, 0ul, nvt_blk) |
>> +        xive_set_field32(END_W6_NVT_INDEX, 0ul, nvt_idx);
>> +    end.w7 =3D xive_set_field32(END_W7_F0_PRIORITY, 0ul, priority);
>> =20
>>      if (flags & SPAPR_XIVE_END_ALWAYS_NOTIFY) {
>>          end.w0 |=3D cpu_to_be32(END_W0_UCOND_NOTIFY);
>> @@ -1040,7 +1040,7 @@ static target_ulong h_int_set_queue_config(Power=
PCCPU *cpu,
>>       * offset counter starts at 0.
>>       */
>>      end.w1 =3D cpu_to_be32(END_W1_GENERATION) |
>> -        SETFIELD_BE32(END_W1_PAGE_OFF, 0ul, 0ul);
>> +        xive_set_field32(END_W1_PAGE_OFF, 0ul, 0ul);
>>      end.w0 |=3D cpu_to_be32(END_W0_VALID);
>> =20
>>      /* TODO: issue syncs required to ensure all in-flight interrupts
>> @@ -1132,7 +1132,7 @@ static target_ulong h_int_get_queue_config(Power=
PCCPU *cpu,
>>      if (xive_end_is_enqueue(end)) {
>>          args[1] =3D (uint64_t) be32_to_cpu(end->w2 & 0x0fffffff) << 3=
2
>>              | be32_to_cpu(end->w3);
>> -        args[2] =3D GETFIELD_BE32(END_W0_QSIZE, end->w0) + 12;
>> +        args[2] =3D xive_get_field32(END_W0_QSIZE, end->w0) + 12;
>>      } else {
>>          args[1] =3D 0;
>>          args[2] =3D 0;
>> @@ -1141,10 +1141,10 @@ static target_ulong h_int_get_queue_config(Pow=
erPCCPU *cpu,
>>      /* TODO: do we need any locking on the END ? */
>>      if (flags & SPAPR_XIVE_END_DEBUG) {
>>          /* Load the event queue generation number into the return fla=
gs */
>> -        args[0] |=3D (uint64_t)GETFIELD_BE32(END_W1_GENERATION, end->=
w1) << 62;
>> +        args[0] |=3D (uint64_t)xive_get_field32(END_W1_GENERATION, en=
d->w1) << 62;
>> =20
>>          /* Load R7 with the event queue offset counter */
>> -        args[3] =3D GETFIELD_BE32(END_W1_PAGE_OFF, end->w1);
>> +        args[3] =3D xive_get_field32(END_W1_PAGE_OFF, end->w1);
>>      } else {
>>          args[3] =3D 0;
>>      }
>> diff --git a/hw/intc/xive.c b/hw/intc/xive.c
>> index 53d2f191e8a3..f8510e426f63 100644
>> --- a/hw/intc/xive.c
>> +++ b/hw/intc/xive.c
>> @@ -982,8 +982,8 @@ void xive_end_queue_pic_print_info(XiveEND *end, u=
int32_t width, Monitor *mon)
>>  {
>>      uint64_t qaddr_base =3D (uint64_t) be32_to_cpu(end->w2 & 0x0fffff=
ff) << 32
>>          | be32_to_cpu(end->w3);
>> -    uint32_t qsize =3D GETFIELD_BE32(END_W0_QSIZE, end->w0);
>> -    uint32_t qindex =3D GETFIELD_BE32(END_W1_PAGE_OFF, end->w1);
>> +    uint32_t qsize =3D xive_get_field32(END_W0_QSIZE, end->w0);
>> +    uint32_t qindex =3D xive_get_field32(END_W1_PAGE_OFF, end->w1);
>>      uint32_t qentries =3D 1 << (qsize + 10);
>>      int i;
>> =20
>> @@ -1012,13 +1012,13 @@ void xive_end_pic_print_info(XiveEND *end, uin=
t32_t end_idx, Monitor *mon)
>>  {
>>      uint64_t qaddr_base =3D (uint64_t) be32_to_cpu(end->w2 & 0x0fffff=
ff) << 32
>>          | be32_to_cpu(end->w3);
>> -    uint32_t qindex =3D GETFIELD_BE32(END_W1_PAGE_OFF, end->w1);
>> -    uint32_t qgen =3D GETFIELD_BE32(END_W1_GENERATION, end->w1);
>> -    uint32_t qsize =3D GETFIELD_BE32(END_W0_QSIZE, end->w0);
>> +    uint32_t qindex =3D xive_get_field32(END_W1_PAGE_OFF, end->w1);
>> +    uint32_t qgen =3D xive_get_field32(END_W1_GENERATION, end->w1);
>> +    uint32_t qsize =3D xive_get_field32(END_W0_QSIZE, end->w0);
>>      uint32_t qentries =3D 1 << (qsize + 10);
>> =20
>> -    uint32_t nvt =3D GETFIELD_BE32(END_W6_NVT_INDEX, end->w6);
>> -    uint8_t priority =3D GETFIELD_BE32(END_W7_F0_PRIORITY, end->w7);
>> +    uint32_t nvt =3D xive_get_field32(END_W6_NVT_INDEX, end->w6);
>> +    uint8_t priority =3D xive_get_field32(END_W7_F0_PRIORITY, end->w7=
);
>> =20
>>      if (!xive_end_is_valid(end)) {
>>          return;
>> @@ -1041,9 +1041,9 @@ static void xive_end_enqueue(XiveEND *end, uint3=
2_t data)
>>  {
>>      uint64_t qaddr_base =3D (uint64_t) be32_to_cpu(end->w2 & 0x0fffff=
ff) << 32
>>          | be32_to_cpu(end->w3);
>> -    uint32_t qsize =3D GETFIELD_BE32(END_W0_QSIZE, end->w0);
>> -    uint32_t qindex =3D GETFIELD_BE32(END_W1_PAGE_OFF, end->w1);
>> -    uint32_t qgen =3D GETFIELD_BE32(END_W1_GENERATION, end->w1);
>> +    uint32_t qsize =3D xive_get_field32(END_W0_QSIZE, end->w0);
>> +    uint32_t qindex =3D xive_get_field32(END_W1_PAGE_OFF, end->w1);
>> +    uint32_t qgen =3D xive_get_field32(END_W1_GENERATION, end->w1);
>> =20
>>      uint64_t qaddr =3D qaddr_base + (qindex << 2);
>>      uint32_t qdata =3D cpu_to_be32((qgen << 31) | (data & 0x7fffffff)=
);
>> @@ -1058,9 +1058,9 @@ static void xive_end_enqueue(XiveEND *end, uint3=
2_t data)
>>      qindex =3D (qindex + 1) & (qentries - 1);
>>      if (qindex =3D=3D 0) {
>>          qgen ^=3D 1;
>> -        end->w1 =3D SETFIELD_BE32(END_W1_GENERATION, end->w1, qgen);
>> +        end->w1 =3D xive_set_field32(END_W1_GENERATION, end->w1, qgen=
);
>>      }
>> -    end->w1 =3D SETFIELD_BE32(END_W1_PAGE_OFF, end->w1, qindex);
>> +    end->w1 =3D xive_set_field32(END_W1_PAGE_OFF, end->w1, qindex);
>>  }
>> =20
>>  /*
>> @@ -1139,13 +1139,13 @@ static int xive_presenter_tctx_match(XiveTCTX =
*tctx, uint8_t format,
>> =20
>>          /* HV POOL ring */
>>          if ((be32_to_cpu(qw2w2) & TM_QW2W2_VP) &&
>> -            cam =3D=3D GETFIELD_BE32(TM_QW2W2_POOL_CAM, qw2w2)) {
>> +            cam =3D=3D xive_get_field32(TM_QW2W2_POOL_CAM, qw2w2)) {
>>              return TM_QW2_HV_POOL;
>>          }
>> =20
>>          /* OS ring */
>>          if ((be32_to_cpu(qw1w2) & TM_QW1W2_VO) &&
>> -            cam =3D=3D GETFIELD_BE32(TM_QW1W2_OS_CAM, qw1w2)) {
>> +            cam =3D=3D xive_get_field32(TM_QW1W2_OS_CAM, qw1w2)) {
>>              return TM_QW1_OS;
>>          }
>>      } else {
>> @@ -1153,9 +1153,9 @@ static int xive_presenter_tctx_match(XiveTCTX *t=
ctx, uint8_t format,
>> =20
>>          /* USER ring */
>>          if  ((be32_to_cpu(qw1w2) & TM_QW1W2_VO) &&
>> -             (cam =3D=3D GETFIELD_BE32(TM_QW1W2_OS_CAM, qw1w2)) &&
>> +             (cam =3D=3D xive_get_field32(TM_QW1W2_OS_CAM, qw1w2)) &&
>>               (be32_to_cpu(qw0w2) & TM_QW0W2_VU) &&
>> -             (logic_serv =3D=3D GETFIELD_BE32(TM_QW0W2_LOGIC_SERV, qw=
0w2))) {
>> +             (logic_serv =3D=3D xive_get_field32(TM_QW0W2_LOGIC_SERV,=
 qw0w2))) {
>>              return TM_QW0_USER;
>>          }
>>      }
>> @@ -1313,8 +1313,8 @@ static void xive_router_end_notify(XiveRouter *x=
rtr, uint8_t end_blk,
>>       *   F=3D1 : User level Event-Based Branch (EBB) notification, no
>>       *         priority
>>       */
>> -    format =3D GETFIELD_BE32(END_W6_FORMAT_BIT, end.w6);
>> -    priority =3D GETFIELD_BE32(END_W7_F0_PRIORITY, end.w7);
>> +    format =3D xive_get_field32(END_W6_FORMAT_BIT, end.w6);
>> +    priority =3D xive_get_field32(END_W7_F0_PRIORITY, end.w7);
>> =20
>>      /* The END is masked */
>>      if (format =3D=3D 0 && priority =3D=3D 0xff) {
>> @@ -1326,11 +1326,11 @@ static void xive_router_end_notify(XiveRouter =
*xrtr, uint8_t end_blk,
>>       * even futher coalescing in the Router
>>       */
>>      if (!xive_end_is_notify(&end)) {
>> -        uint8_t pq =3D GETFIELD_BE32(END_W1_ESn, end.w1);
>> +        uint8_t pq =3D xive_get_field32(END_W1_ESn, end.w1);
>>          bool notify =3D xive_esb_trigger(&pq);
>> =20
>> -        if (pq !=3D GETFIELD_BE32(END_W1_ESn, end.w1)) {
>> -            end.w1 =3D SETFIELD_BE32(END_W1_ESn, end.w1, pq);
>> +        if (pq !=3D xive_get_field32(END_W1_ESn, end.w1)) {
>> +            end.w1 =3D xive_set_field32(END_W1_ESn, end.w1, pq);
>>              xive_router_write_end(xrtr, end_blk, end_idx, &end, 1);
>>          }
>> =20
>> @@ -1344,11 +1344,11 @@ static void xive_router_end_notify(XiveRouter =
*xrtr, uint8_t end_blk,
>>       * Follows IVPE notification
>>       */
>>      xive_presenter_notify(xrtr, format,
>> -                          GETFIELD_BE32(END_W6_NVT_BLOCK, end.w6),
>> -                          GETFIELD_BE32(END_W6_NVT_INDEX, end.w6),
>> -                          GETFIELD_BE32(END_W7_F0_IGNORE, end.w7),
>> +                          xive_get_field32(END_W6_NVT_BLOCK, end.w6),
>> +                          xive_get_field32(END_W6_NVT_INDEX, end.w6),
>> +                          xive_get_field32(END_W7_F0_IGNORE, end.w7),
>>                            priority,
>> -                          GETFIELD_BE32(END_W7_F1_LOG_SERVER_ID, end.=
w7));
>> +                          xive_get_field32(END_W7_F1_LOG_SERVER_ID, e=
nd.w7));
>> =20
>>      /* TODO: Auto EOI. */
>>  }
>> @@ -1385,9 +1385,9 @@ static void xive_router_notify(XiveNotifier *xn,=
 uint32_t lisn)
>>       * The event trigger becomes an END trigger
>>       */
>>      xive_router_end_notify(xrtr,
>> -                           GETFIELD_BE64(EAS_END_BLOCK, eas.w),
>> -                           GETFIELD_BE64(EAS_END_INDEX, eas.w),
>> -                           GETFIELD_BE64(EAS_END_DATA,  eas.w));
>> +                           xive_get_field64(EAS_END_BLOCK, eas.w),
>> +                           xive_get_field64(EAS_END_INDEX, eas.w),
>> +                           xive_get_field64(EAS_END_DATA,  eas.w));
>>  }
>> =20
>>  static void xive_router_class_init(ObjectClass *klass, void *data)
>> @@ -1419,9 +1419,9 @@ void xive_eas_pic_print_info(XiveEAS *eas, uint3=
2_t lisn, Monitor *mon)
>> =20
>>      monitor_printf(mon, "  %08x %s end:%02x/%04x data:%08x\n",
>>                     lisn, xive_eas_is_masked(eas) ? "M" : " ",
>> -                   (uint8_t)  GETFIELD_BE64(EAS_END_BLOCK, eas->w),
>> -                   (uint32_t) GETFIELD_BE64(EAS_END_INDEX, eas->w),
>> -                   (uint32_t) GETFIELD_BE64(EAS_END_DATA, eas->w));
>> +                   (uint8_t)  xive_get_field64(EAS_END_BLOCK, eas->w)=
,
>> +                   (uint32_t) xive_get_field64(EAS_END_INDEX, eas->w)=
,
>> +                   (uint32_t) xive_get_field64(EAS_END_DATA, eas->w))=
;
>>  }
>> =20
>>  /*
>> @@ -1454,7 +1454,7 @@ static uint64_t xive_end_source_read(void *opaqu=
e, hwaddr addr, unsigned size)
>>      }
>> =20
>>      end_esmask =3D addr_is_even(addr, xsrc->esb_shift) ? END_W1_ESn :=
 END_W1_ESe;
>> -    pq =3D GETFIELD_BE32(end_esmask, end.w1);
>> +    pq =3D xive_get_field32(end_esmask, end.w1);
>> =20
>>      switch (offset) {
>>      case XIVE_ESB_LOAD_EOI ... XIVE_ESB_LOAD_EOI + 0x7FF:
>> @@ -1479,8 +1479,8 @@ static uint64_t xive_end_source_read(void *opaqu=
e, hwaddr addr, unsigned size)
>>          return -1;
>>      }
>> =20
>> -    if (pq !=3D GETFIELD_BE32(end_esmask, end.w1)) {
>> -        end.w1 =3D SETFIELD_BE32(end_esmask, end.w1, pq);
>> +    if (pq !=3D xive_get_field32(end_esmask, end.w1)) {
>> +        end.w1 =3D xive_set_field32(end_esmask, end.w1, pq);
>>          xive_router_write_end(xsrc->xrtr, end_blk, end_idx, &end, 1);
>>      }
>> =20
>=20


