Return-Path: <qemu-devel-bounces+like.xu=linux.intel.com@nongnu.org>
Delivered-To: unknown
Received: from linux.intel.com (10.54.29.200:995) by i7-8700 with POP3-SSL;
  24 Dec 2018 15:50:49 -0000
X-Original-To: like.xu@linux.intel.com
Delivered-To: like.xu@linux.intel.com
Received: from fmsmga004.fm.intel.com (fmsmga004.fm.intel.com [10.253.24.48])
	(using TLSv1.2 with cipher ECDHE-RSA-AES256-GCM-SHA384 (256/256 bits))
	(No client certificate requested)
	by linux.intel.com (Postfix) with ESMTPS id EABC4580522
	for <like.xu@linux.intel.com>; Fri, 21 Dec 2018 06:14:10 -0800 (PST)
Received: from orsmga103.jf.intel.com ([10.7.208.35])
  by fmsmga004-1.fm.intel.com with ESMTP/TLS/DHE-RSA-AES256-GCM-SHA384; 21 Dec 2018 06:14:10 -0800
IronPort-PHdr: =?us-ascii?q?9a23=3A3cKOQRQQiPrgNDkP0wQdGW5Pptpsv+yvbD5Q0YIu?=
 =?us-ascii?q?jvd0So/mwa6zYxGN2/xhgRfzUJnB7Loc0qyK6/CmATRIyK3CmUhKSIZLWR4BhJ?=
 =?us-ascii?q?detC0bK+nBN3fGKuX3ZTcxBsVIWQwt1Xi6NU9IBJS2PAWK8TW94jEIBxrwKxd+?=
 =?us-ascii?q?KPjrFY7OlcS30P2594HObwlSizexfbB/IA+qoQnNq8IbnZZsJqEtxxXTv3BGYf?=
 =?us-ascii?q?5WxWRmJVKSmxbz+MK994N9/ipTpvws6ddOXb31cKokQ7NYCi8mM30u683wqRbD?=
 =?us-ascii?q?VwqP6WACXWgQjxFFHhLK7BD+Xpf2ryv6qu9w0zSUMMHqUbw5Xymp4rx1QxH0li?=
 =?us-ascii?q?gIKz858HnWisNuiqJbvAmhrAF7z4LNfY2ZKOZycqbbcNgHR2ROQ9xRWjRPDI28?=
 =?us-ascii?q?cYUBDOgOPehXoIbhqFUAsAO+CAuuCu7g1zNFiGP60rMh0+k6DQHL3hYtE84SvH?=
 =?us-ascii?q?jIstn4MroZX+CvzKnPyDXOd/BY2Tj66IjSbxsvpuuDXbd1ccXP1EYvEB3FhUiX?=
 =?us-ascii?q?pIzkOjOazOENs22F4OV9UuKikHQnpB9srTiv3MgslpPFiZ4SylDB7Ch0xps+K9?=
 =?us-ascii?q?6gSENjf9KoDJhduzuHO4drQc4uWX9ktSg6x7EcpJK2fjAGxIo7yxPbcfCLboaF?=
 =?us-ascii?q?7gz5WOqMIjp1imhpdKy8ihu07EOu0PfzVtOu31ZPtidFksfDtnQK1xHL7siHS+?=
 =?us-ascii?q?B9/lu62TqV2ADT7PxELVozlarBJJ4t2r8wlpwNvkTfBiL6hln6gayMekk55+Sl?=
 =?us-ascii?q?6P7rbqvoq5KcLYN4lwPzPrwrmsOlAOQ4NgYOX3Kc+eS5zLDj5FP2QLBXjvEvj6?=
 =?us-ascii?q?bWro7aKtofpqKgGABV1Zsj6xCjADi4y9QUmn0HLFNGeB2ZlYToNEzOLej8Dfe+?=
 =?us-ascii?q?hVSsjThqy+rHPr3nHpXCMHzDnK39crZ67k5R0wwzzddZ55JbDLEBPej/WkjrtN?=
 =?us-ascii?q?zXFhM5KRC7w/77CNVh0YMTQWaPAq6aMKzMq1OJ6f8vLvKIZI8Uvjb9Nvck6+Tv?=
 =?us-ascii?q?jX8/hV8SY62p0YELZ3C/G/Q1a3ifemfm19cdDX8R7E15SO3xlEbEVzlVaHCvGa?=
 =?us-ascii?q?Um6XY+AYOiCI7FAYe1nL2G2jz8B5BTeyVKB06BFSTVcZ6ZUaIJYSOWPsgzizEB?=
 =?us-ascii?q?SP2tRpEs0VS0uRbnxqF7BuzT/CIeqNTkztci/PDZlxw56WlpCd+A2XqGVWB+kz?=
 =?us-ascii?q?A0QGob0L12u0B6gneK26t/mOAQQdFT7vlKVRwmHYTRw+xzF5b5XQeXLfmTT1Pz?=
 =?us-ascii?q?Y9qhG3kUR9c0ztMJfQ4pGtCrixXO0y2CGbIZl7WXQpcz9/SPjDDKO89hxiOeh+?=
 =?us-ascii?q?EahF48T54KbDX+iw=3D=3D?=
X-IronPort-Anti-Spam-Filtered: true
X-IronPort-Anti-Spam-Result: =?us-ascii?q?A0B+AADV8xxchxHrdtBjHAEBAQQBAQcEA?=
 =?us-ascii?q?QGBVAQBAQsBgTAlgioTjHWLHYINiSSOT4FiEhgUhzAiNwYNAQMBAQEBAQECARM?=
 =?us-ascii?q?BAQEKCwkIGw4vgjoFAgMfAQaCYAEBAQECAQECJBMMCikDAgEBAgYBAQoOCgkaA?=
 =?us-ascii?q?wgDAQtIBhMFFoMHgXUFCAEEpnMzhUCEcIw/F4FAP4ERgxKCEIIrEg4PhXYChn+?=
 =?us-ascii?q?CKCALgXGEZpEcCYpXgyKDZAwYiXqEa4J6mhyBXIF4TSMVgyeCJxcSjgxAMQEBg?=
 =?us-ascii?q?QUciycOFzCBdwEB?=
X-IPAS-Result: =?us-ascii?q?A0B+AADV8xxchxHrdtBjHAEBAQQBAQcEAQGBVAQBAQsBgTA?=
 =?us-ascii?q?lgioTjHWLHYINiSSOT4FiEhgUhzAiNwYNAQMBAQEBAQECARMBAQEKCwkIGw4vg?=
 =?us-ascii?q?joFAgMfAQaCYAEBAQECAQECJBMMCikDAgEBAgYBAQoOCgkaAwgDAQtIBhMFFoM?=
 =?us-ascii?q?HgXUFCAEEpnMzhUCEcIw/F4FAP4ERgxKCEIIrEg4PhXYChn+CKCALgXGEZpEcC?=
 =?us-ascii?q?YpXgyKDZAwYiXqEa4J6mhyBXIF4TSMVgyeCJxcSjgxAMQEBgQUciycOFzCBdwE?=
 =?us-ascii?q?B?=
X-IronPort-AV: E=Sophos;i="5.56,381,1539673200"; 
   d="scan'208";a="57336019"
X-Amp-Result: SKIPPED(no attachment in message)
X-Amp-File-Uploaded: False
Received: from lists.gnu.org ([208.118.235.17])
  by mtab.intel.com with ESMTP/TLS/AES256-SHA; 21 Dec 2018 06:14:09 -0800
Received: from localhost ([::1]:45948 helo=lists.gnu.org)
	by lists.gnu.org with esmtp (Exim 4.71)
	(envelope-from <qemu-devel-bounces+like.xu=linux.intel.com@nongnu.org>)
	id 1gaLZ2-0006ZV-GY
	for like.xu@linux.intel.com; Fri, 21 Dec 2018 09:14:08 -0500
Received: from eggs.gnu.org ([2001:4830:134:3::10]:45735)
	by lists.gnu.org with esmtp (Exim 4.71)
	(envelope-from <imammedo@redhat.com>) id 1gaLYf-0006YI-Tx
	for qemu-devel@nongnu.org; Fri, 21 Dec 2018 09:13:46 -0500
Received: from Debian-exim by eggs.gnu.org with spam-scanned (Exim 4.71)
	(envelope-from <imammedo@redhat.com>) id 1gaLYY-0006pz-1u
	for qemu-devel@nongnu.org; Fri, 21 Dec 2018 09:13:42 -0500
Received: from mx1.redhat.com ([209.132.183.28]:53344)
	by eggs.gnu.org with esmtps (TLS1.0:DHE_RSA_AES_256_CBC_SHA1:32)
	(Exim 4.71) (envelope-from <imammedo@redhat.com>) id 1gaLYS-0006cp-Bz
	for qemu-devel@nongnu.org; Fri, 21 Dec 2018 09:13:34 -0500
Received: from smtp.corp.redhat.com (int-mx07.intmail.prod.int.phx2.redhat.com
	[10.5.11.22])
	(using TLSv1.2 with cipher AECDH-AES256-SHA (256/256 bits))
	(No client certificate requested)
	by mx1.redhat.com (Postfix) with ESMTPS id 9689CAB975;
	Fri, 21 Dec 2018 14:13:28 +0000 (UTC)
Received: from localhost (unknown [10.43.2.182])
	by smtp.corp.redhat.com (Postfix) with ESMTP id 17F851001F3D;
	Fri, 21 Dec 2018 14:13:26 +0000 (UTC)
Date: Fri, 21 Dec 2018 15:13:25 +0100
From: Igor Mammedov <imammedo@redhat.com>
To: Eduardo Habkost <ehabkost@redhat.com>
Message-ID: <20181221151325.39b64733@redhat.com>
In-Reply-To: <20181220211801.GR19442@habkost.net>
References: <1544619939-18102-1-git-send-email-yu.c.zhang@linux.intel.com>
	<1544619939-18102-2-git-send-email-yu.c.zhang@linux.intel.com>
	<20181217141740.16ccfaa1@Igors-MacBook-Pro.local>
	<20181218092723.yhaerzm4vlzgef65@linux.intel.com>
	<20181218155536.2b35a037@Igors-MacBook-Pro.local>
	<20181219025717.6m72hq73p2haexkv@linux.intel.com>
	<20181219114037.5550a562@redhat.com>
	<20181220211801.GR19442@habkost.net>
MIME-Version: 1.0
Content-Type: text/plain; charset=US-ASCII
Content-Transfer-Encoding: 7bit
X-Scanned-By: MIMEDefang 2.84 on 10.5.11.22
X-Greylist: Sender IP whitelisted, not delayed by milter-greylist-4.5.16
	(mx1.redhat.com [10.5.110.26]);
	Fri, 21 Dec 2018 14:13:28 +0000 (UTC)
X-detected-operating-system: by eggs.gnu.org: GNU/Linux 2.2.x-3.x [generic]
	[fuzzy]
X-Received-From: 209.132.183.28
Subject: Re: [Qemu-devel] [PATCH v3 1/2] intel-iommu: differentiate host
 address width from IOVA address width.
X-BeenThere: qemu-devel@nongnu.org
X-Mailman-Version: 2.1.21
Precedence: list
List-Id: <qemu-devel.nongnu.org>
List-Unsubscribe: <https://lists.nongnu.org/mailman/options/qemu-devel>,
	<mailto:qemu-devel-request@nongnu.org?subject=unsubscribe>
List-Archive: <http://lists.nongnu.org/archive/html/qemu-devel/>
List-Post: <mailto:qemu-devel@nongnu.org>
List-Help: <mailto:qemu-devel-request@nongnu.org?subject=help>
List-Subscribe: <https://lists.nongnu.org/mailman/listinfo/qemu-devel>,
	<mailto:qemu-devel-request@nongnu.org?subject=subscribe>
Cc: "Michael S. Tsirkin" <mst@redhat.com>, qemu-devel@nongnu.org,
	Peter Xu <peterx@redhat.com>, Yu Zhang <yu.c.zhang@linux.intel.com>,
	Paolo Bonzini <pbonzini@redhat.com>, Richard Henderson <rth@twiddle.net>
Errors-To: qemu-devel-bounces+like.xu=linux.intel.com@nongnu.org
Sender: "Qemu-devel" <qemu-devel-bounces+like.xu=linux.intel.com@nongnu.org>

On Thu, 20 Dec 2018 19:18:01 -0200
Eduardo Habkost <ehabkost@redhat.com> wrote:

> On Wed, Dec 19, 2018 at 11:40:37AM +0100, Igor Mammedov wrote:
> > On Wed, 19 Dec 2018 10:57:17 +0800
> > Yu Zhang <yu.c.zhang@linux.intel.com> wrote:
> >   
> > > On Tue, Dec 18, 2018 at 03:55:36PM +0100, Igor Mammedov wrote:  
> > > > On Tue, 18 Dec 2018 17:27:23 +0800
> > > > Yu Zhang <yu.c.zhang@linux.intel.com> wrote:
> > > >     
> > > > > On Mon, Dec 17, 2018 at 02:17:40PM +0100, Igor Mammedov wrote:    
> > > > > > On Wed, 12 Dec 2018 21:05:38 +0800
> > > > > > Yu Zhang <yu.c.zhang@linux.intel.com> wrote:
> > > > > >     
> > > > > > > Currently, vIOMMU is using the value of IOVA address width, instead of
> > > > > > > the host address width(HAW) to calculate the number of reserved bits in
> > > > > > > data structures such as root entries, context entries, and entries of
> > > > > > > DMA paging structures etc.
> > > > > > > 
> > > > > > > However values of IOVA address width and of the HAW may not equal. For
> > > > > > > example, a 48-bit IOVA can only be mapped to host addresses no wider than
> > > > > > > 46 bits. Using 48, instead of 46 to calculate the reserved bit may result
> > > > > > > in an invalid IOVA being accepted.
> > > > > > > 
> > > > > > > To fix this, a new field - haw_bits is introduced in struct IntelIOMMUState,
> > > > > > > whose value is initialized based on the maximum physical address set to
> > > > > > > guest CPU.    
> > > > > >     
> > > > > > > Also, definitions such as VTD_HOST_AW_39/48BIT etc. are renamed
> > > > > > > to clarify.
> > > > > > > 
> > > > > > > Signed-off-by: Yu Zhang <yu.c.zhang@linux.intel.com>
> > > > > > > Reviewed-by: Peter Xu <peterx@redhat.com>
> > > > > > > ---    
> > > > > > [...]
> > > > > >     
> > > > > > > @@ -3100,6 +3104,8 @@ static void vtd_iommu_replay(IOMMUMemoryRegion *iommu_mr, IOMMUNotifier *n)
> > > > > > >  static void vtd_init(IntelIOMMUState *s)
> > > > > > >  {
> > > > > > >      X86IOMMUState *x86_iommu = X86_IOMMU_DEVICE(s);
> > > > > > > +    CPUState *cs = first_cpu;
> > > > > > > +    X86CPU *cpu = X86_CPU(cs);
> > > > > > >  
> > > > > > >      memset(s->csr, 0, DMAR_REG_SIZE);
> > > > > > >      memset(s->wmask, 0, DMAR_REG_SIZE);
> > > > > > > @@ -3119,23 +3125,24 @@ static void vtd_init(IntelIOMMUState *s)
> > > > > > >      s->cap = VTD_CAP_FRO | VTD_CAP_NFR | VTD_CAP_ND |
> > > > > > >               VTD_CAP_MAMV | VTD_CAP_PSI | VTD_CAP_SLLPS |
> > > > > > >               VTD_CAP_SAGAW_39bit | VTD_CAP_MGAW(s->aw_bits);
> > > > > > > -    if (s->aw_bits == VTD_HOST_AW_48BIT) {
> > > > > > > +    if (s->aw_bits == VTD_AW_48BIT) {
> > > > > > >          s->cap |= VTD_CAP_SAGAW_48bit;
> > > > > > >      }
> > > > > > >      s->ecap = VTD_ECAP_QI | VTD_ECAP_IRO;
> > > > > > > +    s->haw_bits = cpu->phys_bits;    
> > > > > > Is it possible to avoid accessing CPU fields directly or cpu altogether
> > > > > > and set phys_bits when iommu is created?    
> > > > > 
> > > > > Thanks for your comments, Igor.
> > > > > 
> > > > > Well, I guess you prefer not to query the CPU capabilities while deciding
> > > > > the vIOMMU features. But to me, they are not that irrelevant.:)
> > > > > 
> > > > > Here the hardware address width in vt-d, and the one in cpuid.MAXPHYSADDR
> > > > > are referring to the same concept. In VM, both are the maximum guest physical
> > > > > address width. If we do not check the CPU field here, we will still have to
> > > > > check the CPU field in other places such as build_dmar_q35(), and reset the
> > > > > s->haw_bits again.
> > > > > 
> > > > > Is this explanation convincing enough? :)    
> > > > current build_dmar_q35() doesn't do it, it's all new code in this series that
> > > > contains not acceptable direct access from one device (iommu) to another (cpu).   
> > > > Proper way would be for the owner of iommu to fish limits from somewhere and set
> > > > values during iommu creation.    
> > > 
> > > Well, current build_dmar_q35() doesn't do it, because it is using the incorrect value. :)
> > > According to the spec, the host address width is the maximum physical address width,
> > > yet current implementation is using the DMA address width. For me, this is not only
> > > wrong, but also unsecure. For this point, I think we all agree this need to be fixed.
> > > 
> > > As to how to fix it - should we query the cpu fields, I still do not understand why
> > > this is not acceptable. :)
> > > 
> > > I had thought of other approaches before, yet I did not choose:
> > >   
> > > 1> Introduce a new parameter, say, "x-haw-bits" which is used for iommu to limit its    
> > > physical address width(similar to the "x-aw-bits" for IOVA). But what should we check
> > > this parameter or not? What if this parameter is set to sth. different than the "phys-bits"
> > > or not?
> > >   
> > > 2> Another choice I had thought of is, to query the physical iommu. I abandoned this    
> > > idea because my understanding is that vIOMMU is not a passthrued device, it is emulated.  
> >   
> > > So Igor, may I ask why you think checking against the cpu fields so not acceptable? :)  
> > Because accessing private fields of device from another random device is not robust
> > and a subject to breaking in unpredictable manner when field meaning or initialization
> > order changes. (analogy to baremetal: one does not solder wire to a CPU die to let
> > access some piece of data from random device).
> >   
> 
> With either the solution below or the one I proposed, we still
> have a ordering problem: if we want "-cpu ...,phys-bits=..." to
As Michael said, it's questionable if iommu should rely on guest's
phys-bits at all, but that aside we should use proper interfaces
and hierarchy to initialize devices, see below why I dislike
simplistic pc_max_phys_bits().

> affect the IOMMU device, we will need the CPU objects to be
> created before IOMMU realize.
> 
> At least both proposals make the initialization ordering
> explicitly a responsibility of the machine code.  In either case,
> I don't think we will start creating all CPU objects after device
> realize any time soon.
> 
> 
> > I've looked at intel-iommu code and how it's created so here is a way to do the thing
> > you need using proper interfaces:
> > 
> > 1. add x-haw_bits property
> > 2. include in your series patch
> >     '[Qemu-devel] [PATCH] qdev: let machine hotplug handler to override  bus hotplug handler'
> > 3. add your iommu to pc_get_hotpug_handler() to redirect plug flow to
> >    machine and let _pre_plug handler to check and set x-haw_bits for machine level  
> 
> Wow, that's a very complex way to pass a single integer from
> machine code to device code.  If this is the only way to do that,
> we really need to take a step back and rethink our API design.
> 
> What's wrong with having a simple
>   uint32_t pc_max_phys_bits(PCMachineState*)
> function?
As suggested, it would be only aesthetic change for accessing first_cpu from
random device at random time. IOMMU would still access cpu instance directly
no matter how much wrappers one would use so it's still the same hack.
If phys_bits were changing during VM lifecycle and iommu needed to use
updated value then using pc_max_phys_bits() might be justified as
we don't have interfaces to handle that but that's not the case here.

I suggested a typical way (albeit a bit complex) to handle device
initialization in cases where bus plug handler is not sufficient.
It follows proper hierarchy without any layer violations and can fail
gracefully even if we start creating CPUs later using only '-device cpufoo'
without need to fix iommu code to handle that (it would fail creating
iommu with clear error that CPU isn't available and all user have to
do is to fix CLI to make sure that CPU is created before iommu).

So I'd prefer if we used exiting pattern for device initialization
instead of hacks whenever it is possible.

> 
> > 4. you probably can use phys-bits/host-phys-bits properties to get data that you need
> >    also see how ms->possible_cpus, that's how you can get access to CPU from machine
> >    layer.
> >   
> [...]
> 
PS:
Another thing I'd like to draw your attention to (since you recently looked at
phys-bits) is about host/guest phys_bits and if it's safe from migration pov
between hosts with different limits.



