Return-Path: <linux-kernel-owner@vger.kernel.org>
Delivered-To: unknown
Received: from pop3.zju.edu.cn (124.160.105.205:110) by
  likexu-MOBL1.ccr.corp.intel.com with POP3; 09 Nov 2018 00:35:47 -0000
Received: from icoremail.net (unknown [209.85.214.181])
	by mail-app2 (Coremail) with SMTP id by_KCgDHH3pZW+RbzRFhAQ--.29002S3;
	Thu, 08 Nov 2018 23:50:51 +0800 (CST)
Received: from mail-pl1-f181.google.com (unknown [209.85.214.181])
	by mx2.icoremail.net (Coremail) with SMTP id AQAAfwDnvTlYW+RbpHcdAA--.3725S3;
	Thu, 08 Nov 2018 23:50:48 +0800 (CST)
Received: by mail-pl1-f181.google.com with SMTP id c13-v6so9708557plz.13
        for <xuliker@zju.edu.cn>; Thu, 08 Nov 2018 07:50:48 -0800 (PST)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20161025;
        h=x-gm-message-state:delivered-to:dkim-signature:subject:to:cc
         :references:from:message-id:date:user-agent:mime-version:in-reply-to
         :content-transfer-encoding:content-language:sender:precedence
         :list-id;
        bh=qvsywnKTaNkmTB5rK94X0i85wh7E+KsvzX9QsXg834g=;
        b=T+Gfg1U+26AqbS7R7hfrecGssqMdrc7FwD4mYa3fzVopI3NkieelCteDNqHFecW1fz
         OtMzLMTxZGrdIWUDdo9bxsjlRT7XIznnc0yi5YMO5YNf88M9xJpKGSkRDDjwWprh/76U
         5qFV3CB/7RUn9jsO53CQLaHG07FDZEXpIfb5N6fhvQ0NhXNjkXQOQ6ZRmG18W4dGsEFz
         2hdDOt+dJFrc10zNXdEFQ1jMIdHZp/YBUEvU1z86jvpHRWKX7JkiGFwH33ObRzjwjoTj
         owVTEOy8L+lJpbuec50R9U10c3z25TXndyyB1prdcZ3i63P3aeXxnIVzfQCfpeFnZXpO
         S+OQ==
X-Gm-Message-State: AGRZ1gJNux5bk/hcPk8lYjlJL92Hsh1l/Ulb0/IsBzUMuWRKny4lKKwf
	5eK1u/wC60Rs/gKOpylpfb4IOmiprkVA014eMRMHqAI1cz+4uEdnaw==
X-Received: by 2002:a17:902:a5cc:: with SMTP id t12-v6mr5052554plq.298.1541692248291;
        Thu, 08 Nov 2018 07:50:48 -0800 (PST)
X-Forwarded-To: xuliker@zju.edu.cn
X-Forwarded-For: liker.xu@gmail.com xuliker@zju.edu.cn
Delivered-To: liker.xu@gmail.com
Received: by 2002:a17:90a:c304:0:0:0:0 with SMTP id g4-v6csp355169pjt;
        Thu, 8 Nov 2018 07:50:47 -0800 (PST)
X-Google-Smtp-Source: AJdET5e/fkXR628ITUsAG61QX+k6D3zCrSdhMM+dO1LQd9XYKT6JYzDhoROYBghF4RONpzX8tPCY
X-Received: by 2002:a62:1416:: with SMTP id 22-v6mr5117068pfu.114.1541692247399;
        Thu, 08 Nov 2018 07:50:47 -0800 (PST)
ARC-Seal: i=1; a=rsa-sha256; t=1541692247; cv=none;
        d=google.com; s=arc-20160816;
        b=0XxoolgeVoByKr6CAUFax0AJt6MdC/V3ru3jaY0o6CLpdQxpjCCliNSaWiuJmNeqLT
         R0GdcUsU8oB9AKIGmqb4fsXStwOFubNDvieq+uX9jtocLQXB80cQWPV1eRB+uw6txuIq
         vRXTPjSGuMb0ltdaaL1X/fB1AOh4VfwyCICg4itfUg/nQ0qwptDZCkBZG7dxO42RDjo5
         +rYsCuZh8HGBkLJOmDysUEmgZQv+UEKKr5cAhfnLX8LG5yuksFlaziD2LwAmMXVJost8
         ORpmfSIzDH9GL/IzuwTHehO8+WvRUGzCY8N+FarrQI8E0MkOi5fYLRBmCBc92AyXgbk0
         vG7g==
ARC-Message-Signature: i=1; a=rsa-sha256; c=relaxed/relaxed; d=google.com; s=arc-20160816;
        h=list-id:precedence:sender:content-language
         :content-transfer-encoding:in-reply-to:mime-version:user-agent:date
         :message-id:from:references:cc:to:subject:dkim-signature;
        bh=qvsywnKTaNkmTB5rK94X0i85wh7E+KsvzX9QsXg834g=;
        b=VWYCq02K7q7+i+vVc3dQjDXRp/kqLosIInI2F21ZI3IuiIRkBCV/gYkrshuuheCw8E
         B030/6KlakrTHemATWlL0+mo+wjMaGFOsqIU8I6VDTRkHL4jbiN8a/wzaV9dEAC+yR0K
         oxw+YSmDwdWTQFEpITsNk4YU+Wkw5taVHccEpG5I2rxeJZGAe/BiVv3tuuG8ff/m1dza
         PC0R9s8lsDDFkn7ewtRLeTQyXAX0/LDC4Vutc0TNrCoK9CSi5M+lCRbd8CPirFIUTsXW
         8E9w09dCfUFMx3gEwYVF5WBOr8Qpa1q/4YDnWeEXSRzCrwxcTjf6bFabHamPAf4bw6Kr
         5Syw==
ARC-Authentication-Results: i=1; mx.google.com;
       dkim=pass header.i=@gmail.com header.s=20161025 header.b=ebmciQoQ;
       spf=pass (google.com: best guess record for domain of linux-kernel-owner@vger.kernel.org designates 209.132.180.67 as permitted sender) smtp.mailfrom=linux-kernel-owner@vger.kernel.org;
       dmarc=pass (p=NONE sp=QUARANTINE dis=NONE) header.from=gmail.com
Received: from vger.kernel.org (vger.kernel.org. [209.132.180.67])
        by mx.google.com with ESMTP id j128-v6si4665080pfg.238.2018.11.08.07.50.32;
        Thu, 08 Nov 2018 07:50:47 -0800 (PST)
Received-SPF: pass (google.com: best guess record for domain of linux-kernel-owner@vger.kernel.org designates 209.132.180.67 as permitted sender) client-ip=209.132.180.67;
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
        id S1727132AbeKIBZ7 (ORCPT <rfc822;ankurbansal210989@gmail.com>
        + 99 others); Thu, 8 Nov 2018 20:25:59 -0500
Received: from mail-qk1-f195.google.com ([209.85.222.195]:43193 "EHLO
        mail-qk1-f195.google.com" rhost-flags-OK-OK-OK-OK) by vger.kernel.org
        with ESMTP id S1726584AbeKIBZ6 (ORCPT
        <rfc822;linux-kernel@vger.kernel.org>);
        Thu, 8 Nov 2018 20:25:58 -0500
Received: by mail-qk1-f195.google.com with SMTP id r71so27185659qkr.10;
        Thu, 08 Nov 2018 07:49:52 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20161025;
        h=subject:to:cc:references:from:message-id:date:user-agent
         :mime-version:in-reply-to:content-transfer-encoding:content-language;
        bh=qvsywnKTaNkmTB5rK94X0i85wh7E+KsvzX9QsXg834g=;
        b=ebmciQoQkGdGUTjpM0HKjGqvQz7TYlh1MmnHBssylBwHMPV5jpNj1MKFrnjwqFRfkR
         3vurzsyQj3K0ALEMU9uh3k2UNDeT9sfitNRVVtmlrLHsL5Dhw2JhdRGshrRN9W1imaFS
         RG8BwUnMCrmxAsWGHvFeZjE5Q3aF1C2u8Bp674uWkh5k+hBgo1MOrYrO02kOVP8VNlHc
         cbacdwhrMKkHcnvmjbdcorM4atEf70fV86B05OSp/pDvykmy+sVgOg/ft7W+HPQ1zB+7
         cZBrcE0RcrSv5ZiX1rcO43bHuUSZZSIJEiowUBFFCEYWS1KjwgJZSSJ3v7w3z94ZLRFp
         nB7g==
X-Received: by 2002:ac8:7644:: with SMTP id i4mr4863216qtr.293.1541692191912;
        Thu, 08 Nov 2018 07:49:51 -0800 (PST)
Received: from llong.remote.csb (nat-pool-bos-t.redhat.com. [66.187.233.206])
        by smtp.gmail.com with ESMTPSA id v3-v6sm3159361qth.74.2018.11.08.07.49.50
        (version=TLS1_2 cipher=ECDHE-RSA-AES128-GCM-SHA256 bits=128/128);
        Thu, 08 Nov 2018 07:49:51 -0800 (PST)
Subject: Re: [PATCH v5 4/5] sched/core: Prevent race condition between cpuset
 and __sched_setscheduler()
To: Juri Lelli <juri.lelli@redhat.com>,
        Steven Rostedt <rostedt@goodmis.org>
Cc: peterz@infradead.org, mingo@redhat.com,
        linux-kernel@vger.kernel.org, luca.abeni@santannapisa.it,
        claudio@evidence.eu.com, tommaso.cucinotta@santannapisa.it,
        bristot@redhat.com, mathieu.poirier@linaro.org, lizefan@huawei.com,
        cgroups@vger.kernel.org
References: <20180903142801.20046-1-juri.lelli@redhat.com>
 <20180903142801.20046-5-juri.lelli@redhat.com>
 <20181003154230.4b8792fb@gandalf.local.home>
 <20181004090401.GB12774@localhost.localdomain>
From: Waiman Long <longman9394@gmail.com>
Message-ID: <16587a21-ed6e-809d-78a8-5f76d1787665@gmail.com>
Date: Thu, 8 Nov 2018 10:49:49 -0500
User-Agent: Mozilla/5.0 (X11; Linux x86_64; rv:52.0) Gecko/20100101
 Thunderbird/52.9.1
MIME-Version: 1.0
In-Reply-To: <20181004090401.GB12774@localhost.localdomain>
Content-Type: text/plain; charset=utf-8
Content-Transfer-Encoding: 7bit
Content-Language: en-US
Sender: liker.xu+caf_=xuliker=zju.edu.cn@gmail.com
Precedence: bulk
List-ID: <linux-kernel.vger.kernel.org>
X-Mailing-List: linux-kernel@vger.kernel.org
X-CM-TRANSID: AQAAfwDnvTlYW+RbpHcdAA--.3725S3
Authentication-Results: mail-app2; spf=pass smtp.mail=liker.xu+caf_=xu
	liker=zju.edu.cn@gmail.com;
X-Coremail-Antispam: 1UD129KBjvJXoW3Gw4ftry3ArWkZFykuF4fAFb_yoW7Ar45pF
	yqgFy3JF1UXrn7uwnIqw1UuFyrKws5KF17Gr1xGr15Zr9IyF1vkFyDWFnIqryjyr43CF1j
	krZFk3yfuF1DtFDanT9S1TB71UUUUUUqnTZGkaVYY2UrUUUUjbIjqfuFe4nvWSU8nxnvy2
	9KBjDU0xBIdaVrnRJUUUPab7Iv0xC_tr1lb4IE77IF4wAFF20E14v26r1j6r4UM7CIcVAF
	z4kK6r1j6r18M28lY4IEw2IIxxk0rwA2F7IY1VAKz4vEj48ve4kI8wA2z4x0Y4vE2Ix0cI
	8IcVAFwI0_Ar0_tr1l84ACjcxK6xIIjxv20xvEc7CjxVAFwI0_Cr0_Gr1UM28EF7xvwVC2
	z280aVAFwI0_GcCE3s1l84ACjcxK6I8E87Iv6xkF7I0E14v26rxl6s0DM2vYz4IE04k24V
	AvwVAKI4IrM2AIxVAIcxkEcVAq07x20xvEncxIr21l5I8CrVACY4xI64kE6c02F40Ex7xf
	McIj6xIIjxv20xvE14v26r1j6r18McIj6I8E87Iv67AKxVW8JVWxJwAm72CE4IkC6x0Yz7
	v_Jr0_Gr1lF7xvr2IY64vIr41l7I0Y6sxI4wCYjI0SjxkI62AI1cAE67vIY487MxkF7I0E
	w4C26cxK6c8Ij28IcwCY0x0Ix7I2Y4AK64vIr41lcIIF0xvE2Ix0cI8IcVAFwI0_Xr0_Ar
	1lcIIF0xvE2Ix0cI8IcVCY1x0267AKxVW8JVWxJwCYIxAIcVC2z280aVAFwI0_GcCE3s1l
	cIIF0xvEx4A2jsIEc7CjxVAFwI0_GcCE3s1l42xK82IYc2Ij64vIr41l42xK82IY64kExV
	AvwVAq07x20xyl4x8a6x804xWl4I8I3I0E4IkC6x0Yz7v_Jr0_Gr1lx2IqxVAqx4xG67AK
	xVWUJVWUGwC20s026x8GjcxK67AKxVWUGVWUWwC2zVAF1VAY17CE14v26r1q6r43MIIYrx
	kI7VAKI48JMIIF0xvE42xK8VAvwI8IcIk0rVW8JVW3JbIYCTnIWIevJa73UjIFyTuYvjxU
	fTanUUUUU

On 10/04/2018 05:04 AM, Juri Lelli wrote:
> On 03/10/18 15:42, Steven Rostedt wrote:
>> On Mon,  3 Sep 2018 16:28:00 +0200
>> Juri Lelli <juri.lelli@redhat.com> wrote:
>>
>>
>>> diff --git a/kernel/cgroup/cpuset.c b/kernel/cgroup/cpuset.c
>>> index 5b43f482fa0f..8dc26005bb1e 100644
>>> --- a/kernel/cgroup/cpuset.c
>>> +++ b/kernel/cgroup/cpuset.c
>>> @@ -2410,6 +2410,24 @@ void __init cpuset_init_smp(void)
>>>  	BUG_ON(!cpuset_migrate_mm_wq);
>>>  }
>>>  
>>> +/**
>>> + * cpuset_read_only_lock - Grab the callback_lock from another subsysytem
>>> + *
>>> + * Description: Gives the holder read-only access to cpusets.
>>> + */
>>> +void cpuset_read_only_lock(void)
>>> +{
>>> +	raw_spin_lock(&callback_lock);
>> This was confusing to figure out why grabbing a spinlock gives read
>> only access. So I read the long comment above the definition of
>> callback_lock. A couple of notes.
>>
>> 1) The above description needs to go into more detail as to why
>> grabbing a spinlock is "read only".
>>
>> 2) The comment above the callback_lock needs to incorporate this, as
>> reading that comment alone will not give anyone an idea that this
>> exists.
> Right, does the updated version below look any better?
>
> Thanks for reviewing!
>
> Best,
>
> - Juri
>
> --->8---
> From d704536ba80a01116007024ec055efcc4a9ee558 Mon Sep 17 00:00:00 2001
> From: Mathieu Poirier <mathieu.poirier@linaro.org>
> Date: Thu, 23 Aug 2018 14:52:13 +0200
> Subject: [PATCH v5 4/5] sched/core: Prevent race condition between cpuset and
>  __sched_setscheduler()
>
> No synchronisation mechanism exists between the cpuset subsystem and calls
> to function __sched_setscheduler(). As such, it is possible that new root
> domains are created on the cpuset side while a deadline acceptance test
> is carried out in __sched_setscheduler(), leading to a potential oversell
> of CPU bandwidth.
>
> Grab callback_lock from core scheduler, so to prevent situations such as
> the one described above from happening.
>
> Signed-off-by: Mathieu Poirier <mathieu.poirier@linaro.org>
> Signed-off-by: Juri Lelli <juri.lelli@redhat.com>
>
> ---
>
> v4->v5: grab callback_lock instead of cpuset_mutex, as callback_lock is
> enough to get read-only access to cpusets [1] and it can be easily
> converted to be a raw_spinlock (done in previous - new - patch).
>
> [1] https://elixir.bootlin.com/linux/latest/source/kernel/cgroup/cpuset.c#L275
> ---
>  include/linux/cpuset.h |  6 ++++++
>  kernel/cgroup/cpuset.c | 25 ++++++++++++++++++++++++-
>  kernel/sched/core.c    | 10 ++++++++++
>  3 files changed, 40 insertions(+), 1 deletion(-)
>
> diff --git a/include/linux/cpuset.h b/include/linux/cpuset.h
> index 934633a05d20..8e5a8dd0622b 100644
> --- a/include/linux/cpuset.h
> +++ b/include/linux/cpuset.h
> @@ -55,6 +55,8 @@ extern void cpuset_init_smp(void);
>  extern void cpuset_force_rebuild(void);
>  extern void cpuset_update_active_cpus(void);
>  extern void cpuset_wait_for_hotplug(void);
> +extern void cpuset_read_only_lock(void);
> +extern void cpuset_read_only_unlock(void);
>  extern void cpuset_cpus_allowed(struct task_struct *p, struct cpumask *mask);
>  extern void cpuset_cpus_allowed_fallback(struct task_struct *p);
>  extern nodemask_t cpuset_mems_allowed(struct task_struct *p);
> @@ -176,6 +178,10 @@ static inline void cpuset_update_active_cpus(void)
>  
>  static inline void cpuset_wait_for_hotplug(void) { }
>  
> +static inline void cpuset_read_only_lock(void) { }
> +
> +static inline void cpuset_read_only_unlock(void) { }
> +
>  static inline void cpuset_cpus_allowed(struct task_struct *p,
>  				       struct cpumask *mask)
>  {
> diff --git a/kernel/cgroup/cpuset.c b/kernel/cgroup/cpuset.c
> index 5b43f482fa0f..bff72b920624 100644
> --- a/kernel/cgroup/cpuset.c
> +++ b/kernel/cgroup/cpuset.c
> @@ -273,7 +273,8 @@ static struct cpuset top_cpuset = {
>   * __alloc_pages().
>   *
>   * If a task is only holding callback_lock, then it has read-only
> - * access to cpusets.
> + * access to cpusets. Mind that callback_lock might be grabbed from other
> + * subsystems as well (via cpuset_read_only_lock()).
>   *
>   * Now, the task_struct fields mems_allowed and mempolicy may be changed
>   * by other task, we use alloc_lock in the task_struct fields to protect
> @@ -2410,6 +2411,28 @@ void __init cpuset_init_smp(void)
>  	BUG_ON(!cpuset_migrate_mm_wq);
>  }
>  
> +/**
> + * cpuset_read_only_lock - Grab the callback_lock from cpuset subsystem.
> + *
> + * Description: As described in full details the comment above cpuset_mutex
> + * and callback_lock definitions, holding callback_lock gives the holder
> + * read-only access to cpusets. Even though it might look counter-intuitive
> + * (as callback_lock is a spinlock), in fact a task must hold both
> + * callback_lock _and_ cpuset_mutex to modify cpusets (write access).
> + */
> +void cpuset_read_only_lock(void)
> +{
> +	raw_spin_lock(&callback_lock);
> +}
> +
> +/**
> + * cpuset_read_only_unlock - Release the callback_lock from cpuset subsystem.
> + */
> +void cpuset_read_only_unlock(void)
> +{
> +	raw_spin_unlock(&callback_lock);
> +}
> +

Maybe you can drop the "_only" part to be consistent with the rwlock
APIs (read_lock/write_lock).

Cheers,
Longman
