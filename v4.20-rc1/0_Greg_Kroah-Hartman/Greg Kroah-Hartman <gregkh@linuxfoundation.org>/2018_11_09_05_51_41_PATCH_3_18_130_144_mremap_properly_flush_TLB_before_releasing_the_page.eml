Return-Path: <linux-kernel-owner@vger.kernel.org>
Delivered-To: unknown
Received: from pop3.zju.edu.cn (124.160.105.205:110) by
  likexu-MOBL1.ccr.corp.intel.com with POP3; 09 Nov 2018 00:38:24 -0000
Received: from icoremail.net (unknown [209.85.214.177])
	by mail-app2 (Coremail) with SMTP id by_KCgC3f9GPseRbw95iAQ--.29786S3;
	Fri, 09 Nov 2018 05:58:40 +0800 (CST)
Received: from mail-pl1-f177.google.com (unknown [209.85.214.177])
	by mx2.icoremail.net (Coremail) with SMTP id AQAAfwCXekaNseRbAtgeAA--.6171S3;
	Fri, 09 Nov 2018 05:58:37 +0800 (CST)
Received: by mail-pl1-f177.google.com with SMTP id o19-v6so10151728pll.12
        for <xuliker@zju.edu.cn>; Thu, 08 Nov 2018 13:58:37 -0800 (PST)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20161025;
        h=x-gm-message-state:delivered-to:dkim-signature:from:to:cc:subject
         :date:message-id:in-reply-to:references:user-agent:mime-version
         :content-transfer-encoding:sender:precedence:list-id;
        bh=uTQlB0sZboqxoxz9/kg6BHxJTbHDcNjpJz5F5cGEnLM=;
        b=dQq7weyI24uZkiHTJBoHjqxzBP/LBnv9TyXbK0OvorpnWHFmHR/aqfJEZq/OwGnDwC
         CMpKFpaapM5QQ/c2RKGmEP9GF1RKzqUTjJinG3c4Xu/X2rdAsy8kK6pVLj+gGCyk/YRy
         E8suY+CrGG7FnbUdps8W9a0wBxea5KYu75Ii0uM7gemh22T0i2f44SW8IbCywXrOaqAa
         BCDq+XzMlS6pNYGoYvB/i9nc6+4eSX49bOGtWZF5gpQWbatY1LxsOL4PmT46EuDdtPv/
         PVDm5Gt1hh9xmZ5MSotjVKBCa+jncGLc5og/vSVGdikA8nyINQyC9YKM1Q1dGP/gpNZV
         3dAA==
X-Gm-Message-State: AGRZ1gIT/7Ys7T0gV9aXjtOHUFiLLQIlgxjGnUpQ7k4Aoe/OK2zVag7Q
	/eUEsKXZVGrQ8TPGBwH04Dhw2Z8tDv04stSnsjR7SbCsHL6fLWbaMw==
X-Received: by 2002:a17:902:560f:: with SMTP id h15-v6mr3027012pli.160.1541714317286;
        Thu, 08 Nov 2018 13:58:37 -0800 (PST)
X-Forwarded-To: xuliker@zju.edu.cn
X-Forwarded-For: liker.xu@gmail.com xuliker@zju.edu.cn
Delivered-To: liker.xu@gmail.com
Received: by 2002:a17:90a:c304:0:0:0:0 with SMTP id g4-v6csp777754pjt;
        Thu, 8 Nov 2018 13:58:35 -0800 (PST)
X-Google-Smtp-Source: AJdET5dS8b17I+gUXa+4ggFOa8DD//rP0t6sZ0j09ahxyP6gR32fIl+mmth4ZyZERBngiTY5Ogml
X-Received: by 2002:a63:e749:: with SMTP id j9-v6mr5127742pgk.246.1541714315716;
        Thu, 08 Nov 2018 13:58:35 -0800 (PST)
ARC-Seal: i=1; a=rsa-sha256; t=1541714315; cv=none;
        d=google.com; s=arc-20160816;
        b=OBV9BoEaF+SUUL6Mcyzost5W+XMaPB6jnVaedrWyJQ8PC+FF3b33vjMVFZDV7Ubk7r
         Xk8/E4mcE5L2gML5FrRLD1/CmXfGYZUVQ0WW+vNANCCNQqALujtCJ0foUjpWmE2aLTli
         7EOxApp1oiBC2nHzMftrIQKg8UDOM78MQ4BXAWA1zLdETUti319JhPGSW6lr28APjcie
         E0wK8MDzefEIppSy/ksz03UeRd3Zdm/mcgPeuF+Ln0ST0I9TkKf7ToTx07+5Frhvb+yu
         +9Q0fiZ1NmyXpirL4KZLc63TFY23Nr90sTFKA8s+MR649+SfMyknE3QQGdunldO3q/LK
         N/hg==
ARC-Message-Signature: i=1; a=rsa-sha256; c=relaxed/relaxed; d=google.com; s=arc-20160816;
        h=list-id:precedence:sender:content-transfer-encoding:mime-version
         :user-agent:references:in-reply-to:message-id:date:subject:cc:to
         :from:dkim-signature;
        bh=uTQlB0sZboqxoxz9/kg6BHxJTbHDcNjpJz5F5cGEnLM=;
        b=B7EmIVlg9vr6Gp1SirxL7s4CMopoQT4/M08cie5TpKGvAR3IdHEOrsDU7/C62Zk4WS
         /gyBNg/RcHGwsGC8DYi/yAVKU+lp+ZqlNlQUJSnM+QQFTsILzsFQs40J1aBl6wlijw0H
         dtpR7cOpP7b/jtBKDNqyCYaoy46kaDa8w5q4VDE+h1ebpLttFPhRbMvNOclD+O+vU+lm
         4hg0KgpljFBPVcE9Co+TwBHb/kz5My/XIiZ5iVrum8y3tFym+/mL8ru+YPx3iDDO0qF9
         pScB5TYwi+si0OCwwGUTlIwuh7pF8aal2PBbS1UldEdSPCzSLahIYFn/+LMJmdZKn7Dq
         SqeA==
ARC-Authentication-Results: i=1; mx.google.com;
       dkim=pass header.i=@kernel.org header.s=default header.b=Snsq0ZLf;
       spf=pass (google.com: best guess record for domain of linux-kernel-owner@vger.kernel.org designates 209.132.180.67 as permitted sender) smtp.mailfrom=linux-kernel-owner@vger.kernel.org
Received: from vger.kernel.org (vger.kernel.org. [209.132.180.67])
        by mx.google.com with ESMTP id j14si4813070pgi.354.2018.11.08.13.58.21;
        Thu, 08 Nov 2018 13:58:35 -0800 (PST)
Received-SPF: pass (google.com: best guess record for domain of linux-kernel-owner@vger.kernel.org designates 209.132.180.67 as permitted sender) client-ip=209.132.180.67;
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
        id S1729494AbeKIHeu (ORCPT <rfc822;tu.k.phung@gmail.com>
        + 99 others); Fri, 9 Nov 2018 02:34:50 -0500
Received: from mail.kernel.org ([198.145.29.99]:51422 "EHLO mail.kernel.org"
        rhost-flags-OK-OK-OK-OK) by vger.kernel.org with ESMTP
        id S1726926AbeKIHeq (ORCPT <rfc822;linux-kernel@vger.kernel.org>);
        Fri, 9 Nov 2018 02:34:46 -0500
Received: from localhost (unknown [208.72.13.198])
        (using TLSv1.2 with cipher ECDHE-RSA-AES256-GCM-SHA384 (256/256 bits))
        (No client certificate requested)
        by mail.kernel.org (Postfix) with ESMTPSA id EC81C20989;
        Thu,  8 Nov 2018 21:57:17 +0000 (UTC)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/simple; d=kernel.org;
        s=default; t=1541714238;
        bh=K+2Iq0G/k3IXzsQ0SAXDVcx3jT80DMv1XTVuijL7ZdM=;
        h=From:To:Cc:Subject:Date:In-Reply-To:References:From;
        b=Snsq0ZLfdJf+tqKgiNVU66Nzmy7QqQj5rrEbhVoKublh00yxAhk2UDZ/ceWU+bsiu
         hqMU/f1Y7ooVr5Unc2x2oup3bLBXbFr9hnMLvadQau0/Q0tt5/YVhUCZ5thXeGbmHT
         RVQzvSqJemDi10v19P4wxVC7Bz4Jhad4DB7AkugU=
From: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
To: linux-kernel@vger.kernel.org, stable@vger.kernel.org
Cc: Greg Kroah-Hartman <gregkh@linuxfoundation.org>,
        Will Deacon <will.deacon@arm.com>,
        Ingo Molnar <mingo@kernel.org>,
        "Peter Zijlstra (Intel)" <peterz@infradead.org>,
        Linus Torvalds <torvalds@linux-foundation.org>,
        Greg Hackmann <ghackmann@google.com>
Subject: [PATCH 3.18 130/144] mremap: properly flush TLB before releasing the page
Date: Thu,  8 Nov 2018 13:51:41 -0800
Message-Id: <20181108215107.526160296@linuxfoundation.org>
X-Mailer: git-send-email 2.19.1
In-Reply-To: <20181108215054.826084593@linuxfoundation.org>
References: <20181108215054.826084593@linuxfoundation.org>
User-Agent: quilt/0.65
X-stable: review
MIME-Version: 1.0
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: 8bit
Sender: liker.xu+caf_=xuliker=zju.edu.cn@gmail.com
Precedence: bulk
List-ID: <linux-kernel.vger.kernel.org>
X-Mailing-List: linux-kernel@vger.kernel.org
X-CM-TRANSID: AQAAfwCXekaNseRbAtgeAA--.6171S3
Authentication-Results: mail-app2; spf=pass smtp.mail=liker.xu+caf_=xu
	liker=zju.edu.cn@gmail.com;
X-Coremail-Antispam: 1UD129KBjvJXoWxGrWUWrWxGw43Gw47AFyxXwb_yoW7JFW5pa
	yfKa9xKr4DJr48Gr18Xr1q9ry5Ww4I9ay8A345tFsY9F1aqrWagFW3JFZ5AF90gFZ7AF43
	JFWjgF1kGayjq37anT9S1TB71UUUUUUqnTZGkaVYY2UrUUUU0bIjqfuFe4nvWSU8nxnvy2
	9KBjDU0xBIdaVrnRJUUUPab7Iv0xC_Kw4lb4IE77IF4wAFF20E14v26r1j6r4UM7CIcVAF
	z4kK6r1j6r18M28lY4IEw2IIxxk0rwA2F7IY1VAKz4vEj48ve4kI8wA2z4x0Y4vE2Ix0cI
	8IcVAFwI0_Ar0_tr1l84ACjcxK6xIIjxv20xvEc7CjxVAFwI0_Cr0_Gr1UM28EF7xvwVC2
	z280aVAFwI0_GcCE3s1l84ACjcxK6I8E87Iv6xkF7I0E14v26rxl6s0DM2AIxVAIcxkEcV
	Aq07x20xvEncxIr21l5I8CrVACY4xI64kE6c02F40Ex7xfMcIj6xIIjxv20xvE14v26r1j
	6r18McIj6I8E87Iv67AKxVW8JVWxJwAm72CE4IkC6x0Yz7v_Jr0_Gr1lF7xvr2IYc2Ij64
	vIr41l7I0Y6sxI4wCY1x0264kExVAvwVAq07x20xylc7Ca8VAvwVCFzxkY4VCF77xAMxkI
	ecxEwVCI4VWxMxkI7II2jI8vz4vEwIxGrwCYIxAIcVC0I7IYx2IY67AKxVW7JVWDJwCYIx
	AIcVC0I7IYx2IY6xkF7I0E14v26r4j6F4UMxvI42IY6I8E87Iv67AKxVW8Jr0_Cr1UMxvI
	42IY6I8E87Iv6xkF7I0E14v26r4UJVWxJr1l42xK82IYc2Ij64vIr41l42xK82IY64kExV
	AvwVAq07x20xyl4x8a6x804xWl4I8I3I0E4IkC6x0Yz7v_Jr0_Gr1lx2IqxVAqx4xG67AK
	xVWUJVWUGwC20s026x8GjcxK67AKxVWUGVWUWwC2zVAF1VAY17CE14v26r1q6r43MIIYrx
	kI7VAKI48JMIIF0xvE42xK8VAvwI8IcIk0rVWUCVW8JbIYCTnIWIevJa73UjIFyTuYvjxU
	djQDDUUUU

3.18-stable review patch.  If anyone has any objections, please let me know.

------------------

From: Linus Torvalds <torvalds@linux-foundation.org>

Commit eb66ae030829605d61fbef1909ce310e29f78821 upstream.

This is a backport to stable 3.18.y, based on Will Deacon's 4.4.y
backport.

Jann Horn points out that our TLB flushing was subtly wrong for the
mremap() case.  What makes mremap() special is that we don't follow the
usual "add page to list of pages to be freed, then flush tlb, and then
free pages".  No, mremap() obviously just _moves_ the page from one page
table location to another.

That matters, because mremap() thus doesn't directly control the
lifetime of the moved page with a freelist: instead, the lifetime of the
page is controlled by the page table locking, that serializes access to
the entry.

As a result, we need to flush the TLB not just before releasing the lock
for the source location (to avoid any concurrent accesses to the entry),
but also before we release the destination page table lock (to avoid the
TLB being flushed after somebody else has already done something to that
page).

This also makes the whole "need_flush" logic unnecessary, since we now
always end up flushing the TLB for every valid entry.

Reported-and-tested-by: Jann Horn <jannh@google.com>
Acked-by: Will Deacon <will.deacon@arm.com>
Tested-by: Ingo Molnar <mingo@kernel.org>
Acked-by: Peter Zijlstra (Intel) <peterz@infradead.org>
Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
[will: backport to 4.4 stable]
Signed-off-by: Will Deacon <will.deacon@arm.com>
[ghackmann@google.com: adjust context]
Signed-off-by: Greg Hackmann <ghackmann@google.com>
Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

---
 mm/huge_memory.c |    6 +++++-
 mm/mremap.c      |   21 ++++++++++++++++-----
 2 files changed, 21 insertions(+), 6 deletions(-)

--- a/mm/huge_memory.c
+++ b/mm/huge_memory.c
@@ -1462,7 +1462,7 @@ int move_huge_pmd(struct vm_area_struct
 	spinlock_t *old_ptl, *new_ptl;
 	int ret = 0;
 	pmd_t pmd;
-
+	bool force_flush = false;
 	struct mm_struct *mm = vma->vm_mm;
 
 	if ((old_addr & ~HPAGE_PMD_MASK) ||
@@ -1490,6 +1490,8 @@ int move_huge_pmd(struct vm_area_struct
 		if (new_ptl != old_ptl)
 			spin_lock_nested(new_ptl, SINGLE_DEPTH_NESTING);
 		pmd = pmdp_get_and_clear(mm, old_addr, old_pmd);
+		if (pmd_present(pmd))
+			force_flush = true;
 		VM_BUG_ON(!pmd_none(*new_pmd));
 
 		if (pmd_move_must_withdraw(new_ptl, old_ptl)) {
@@ -1498,6 +1500,8 @@ int move_huge_pmd(struct vm_area_struct
 			pgtable_trans_huge_deposit(mm, new_pmd, pgtable);
 		}
 		set_pmd_at(mm, new_addr, new_pmd, pmd_mksoft_dirty(pmd));
+		if (force_flush)
+			flush_tlb_range(vma, old_addr, old_addr + PMD_SIZE);
 		if (new_ptl != old_ptl)
 			spin_unlock(new_ptl);
 		spin_unlock(old_ptl);
--- a/mm/mremap.c
+++ b/mm/mremap.c
@@ -97,6 +97,8 @@ static void move_ptes(struct vm_area_str
 	struct mm_struct *mm = vma->vm_mm;
 	pte_t *old_pte, *new_pte, pte;
 	spinlock_t *old_ptl, *new_ptl;
+	bool force_flush = false;
+	unsigned long len = old_end - old_addr;
 
 	/*
 	 * When need_rmap_locks is true, we take the i_mmap_mutex and anon_vma
@@ -143,12 +145,26 @@ static void move_ptes(struct vm_area_str
 		if (pte_none(*old_pte))
 			continue;
 		pte = ptep_get_and_clear(mm, old_addr, old_pte);
+		/*
+		 * If we are remapping a valid PTE, make sure
+		 * to flush TLB before we drop the PTL for the PTE.
+		 *
+		 * NOTE! Both old and new PTL matter: the old one
+		 * for racing with page_mkclean(), the new one to
+		 * make sure the physical page stays valid until
+		 * the TLB entry for the old mapping has been
+		 * flushed.
+		 */
+		if (pte_present(pte))
+			force_flush = true;
 		pte = move_pte(pte, new_vma->vm_page_prot, old_addr, new_addr);
 		pte = move_soft_dirty_pte(pte);
 		set_pte_at(mm, new_addr, new_pte, pte);
 	}
 
 	arch_leave_lazy_mmu_mode();
+	if (force_flush)
+		flush_tlb_range(vma, old_end - len, old_end);
 	if (new_ptl != old_ptl)
 		spin_unlock(new_ptl);
 	pte_unmap(new_pte - 1);
@@ -168,7 +184,6 @@ unsigned long move_page_tables(struct vm
 {
 	unsigned long extent, next, old_end;
 	pmd_t *old_pmd, *new_pmd;
-	bool need_flush = false;
 	unsigned long mmun_start;	/* For mmu_notifiers */
 	unsigned long mmun_end;		/* For mmu_notifiers */
 
@@ -207,7 +222,6 @@ unsigned long move_page_tables(struct vm
 					anon_vma_unlock_write(vma->anon_vma);
 			}
 			if (err > 0) {
-				need_flush = true;
 				continue;
 			} else if (!err) {
 				split_huge_page_pmd(vma, old_addr, old_pmd);
@@ -224,10 +238,7 @@ unsigned long move_page_tables(struct vm
 			extent = LATENCY_LIMIT;
 		move_ptes(vma, old_pmd, old_addr, old_addr + extent,
 			  new_vma, new_pmd, new_addr, need_rmap_locks);
-		need_flush = true;
 	}
-	if (likely(need_flush))
-		flush_tlb_range(vma, old_end-len, old_addr);
 
 	mmu_notifier_invalidate_range_end(vma->vm_mm, mmun_start, mmun_end);
 

