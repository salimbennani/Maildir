Return-Path: <linux-kernel-owner@vger.kernel.org>
Delivered-To: unknown
Received: from linux.intel.com (10.54.29.200:995) by likexu-workstation with
  POP3-SSL; 30 Nov 2018 08:49:59 -0000
X-Original-To: like.xu@linux.intel.com
Delivered-To: like.xu@linux.intel.com
Received: from orsmga002.jf.intel.com (orsmga002.jf.intel.com [10.7.209.21])
	(using TLSv1.2 with cipher ECDHE-RSA-AES256-GCM-SHA384 (256/256 bits))
	(No client certificate requested)
	by linux.intel.com (Postfix) with ESMTPS id 8398D580213;
	Thu, 29 Nov 2018 10:55:15 -0800 (PST)
Received: from fmsmga105.fm.intel.com ([10.1.193.10])
  by orsmga002-1.jf.intel.com with ESMTP/TLS/DHE-RSA-AES256-GCM-SHA384; 29 Nov 2018 10:55:15 -0800
X-SG-BADATTACHMENTNOREPLY: True
IronPort-PHdr: =?us-ascii?q?9a23=3A1f6axREFEcteKx2a4Zq0xJ1GYnF86YWxBRYc798d?=
 =?us-ascii?q?s5kLTJ75o8m9bnLW6fgltlLVR4KTs6sC17KG9fi4EUU7or+5+EgYd5JNUxJXwe?=
 =?us-ascii?q?43pCcHRPC/NEvgMfTxZDY7FskRHHVs/nW8LFQHUJ2mPw6arXK99yMdFQviPgRp?=
 =?us-ascii?q?OOv1BpTSj8Oq3Oyu5pHfeQpFiCa+bL9oMBm6sRjau9ULj4dlNqs/0AbCrGFSe+?=
 =?us-ascii?q?RRy2NoJFaTkAj568yt4pNt8Dletuw4+cJYXqr0Y6o3TbpDDDQ7KG81/9HktQPC?=
 =?us-ascii?q?TQSU+HQRVHgdnwdSDAjE6BH6WYrxsjf/u+Fg1iSWIdH6QLYpUjm58axlVAHnhz?=
 =?us-ascii?q?sGNz4h8WHYlMpwjL5AoBm8oxBz2pPYbJ2JOPZ7eK7WYNEUSndbXstJWCNBDIGz?=
 =?us-ascii?q?YYsBAeQCIOhWsZXyqVQVrRumBwShH//vyiZSi3PqwaE2z+YsHAfb1wIgBdIOt3?=
 =?us-ascii?q?HUoc3vOqgIT+C60q3IxijeYfNW2Df97I/Icg46ofGPXbN7bM3cyVEuFwzflVWQ?=
 =?us-ascii?q?tZblPjOV1+UNqGWb4O9gWviui24jsQ1+vj+vxsI1h4TPm4kbyUjE+D1nzIopId?=
 =?us-ascii?q?C0UlN3bNC6HJdKqi2XNJd6TtkjTmxqoCo21KEKtJqhcCUJyJkr3QPTZv2FfoSS?=
 =?us-ascii?q?4x/uVeCcKipiin1/YrKwnROy/FCgyuLiUsm0105HrjRKktbSrHABzR/T5dadSv?=
 =?us-ascii?q?t74Eih3SyD1wfJ6uFLOUw0lKzbJIA9wrMoiJYfrUDOEjXrlEj4kqOabFgo9+u0?=
 =?us-ascii?q?5+j9Y7jrpIeQN4puhQH/NqQulNa/AeM9MgUWW2ib+OK81KDs/EHgQ7VFkOc2kq?=
 =?us-ascii?q?/Hv5DePMgboaC4AwlL3YY58Bu/ETim38oCnXUdL1JKZgiHj473NFHKOvz4Cu2/?=
 =?us-ascii?q?g1u0nDdx2//GJqHhAonKLnXblLfhfLV95FBGxAs80NBS/JZUCrAHIPLuVU79rt?=
 =?us-ascii?q?3YDhklMwOqx+brEsly1oQbWWiXGK+WLLvSsUOU5uIoO+SMZJUauDfhK/c/4P7i?=
 =?us-ascii?q?l385mUIHcqmv0psac3S4HvVgI0WEbnvgmNYBEWEWvgUgSOzmkkGNUTlWZ3yqRa?=
 =?us-ascii?q?Iz+ik7CJ66DYfEXo2tgruB0zmhEp1VYWBGDFaMEXDzeoWAWvcMbj+SI8B7njwF?=
 =?us-ascii?q?U7ihV5Eu1RW0uADmzLpnK/Le+jcEupL7yNh1++rTmAko+jxvD8Sd1GKNQ3tunm?=
 =?us-ascii?q?wSRT87x6R/oU17ylee3ql0mf1YFdpP5/xXVgc2L4LTz+t/C9rqQALOYs+JSEq6?=
 =?us-ascii?q?QtWhGTwxTcg+w9kUb0Z5GtWtlBbD3yWxDr8RlryLAoE0863G03jwIcZ912jJ1K?=
 =?us-ascii?q?07g1Y6RctPMHWshrRj+AjLG47Jj0KZmr63eqsGwi7C6n2PzWqUs0FeSw5/T6PF?=
 =?us-ascii?q?UXcbZkvVqNT54ljPT7uvCbQhLwtAxtSOKqpMat31k1pGQO3vN8jZY2K0g22wHw?=
 =?us-ascii?q?qHxquQbIr2fGUQxDjSB1Iakw8N53qGNRIxBiG6o23ACjxjDlbvY0Lq8eljp3K3?=
 =?us-ascii?q?VE40zweWb0J/07q54AIahfuZS/kLxLILpD8hqyloHFa6x9/WF9uApw9mfKVAYd?=
 =?us-ascii?q?M84E1L1X7Duwx6JJygK6FihlgRcwlsu0Pu1hN3CphPkMQwrXMqyhZyJryc0F9b?=
 =?us-ascii?q?azyY2pXwMKXNKmbu5BCvd7LW2lbG3dmM/qcA9vs5pEvjvQ2zDUUi7mho3MNT03?=
 =?us-ascii?q?uf4ZXKEhEfUZbwUkYx6hh7qKvWYig754PIy3JsNbO4vSPF29IsHOEl0Aqvf89D?=
 =?us-ascii?q?MKOYEw//C80bB9W0JOM2gVSobxIEM/pU9K47JM6mc/qG2Ki2POdvhj6mjGJH4J?=
 =?us-ascii?q?xj3UKI7SZzVunI35MdyfGCwgSHTyv8jEumss3vg4BEZC0dEXClySf5A45dfKty?=
 =?us-ascii?q?cpgRCWevOsG42s9xh5rwVHFG7l6jAFUG1dSteRqTaVz9wAJR2V4WoXyhhSu30T?=
 =?us-ascii?q?h0nys1oaqY2SzE2/7iewYfOm5XWGliik/hIIi1j9wAXEmkdRMplAaj5Uvhw6hb?=
 =?us-ascii?q?paJ/L3TcQEtSfij2KX1iXbW0traYf8FP75Youz1NUOugeVCaVqL9oxwC3iPhBW?=
 =?us-ascii?q?Re3jM7dzKtupnjhBx1kmGdLHVyrHrfZ85wwwzS5NjdRf5XwzoHSzN0iTjRBlig?=
 =?us-ascii?q?Idap+c+YmIvEsuC7T2ihTIFccTH3zYOcsyu2/W1rDge4n/ypmN3nEA463DT/19?=
 =?us-ascii?q?lrUyXIsRn9bpPq16S8LeJoYE1oCEXg5Mp9H4F0ipEwi40I2XgGmpWV+mIKkWTp?=
 =?us-ascii?q?PtVaw67+bGcNSiQNw97a+wXl3ExjLnSUx4P2THmdw81hZ8WkbWMSwC4y88dKCK?=
 =?us-ascii?q?KM5rxegSR1uka4rR7WYfVlmzcdyPgu52QAj+AHpgUt1TmdDa4IHUZDIyPsjRuI?=
 =?us-ascii?q?4su6rKVWYmavbLex2FB/ndCnELGNvAVcVGzldZclGC969t9/P07U0H3v9oHkf8?=
 =?us-ascii?q?Hdbc4Uth2RiRvBjvJaKJQslvoRnipnOHnwvXkky+49kBxv0ou2vImBK2Vx4q25?=
 =?us-ascii?q?BgRUOSHyZ8MW4jvtl7pRnt6K34CzGZVsAi4EU4HvTfKsDTIer/DnNxuVHT04q3?=
 =?us-ascii?q?ebH6ffHACF5EdnqXLPD46kN3WNKHYFytViQQGXJFZDjwAMQDU6gpk5GxioxMP7?=
 =?us-ascii?q?dUd2+CsR6kTkqhdWyeJoKhr/UnrZpAiycTc5U5yfLBtQ7gFf6EbZK82e7uRvHy?=
 =?us-ascii?q?5G+p2tthCCKmueZw5QF2EGRlSEB0z/Prmp/dTB8++YBvenL/vTe7qOr/ZSV+yP?=
 =?us-ascii?q?xZKp3Ytr5DKMNsSJPnl/APw3wEtDXXZlG8vHnzUDUTAYlyXIb8SDvhez5jV3rt?=
 =?us-ascii?q?yj8PTsQA/v5ZWAC7pRMdVs+hC6m6SDN/SXhCZ2NzlYzI4MxWTTxbgb3V4SjTxu?=
 =?us-ascii?q?dja3HbQBsy7NULzfmqtNAxEHbCNzMdNC77gg0QlVJc7bltT126Zigf4oEFhFT0?=
 =?us-ascii?q?Lum8GzacwOImGwL1fHBEeNNLSbKjzH2cD3YaWgSbJOiOVYrQG/uTGeE0X7JDSM?=
 =?us-ascii?q?iyHpVwyzMeFLlCybIB1euISnfhlxE2TsUNLmZQO9MNJsiT02wLs0hm7FNGIGMD?=
 =?us-ascii?q?h8dV9NoaOU7S9Cnvp/HGlB5GJ/LeaYgyaZ8/XYKpEOvPprGCt0keda4HU8y7RN?=
 =?us-ascii?q?7SBEROZ6mC3drtN1p1Gmk++PyidoURZUqzZLgp6LsltmOanD6pZAXnPEr1ox6j?=
 =?us-ascii?q?C0DBIF7/9kQonrvKZfztnnkaP4MjBZ9NzIu8AbAp6HBtiANS8ZOATkHHbvDAoB?=
 =?us-ascii?q?SiCwNnCX01RcmeqO7GyEv7A1r5HtnNwFTboNBw99Le8TFkkwRI9KG5xwRD5x1O?=
 =?us-ascii?q?fD1MM=3D?=
X-IronPort-Anti-Spam-Filtered: true
X-IronPort-Anti-Spam-Result: =?us-ascii?q?A0AgAABZNQBch0O0hNFkHQEBBQEHBQGBU?=
 =?us-ascii?q?QgBCwGCXYEOJ4N5g3uEHYwIUAEBBoE1FIkKcY01gWwzEwGEQIM0IjQJDQEDAQE?=
 =?us-ascii?q?BAQEBAgETAQEBCA0JCCkjDII2JAGCYQEBAQEDAQIgBBkBGx0BAwIJAQEFAwILC?=
 =?us-ascii?q?gIDAiYCAgMfAREBBQEUCAYKCQUDgxmBaQEDCA0FjC2QBzyLDXwWBQEXgncFhEA?=
 =?us-ascii?q?KGScNXYE3AgYSeYsLF3iBB4ERgxKEaxaDBIJXApAekAUJkTIYgVqFEIMkhw6VH?=
 =?us-ascii?q?oMhMIElgg1NI1AxgjuCGwkDF4NKinQeM4EFAQGKcgeCRgEB?=
X-IPAS-Result: =?us-ascii?q?A0AgAABZNQBch0O0hNFkHQEBBQEHBQGBUQgBCwGCXYEOJ4N?=
 =?us-ascii?q?5g3uEHYwIUAEBBoE1FIkKcY01gWwzEwGEQIM0IjQJDQEDAQEBAQEBAgETAQEBC?=
 =?us-ascii?q?A0JCCkjDII2JAGCYQEBAQEDAQIgBBkBGx0BAwIJAQEFAwILCgIDAiYCAgMfARE?=
 =?us-ascii?q?BBQEUCAYKCQUDgxmBaQEDCA0FjC2QBzyLDXwWBQEXgncFhEAKGScNXYE3AgYSe?=
 =?us-ascii?q?YsLF3iBB4ERgxKEaxaDBIJXApAekAUJkTIYgVqFEIMkhw6VHoMhMIElgg1NI1A?=
 =?us-ascii?q?xgjuCGwkDF4NKinQeM4EFAQGKcgeCRgEB?=
X-IronPort-AV: E=Sophos;i="5.56,295,1539673200"; 
   d="scan'208";a="140144141"
X-Amp-Result: SKIPPED(no attachment in message)
X-Amp-File-Uploaded: False
Received: from vger.kernel.org ([209.132.180.67])
  by mtab.intel.com with ESMTP; 29 Nov 2018 10:55:13 -0800
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
        id S1726512AbeK3GBc (ORCPT <rfc822;like.xu@linux.intel.com>
        + 23 others); Fri, 30 Nov 2018 01:01:32 -0500
Received: from mail-lf1-f66.google.com ([209.85.167.66]:34784 "EHLO
        mail-lf1-f66.google.com" rhost-flags-OK-OK-OK-OK) by vger.kernel.org
        with ESMTP id S1725877AbeK3GBb (ORCPT
        <rfc822;linux-kernel@vger.kernel.org>);
        Fri, 30 Nov 2018 01:01:31 -0500
Received: by mail-lf1-f66.google.com with SMTP id p6so2272621lfc.1;
        Thu, 29 Nov 2018 10:55:07 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20161025;
        h=mime-version:references:in-reply-to:from:date:message-id:subject:to
         :cc:content-transfer-encoding;
        bh=PuQ3VzYTg5anlaHHXY5Tzt/odr5efDFgtIelJYwwf1E=;
        b=aFCpLDUpGFAx21tsrvJdxhHMSo9gfCkZ2Oa3JiS7NXVTHuem1Y2hCRX9RsLdu0f0EE
         ELfJZCQXbMGYViLVkWAlJLNnCqV96bw/xXAguTJZjj/ILI0XfOb6KO8wbP4ywcVzk/O9
         VIrZxqW5MuZLaVEHZontr3WPUxShss9wlZnpoTYVFSQKc5byigDEEsw1yXrUSMm7b9Uf
         rQZ4BtN2iHVqZwxxVxOLW0gjNYrNoOCtVXdvEVmdP+0XG1iJm4XueEB36WfCqn4Z/OBR
         6YC0252+rQ4/y8Pp28c6c1sdloySYCBBt2YRZZYdTvYOmF7DvL7GWs0+SCEPC6dbMSY9
         av+g==
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20161025;
        h=x-gm-message-state:mime-version:references:in-reply-to:from:date
         :message-id:subject:to:cc:content-transfer-encoding;
        bh=PuQ3VzYTg5anlaHHXY5Tzt/odr5efDFgtIelJYwwf1E=;
        b=JsB6AGFTp5S3Aavl0Jg63CDRUWOJoArbFVM/SawwUUdAawp/vkGsTl7jjYykKUjuOE
         B+sq1Yo8y7/Wy8/46W4mwA15MYAXPIuMR3YU/JEw7BdwMYuqxDhWnQ8m6fLPxUcdl34i
         mXdSzbqnrri9iGjLGHYuwuPFe8zxGmmxmn3PIsoDB9lwVXlXPdDf72PYaq0ZgzQjnDqA
         r1l5URGwp1ruqJEOJvwx14odMRXFFCzJy4wFaIZtJjJKhy4Cw8auSGzTZL30aFjjKVdh
         at3OSy8LobW/JDS+nHlaCHXZsrzFG/MCrJYAKUzlVG5sCMTUVyP6ezysowk4TJhQIBOS
         aF8A==
X-Gm-Message-State: AA+aEWbnnenyWnxjvLSs1tOFOA8zi1exRHXw+xs5Z55D885oYXfgue8E
        s8SbghOD61v7+dw7ghQQ5GRbbT0eg54RM4V0/v+p85k=
X-Google-Smtp-Source: AFSGD/WhAskG/Km4ifD9rDcEIJG2iwI6iFDhWHsATDotuXcT8KcGS4JTYaoMRRWHYMBXAjvVyi6WwbERf4hRS1qvVUk=
X-Received: by 2002:a19:f510:: with SMTP id j16mr1682516lfb.35.1543517706409;
 Thu, 29 Nov 2018 10:55:06 -0800 (PST)
MIME-Version: 1.0
References: <20181031221311.2596-1-longli@linuxonhyperv.com>
 <CAKywueSjVA=hwM7QCQqY_g_XNKonGWK9c+q4oHmdm0dWAdZCzg@mail.gmail.com> <DM5PR21MB0185227A3633878FF63ABB2BCED10@DM5PR21MB0185.namprd21.prod.outlook.com>
In-Reply-To: <DM5PR21MB0185227A3633878FF63ABB2BCED10@DM5PR21MB0185.namprd21.prod.outlook.com>
From: Pavel Shilovsky <piastryyy@gmail.com>
Date: Thu, 29 Nov 2018 10:54:54 -0800
Message-ID: <CAKywueSHGj7xr709+Xfmtox_RkZtCVgyKDXP3T_gX3N10cQrrQ@mail.gmail.com>
Subject: Re: [Patch v4 1/3] CIFS: Add support for direct I/O read
To: Long Li <longli@microsoft.com>
Cc: Steve French <sfrench@samba.org>,
        linux-cifs <linux-cifs@vger.kernel.org>,
        samba-technical <samba-technical@lists.samba.org>,
        Kernel Mailing List <linux-kernel@vger.kernel.org>
Content-Type: text/plain; charset="UTF-8"
Content-Transfer-Encoding: quoted-printable
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: <linux-kernel.vger.kernel.org>
X-Mailing-List: linux-kernel@vger.kernel.org

=D1=81=D1=80, 28 =D0=BD=D0=BE=D1=8F=D0=B1. 2018 =D0=B3. =D0=B2 15:43, Long =
Li <longli@microsoft.com>:
>
> > Subject: Re: [Patch v4 1/3] CIFS: Add support for direct I/O read
> >
> > Hi Long,
> >
> > Please find my comments below.
> >
> >
> > =D1=81=D1=80, 31 =D0=BE=D0=BA=D1=82. 2018 =D0=B3. =D0=B2 15:14, Long Li=
 <longli@linuxonhyperv.com>:
> > >
> > > From: Long Li <longli@microsoft.com>
> > >
> > > With direct I/O read, we transfer the data directly from transport
> > > layer to the user data buffer.
> > >
> > > Change in v3: add support for kernel AIO
> > >
> > > Change in v4:
> > > Refactor common read code to __cifs_readv for direct and non-direct I=
/O.
> > > Retry on direct I/O failure.
> > >
> > > Signed-off-by: Long Li <longli@microsoft.com>
> > > ---
> > >  fs/cifs/cifsfs.h   |   1 +
> > >  fs/cifs/cifsglob.h |   5 ++
> > >  fs/cifs/file.c     | 219 +++++++++++++++++++++++++++++++++++++++++++=
--
> > --------
> > >  3 files changed, 186 insertions(+), 39 deletions(-)
> > >
> > > diff --git a/fs/cifs/cifsfs.h b/fs/cifs/cifsfs.h index
> > > 5f02318..7fba9aa 100644
> > > --- a/fs/cifs/cifsfs.h
> > > +++ b/fs/cifs/cifsfs.h
> > > @@ -102,6 +102,7 @@ extern int cifs_open(struct inode *inode, struct
> > > file *file);  extern int cifs_close(struct inode *inode, struct file
> > > *file);  extern int cifs_closedir(struct inode *inode, struct file
> > > *file);  extern ssize_t cifs_user_readv(struct kiocb *iocb, struct
> > > iov_iter *to);
> > > +extern ssize_t cifs_direct_readv(struct kiocb *iocb, struct iov_iter
> > > +*to);
> > >  extern ssize_t cifs_strict_readv(struct kiocb *iocb, struct iov_iter
> > > *to);  extern ssize_t cifs_user_writev(struct kiocb *iocb, struct
> > > iov_iter *from);  extern ssize_t cifs_strict_writev(struct kiocb
> > > *iocb, struct iov_iter *from); diff --git a/fs/cifs/cifsglob.h
> > > b/fs/cifs/cifsglob.h index 7f62c98..52248dd 100644
> > > --- a/fs/cifs/cifsglob.h
> > > +++ b/fs/cifs/cifsglob.h
> > > @@ -1146,6 +1146,11 @@ struct cifs_aio_ctx {
> > >         unsigned int            len;
> > >         unsigned int            total_len;
> > >         bool                    should_dirty;
> > > +       /*
> > > +        * Indicates if this aio_ctx is for direct_io,
> > > +        * If yes, iter is a copy of the user passed iov_iter
> > > +        */
> > > +       bool                    direct_io;
> > >  };
> > >
> > >  struct cifs_readdata;
> > > diff --git a/fs/cifs/file.c b/fs/cifs/file.c index 87eece6..daab878
> > > 100644
> > > --- a/fs/cifs/file.c
> > > +++ b/fs/cifs/file.c
> > > @@ -2965,7 +2965,6 @@ cifs_uncached_readdata_release(struct kref
> > *refcount)
> > >         kref_put(&rdata->ctx->refcount, cifs_aio_ctx_release);
> > >         for (i =3D 0; i < rdata->nr_pages; i++) {
> > >                 put_page(rdata->pages[i]);
> > > -               rdata->pages[i] =3D NULL;
> > >         }
> > >         cifs_readdata_release(refcount);  } @@ -3092,6 +3091,63 @@
> > > cifs_uncached_copy_into_pages(struct TCP_Server_Info *server,
> > >         return uncached_fill_pages(server, rdata, iter, iter->count);
> > > }
> > >
> > > +static int cifs_resend_rdata(struct cifs_readdata *rdata,
> > > +                     struct list_head *rdata_list,
> > > +                     struct cifs_aio_ctx *ctx) {
> > > +       int wait_retry =3D 0;
> > > +       unsigned int rsize, credits;
> > > +       int rc;
> > > +       struct TCP_Server_Info *server =3D
> > > +tlink_tcon(rdata->cfile->tlink)->ses->server;
> > > +
> > > +       /*
> > > +        * Try to resend this rdata, waiting for credits up to 3 seco=
nds.
> > > +        * Note: we are attempting to resend the whole rdata not in s=
egments
> > > +        */
> > > +       do {
> > > +               rc =3D server->ops->wait_mtu_credits(server, rdata->b=
ytes,
> > > +                                               &rsize, &credits);
> > > +
> > > +               if (rc)
> > > +                       break;
> > > +
> > > +               if (rsize < rdata->bytes) {
> > > +                       add_credits_and_wake_if(server, credits, 0);
> > > +                       msleep(1000);
> > > +                       wait_retry++;
> > > +               }
> > > +       } while (rsize < rdata->bytes && wait_retry < 3);
> > > +
> > > +       /*
> > > +        * If we can't find enough credits to send this rdata
> > > +        * release the rdata and return failure, this will pass
> > > +        * whatever I/O amount we have finished to VFS.
> > > +        */
> > > +       if (rsize < rdata->bytes) {
> > > +               rc =3D -EBUSY;
> >
> > We don't have enough credits and return EBUSY here...
> >
> > > +               goto out;
> > > +       }
> > > +
> > > +       rc =3D -EAGAIN;
> > > +       while (rc =3D=3D -EAGAIN)
> > > +               if (!rdata->cfile->invalidHandle ||
> > > +                   !(rc =3D cifs_reopen_file(rdata->cfile, true)))
> > > +                       rc =3D server->ops->async_readv(rdata);
> > > +
> > > +       if (!rc) {
> > > +               /* Add to aio pending list */
> > > +               list_add_tail(&rdata->list, rdata_list);
> > > +               return 0;
> > > +       }
> > > +
> > > +       add_credits_and_wake_if(server, rdata->credits, 0);
> > > +out:
> > > +       kref_put(&rdata->refcount,
> > > +               cifs_uncached_readdata_release);
> > > +
> > > +       return rc;
> > > +}
> > > +
> > >  static int
> > >  cifs_send_async_read(loff_t offset, size_t len, struct cifsFileInfo =
*open_file,
> > >                      struct cifs_sb_info *cifs_sb, struct list_head
> > > *rdata_list, @@ -3103,6 +3159,9 @@ cifs_send_async_read(loff_t offset=
,
> > size_t len, struct cifsFileInfo *open_file,
> > >         int rc;
> > >         pid_t pid;
> > >         struct TCP_Server_Info *server;
> > > +       struct page **pagevec;
> > > +       size_t start;
> > > +       struct iov_iter direct_iov =3D ctx->iter;
> > >
> > >         server =3D tlink_tcon(open_file->tlink)->ses->server;
> > >
> > > @@ -3111,6 +3170,9 @@ cifs_send_async_read(loff_t offset, size_t len,
> > struct cifsFileInfo *open_file,
> > >         else
> > >                 pid =3D current->tgid;
> > >
> > > +       if (ctx->direct_io)
> > > +               iov_iter_advance(&direct_iov, offset - ctx->pos);
> > > +
> > >         do {
> > >                 rc =3D server->ops->wait_mtu_credits(server, cifs_sb-=
>rsize,
> > >                                                    &rsize, &credits);
> > > @@ -3118,20 +3180,56 @@ cifs_send_async_read(loff_t offset, size_t le=
n,
> > struct cifsFileInfo *open_file,
> > >                         break;
> > >
> > >                 cur_len =3D min_t(const size_t, len, rsize);
> > > -               npages =3D DIV_ROUND_UP(cur_len, PAGE_SIZE);
> > >
> > > -               /* allocate a readdata struct */
> > > -               rdata =3D cifs_readdata_alloc(npages,
> > > +               if (ctx->direct_io) {
> > > +
> > > +                       cur_len =3D iov_iter_get_pages_alloc(
> > > +                                       &direct_iov, &pagevec,
> > > +                                       cur_len, &start);
> > > +                       if (cur_len < 0) {
> > > +                               cifs_dbg(VFS,
> > > +                                       "couldn't get user pages (cur=
_len=3D%zd)"
> > > +                                       " iter type %d"
> > > +                                       " iov_offset %zd count %zd\n"=
,
> > > +                                       cur_len, direct_iov.type, dir=
ect_iov.iov_offset,
> > > +                                       direct_iov.count);
> > > +                               dump_stack();
> > > +                               break;
> > > +                       }
> > > +                       iov_iter_advance(&direct_iov, cur_len);
> > > +
> > > +                       rdata =3D cifs_readdata_direct_alloc(
> > > +                                       pagevec, cifs_uncached_readv_=
complete);
> > > +                       if (!rdata) {
> > > +                               add_credits_and_wake_if(server, credi=
ts, 0);
> > > +                               rc =3D -ENOMEM;
> > > +                               break;
> > > +                       }
> > > +
> > > +                       npages =3D (cur_len + start + PAGE_SIZE-1) / =
PAGE_SIZE;
> > > +                       rdata->page_offset =3D start;
> > > +                       rdata->tailsz =3D npages > 1 ?
> > > +                               cur_len-(PAGE_SIZE-start)-(npages-2)*=
PAGE_SIZE :
> > > +                               cur_len;
> > > +
> > > +               } else {
> > > +
> > > +                       npages =3D DIV_ROUND_UP(cur_len, PAGE_SIZE);
> > > +                       /* allocate a readdata struct */
> > > +                       rdata =3D cifs_readdata_alloc(npages,
> > >                                             cifs_uncached_readv_compl=
ete);
> > > -               if (!rdata) {
> > > -                       add_credits_and_wake_if(server, credits, 0);
> > > -                       rc =3D -ENOMEM;
> > > -                       break;
> > > -               }
> > > +                       if (!rdata) {
> > > +                               add_credits_and_wake_if(server, credi=
ts, 0);
> > > +                               rc =3D -ENOMEM;
> > > +                               break;
> > > +                       }
> > >
> > > -               rc =3D cifs_read_allocate_pages(rdata, npages);
> > > -               if (rc)
> > > -                       goto error;
> > > +                       rc =3D cifs_read_allocate_pages(rdata, npages=
);
> > > +                       if (rc)
> > > +                               goto error;
> > > +
> > > +                       rdata->tailsz =3D PAGE_SIZE;
> > > +               }
> > >
> > >                 rdata->cfile =3D cifsFileInfo_get(open_file);
> > >                 rdata->nr_pages =3D npages; @@ -3139,7 +3237,6 @@
> > > cifs_send_async_read(loff_t offset, size_t len, struct cifsFileInfo *=
open_file,
> > >                 rdata->bytes =3D cur_len;
> > >                 rdata->pid =3D pid;
> > >                 rdata->pagesz =3D PAGE_SIZE;
> > > -               rdata->tailsz =3D PAGE_SIZE;
> > >                 rdata->read_into_pages =3D cifs_uncached_read_into_pa=
ges;
> > >                 rdata->copy_into_pages =3D cifs_uncached_copy_into_pa=
ges;
> > >                 rdata->credits =3D credits; @@ -3153,9 +3250,11 @@
> > > cifs_send_async_read(loff_t offset, size_t len, struct cifsFileInfo *=
open_file,
> > >                 if (rc) {
> > >                         add_credits_and_wake_if(server, rdata->credit=
s, 0);
> > >                         kref_put(&rdata->refcount,
> > > -                                cifs_uncached_readdata_release);
> > > -                       if (rc =3D=3D -EAGAIN)
> > > +                               cifs_uncached_readdata_release);
> > > +                       if (rc =3D=3D -EAGAIN) {
> > > +                               iov_iter_revert(&direct_iov, cur_len)=
;
> > >                                 continue;
> > > +                       }
> > >                         break;
> > >                 }
> > >
> > > @@ -3211,45 +3310,62 @@ collect_uncached_read_data(struct
> > cifs_aio_ctx *ctx)
> > >                                  * reading.
> > >                                  */
> > >                                 if (got_bytes && got_bytes < rdata->b=
ytes) {
> > > -                                       rc =3D cifs_readdata_to_iov(r=
data, to);
> > > +                                       rc =3D 0;
> > > +                                       if (!ctx->direct_io)
> > > +                                               rc =3D
> > > + cifs_readdata_to_iov(rdata, to);
> > >                                         if (rc) {
> > >                                                 kref_put(&rdata->refc=
ount,
> > > -                                               cifs_uncached_readdat=
a_release);
> > > +
> > > + cifs_uncached_readdata_release);
> > >                                                 continue;
> > >                                         }
> > >                                 }
> > >
> > > -                               rc =3D cifs_send_async_read(
> > > +                               if (ctx->direct_io) {
> > > +                                       /*
> > > +                                        * Re-use rdata as this is a
> > > +                                        * direct I/O
> > > +                                        */
> > > +                                       rc =3D cifs_resend_rdata(
> > > +                                               rdata,
> > > +                                               &tmp_list, ctx);
> >
> > ...so we set rc to -EBUSY...
> >
> >
> > > +                               } else {
> > > +                                       rc =3D cifs_send_async_read(
> > >                                                 rdata->offset + got_b=
ytes,
> > >                                                 rdata->bytes - got_by=
tes,
> > >                                                 rdata->cfile, cifs_sb=
,
> > >                                                 &tmp_list, ctx);
> > >
> > > +                                       kref_put(&rdata->refcount,
> > > +                                               cifs_uncached_readdat=
a_release);
> > > +                               }
> > > +
> > >                                 list_splice(&tmp_list, &ctx->list);
> > >
> > > -                               kref_put(&rdata->refcount,
> > > -                                        cifs_uncached_readdata_relea=
se);
> > >                                 goto again;
> > >                         } else if (rdata->result)
> > >                                 rc =3D rdata->result;
> > > -                       else
> > > +                       else if (!ctx->direct_io)
> > >                                 rc =3D cifs_readdata_to_iov(rdata, to=
);
> > >
> > >                         /* if there was a short read -- discard anyth=
ing left */
> > >                         if (rdata->got_bytes && rdata->got_bytes < rd=
ata->bytes)
> > >                                 rc =3D -ENODATA;
> > > +
> > > +                       ctx->total_len +=3D rdata->got_bytes;
> > >                 }
> > >                 list_del_init(&rdata->list);
> > >                 kref_put(&rdata->refcount, cifs_uncached_readdata_rel=
ease);
> > >         }
> > >
> > > -       for (i =3D 0; i < ctx->npages; i++) {
> > > -               if (ctx->should_dirty)
> > > -                       set_page_dirty(ctx->bv[i].bv_page);
> > > -               put_page(ctx->bv[i].bv_page);
> > > -       }
> > > +       if (!ctx->direct_io) {
> > > +               for (i =3D 0; i < ctx->npages; i++) {
> > > +                       if (ctx->should_dirty)
> > > +                               set_page_dirty(ctx->bv[i].bv_page);
> > > +                       put_page(ctx->bv[i].bv_page);
> > > +               }
> > >
> > > -       ctx->total_len =3D ctx->len - iov_iter_count(to);
> > > +               ctx->total_len =3D ctx->len - iov_iter_count(to);
> > > +       }
> > >
> > >         cifs_stats_bytes_read(tcon, ctx->total_len);
> > >
> > > @@ -3267,18 +3383,27 @@ collect_uncached_read_data(struct
> > cifs_aio_ctx *ctx)
> > >                 complete(&ctx->done);
> >
> > and then ctx->rc is set to -EBUSY too.
> >
> > >  }
> > >
> > > -ssize_t cifs_user_readv(struct kiocb *iocb, struct iov_iter *to)
> > > +ssize_t __cifs_readv(struct kiocb *iocb, struct iov_iter *to, bool
> > > +direct)
> > >  {
> > > -       struct file *file =3D iocb->ki_filp;
> > > -       ssize_t rc;
> > >         size_t len;
> > > -       ssize_t total_read =3D 0;
> > > -       loff_t offset =3D iocb->ki_pos;
> > > +       struct file *file =3D iocb->ki_filp;
> > >         struct cifs_sb_info *cifs_sb;
> > > -       struct cifs_tcon *tcon;
> > >         struct cifsFileInfo *cfile;
> > > +       struct cifs_tcon *tcon;
> > > +       ssize_t rc, total_read =3D 0;
> > > +       loff_t offset =3D iocb->ki_pos;
> > >         struct cifs_aio_ctx *ctx;
> > >
> > > +       /*
> > > +        * iov_iter_get_pages_alloc() doesn't work with ITER_KVEC,
> > > +        * fall back to data copy read path
> > > +        * this could be improved by getting pages directly in ITER_K=
VEC
> > > +        */
> > > +       if (direct && to->type & ITER_KVEC) {
> > > +               cifs_dbg(FYI, "use non-direct cifs_user_readv for kve=
c I/O\n");
> > > +               direct =3D false;
> > > +       }
> > > +
> > >         len =3D iov_iter_count(to);
> > >         if (!len)
> > >                 return 0;
> > > @@ -3305,14 +3430,20 @@ ssize_t cifs_user_readv(struct kiocb *iocb,
> > struct iov_iter *to)
> > >         if (to->type =3D=3D ITER_IOVEC)
> > >                 ctx->should_dirty =3D true;
> > >
> > > -       rc =3D setup_aio_ctx_iter(ctx, to, READ);
> > > -       if (rc) {
> > > -               kref_put(&ctx->refcount, cifs_aio_ctx_release);
> > > -               return rc;
> > > +       if (direct) {
> > > +               ctx->pos =3D offset;
> > > +               ctx->direct_io =3D true;
> > > +               ctx->iter =3D *to;
> > > +               ctx->len =3D len;
> > > +       } else {
> > > +               rc =3D setup_aio_ctx_iter(ctx, to, READ);
> > > +               if (rc) {
> > > +                       kref_put(&ctx->refcount, cifs_aio_ctx_release=
);
> > > +                       return rc;
> > > +               }
> > > +               len =3D ctx->len;
> > >         }
> > >
> > > -       len =3D ctx->len;
> > > -
> > >         /* grab a lock here due to read response handlers can access =
ctx */
> > >         mutex_lock(&ctx->aio_mutex);
> > >
> > > @@ -3354,6 +3485,16 @@ ssize_t cifs_user_readv(struct kiocb *iocb,
> > struct iov_iter *to)
> > >         return rc;
> >
> > In case of a blocking read we will return -EBUSY to the caller but read=
 man
> > page doesn't say anything about a possibility to return this error code=
. Is it
> > being mapped somehow by VFS or is there another consideration? The same
> > question applies to the write patch as well.
>
> Thanks Pavel,  Yes this is a bug.
>
> In practice, the retry logic will rarely get hit. If getting hit, normall=
y the server will give us far more credits for resending this whole packet.
>
> How about just retrying forever (instead of trying 3 times) on this resen=
d packet? This will change the code to the same behavior before direct I/O =
patches.
>
> e.g.:
>
>         /*
>          * Try to resend this wdata, waiting for credits before sending
>          * Note: we are attempting to resend the whole wdata not in segme=
nts
>          */
>         do {
>                 rc =3D server->ops->wait_mtu_credits(
>                         server, wdata->bytes, &wsize, &credits);
>
>                 if (rc)
>                         break;
>
>                 if (wsize < wdata->bytes) {
>                         add_credits_and_wake_if(server, credits, 0);
>                         msleep(1000);
>                 }
>         } while (wsize < wdata->bytes);
>

We can do that but it won't be the same behavior because we were using
a partial send:

+                               if (ctx->direct_io) {
+                                       /*
+                                        * Re-use rdata as this is a
+                                        * direct I/O
+                                        */
+                                       rc =3D cifs_resend_rdata(
+                                               rdata,
+                                               &tmp_list, ctx);
+                               } else {
+                                       rc =3D cifs_send_async_read(
                                                rdata->offset + got_bytes,
                                                rdata->bytes - got_bytes,
                                                rdata->cfile, cifs_sb,
                                                &tmp_list, ctx);

--
Best regards,
Pavel Shilovsky
