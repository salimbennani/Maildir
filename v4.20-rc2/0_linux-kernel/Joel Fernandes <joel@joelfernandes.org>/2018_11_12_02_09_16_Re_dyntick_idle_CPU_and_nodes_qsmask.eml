Return-Path: <linux-kernel-owner@vger.kernel.org>
Delivered-To: unknown
Received: from pop3.zju.edu.cn (124.160.105.205:110) by
  likexu-MOBL1.ccr.corp.intel.com with POP3; 12 Nov 2018 00:40:00 -0000
Received: from icoremail.net (unknown [209.85.215.172])
	by mail-app2 (Coremail) with SMTP id by_KCgDXv5p5cOhb6Dl3AQ--.35934S3;
	Mon, 12 Nov 2018 02:10:01 +0800 (CST)
Received: from mail-pg1-f172.google.com (unknown [209.85.215.172])
	by mx2.icoremail.net (Coremail) with SMTP id AQAAfwCHaUV2cOhbsc4tAA--.4504S3;
	Mon, 12 Nov 2018 02:09:58 +0800 (CST)
Received: by mail-pg1-f172.google.com with SMTP id n10-v6so2985182pgv.10
        for <xuliker@zju.edu.cn>; Sun, 11 Nov 2018 10:09:58 -0800 (PST)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20161025;
        h=x-gm-message-state:delivered-to:dkim-signature:date:from:to:cc
         :subject:message-id:references:mime-version:content-disposition
         :in-reply-to:user-agent:sender:precedence:list-id;
        bh=VgMWYHJGewlEaaFvNqV3WhyncUDrW5qmMNARt3zyqGk=;
        b=DK0mZfssPVjznFVOVyHgwD7MLbR7iGSk6ikm2ThutqAh/nBV/4gEY2DeOWiqju0ChJ
         VoSENmXaVfdvCiPPIThOZ4PLMBRl2RZhBK6++lhFraiE/LTwnzJEqEHbyJ1jWrARaQ0l
         tipjCosjXIlkP5ItSUkUYD4NAZ4hoAisKqBBIU5DAagniv+Ak47gI3/tdS4R1PJDXeqB
         lHm+9wOdQU+mA6mBAf4GMEcZ+BLg5oILKlKMyDGs8BX79dvBVUgv+eI/gA54j28T2qvH
         2GzY2OxYceYW10QpmU1bJdfqiwKfv+/YbEk3gdY8TQebP7VXmHDbLWb0w5DQ5GsqkLJb
         56rA==
X-Gm-Message-State: AGRZ1gIdTx+PNIxEAHWHUWfda3yUb7bkaU4qWE6dGvbB35jqfN/DX94A
	hY/q7T8WLQAVZ3wz7GBdD5dhTEVpe6Fdg27EtsGympRMY8Hz5TI=
X-Received: by 2002:a62:1c53:: with SMTP id c80-v6mr17080474pfc.14.1541959798118;
        Sun, 11 Nov 2018 10:09:58 -0800 (PST)
X-Forwarded-To: xuliker@zju.edu.cn
X-Forwarded-For: liker.xu@gmail.com xuliker@zju.edu.cn
Delivered-To: liker.xu@gmail.com
Received: by 2002:a17:90a:c304:0:0:0:0 with SMTP id g4-v6csp2340641pjt;
        Sun, 11 Nov 2018 10:09:57 -0800 (PST)
X-Google-Smtp-Source: AJdET5eNa26dDRUBPgnpgpeR2a7H4cw6Am+03zUNNW1Ga0OsCLRjpTEps1yDj744rt6A4zIHJ0MW
X-Received: by 2002:a17:902:1e3:: with SMTP id b90-v6mr14055126plb.117.1541959797027;
        Sun, 11 Nov 2018 10:09:57 -0800 (PST)
ARC-Seal: i=1; a=rsa-sha256; t=1541959796; cv=none;
        d=google.com; s=arc-20160816;
        b=nDX6i7WMBtVSO5Uu3vsn0jWQC+cjRaOZLeK6pyIslAh51O2Htqe6sV1VfUx8ht2q8f
         FZMqCK32sJG+U9E83xUT3VmrA/xYM8QZUf2KKcTvg1nyx2uzBHvWCYwqkbPxJ28ZivVg
         JpMALq+3AMGin0VrIbwWEnNaIHiudm163wBjfTtVFd1vXq6E5jX7mQUK/vPJUDNxOy1U
         LiOiCyxQ6hGjWAMxHt9EL4oo7Uq6jx83m2Gd4DInzjovVk0/Kqd3FsqBlvqcP5g8Z0u/
         9ZFGi//R0NQOSbeZrU0ktH99aTihEZk9vUaBuNk78zq8O/c97YyMbnA03h9DONVJBvzp
         McYg==
ARC-Message-Signature: i=1; a=rsa-sha256; c=relaxed/relaxed; d=google.com; s=arc-20160816;
        h=list-id:precedence:sender:user-agent:in-reply-to
         :content-disposition:mime-version:references:message-id:subject:cc
         :to:from:date:dkim-signature;
        bh=VgMWYHJGewlEaaFvNqV3WhyncUDrW5qmMNARt3zyqGk=;
        b=e5TBCMMJRId/oWhGKgVGBrjpXs03Kjj/RDyj+AGD5L4CpnaDiSPUHikc3jSkFtNruX
         ZnUwWolp16iCId2zvFUVbqFpiHaAacoL0F4+PqQR/RNaAMU6JL8zo7iCCU3Yu90s2kL6
         gI6MS9G8xZIYXv5yX2wKCgF9DDRROX5DueTc8XGXqji8YRS7ViAEuLC3zzQKblGhS/Bu
         N8yaLj1yHc2DucmCDsY0a34ww8jTAIxGmEot0KswQ7tlvu75cP062mA3dhIaG7Pn2x+Y
         3Qosw7eDsiHhWV+fEaqp2cO5nbZsEUmkw6zifjADLIwnQlii8bKUWm8MWq+gkEz4ZvZo
         0m7A==
ARC-Authentication-Results: i=1; mx.google.com;
       dkim=pass header.i=@joelfernandes.org header.s=google header.b=B8OdPjaD;
       spf=pass (google.com: best guess record for domain of linux-kernel-owner@vger.kernel.org designates 209.132.180.67 as permitted sender) smtp.mailfrom=linux-kernel-owner@vger.kernel.org
Received: from vger.kernel.org (vger.kernel.org. [209.132.180.67])
        by mx.google.com with ESMTP id y35-v6si13759468pgl.14.2018.11.11.10.09.41;
        Sun, 11 Nov 2018 10:09:56 -0800 (PST)
Received-SPF: pass (google.com: best guess record for domain of linux-kernel-owner@vger.kernel.org designates 209.132.180.67 as permitted sender) client-ip=209.132.180.67;
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
        id S1729344AbeKLD6c (ORCPT <rfc822;berg.ding@gmail.com> + 99 others);
        Sun, 11 Nov 2018 22:58:32 -0500
Received: from mail-pf1-f179.google.com ([209.85.210.179]:44859 "EHLO
        mail-pf1-f179.google.com" rhost-flags-OK-OK-OK-OK) by vger.kernel.org
        with ESMTP id S1726283AbeKLD6c (ORCPT
        <rfc822;linux-kernel@vger.kernel.org>);
        Sun, 11 Nov 2018 22:58:32 -0500
Received: by mail-pf1-f179.google.com with SMTP id b81-v6so2671300pfe.11
        for <linux-kernel@vger.kernel.org>; Sun, 11 Nov 2018 10:09:19 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=joelfernandes.org; s=google;
        h=date:from:to:cc:subject:message-id:references:mime-version
         :content-disposition:in-reply-to:user-agent;
        bh=VgMWYHJGewlEaaFvNqV3WhyncUDrW5qmMNARt3zyqGk=;
        b=B8OdPjaDxVD0kDoKdiZZY6ghLHQoCRDp0n6vEdCxZT0LpCDJvurdPXp3r5/O/NI8rQ
         uyE36H/aiqFJ1WJQ6q8OJWLBu39L/WXjYZ1jMxBkb2guEGnbV/ROtgf5uw/EkO9zQJRa
         NqQec1Y33cNtLWNqxYOg2NvEbcbrV8jf23bD4=
X-Received: by 2002:a63:907:: with SMTP id 7-v6mr14617384pgj.121.1541959758142;
        Sun, 11 Nov 2018 10:09:18 -0800 (PST)
Received: from localhost ([2620:0:1000:1601:3aef:314f:b9ea:889f])
        by smtp.gmail.com with ESMTPSA id 123sm11442922pgd.75.2018.11.11.10.09.16
        (version=TLS1_2 cipher=ECDHE-RSA-CHACHA20-POLY1305 bits=256/256);
        Sun, 11 Nov 2018 10:09:17 -0800 (PST)
Date: Sun, 11 Nov 2018 10:09:16 -0800
From: Joel Fernandes <joel@joelfernandes.org>
To: "Paul E. McKenney" <paulmck@linux.ibm.com>
Cc: linux-kernel@vger.kernel.org, josh@joshtriplett.org,
        rostedt@goodmis.org, mathieu.desnoyers@efficios.com,
        jiangshanlai@gmail.com
Subject: Re: dyntick-idle CPU and node's qsmask
Message-ID: <20181111180916.GA25327@google.com>
References: <20181110214659.GA96924@google.com>
 <20181110230436.GL4170@linux.ibm.com>
 <20181111030925.GA182908@google.com>
 <20181111042210.GN4170@linux.ibm.com>
MIME-Version: 1.0
Content-Type: text/plain; charset=us-ascii
Content-Disposition: inline
In-Reply-To: <20181111042210.GN4170@linux.ibm.com>
User-Agent: Mutt/1.10.1 (2018-07-13)
Sender: liker.xu+caf_=xuliker=zju.edu.cn@gmail.com
Precedence: bulk
List-ID: <linux-kernel.vger.kernel.org>
X-Mailing-List: linux-kernel@vger.kernel.org
X-CM-TRANSID: AQAAfwCHaUV2cOhbsc4tAA--.4504S3
Authentication-Results: mail-app2; spf=pass smtp.mail=liker.xu+caf_=xu
	liker=zju.edu.cn@gmail.com;
X-Coremail-Antispam: 1UD129KBjvJXoW3Wr43XrW7Cr1kuw1UKw13twb_yoW7Ww4rpF
	ZrK3Z8Crn5JrWIkws2vw47Xa4F9w4fWFZxXry5Kryqyr98KF1Sqr17t3yUua4fuw4Syw12
	qFsFqr9ruw1qyaDanT9S1TB71UUUUUUqnTZGkaVYY2UrUUUU0bIjqfuFe4nvWSU8nxnvy2
	9KBjDU0xBIdaVrnRJUUUPFb7Iv0xC_Kw4lb4IE77IF4wAFF20E14v26r1j6r4UM7CIcVAF
	z4kK6r1j6r18M28lY4IEw2IIxxk0rwA2F7IY1VAKz4vEj48ve4kI8wA2z4x0Y4vE2Ix0cI
	8IcVAFwI0_Xr0_Ar1l84ACjcxK6xIIjxv20xvEc7CjxVAFwI0_Gr0_Cr1l84ACjcxK6I8E
	87Iv67AKxVW8Jr0_Cr1UM28EF7xvwVC2z280aVCY1x0267AKxVW8Jr0_Cr1UM2AIxVAIcx
	kEcVAq07x20xvEncxIr21l5I8CrVACY4xI64kE6c02F40Ex7xfMcIj6xIIjxv20xvE14v2
	6r1j6r18McIj6I8E87Iv67AKxVWUJVW8JwAm72CE4IkC6x0Yz7v_Jr0_Gr1lF7xvr2IY64
	vIr41l7I0Y6sxI4wCY1x0264kExVAvwVAq07x20xylc7Ca8VAvwVCFzxkY4VCF77xAMxkI
	ecxEwVCI4VW5MxkI7II2jI8vz4vEwIxGrwCYIxAIcVC0I7IYx2IY67AKxVWUJVWUCwCYIx
	AIcVC0I7IYx2IY6xkF7I0E14v26r1j6r4UMxvI42IY6I8E87Iv67AKxVW8JVWxJwCYIxAI
	cVC2z280aVCY1x0267AKxVW8JVW8Jr1l42xK82IYc2Ij64vIr41l42xK82IY64kExVAvwV
	Aq07x20xyl4x8a6x804xWl4I8I3I0E4IkC6x0Yz7v_Jr0_Gr1lx2IqxVAqx4xG67AKxVWU
	JVWUGwC20s026x8GjcxK67AKxVWUGVWUWwC2zVAF1VAY17CE14v26r126r1DMIIYrxkI7V
	AKI48JMIIF0xvE42xK8VAvwI8IcIk0rVW8JVW3JbIYCTnIWIevJa73UjIFyTuYvjxUQFoX
	UUUUU

On Sat, Nov 10, 2018 at 08:22:10PM -0800, Paul E. McKenney wrote:
> On Sat, Nov 10, 2018 at 07:09:25PM -0800, Joel Fernandes wrote:
> > On Sat, Nov 10, 2018 at 03:04:36PM -0800, Paul E. McKenney wrote:
> > > On Sat, Nov 10, 2018 at 01:46:59PM -0800, Joel Fernandes wrote:
> > > > Hi Paul and everyone,
> > > > 
> > > > I was tracing/studying the RCU code today in paul/dev branch and noticed that
> > > > for dyntick-idle CPUs, the RCU GP thread is clearing the rnp->qsmask
> > > > corresponding to the leaf node for the idle CPU, and reporting a QS on their
> > > > behalf.
> > > > 
> > > > rcu_sched-10    [003]    40.008039: rcu_fqs:              rcu_sched 792 0 dti
> > > > rcu_sched-10    [003]    40.008039: rcu_fqs:              rcu_sched 801 2 dti
> > > > rcu_sched-10    [003]    40.008041: rcu_quiescent_state_report: rcu_sched 805 5>0 0 0 3 0
> > > > 
> > > > That's all good but I was wondering if we can do better for the idle CPUs if
> > > > we can some how not set the qsmask of the node in the first place. Then no
> > > > reporting would be needed of quiescent state is needed for idle CPUs right?
> > > > And we would also not need to acquire the rnp lock I think.
> > > > 
> > > > At least for a single node tree RCU system, it seems that would avoid needing
> > > > to acquire the lock without complications. Anyway let me know your thoughts
> > > > and happy to discuss this at the hallways of the LPC as well for folks
> > > > attending :)
> > > 
> > > We could, but that would require consulting the rcu_data structure for
> > > each CPU while initializing the grace period, thus increasing the number
> > > of cache misses during grace-period initialization and also shortly after
> > > for any non-idle CPUs.  This seems backwards on busy systems where each
> > 
> > When I traced, it appears to me that rcu_data structure of a remote CPU was
> > being consulted anyway by the rcu_sched thread. So it seems like such cache
> > miss would happen anyway whether it is during grace-period initialization or
> > during the fqs stage? I guess I'm trying to say, the consultation of remote
> > CPU's rcu_data happens anyway.
> 
> Hmmm...
> 
> The rcu_gp_init() function does access an rcu_data structure, but it is
> that of the current CPU, so shouldn't involve a communications cache miss,
> at least not in the common case.
> 
> Or are you seeing these cross-CPU rcu_data accesses in rcu_gp_fqs() or
> functions that it calls?  In that case, please see below.

Yes, it was rcu_implicit_dynticks_qs called from rcu_gp_fqs.

> > > CPU will with high probability report its own quiescent state before three
> > > jiffies pass, in which case the cache misses on the rcu_data structures
> > > would be wasted motion.
> > 
> > If all the CPUs are busy and reporting their QS themselves, then I think the
> > qsmask is likely 0 so then rcu_implicit_dynticks_qs (called from
> > force_qs_rnp) wouldn't be called and so there would no cache misses on
> > rcu_data right?
> 
> Yes, but assuming that all CPUs report their quiescent states before
> the first call to rcu_gp_fqs().  One exception is when some CPU is
> looping in the kernel for many milliseconds without passing through a
> quiescent state.  This is because for recent kernels, cond_resched()
> is not a quiescent state until the grace period is something like 100
> milliseconds old.  (For older kernels, cond_resched() was never an RCU
> quiescent state unless it actually scheduled.)
> 
> Why wait 100 milliseconds?  Because otherwise the increase in
> cond_resched() overhead shows up all too well, causing 0day test robot
> to complain bitterly.  Besides, I would expect that in the common case,
> CPUs would be executing usermode code.

Makes sense. I was also wondering about this other thing you mentioned about
waiting for 3 jiffies before reporting the idle CPU's quiescent state. Does
that mean that even if a single CPU is dyntick-idle for a long period of
time, then the minimum grace period duration would be atleast 3 jiffies? In
our mobile embedded devices, jiffies is set to 3.33ms (HZ=300) to keep power
consumption low. Not that I'm saying its an issue or anything (since IIUC if
someone wants shorter grace periods, they should just use expedited GPs), but
it sounds like it would be shorter GP if we just set the qsmask early on some
how and we can manage the overhead of doing so.

> Ah, did you build with NO_HZ_FULL, boot with nohz_full CPUs, and then run
> CPU-bound usermode workloads on those CPUs?  Such CPUs would appear to
> be idle from an RCU perspective.  But these CPUs would never touch their
> rcu_data structures, so they would likely remain in the RCU grace-period
> kthread's cache.  So this should work well also.  Give or take that other
> work would likely eject them from the cache, but in that case they would
> be capacity cache misses rather than the aforementioned communications
> cache misses.  Not that this distinction matters to whoever is measuring
> performance.  ;-)

Ah ok :-) I had booted with !CONFIG_NO_HZ_FULL for this test.

> > Anyway it was just an idea that popped up when I was going through traces :)
> > Thanks for the discussion and happy to discuss further or try out anything.
> 
> Either way, I do appreciate your going through this.  People have found
> RCU bugs this way, one of which involved RCU uselessly calling a particular
> function twice in quick succession.  ;-)
 
Thanks.  It is my pleasure and happy to help :) I'll keep digging into it.

 - Joel
