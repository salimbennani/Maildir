Return-Path: <linux-kernel-owner@vger.kernel.org>
Delivered-To: unknown
Received: from pop3.zju.edu.cn (124.160.105.205:110) by
  likexu-MOBL1.ccr.corp.intel.com with POP3; 12 Nov 2018 00:43:50 -0000
Received: from icoremail.net (unknown [209.85.215.172])
	by mail-app2 (Coremail) with SMTP id by_KCgDnX9_GtehbNJN4AQ--.36415S3;
	Mon, 12 Nov 2018 07:05:43 +0800 (CST)
Received: from mail-pg1-f172.google.com (unknown [209.85.215.172])
	by mx2.icoremail.net (Coremail) with SMTP id AQAAfwC3nUnEtehb9J4uAA--.6030S3;
	Mon, 12 Nov 2018 07:05:40 +0800 (CST)
Received: by mail-pg1-f172.google.com with SMTP id z17-v6so3171179pgv.3
        for <xuliker@zju.edu.cn>; Sun, 11 Nov 2018 15:05:40 -0800 (PST)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20161025;
        h=x-gm-message-state:delivered-to:dkim-signature:mime-version
         :references:in-reply-to:from:date:message-id:subject:to:cc
         :content-transfer-encoding:sender:precedence:list-id;
        bh=0U9ceAnB4nAEnMcfQJhz58KUPoxlp94Luh91H/EYKkY=;
        b=YVA5IkFuVME6BDgWPOpSZiWoVyf+f1OvDQpqXa9OKkaMY1HyEo1I/jcPT+MmV8fq7U
         UTfGjHpceE29nn/asay002WXJvTISYebThaExGooMHhsGBNK6Fr4IUYjCpVafUDHG/t8
         9/CMAUjfGVieAbyqHVPsy8/5e6hN9LTMvOVREXT5VTcKlQjqQFv9J9j9H3+dkVvyAHbP
         Vs5DzAI6GyUeMmpJ7jE8pcxBdYLi6ZFqaKLy7SQ9ftFd08XbXDWb3YnZzxML6RkuMvo1
         JrtCAQO7lC+SUUe5ddUDFh0KjVheuTiBWIzPcvs1BGRUOQRSboBTGYwZrsy24sgBVBIU
         zCrg==
X-Gm-Message-State: AGRZ1gIb+gKd1cle57qBeQQDdzQq3X3k5fVnPbCNWc583dHabrJjeYGq
	i/rfi19Eklg4B9A+6U/yniuN77vGMWv0GU5X+tD/bi3A0ST5GTQ=
X-Received: by 2002:a65:66ce:: with SMTP id c14mr15304331pgw.450.1541977540359;
        Sun, 11 Nov 2018 15:05:40 -0800 (PST)
X-Forwarded-To: xuliker@zju.edu.cn
X-Forwarded-For: liker.xu@gmail.com xuliker@zju.edu.cn
Delivered-To: liker.xu@gmail.com
Received: by 2002:a17:90a:c304:0:0:0:0 with SMTP id g4-v6csp2545759pjt;
        Sun, 11 Nov 2018 15:05:39 -0800 (PST)
X-Google-Smtp-Source: AJdET5czr8K3iC2nveUidTkgX7MWTHcspPh8X5FfeVnUbdVnTMVjZ5amPBtJGSHw/cKljlQcSVNy
X-Received: by 2002:a63:2141:: with SMTP id s1mr12913425pgm.148.1541977539297;
        Sun, 11 Nov 2018 15:05:39 -0800 (PST)
ARC-Seal: i=1; a=rsa-sha256; t=1541977539; cv=none;
        d=google.com; s=arc-20160816;
        b=h5tVP7gCWvKl8d8Man8noqhhkbrW1VqEtAk61gN9k3ZawaBJiqR28jw6r8Zt/XO4Dj
         Oa//a/VA3KqHTXqt9tlQQqUVdLkxsxGEz+reweI5U5U1YvvNeJoqL8ovrAbPdbzWksgD
         AhE3ikqFFrC7SACopPcaATE4NJLprBZfSt3oxvm9n3HXwhripSJa6I49dvuk/RgU1uoc
         LjdhKYz/zmyqBJzVyyqDreYul1j9QH+TdFDiTE12/hVZWFvHPgSX5Qj0KFfMR+haEOUt
         6dFpv7RNPyTYQH7SO6TeHVE95bgDkj1V7PanaMGh3QRjU5yVdF7MZ/Xi2JXpTqHbXiJ1
         FCaw==
ARC-Message-Signature: i=1; a=rsa-sha256; c=relaxed/relaxed; d=google.com; s=arc-20160816;
        h=list-id:precedence:sender:content-transfer-encoding:cc:to:subject
         :message-id:date:from:in-reply-to:references:mime-version
         :dkim-signature;
        bh=0U9ceAnB4nAEnMcfQJhz58KUPoxlp94Luh91H/EYKkY=;
        b=oeYrDvzKy5xxRQzdXpT7NULhsPS29eUhSTF5i4b/VwABYIrDmrI+dqEGXV93q7A9fD
         mJDgpmnHdb2LUeJpWsFnkilJYG0hdewUV2rrtkSxQ/PdZdbRTqlxjIaBZpZ5qqYueukg
         x6vEDCBf39yx4VWs3ouF9kFw477HBNw+l92mT+gEVY36oE7H848IUFbSOA3suhEoBVxp
         ybqnMaHqka04/WJBRsIsRoZbfN4sRGruC+hOjfPlCxpsfqkvogzrES9sLrNG1t95soZ9
         PhhCmHbwZL3v1LJLpvzGKLPr419U5FA21ORXZlBLX4WK6xhFEYl7w9Y4GjOEqlnt0Ixz
         fNHA==
ARC-Authentication-Results: i=1; mx.google.com;
       dkim=pass header.i=@gmail.com header.s=20161025 header.b=NrEkLR0D;
       spf=pass (google.com: best guess record for domain of linux-kernel-owner@vger.kernel.org designates 209.132.180.67 as permitted sender) smtp.mailfrom=linux-kernel-owner@vger.kernel.org;
       dmarc=pass (p=NONE sp=QUARANTINE dis=NONE) header.from=gmail.com
Received: from vger.kernel.org (vger.kernel.org. [209.132.180.67])
        by mx.google.com with ESMTP id 15-v6si16645905pfr.242.2018.11.11.15.05.24;
        Sun, 11 Nov 2018 15:05:39 -0800 (PST)
Received-SPF: pass (google.com: best guess record for domain of linux-kernel-owner@vger.kernel.org designates 209.132.180.67 as permitted sender) client-ip=209.132.180.67;
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
        id S2390564AbeKLIzW (ORCPT <rfc822;berg.ding@gmail.com> + 99 others);
        Mon, 12 Nov 2018 03:55:22 -0500
Received: from mail-io1-f65.google.com ([209.85.166.65]:41103 "EHLO
        mail-io1-f65.google.com" rhost-flags-OK-OK-OK-OK) by vger.kernel.org
        with ESMTP id S1731378AbeKLIzV (ORCPT
        <rfc822;linux-kernel@vger.kernel.org>);
        Mon, 12 Nov 2018 03:55:21 -0500
Received: by mail-io1-f65.google.com with SMTP id r6-v6so2214630ioj.8;
        Sun, 11 Nov 2018 15:05:14 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20161025;
        h=mime-version:references:in-reply-to:from:date:message-id:subject:to
         :cc:content-transfer-encoding;
        bh=0U9ceAnB4nAEnMcfQJhz58KUPoxlp94Luh91H/EYKkY=;
        b=NrEkLR0DUbSE6ST3VED/lXRjY1F10bkMITeyWwrIA/ZxvIw/3uQqGedqQjSNd4nvET
         ORoWvtamNnLuKSVmhqrk14g9StK9aPNNxSSag1xsT+u3A3rqTSzgZCAQyxhjUi3JI292
         FT1BFUiS/PAv7oVZQeHSZJsyiaTRQCwSneW65yxvuWbY1Orevpp9QNhUABBINlfe9TsC
         wxl2uz7DHSZfWvK9CHcZB9rc3nsM5JzudEz8php3M119FWLCdkqLZOl41cmV2MOYw+4Y
         dyGpF3pwOyykeOPaov2Mwh9rPj2cwivA4Hwd5y12dnWJaTPM6u8YNYyFdENDJ4lkGlxv
         1GrQ==
X-Received: by 2002:a6b:4f14:: with SMTP id d20-v6mr14574428iob.68.1541977513600;
 Sun, 11 Nov 2018 15:05:13 -0800 (PST)
MIME-Version: 1.0
References: <20181105085820.6341-1-aaron.lu@intel.com> <CAKgT0UdvYVTA8OjgLhXo9tRUOGikrCi3zJXSrqM0ZmeHb5P2mA@mail.gmail.com>
 <b8b1fbb7-9139-9455-69b8-8c1bed4f7c74@itcare.pl>
In-Reply-To: <b8b1fbb7-9139-9455-69b8-8c1bed4f7c74@itcare.pl>
From: Alexander Duyck <alexander.duyck@gmail.com>
Date: Sun, 11 Nov 2018 15:05:01 -0800
Message-ID: <CAKgT0UdhcXF-ohPHPbg8onRjFabEMnbpXGmLm-27skCNzGKOgw@mail.gmail.com>
Subject: Re: [PATCH 1/2] mm/page_alloc: free order-0 pages through PCP in page_frag_free()
To: =?UTF-8?Q?Pawe=C5=82_Staszewski?= <pstaszewski@itcare.pl>
Cc: aaron.lu@intel.com, linux-mm <linux-mm@kvack.org>,
        LKML <linux-kernel@vger.kernel.org>,
        Netdev <netdev@vger.kernel.org>,
        Andrew Morton <akpm@linux-foundation.org>,
        Jesper Dangaard Brouer <brouer@redhat.com>,
        Eric Dumazet <eric.dumazet@gmail.com>,
        Tariq Toukan <tariqt@mellanox.com>,
        ilias.apalodimas@linaro.org, yoel@kviknet.dk,
        Mel Gorman <mgorman@techsingularity.net>,
        Saeed Mahameed <saeedm@mellanox.com>,
        Michal Hocko <mhocko@suse.com>,
        Vlastimil Babka <vbabka@suse.cz>, dave.hansen@linux.intel.com
Content-Type: text/plain; charset="UTF-8"
Content-Transfer-Encoding: quoted-printable
Sender: liker.xu+caf_=xuliker=zju.edu.cn@gmail.com
Precedence: bulk
List-ID: <linux-kernel.vger.kernel.org>
X-Mailing-List: linux-kernel@vger.kernel.org
X-CM-TRANSID: AQAAfwC3nUnEtehb9J4uAA--.6030S3
Authentication-Results: mail-app2; spf=pass smtp.mail=liker.xu+caf_=xu
	liker=zju.edu.cn@gmail.com;
X-Coremail-Antispam: 1UD129KBjvJXoW3AFWftF1xGr13trWxJw4xJFb_yoWxXw1Upa
	y5K3ZrCF4DJF15JwnFy3Z2yr1Syws5GFW5Gry8JrWUZwnIvF9avr17KrWUuFW7Crs7Ca10
	qr4Yvry3u3WqvaDanT9S1TB71UUUUUUqnTZGkaVYY2UrUUUU0bIjqfuFe4nvWSU8nxnvy2
	9KBjDU0xBIdaVrnRJUUUP2b7Iv0xC_Kw4lb4IE77IF4wAFF20E14v26r1j6r4UM7CIcVAF
	z4kK6r1j6r18M28lY4IEw2IIxxk0rwA2F7IY1VAKz4vEj48ve4kI8wA2z4x0Y4vE2Ix0cI
	8IcVAFwI0_tr0E3s1l84ACjcxK6xIIjxv20xvEc7CjxVAFwI0_Gr1j6F4UJwA2z4x0Y4vE
	x4A2jsIE14v26rxl6s0DM28EF7xvwVC2z280aVCY1x0267AKxVW0oVCq3wAS0I0E0xvYzx
	vE52x082IY62kv0487Mc02F40EFcxC0VAKzVAqx4xG6I80ewAv7VC0I7IYx2IY67AKxVWU
	AVWUtwAv7VC2z280aVAFwI0_Gr0_Cr1lOx8S6xCaFVCjc4AY6r1j6r4UM4x0Y48IcVAKI4
	8JMx02cVCv0xWlc7CjxVAKzI0EY4vE52x082I5MxkFs20EY4vE44CYbxCE4x80FwCY02Av
	z4vEIxC_uwCY0x0Ix7I2Y4AK64vIr41lcIIF0xvE2Ix0cI8IcVAFwI0_tr0E3s1lcIIF0x
	vE2Ix0cI8IcVCY1x0267AKxVW8Jr0_Cr1UMxvI42IY6I8E87Iv67AKxVWxJr0_GcWlcIIF
	0xvEx4A2jsIEc7CjxVAFwI0_Cr1j6rxdMxAIw28IcxkI7VAKI48JMxAIw28IcVAKzI0EY4
	vE52x082I5MxCjnVCjjxCrMxC20s026xCaFVCjc4AY6r1j6r4UMI8I3I0E5I8CrVAFwI0_
	Jr0_Jr4lx2IqxVCjr7xvwVAFwI0_JrI_JrWlx4CE17CEb7AF67AKxVW8ZVWrXwCIc40Y0x
	0EwIxGrwCI42IY6xAIw20EY4v20xvaj40_JFI_GrUvcSsGvfC2KfnxnUUI43ZEXa7IUOK4
	i5UUUUU==

On Sat, Nov 10, 2018 at 3:54 PM Pawe=C5=82 Staszewski <pstaszewski@itcare.p=
l> wrote:
>
>
>
> W dniu 05.11.2018 o 16:44, Alexander Duyck pisze:
> > On Mon, Nov 5, 2018 at 12:58 AM Aaron Lu <aaron.lu@intel.com> wrote:
> >> page_frag_free() calls __free_pages_ok() to free the page back to
> >> Buddy. This is OK for high order page, but for order-0 pages, it
> >> misses the optimization opportunity of using Per-Cpu-Pages and can
> >> cause zone lock contention when called frequently.
> >>
> >> Pawe=C5=82 Staszewski recently shared his result of 'how Linux kernel
> >> handles normal traffic'[1] and from perf data, Jesper Dangaard Brouer
> >> found the lock contention comes from page allocator:
> >>
> >>    mlx5e_poll_tx_cq
> >>    |
> >>     --16.34%--napi_consume_skb
> >>               |
> >>               |--12.65%--__free_pages_ok
> >>               |          |
> >>               |           --11.86%--free_one_page
> >>               |                     |
> >>               |                     |--10.10%--queued_spin_lock_slowpa=
th
> >>               |                     |
> >>               |                      --0.65%--_raw_spin_lock
> >>               |
> >>               |--1.55%--page_frag_free
> >>               |
> >>                --1.44%--skb_release_data
> >>
> >> Jesper explained how it happened: mlx5 driver RX-page recycle
> >> mechanism is not effective in this workload and pages have to go
> >> through the page allocator. The lock contention happens during
> >> mlx5 DMA TX completion cycle. And the page allocator cannot keep
> >> up at these speeds.[2]
> >>
> >> I thought that __free_pages_ok() are mostly freeing high order
> >> pages and thought this is an lock contention for high order pages
> >> but Jesper explained in detail that __free_pages_ok() here are
> >> actually freeing order-0 pages because mlx5 is using order-0 pages
> >> to satisfy its page pool allocation request.[3]
> >>
> >> The free path as pointed out by Jesper is:
> >> skb_free_head()
> >>    -> skb_free_frag()
> >>      -> skb_free_frag()
> >>        -> page_frag_free()
> >> And the pages being freed on this path are order-0 pages.
> >>
> >> Fix this by doing similar things as in __page_frag_cache_drain() -
> >> send the being freed page to PCP if it's an order-0 page, or
> >> directly to Buddy if it is a high order page.
> >>
> >> With this change, Pawe=C5=82 hasn't noticed lock contention yet in
> >> his workload and Jesper has noticed a 7% performance improvement
> >> using a micro benchmark and lock contention is gone.
> >>
> >> [1]: https://www.spinics.net/lists/netdev/msg531362.html
> >> [2]: https://www.spinics.net/lists/netdev/msg531421.html
> >> [3]: https://www.spinics.net/lists/netdev/msg531556.html
> >> Reported-by: Pawe=C5=82 Staszewski <pstaszewski@itcare.pl>
> >> Analysed-by: Jesper Dangaard Brouer <brouer@redhat.com>
> >> Signed-off-by: Aaron Lu <aaron.lu@intel.com>
> >> ---
> >>   mm/page_alloc.c | 10 ++++++++--
> >>   1 file changed, 8 insertions(+), 2 deletions(-)
> >>
> >> diff --git a/mm/page_alloc.c b/mm/page_alloc.c
> >> index ae31839874b8..91a9a6af41a2 100644
> >> --- a/mm/page_alloc.c
> >> +++ b/mm/page_alloc.c
> >> @@ -4555,8 +4555,14 @@ void page_frag_free(void *addr)
> >>   {
> >>          struct page *page =3D virt_to_head_page(addr);
> >>
> >> -       if (unlikely(put_page_testzero(page)))
> >> -               __free_pages_ok(page, compound_order(page));
> >> +       if (unlikely(put_page_testzero(page))) {
> >> +               unsigned int order =3D compound_order(page);
> >> +
> >> +               if (order =3D=3D 0)
> >> +                       free_unref_page(page);
> >> +               else
> >> +                       __free_pages_ok(page, order);
> >> +       }
> >>   }
> >>   EXPORT_SYMBOL(page_frag_free);
> >>
> > One thing I would suggest for Pawel to try would be to reduce the Tx
> > qdisc size on his transmitting interfaces, Reduce the Tx ring size,
> > and possibly increase the Tx interrupt rate. Ideally we shouldn't have
> > too many packets in-flight and I suspect that is the issue that Pawel
> > is seeing that is leading to the page pool allocator freeing up the
> > memory. I know we like to try to batch things but the issue is
> > processing too many Tx buffers in one batch leads to us eating up too
> > much memory and causing evictions from the cache. Ideally the Rx and
> > Tx rings and queues should be sized as small as possible while still
> > allowing us to process up to our NAPI budget. Usually I run things
> > with a 128 Rx / 128 Tx setup and then reduce the Tx queue length so we
> > don't have more buffers stored there than we can place in the Tx ring.
> > Then we can avoid the extra thrash of having to pull/push memory into
> > and out of the freelists. Essentially the issue here ends up being
> > another form of buffer bloat.
> Thanks Aleksandar - yes it can be - but in my scenario setting RX buffer
> <4096 producing more interface rx drops - and no_rx_buffer on network
> controller that is receiving more packets
> So i need to stick with 3000-4000 on RX - and yes i was trying to lower
> the TX buff on connectx4 - but that changed nothing before Aaron patch
>
> After Aaron patch - decreasing TX buffer influencing total bandwidth
> that can be handled by the router/server
> Dono why before this patch there was no difference there no matter what
> i set there there was always page_alloc/slowpath on top in perf
>
>
> Currently testing RX4096/TX256 - this helps with bandwidth like +10%
> more bandwidth with less interrupts...

The problem is if you are going for less interrupts you are setting
yourself up for buffer bloat. Basically you are going to use much more
cache and much more memory then you actually need and if things are
properly configured NAPI should take care of the interrupts anyway
since under maximum load you shouldn't stop polling normally.

One issue I have seen is people delay interrupts for as long as
possible which isn't really a good thing since most network
controllers will use NAPI which will disable the interrupts and leave
them disabled whenever the system is under heavy stress so you should
be able to get the maximum performance by configuring an adapter with
small ring sizes and for high interrupt rates.

It is easiest to think of it this way. Your total packet rate is equal
to your interrupt rate times the number of buffers you will store in
the ring. So if you have some fixed rate "X" for packets and an
interrupt rate of "i" then your optimal ring size should be "X/i". So
if you lower the interrupt rate you end up hurting the throughput
unless you increase the buffer size. However at a certain point the
buffer size starts becoming an issue. For example with UDP flows I
often see massive packet drops if you tune the interrupt rate too low
and then put the system under heavy stress.

- Alex
