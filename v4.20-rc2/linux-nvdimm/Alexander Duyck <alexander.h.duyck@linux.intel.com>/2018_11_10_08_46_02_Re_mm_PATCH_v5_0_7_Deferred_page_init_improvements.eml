Return-Path: <linux-kernel-owner@vger.kernel.org>
Delivered-To: unknown
Received: from pop3.zju.edu.cn (61.164.42.155:110) by
  likexu-MOBL1.ccr.corp.intel.com with POP3; 10 Nov 2018 00:58:13 -0000
Received: from icoremail.net (unknown [209.85.210.182])
	by mail-app2 (Coremail) with SMTP id by_KCgDnX99oKuZban1rAQ--.32923S3;
	Sat, 10 Nov 2018 08:46:33 +0800 (CST)
Received: from mail-pf1-f182.google.com (unknown [209.85.210.182])
	by mx2.icoremail.net (Coremail) with SMTP id AQAAfwD32UVmKuZbFtokAA--.3569S3;
	Sat, 10 Nov 2018 08:46:31 +0800 (CST)
Received: by mail-pf1-f182.google.com with SMTP id e22-v6so1657513pfn.8
        for <xuliker@zju.edu.cn>; Fri, 09 Nov 2018 16:46:31 -0800 (PST)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20161025;
        h=x-original-authentication-results:x-gm-message-state:delivered-to
         :message-id:subject:from:to:cc:date:in-reply-to:references
         :mime-version:content-transfer-encoding:sender:precedence:list-id;
        bh=4s0QSgoE5PuZ0U5YN8AdG8NfUxYxoodM6WBs+2wH6dI=;
        b=ov0oIa2ynoyn+NdpgCcd59mjFyn17Ul/Y/B0legLBvEpzPK5U23bubaApFuYE0kNde
         wStBxiIiUJEDQBqwkZHpGrc/FEsQwNBM4Yl5Zj1oKfR05Z+9jEKCwSgL/pULTbj7u0Zp
         KrAuqWG89YGVVFz3hXQUb4iSZe84vdpC7vE/X49b8Twa05vZQNvZE83jmfT1pKpy1uox
         eG5nFzmrP/85ZfiTxcQpZuqGeQn1fTzsHVc7xS7l1QD1qYZcvmEwgL4MIQ7Cz2nVvujz
         p4ICZ63p8c6sxoAzfC7TESLUxDwZ11czq0icxes6waIq/uBfZIafiFLnHtp03fL9y7wi
         lXuQ==
X-Original-Authentication-Results: mx.google.com;       spf=pass (google.com: best guess record for domain of linux-kernel-owner@vger.kernel.org designates 209.132.180.67 as permitted sender) smtp.mailfrom=linux-kernel-owner@vger.kernel.org;       dmarc=fail (p=NONE sp=NONE dis=NONE) header.from=intel.com
X-Gm-Message-State: AGRZ1gKOk+FpJc43KNlwJCsuU/jiVlcfHOb2P2OIqnAzlKtzrE/l4Z3M
	Gb0+frK8zUZmu1uy6RwEuje0mHuCT0TtM1ql0G6Mg+F/GUWbHLWffg==
X-Received: by 2002:a63:bc02:: with SMTP id q2mr5089683pge.116.1541810790784;
        Fri, 09 Nov 2018 16:46:30 -0800 (PST)
X-Forwarded-To: xuliker@zju.edu.cn
X-Forwarded-For: liker.xu@gmail.com xuliker@zju.edu.cn
Delivered-To: liker.xu@gmail.com
Received: by 2002:a17:90a:c304:0:0:0:0 with SMTP id g4-v6csp567013pjt;
        Fri, 9 Nov 2018 16:46:29 -0800 (PST)
X-Google-Smtp-Source: AJdET5cOCIvsRM38Ln2PJyQ5s7WUsl0MLP6muxcuYFIQ3gPhguhcqkgMn4eKgCy27vSXtvhScOZz
X-Received: by 2002:a63:91c1:: with SMTP id l184mr9441344pge.29.1541810789695;
        Fri, 09 Nov 2018 16:46:29 -0800 (PST)
ARC-Seal: i=1; a=rsa-sha256; t=1541810789; cv=none;
        d=google.com; s=arc-20160816;
        b=J8ptixZtkLsevIhwAeIABRRqHIvZwidzTyG58Chubxu0B6lqYGVb/pL+sumiOUH/3l
         3eRZmBnYfxbVrJl/esWWTwUbHr73+QzCGFVpfe1XE/WJQD5W9PgrqxVZDD1OIyJC9vh0
         d20DHzNm61DWTy1KNOzsxbTdt//qol/ooAxvTAsjxhq6nlGMxRr77/c38yMd5L85eAyx
         92RxM04vwgKdMVbryveJEFUYE3RvWPxdxyrdkCPY4B7vhKOyRk+5iLRqb6VcNle8hLlx
         knA0Dyma5D8ShfgNYCJB12uibDbyV4B+WAmTxk0Xu/QT/NCOSQ2DAL7uIfyOAC76JbHE
         +tlw==
ARC-Message-Signature: i=1; a=rsa-sha256; c=relaxed/relaxed; d=google.com; s=arc-20160816;
        h=list-id:precedence:sender:content-transfer-encoding:mime-version
         :references:in-reply-to:date:cc:to:from:subject:message-id;
        bh=4s0QSgoE5PuZ0U5YN8AdG8NfUxYxoodM6WBs+2wH6dI=;
        b=yJiGbtmKfQrSN3UOhwx3TEh7R84czPeiVvVlOaiqbVNad6DC8BUx4LHH2gCkzra893
         SKIPXALXKMeBdO8Ca84VDAdj93EKPgrOc7bQLBqE24JC/QPEKP1MgI/pQJ1q08A+59Bu
         +sIO/5fyf7fTk3O6k/ZZCUb+6AauOK1lJJIa4LjvumE7l3fYkSGQft9Ig4lpemlfo95x
         V0vpxUUWcTnuXjzu010aX9SAmFSK9D884OjQwKWrbE96Hpfp6N2GkOesH7y/upwZdMuy
         QTIb0+riKJIsSyNarhpic4OV63h/z2NT8toCwgNwQaksE3+NkjA+KjiJ6/waFnCYVQjV
         pFgw==
ARC-Authentication-Results: i=1; mx.google.com;
       spf=pass (google.com: best guess record for domain of linux-kernel-owner@vger.kernel.org designates 209.132.180.67 as permitted sender) smtp.mailfrom=linux-kernel-owner@vger.kernel.org;
       dmarc=fail (p=NONE sp=NONE dis=NONE) header.from=intel.com
Received: from vger.kernel.org (vger.kernel.org. [209.132.180.67])
        by mx.google.com with ESMTP id i136-v6si10098542pfe.224.2018.11.09.16.46.14;
        Fri, 09 Nov 2018 16:46:29 -0800 (PST)
Received-SPF: pass (google.com: best guess record for domain of linux-kernel-owner@vger.kernel.org designates 209.132.180.67 as permitted sender) client-ip=209.132.180.67;
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
        id S1728542AbeKJK3J (ORCPT <rfc822;tomnomnom1@gmail.com>
        + 99 others); Sat, 10 Nov 2018 05:29:09 -0500
Received: from mga17.intel.com ([192.55.52.151]:47451 "EHLO mga17.intel.com"
        rhost-flags-OK-OK-OK-OK) by vger.kernel.org with ESMTP
        id S1727322AbeKJK3J (ORCPT <rfc822;linux-kernel@vger.kernel.org>);
        Sat, 10 Nov 2018 05:29:09 -0500
X-Amp-Result: SKIPPED(no attachment in message)
X-Amp-File-Uploaded: False
Received: from orsmga001.jf.intel.com ([10.7.209.18])
  by fmsmga107.fm.intel.com with ESMTP/TLS/DHE-RSA-AES256-GCM-SHA384; 09 Nov 2018 16:46:03 -0800
X-ExtLoop1: 1
X-IronPort-AV: E=Sophos;i="5.54,485,1534834800"; 
   d="scan'208";a="107013995"
Received: from ahduyck-desk1.jf.intel.com ([10.7.198.76])
  by orsmga001.jf.intel.com with ESMTP; 09 Nov 2018 16:46:02 -0800
Message-ID: <0d8782742d016565870c578848138aaedf873a7c.camel@linux.intel.com>
Subject: Re: [mm PATCH v5 0/7] Deferred page init improvements
From: Alexander Duyck <alexander.h.duyck@linux.intel.com>
To: Pavel Tatashin <pasha.tatashin@soleen.com>,
        daniel.m.jordan@oracle.com
Cc: akpm@linux-foundation.org, linux-mm@kvack.org,
        sparclinux@vger.kernel.org, linux-kernel@vger.kernel.org,
        linux-nvdimm@lists.01.org, davem@davemloft.net,
        pavel.tatashin@microsoft.com, mhocko@suse.com, mingo@kernel.org,
        kirill.shutemov@linux.intel.com, dan.j.williams@intel.com,
        dave.jiang@intel.com, rppt@linux.vnet.ibm.com, willy@infradead.org,
        vbabka@suse.cz, khalid.aziz@oracle.com, ldufour@linux.vnet.ibm.com,
        mgorman@techsingularity.net, yi.z.zhang@linux.intel.com
Date: Fri, 09 Nov 2018 16:46:02 -0800
In-Reply-To: <20181110000006.tmcfnzynelaznn7u@xakep.localdomain>
References: <20181109211521.5ospn33pp552k2xv@xakep.localdomain>
         <18b6634b912af7b4ec01396a2b0f3b31737c9ea2.camel@linux.intel.com>
         <20181110000006.tmcfnzynelaznn7u@xakep.localdomain>
Content-Type: text/plain; charset="UTF-8"
X-Mailer: Evolution 3.28.5 (3.28.5-1.fc28) 
Mime-Version: 1.0
Content-Transfer-Encoding: 7bit
Sender: liker.xu+caf_=xuliker=zju.edu.cn@gmail.com
Precedence: bulk
List-ID: <linux-kernel.vger.kernel.org>
X-Mailing-List: linux-kernel@vger.kernel.org
X-CM-TRANSID: AQAAfwD32UVmKuZbFtokAA--.3569S3
Authentication-Results: mail-app2; spf=pass smtp.mail=liker.xu+caf_=xu
	liker=zju.edu.cn@gmail.com;
X-Coremail-Antispam: 1UD129KBjvJXoWxuFWUuFW5KF45Cw4DKry7trb_yoWxAF1fpa
	y3t3Z0kr4vy3y8Awn2yw18XFyvqwn5GFy5GFy5CryDCwn5GF12vr4ftw4F9F9rursYk3Wj
	vFWjq3sxZ3WDAaDanT9S1TB71UUUUUUqnTZGkaVYY2UrUUUU0bIjqfuFe4nvWSU8nxnvy2
	9KBjDU0xBIdaVrnRJUUUBFb7Iv0xC_Kw4lb4IE77IF4wAFF20E14v26r1j6r4UM7CIcVAF
	z4kK6r1j6r18M28lY4IEw2IIxxk0rwA2F7IY1VAKz4vEj48ve4kI8wA2z4x0Y4vE2Ix0cI
	8IcVAFwI0_Xr0_Ar1l84ACjcxK6xIIjxv20xvEc7CjxVAFwI0_Gr0_Cr1l84ACjcxK6I8E
	87Iv67AKxVW0oVCq3wA2z4x0Y4vEx4A2jsIEc7CjxVAFwI0_GcCE3s1le2I262IYc4CY6c
	8Ij28IcVAaY2xG8wAqx4xG64xvF2IEw4CE5I8CrVC2j2WlYx0E2Ix0cI8IcVAFwI0_Jr0_
	Jr4lYx0Ex4A2jsIE14v26r4j6F4UMcvjeVCFs4IE7xkEbVWUJVW8JwACjcxG0xvY0x0EwI
	xGrwCjxxvEa2IrMxkF7I0Ew4C26cxK6c8Ij28IcwCY02Avz4vEIxC_twCY0x0Ix7I2Y4AK
	64vIr41lcIIF0xvE2Ix0cI8IcVAFwI0_JFI_Gr1lcIIF0xvE2Ix0cI8IcVCY1x0267AKxV
	WUJVW8JwCYIxAIcVC2z280aVAFwI0_Gr1j6F4UJwCYIxAIcVC2z280aVCY1x0267AKxVW8
	Jr0_Cr1UMxAIw28IcxkI7VAKI48JMxAIw28IcVAKzI0EY4vE52x082I5MxCjnVCjjxCrMx
	C20s026xCaFVCjc4AY6r1j6r4UMI8I3I0E5I8CrVAFwI0_Jr0_Jr4lx2IqxVCjr7xvwVAF
	wI0_JrI_JrWlx4CE17CEb7AF67AKxVW8ZVWrXwCIc40Y0x0EwIxGrwCI42IY6xAIw20EY4
	v20xvaj40_Zr0_Wr1UYxBIdaVFxhVjvjDU0xZFpf9x07bm2-5UUUUU=

On Fri, 2018-11-09 at 19:00 -0500, Pavel Tatashin wrote:
> On 18-11-09 15:14:35, Alexander Duyck wrote:
> > On Fri, 2018-11-09 at 16:15 -0500, Pavel Tatashin wrote:
> > > On 18-11-05 13:19:25, Alexander Duyck wrote:
> > > > This patchset is essentially a refactor of the page initialization logic
> > > > that is meant to provide for better code reuse while providing a
> > > > significant improvement in deferred page initialization performance.
> > > > 
> > > > In my testing on an x86_64 system with 384GB of RAM and 3TB of persistent
> > > > memory per node I have seen the following. In the case of regular memory
> > > > initialization the deferred init time was decreased from 3.75s to 1.06s on
> > > > average. For the persistent memory the initialization time dropped from
> > > > 24.17s to 19.12s on average. This amounts to a 253% improvement for the
> > > > deferred memory initialization performance, and a 26% improvement in the
> > > > persistent memory initialization performance.
> > > 
> > > Hi Alex,
> > > 
> > > Please try to run your persistent memory init experiment with Daniel's
> > > patches:
> > > 
> > > https://lore.kernel.org/lkml/20181105165558.11698-1-daniel.m.jordan@oracle.com/
> > 
> > I've taken a quick look at it. It seems like a bit of a brute force way
> > to try and speed things up. I would be worried about it potentially
> 
> There is a limit to max number of threads that ktasks start. The memory
> throughput is *much* higher than what one CPU can maxout in a node, so
> there is no reason to leave the other CPUs sit idle during boot when
> they can help to initialize.

Right, but right now that limit can still be pretty big when it is
something like 25% of all the CPUs on a 288 CPU system.

One issue is the way the code was ends up essentially blowing out the
cache over and over again. Doing things in two passes made it really
expensive as you took one cache miss to initialize it, and another to
free it. I think getting rid of that is one of the biggest gains with
my patch set.

> > introducing performance issues if the number of CPUs thrown at it end
> > up exceeding the maximum throughput of the memory.
> > 
> > The data provided with patch 11 seems to point to issues such as that.
> > In the case of the E7-8895 example cited it is increasing the numbers
> > of CPUs used from memory initialization from 8 to 72, a 9x increase in
> > the number of CPUs but it is yeilding only a 3.88x speedup.
> 
> Yes, but in both cases we are far from maxing out the memory throughput.
> The 3.88x is indeed low, and I do not know what slows it down.
> 
> Daniel,
> 
> Could you please check why multi-threading efficiency is so low here?
> 
> I bet, there is some atomic operation introduces a contention within a
> node. It should be possible to resolve.

Depending on what kernel this was based on it probably was something
like SetPageReserved triggering pipeline stalls, or maybe it is freeing
the pages themselves since I would imagine that has a pretty big
overhead an may end up serializing some things.

> > 
> > > The performance should improve by much more than 26%.
> > 
> > The 26% improvement, or speedup of 1.26x using the ktask approach, was
> > for persistent memory, not deferred memory init. The ktask patch
> > doesn't do anything for persistent memory since it is takes the hot-
> > plug path and isn't handled via the deferred memory init.
> 
> Ah, I thought in your experiment persistent memory takes deferred init
> path. So, what exactly in your patches make this 1.26x speedup?

Basically it is the folding of the reserved bit into the setting of the
rest of the values written into the page flags. With that change we are
able to tighten the memory initialization loop to the point where it
almost looks like a memset case as it will put together all of the
memory values outside of the loop and then just loop through assigning
the values for each page.

> > 
> > I had increased deferred memory init to about 3.53x the original speed
> > (3.75s to 1.06s) on the system which I was testing. I do agree the two
> > patches should be able to synergistically boost each other though as
> > this patch set was meant to make the init much more cache friendly so
> > as a result it should scale better as you add additional cores. I know
> > I had done some playing around with fake numa to split up a single node
> > into 8 logical nodes and I had seen a similar speedup of about 3.85x
> > with my test memory initializing in about 275ms.

It is also possible that the the 3.8x is an upper limit for something
on the system in terms of scaling. I just realized that the 3.85x I saw
with an 8 way split over a 4 socket system isn't too different from the
3.88x that was recorded for a 9 way split over an 8 socket system.

> > > Overall, your works looks good, but it needs to be considered how easy it will be
> > > to merge with ktask. I will try to complete the review today.
> > > 
> > > Thank you,
> > > Pasha
> > 
> > Looking over the patches they are still in the RFC stage and the data
> > is in need of updates since it is referencing 4.15-rc kernels as its
> > baseline. If anything I really think the ktask patch 11 would be easier
> > to rebase around my patch set then the other way around. Also, this
> > series is in Andrew's mmots as of a few days ago, so I think it will be
> > in the next mmotm that comes out.
> 
> I do not disagree, I think these two patch series should complement each
> other. But, if your changes make it impossible for ktask, I would strongly argue
> against it, as the potential improvements with ktasks are much higher.
> But, so far I do not see anything, so I think they can work together. I
> am still reviewing your work.

I am assuming patch 11 from the ktask set is the only one that really
touches the deferred memory init. I'm thinking that the actual patch
should be smaller if it is rebased off of this patch set. I didn't see
anything that should conflict with my patch set, and as I said the only
concern would be making certain to split the zone correctly to prevent
the free thread from hopping across the MAX_ORDER boundaries.

> > 
> > The integration with the ktask code should be pretty straight forward.
> > If anything I think my code would probably make it easier since it gets
> > rid of the need to do all this in two passes. The only new limitation
> > it would add is that you would probably want to split up the work along
> > either max order or section aligned boundaries. What it would
> 
> Which is totally OK, it should make ktasks scale even better.

Right.

> > essentially do is make things so that each of the ktask threads would
> > probably look more like deferred_grow_zone which after my patch set is
> > actually a fairly simple function.
> > 
> > Thanks.
> 
> Thank you,
> Pasha


