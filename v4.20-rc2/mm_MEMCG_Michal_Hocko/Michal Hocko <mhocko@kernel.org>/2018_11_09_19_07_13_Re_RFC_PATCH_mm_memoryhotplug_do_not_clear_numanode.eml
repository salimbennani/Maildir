Return-Path: <linux-kernel-owner@vger.kernel.org>
Delivered-To: unknown
Received: from pop3.zju.edu.cn (61.164.42.155:110) by
  likexu-MOBL1.ccr.corp.intel.com with POP3; 10 Nov 2018 00:52:07 -0000
Received: from icoremail.net (unknown [209.85.215.171])
	by mail-app2 (Coremail) with SMTP id by_KCgC3f0GpauVbuERnAQ--.31179S3;
	Fri, 09 Nov 2018 19:08:26 +0800 (CST)
Received: from mail-pg1-f171.google.com (unknown [209.85.215.171])
	by mx2.icoremail.net (Coremail) with SMTP id AQAAfwC3kT2nauVbET8iAA--.1760S3;
	Fri, 09 Nov 2018 19:08:24 +0800 (CST)
Received: by mail-pg1-f171.google.com with SMTP id f8-v6so723454pgq.5
        for <xuliker@zju.edu.cn>; Fri, 09 Nov 2018 03:08:24 -0800 (PST)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20161025;
        h=x-original-authentication-results:x-gm-message-state:delivered-to
         :date:from:to:cc:subject:message-id:references:mime-version
         :content-disposition:in-reply-to:user-agent:sender:precedence
         :list-id;
        bh=p9KlGQxoHplejDQdjO3p1YK2hGMejN+HnmKoGf9cS7A=;
        b=VT+lrnAFrQ35foboP2AlbEvSTHyDYS7rhqX52sLdN2mISRHqCjSjquL+g32n88IAz8
         nQof2VQTAsG/bpc6bkQpxVw+lcJb7pPay7+Qzh+mLz5bAjvpknqFrnZ9/Mg2mIU/06Yo
         E+4YzXnZ+eG6dTOuD9gwcwqqCUpCNeWTG0Wa4C3EWQjM1IHNOLvijDKfBQ0hH8k1FDDq
         b8Th1OIiUmzuyrqTn0LcnfwEDxSDvGgpqmqQWqIU0pqadtnfTm3saJ9M8RGJLYrFM+hq
         mR6qihw6CpL7NM+/oCr7bCSZcz/3S0KiEjGVk0who5dZam4HZn3PB0n5aRN/bHy6+Nw1
         C9ug==
X-Original-Authentication-Results: mx.google.com;       spf=pass (google.com: best guess record for domain of linux-kernel-owner@vger.kernel.org designates 209.132.180.67 as permitted sender) smtp.mailfrom=linux-kernel-owner@vger.kernel.org;       dmarc=fail (p=NONE sp=NONE dis=NONE) header.from=kernel.org
X-Gm-Message-State: AGRZ1gI4R3K9H4bkAXtNEzUQD0dl8ZcIDpulKjsAFSUvPeyn8PTMYrN9
	v6OhUCe3fwepIsgT4OB3t6wVsHh6OHEsfzsHrn1orsiUrknpzKRizw==
X-Received: by 2002:a63:2315:: with SMTP id j21mr7116678pgj.297.1541761703660;
        Fri, 09 Nov 2018 03:08:23 -0800 (PST)
X-Forwarded-To: xuliker@zju.edu.cn
X-Forwarded-For: liker.xu@gmail.com xuliker@zju.edu.cn
Delivered-To: liker.xu@gmail.com
Received: by 2002:a17:90a:c304:0:0:0:0 with SMTP id g4-v6csp65072pjt;
        Fri, 9 Nov 2018 03:08:22 -0800 (PST)
X-Google-Smtp-Source: AJdET5e4a07/KUqNWYy2ZLdAvYI0Ls+TdjiRRB5h8KuL5TOMHf71U9yzawvJBZ5BcDswc6LBTDBe
X-Received: by 2002:a62:5c6:: with SMTP id 189-v6mr886093pff.193.1541761702597;
        Fri, 09 Nov 2018 03:08:22 -0800 (PST)
ARC-Seal: i=1; a=rsa-sha256; t=1541761702; cv=none;
        d=google.com; s=arc-20160816;
        b=c97LBLDQwwEzAaorr5bRKZ2dGwHy4M8uk41h36Lbdko/5TBVzDw/J4Nkxu0pWYdKjl
         j2XlB+cdu/+lPVYV/+YJMXf89zm0gCKRyNVNt4g6BAO/M1x8dSRrmND5Pwy3p8Wxjnlp
         9/SMDhdFu9PBY+pHUTUCwxATH0eilXNcssA8G/dQaPckKNErHjPNmW73rCSLPipgB7Nu
         a1kvNHiAFHY5Zplwa21loU7s2KkyEsrYRXGkYo9UZ2gHICLwEzT235Gcew8Bl0yw5cGj
         BQ6Pn4n79hDKlil+ejh2PHUeDFQVCiuAv0orSdeFsVBM6b4FC7bUI5UQoVkvdpztlh6J
         hCUg==
ARC-Message-Signature: i=1; a=rsa-sha256; c=relaxed/relaxed; d=google.com; s=arc-20160816;
        h=list-id:precedence:sender:user-agent:in-reply-to
         :content-disposition:mime-version:references:message-id:subject:cc
         :to:from:date;
        bh=p9KlGQxoHplejDQdjO3p1YK2hGMejN+HnmKoGf9cS7A=;
        b=n8opPgUmq5bTvEM3jeqhG24O1Gn8mdOlC8T4rgywa4hNq/Z1E/UGPnbcxZbMZUdOUM
         /97Mmy1338GYzBN+4U/RkCuKfuIHjQJ/TfLd6d0lrCLKt9TAqnBHVrXFg8b4pvMdv6Cj
         6+btoA8N+E1dk4scj3FvLzsy3OS0QMlhbsSxGmQ3XD6Pd9AxxrfijqQdvr591hwuypJI
         0cHKoG0ZCXdmqxDkFAXfnMSSwnjSLqTJ1/WVUFTFrtPhOb9kGnNwju7vE4bID9mGotP1
         VotFWNDUtMYJd2EesqqbOKV2n14iDVSywIJY65B0i2Oqiuu7DOP/WRa4bU+X8DQw1vO4
         pKDA==
ARC-Authentication-Results: i=1; mx.google.com;
       spf=pass (google.com: best guess record for domain of linux-kernel-owner@vger.kernel.org designates 209.132.180.67 as permitted sender) smtp.mailfrom=linux-kernel-owner@vger.kernel.org;
       dmarc=fail (p=NONE sp=NONE dis=NONE) header.from=kernel.org
Received: from vger.kernel.org (vger.kernel.org. [209.132.180.67])
        by mx.google.com with ESMTP id 19-v6si8743754pfb.113.2018.11.09.03.08.01;
        Fri, 09 Nov 2018 03:08:22 -0800 (PST)
Received-SPF: pass (google.com: best guess record for domain of linux-kernel-owner@vger.kernel.org designates 209.132.180.67 as permitted sender) client-ip=209.132.180.67;
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
        id S1728393AbeKIUr2 (ORCPT <rfc822;changseok.bae@gmail.com>
        + 99 others); Fri, 9 Nov 2018 15:47:28 -0500
Received: from mx2.suse.de ([195.135.220.15]:38670 "EHLO mx1.suse.de"
        rhost-flags-OK-OK-OK-FAIL) by vger.kernel.org with ESMTP
        id S1728272AbeKIUr2 (ORCPT <rfc822;linux-kernel@vger.kernel.org>);
        Fri, 9 Nov 2018 15:47:28 -0500
X-Virus-Scanned: by amavisd-new at test-mx.suse.de
Received: from relay2.suse.de (unknown [195.135.220.254])
        by mx1.suse.de (Postfix) with ESMTP id BCB4FAF3E;
        Fri,  9 Nov 2018 11:07:19 +0000 (UTC)
Date: Fri, 9 Nov 2018 12:07:13 +0100
From: Michal Hocko <mhocko@kernel.org>
To: Anshuman Khandual <anshuman.khandual@arm.com>
Cc: linux-mm@kvack.org, Andrew Morton <akpm@linux-foundation.org>,
        Oscar Salvador <OSalvador@suse.com>,
        LKML <linux-kernel@vger.kernel.org>,
        Miroslav Benes <mbenes@suse.cz>,
        Vlastimil Babka <vbabka@suse.cz>
Subject: Re: [RFC PATCH] mm, memory_hotplug: do not clear numa_node
 association after hot_remove
Message-ID: <20181109110713.GG5321@dhcp22.suse.cz>
References: <20181108100413.966-1-mhocko@kernel.org>
 <20181108102917.GV27423@dhcp22.suse.cz>
 <048c04ae-7394-d03f-813e-42acdc965dd2@arm.com>
 <20181109075914.GD18390@dhcp22.suse.cz>
 <f9dd3dd0-3b20-446f-a131-70180fb733bf@arm.com>
MIME-Version: 1.0
Content-Type: text/plain; charset=us-ascii
Content-Disposition: inline
In-Reply-To: <f9dd3dd0-3b20-446f-a131-70180fb733bf@arm.com>
User-Agent: Mutt/1.10.1 (2018-07-13)
Sender: liker.xu+caf_=xuliker=zju.edu.cn@gmail.com
Precedence: bulk
List-ID: <linux-kernel.vger.kernel.org>
X-Mailing-List: linux-kernel@vger.kernel.org
X-CM-TRANSID: AQAAfwC3kT2nauVbET8iAA--.1760S3
Authentication-Results: mail-app2; spf=pass smtp.mail=liker.xu+caf_=xu
	liker=zju.edu.cn@gmail.com;
X-Coremail-Antispam: 1UD129KBjvJXoWxCrWxurWfXry5urW7Zr1fWFg_yoW7GryUpr
	WUXF4Ykr4ktr1UCr18t345GryUtr17Aay7Xr1xWr1UZF1DKr1DJr1UJr4UCryDJr18AF17
	trs8tw4Iqr15JaUanT9S1TB71UUUUUUqnTZGkaVYY2UrUUUU0bIjqfuFe4nvWSU8nxnvy2
	9KBjDU0xBIdaVrnRJUUUPjb7Iv0xC_Kw4lb4IE77IF4wAFF20E14v26r1j6r4UM7CIcVAF
	z4kK6r1j6r18M28lY4IEw2IIxxk0rwA2F7IY1VAKz4vEj48ve4kI8wA2z4x0Y4vE2Ix0cI
	8IcVAFwI0_Ar0_tr1l84ACjcxK6xIIjxv20xvEc7CjxVAFwI0_Cr0_Gr1UM28EF7xvwVC2
	z280aVAFwI0_GcCE3s1l84ACjcxK6I8E87Iv6xkF7I0E14v26rxl6s0DM2AIxVAIcxkEcV
	Aq07x20xvEncxIr21l5I8CrVACY4xI64kE6c02F40Ex7xfMcIj6xIIjxv20xvE14v26r1j
	6r18McIj6I8E87Iv67AKxVW8JVWxJwAm72CE4IkC6x0Yz7v_Jr0_Gr1lF7xvr2IY64vIr4
	1l7I0Y6sxI4wCY1x0264kExVAvwVAq07x20xylc7Ca8VAvwVCFzxkY4VCF77xAMxkIecxE
	wVCI4VW8KwCY0x0Ix7I2Y4AK64vIr41lcIIF0xvE2Ix0cI8IcVAFwI0_Gr0_Xr1lcIIF0x
	vE2Ix0cI8IcVCY1x0267AKxVW8JVWxJwCYIxAIcVC2z280aVAFwI0_GcCE3s1lcIIF0xvE
	x4A2jsIEc7CjxVAFwI0_GcCE3s1l42xK82IYc2Ij64vIr41l42xK82IY64kExVAvwVAq07
	x20xyl4x8a6x804xWl4I8I3I0E4IkC6x0Yz7v_Jr0_Gr1lx2IqxVAqx4xG67AKxVWUJVWU
	GwC20s026x8GjcxK67AKxVWUGVWUWwC2zVAF1VAY17CE14v26r1q6r43MIIYrxkI7VAKI4
	8JMIIF0xvE42xK8VAvwI8IcIk0rVWUJVWUCbIYCTnIWIevJa73UjIFyTuYvjxUHzV1UUUU
	U

On Fri 09-11-18 16:34:29, Anshuman Khandual wrote:
> 
> 
> On 11/09/2018 01:29 PM, Michal Hocko wrote:
> > On Fri 09-11-18 09:12:09, Anshuman Khandual wrote:
> >>
> >>
> >> On 11/08/2018 03:59 PM, Michal Hocko wrote:
> >>> [Removing Wen Congyang and Tang Chen from the CC list because their
> >>>  emails bounce. It seems that we will never learn about their motivation]
> >>>
> >>> On Thu 08-11-18 11:04:13, Michal Hocko wrote:
> >>>> From: Michal Hocko <mhocko@suse.com>
> >>>>
> >>>> Per-cpu numa_node provides a default node for each possible cpu. The
> >>>> association gets initialized during the boot when the architecture
> >>>> specific code explores cpu->NUMA affinity. When the whole NUMA node is
> >>>> removed though we are clearing this association
> >>>>
> >>>> try_offline_node
> >>>>   check_and_unmap_cpu_on_node
> >>>>     unmap_cpu_on_node
> >>>>       numa_clear_node
> >>>>         numa_set_node(cpu, NUMA_NO_NODE)
> >>>>
> >>>> This means that whoever calls cpu_to_node for a cpu associated with such
> >>>> a node will get NUMA_NO_NODE. This is problematic for two reasons. First
> >>>> it is fragile because __alloc_pages_node would simply blow up on an
> >>>> out-of-bound access. We have encountered this when loading kvm module
> >>>> BUG: unable to handle kernel paging request at 00000000000021c0
> >>>> IP: [<ffffffff8119ccb3>] __alloc_pages_nodemask+0x93/0xb70
> >>>> PGD 800000ffe853e067 PUD 7336bbc067 PMD 0
> >>>> Oops: 0000 [#1] SMP
> >>>> [...]
> >>>> CPU: 88 PID: 1223749 Comm: modprobe Tainted: G        W          4.4.156-94.64-default #1
> >>>> task: ffff88727eff1880 ti: ffff887354490000 task.ti: ffff887354490000
> >>>> RIP: 0010:[<ffffffff8119ccb3>]  [<ffffffff8119ccb3>] __alloc_pages_nodemask+0x93/0xb70
> >>>> RSP: 0018:ffff887354493b40  EFLAGS: 00010202
> >>>> RAX: 00000000000021c0 RBX: 0000000000000000 RCX: 0000000000000000
> >>>> RDX: 0000000000000000 RSI: 0000000000000002 RDI: 00000000014000c0
> >>>> RBP: 00000000014000c0 R08: ffffffffffffffff R09: 0000000000000000
> >>>> R10: ffff88fffc89e790 R11: 0000000000014000 R12: 0000000000000101
> >>>> R13: ffffffffa0772cd4 R14: ffffffffa0769ac0 R15: 0000000000000000
> >>>> FS:  00007fdf2f2f1700(0000) GS:ffff88fffc880000(0000) knlGS:0000000000000000
> >>>> CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033
> >>>> CR2: 00000000000021c0 CR3: 00000077205ee000 CR4: 0000000000360670
> >>>> DR0: 0000000000000000 DR1: 0000000000000000 DR2: 0000000000000000
> >>>> DR3: 0000000000000000 DR6: 00000000fffe0ff0 DR7: 0000000000000400
> >>>> Stack:
> >>>>  0000000000000086 014000c014d20400 ffff887354493bb8 ffff882614d20f4c
> >>>>  0000000000000000 0000000000000046 0000000000000046 ffffffff810ac0c9
> >>>>  ffff88ffe78c0000 ffffffff0000009f ffffe8ffe82d3500 ffff88ff8ac55000
> >>>> Call Trace:
> >>>>  [<ffffffffa07476cd>] alloc_vmcs_cpu+0x3d/0x90 [kvm_intel]
> >>>>  [<ffffffffa0772c0c>] hardware_setup+0x781/0x849 [kvm_intel]
> >>>>  [<ffffffffa04a1c58>] kvm_arch_hardware_setup+0x28/0x190 [kvm]
> >>>>  [<ffffffffa04856fc>] kvm_init+0x7c/0x2d0 [kvm]
> >>>>  [<ffffffffa0772cf2>] vmx_init+0x1e/0x32c [kvm_intel]
> >>>>  [<ffffffff8100213a>] do_one_initcall+0xca/0x1f0
> >>>>  [<ffffffff81193886>] do_init_module+0x5a/0x1d7
> >>>>  [<ffffffff81112083>] load_module+0x1393/0x1c90
> >>>>  [<ffffffff81112b30>] SYSC_finit_module+0x70/0xa0
> >>>>  [<ffffffff8161cbc3>] entry_SYSCALL_64_fastpath+0x1e/0xb7
> >>>> DWARF2 unwinder stuck at entry_SYSCALL_64_fastpath+0x1e/0xb7
> >>>>
> >>>> on an older kernel but the code is basically the same in the current
> >>>> Linus tree as well. alloc_vmcs_cpu could use alloc_pages_nodemask which
> >>>> would recognize NUMA_NO_NODE and use alloc_pages_node which would translate
> >>>> it to numa_mem_id but that is wrong as well because it would use a cpu
> >>>> affinity of the local CPU which might be quite far from the original node.
> >>
> >> But then the original node is getting/already off-lined. The allocation is
> >> going to come from a different node. alloc_pages_node() at least steer the
> >> allocation alway from VM_BUG_ON() because of NUMA_NO_NODE by replacing it
> >> with numa_mem_id().
> >>
> >> If node fallback order is important for this allocation then could not it
> >> use __alloc_pages_nodemask() directly giving preference for its zonelist
> >> node and nodemask. Just curious.
> > 
> > How does the caller get the right node to allocate from? We do have the
> > proper zone list for the offline node so why not use it?
> I get your point. NODE_DATA() for the off lined node is still around and
> so does the proper zone list for allocation, so why the caller should work
> around the problem by building it's preferred nodemask_t etc. No problem,
> I was just curious.

I thought I've made it cler in the changelog. If not, I am open to
suggestions on how to make it more clear.
-- 
Michal Hocko
SUSE Labs
