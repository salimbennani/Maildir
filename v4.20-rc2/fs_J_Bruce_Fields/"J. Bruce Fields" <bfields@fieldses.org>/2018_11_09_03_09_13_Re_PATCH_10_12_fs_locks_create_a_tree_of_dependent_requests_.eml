Return-Path: <linux-kernel-owner@vger.kernel.org>
Delivered-To: unknown
Received: from pop3.zju.edu.cn (124.160.105.205:110) by
  likexu-MOBL1.ccr.corp.intel.com with POP3; 09 Nov 2018 05:30:42 -0000
Received: from icoremail.net (unknown [209.85.215.173])
	by mail-app2 (Coremail) with SMTP id by_KCgDnX19z+uRbpYNkAQ--.30756S3;
	Fri, 09 Nov 2018 11:09:40 +0800 (CST)
Received: from mail-pg1-f173.google.com (unknown [209.85.215.173])
	by mx2.icoremail.net (Coremail) with SMTP id AQAAfwCnjEhx+uRb9SogAA--.8833S3;
	Fri, 09 Nov 2018 11:09:37 +0800 (CST)
Received: by mail-pg1-f173.google.com with SMTP id z17-v6so236801pgv.3
        for <xuliker@zju.edu.cn>; Thu, 08 Nov 2018 19:09:37 -0800 (PST)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20161025;
        h=x-original-authentication-results:x-gm-message-state:delivered-to
         :date:from:to:cc:subject:message-id:references:mime-version
         :content-disposition:in-reply-to:user-agent:sender:precedence
         :list-id;
        bh=pNNF1IJYTi/5MWvzt91TEaZFTci9UrrbAWyEMnk7QIQ=;
        b=nh0XcXPDFSFT31mBj9sUg0PqCv+EntR7FWvvMPlubhgCap92Xp5OcMz2mVEaqC606O
         Ge0wpOFgDltoI76omuC1hMk7+KKze6bBTINZ4R36XXZ2K62r4o8+Ud2FAZuC0CZaEmEm
         onf0yCX2JMI0beBPYnsmXE77of6jfxexObnDlSdAIAuTP4B+4MucXT0E/lkZ8CuR5JQd
         igl6hzBb59O0C2DR8UJGkt+cKTY6JXl4sgfzDP3L4u5H0nCqJIYCeNM1lHTRsRNdS7Cj
         602a44BWvOxELZka/CEJtdH3vB/sB77VAC/e38/mqJ+aX8Kjmsvz1CN1Lu4OxYSgf55G
         wmPA==
X-Original-Authentication-Results: mx.google.com;       spf=pass (google.com: best guess record for domain of linux-kernel-owner@vger.kernel.org designates 209.132.180.67 as permitted sender) smtp.mailfrom=linux-kernel-owner@vger.kernel.org
X-Gm-Message-State: AGRZ1gLWvkkwmtR98sBz3h/yGk496WkKyX/NGPcHxE+HmI+HSL0NAB1C
	yEPWrKqD7SSJ6IHMBDL2AfeD59IAUzXFQbuhmtD1E1Uz1yXCaf6isA==
X-Received: by 2002:a63:9402:: with SMTP id m2mr5767055pge.93.1541732977377;
        Thu, 08 Nov 2018 19:09:37 -0800 (PST)
X-Forwarded-To: xuliker@zju.edu.cn
X-Forwarded-For: liker.xu@gmail.com xuliker@zju.edu.cn
Delivered-To: liker.xu@gmail.com
Received: by 2002:a17:90a:c304:0:0:0:0 with SMTP id g4-v6csp1020108pjt;
        Thu, 8 Nov 2018 19:09:36 -0800 (PST)
X-Google-Smtp-Source: AJdET5f3CjYhYNaOdmiXo9j1GO5n2PvWpmb8NswNQNSz000S550UdYx2Iz0NeaT9GpdP9uQ4ZZ0p
X-Received: by 2002:a17:902:bf49:: with SMTP id u9-v6mr7292504pls.10.1541732976402;
        Thu, 08 Nov 2018 19:09:36 -0800 (PST)
ARC-Seal: i=1; a=rsa-sha256; t=1541732976; cv=none;
        d=google.com; s=arc-20160816;
        b=aZgDw7snyXPhSJV+wMVfc2Gu1s6BbpMbtKRzdV4KZHe9iEkEBWYtF0YsbQ4iS8yV75
         lz/F+rRiyQ9FWdTNuMiNoJeBc2mlbDCKPMfdasx6SqQRKU04uy4CHVkKac/p/U5lZGe8
         M/xLOv86kxyLgjVuTCQT9B1BZjki4PIyBvw+Ei4GUn5ggR71O/v+htvGJIP9hUpLRAKx
         ayX6EczZbBnTj58Wnhi5wkUAQC7amlgzfT7RVmjJZFXhoEOOx6I6saPpplOdE55vMZ+w
         FRFD2hV6uDha6qh7jgeCmDV8MEQ/oagyEfQtDuvROIyuM3dfj6I+o5oQ0kE5IWfPCO0p
         5O4A==
ARC-Message-Signature: i=1; a=rsa-sha256; c=relaxed/relaxed; d=google.com; s=arc-20160816;
        h=list-id:precedence:sender:user-agent:in-reply-to
         :content-disposition:mime-version:references:message-id:subject:cc
         :to:from:date;
        bh=pNNF1IJYTi/5MWvzt91TEaZFTci9UrrbAWyEMnk7QIQ=;
        b=okPADT/8gElqmYHv90k2iQ0ym4VE3UF6wUfzjhtyURVhy5pEjaumNYfT9A9JsX3RXH
         E908spXNADSCPIcsuX5uqL4BuGH57JIyIPsG99ludVUpBC+Cbw2wxqDVMuHDXz3ejwc8
         ZYBnGBaYkTw/MrDrXctlHzcCU6JTSwuaSv/cJVc1Yuz6XfdSfUzP88oNuxEHxBpzzFC0
         ozeajtG2fOM4MpZMQnHkQQ4Je/ez/G0ek+ZEGaApn6fQglTUsmW+a1tFfHfmtT5n1yQZ
         R6twLDrJX5JNodjJPl8Gbis8iK0ELQyP9SYyBHxLDaL2LWGKEBdNN7+KRUyrPzrR9Rb4
         W8mw==
ARC-Authentication-Results: i=1; mx.google.com;
       spf=pass (google.com: best guess record for domain of linux-kernel-owner@vger.kernel.org designates 209.132.180.67 as permitted sender) smtp.mailfrom=linux-kernel-owner@vger.kernel.org
Received: from vger.kernel.org (vger.kernel.org. [209.132.180.67])
        by mx.google.com with ESMTP id b21-v6si6327127pfo.130.2018.11.08.19.09.19;
        Thu, 08 Nov 2018 19:09:36 -0800 (PST)
Received-SPF: pass (google.com: best guess record for domain of linux-kernel-owner@vger.kernel.org designates 209.132.180.67 as permitted sender) client-ip=209.132.180.67;
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
        id S1727510AbeKIMru (ORCPT <rfc822;tu.k.phung@gmail.com>
        + 99 others); Fri, 9 Nov 2018 07:47:50 -0500
Received: from fieldses.org ([173.255.197.46]:39454 "EHLO fieldses.org"
        rhost-flags-OK-OK-OK-OK) by vger.kernel.org with ESMTP
        id S1727238AbeKIMrt (ORCPT <rfc822;linux-kernel@vger.kernel.org>);
        Fri, 9 Nov 2018 07:47:49 -0500
Received: by fieldses.org (Postfix, from userid 2815)
        id CB2581E29; Thu,  8 Nov 2018 22:09:13 -0500 (EST)
Date: Thu, 8 Nov 2018 22:09:13 -0500
From: "J. Bruce Fields" <bfields@fieldses.org>
To: NeilBrown <neilb@suse.com>
Cc: Jeff Layton <jlayton@kernel.org>,
        Alexander Viro <viro@zeniv.linux.org.uk>,
        Martin Wilck <mwilck@suse.de>, linux-fsdevel@vger.kernel.org,
        Frank Filz <ffilzlnx@mindspring.com>,
        linux-kernel@vger.kernel.org
Subject: Re: [PATCH 10/12] fs/locks: create a tree of dependent requests.
Message-ID: <20181109030913.GA8831@fieldses.org>
References: <154138128401.31651.1381177427603557514.stgit@noble>
 <154138144796.31651.14201944346371750178.stgit@noble>
 <20181108213030.GF6090@fieldses.org>
 <87k1lnw0ec.fsf@notabene.neil.brown.name>
MIME-Version: 1.0
Content-Type: text/plain; charset=us-ascii
Content-Disposition: inline
In-Reply-To: <87k1lnw0ec.fsf@notabene.neil.brown.name>
User-Agent: Mutt/1.5.21 (2010-09-15)
Sender: liker.xu+caf_=xuliker=zju.edu.cn@gmail.com
Precedence: bulk
List-ID: <linux-kernel.vger.kernel.org>
X-Mailing-List: linux-kernel@vger.kernel.org
X-CM-TRANSID: AQAAfwCnjEhx+uRb9SogAA--.8833S3
Authentication-Results: mail-app2; spf=pass smtp.mail=liker.xu+caf_=xu
	liker=zju.edu.cn@gmail.com;
X-Coremail-Antispam: 1UD129KBjvJXoWxKFW3Cr48GF1kKw43WF45Jrb_yoWxCF4fpr
	Z0gFWYkF4kWr18W3Z2q3W0gF1SgwsxKr47Ar1rJr4UAr98Jrn7WrnrGF1YgF12yr4fXFs0
	qF45t3srur4DZFJanT9S1TB71UUUUUUqnTZGkaVYY2UrUUUU0bIjqfuFe4nvWSU8nxnvy2
	9KBjDU0xBIdaVrnRJUUUB2b7Iv0xC_Kw4lb4IE77IF4wAFF20E14v26r1j6r4UM7CIcVAF
	z4kK6r1j6r18M28lY4IEw2IIxxk0rwA2F7IY1VAKz4vEj48ve4kI8wA2z4x0Y4vE2Ix0cI
	8IcVAFwI0_Xr0_Ar1l84ACjcxK6xIIjxv20xvEc7CjxVAFwI0_Gr0_Cr1l84ACjcxK6I8E
	87Iv67AKxVW0oVCq3wA2z4x0Y4vEx4A2jsIEc7CjxVAFwI0_GcCE3s1le2I262IYc4CY6c
	8Ij28IcVAaY2xG8wAqx4xG64xvF2IEw4CE5I8CrVC2j2WlYx0E2Ix0cI8IcVAFwI0_Jr0_
	Jr4lYx0Ex4A2jsIE14v26r4j6F4UMcvjeVCFs4IE7xkEbVWUJVW8JwCjxxvEa2IrMxkF7I
	0Ew4C26cxK6c8Ij28IcwCY1Ik26cxK6xAEc7vF6xCjj44lc2xSY4AK6IIF6r48MxkI7II2
	jI8vz4vEwIxGrwCYIxAIcVC0I7IYx2IY67AKxVWUCVW8JwCYIxAIcVC0I7IYx2IY6xkF7I
	0E14v26r1j6r4UMxvI42IY6I8E87Iv67AKxVW0oVCq3wCYIxAIcVC2z280aVCY1x0267AK
	xVW0oVCq3wCF04k20xvY0x0EwIxGrwCF04k20xvEw4C26cxK6c8Ij28IcwCF72vE77IF4w
	CFx2IqxVCFs4IE7xkEbVWUJVW8JwC20s026c02F40E14v26r1j6r18MI8I3I0E7480Y4vE
	14v26r106r1rMI8E67AF67kF1VAFwI0_Jw0_GFylIxkGc2Ij64vIr41lIxAIcVCF04k26c
	xKx2IYs7xG6Fyj6rWUJbIYCTnIWIevJa73UjIFyTuYvjxUd75FUUUUU

On Fri, Nov 09, 2018 at 11:38:19AM +1100, NeilBrown wrote:
> On Thu, Nov 08 2018, J. Bruce Fields wrote:
> 
> > On Mon, Nov 05, 2018 at 12:30:48PM +1100, NeilBrown wrote:
> >> When we find an existing lock which conflicts with a request,
> >> and the request wants to wait, we currently add the request
> >> to a list.  When the lock is removed, the whole list is woken.
> >> This can cause the thundering-herd problem.
> >> To reduce the problem, we make use of the (new) fact that
> >> a pending request can itself have a list of blocked requests.
> >> When we find a conflict, we look through the existing blocked requests.
> >> If any one of them blocks the new request, the new request is attached
> >> below that request, otherwise it is added to the list of blocked
> >> requests, which are now known to be mutually non-conflicting.
> >> 
> >> This way, when the lock is released, only a set of non-conflicting
> >> locks will be woken, the rest can stay asleep.
> >> If the lock request cannot be granted and the request needs to be
> >> requeued, all the other requests it blocks will then be woken
> >
> > So, to make sure I understand: the tree of blocking locks only ever has
> > three levels (the active lock, the locks blocking on it, and their
> > children?)
> 
> Not correct.
> Blocks is only vertical, never horizontal.  Siblings never block each
> other.
> So one process hold a lock on a byte, and 27 other process want a lock
> on that byte, then there will be 28 levels in a narrow tree - it is
> effectively a queue.
> Branching (via siblings) only happens when a child conflict with only
> part of the lock held by the parent.
> So if one process locks 32K, then two other processes request locks on
> the 2 16K halves, then 4 processes request locks on the 8K quarters, and
> so-on, then you could end up with 32767 processes in a binary tree, with
> half of them all waiting on different individual bytes.

Maybe I should actually read the code carefully instead of just skimming
the changelog and jumping to conclusions.

I think this is correct, but I wish we had an actual written-out
argument that it's correct, because intuition isn't a great guide for
posix file locks.

Maybe:

Waiting and applied locks are all kept in trees whose properties are:

	- the root of a tree may be an applied or unapplied lock.
	- every other node in the tree is an unapplied lock that
	  conflicts with every ancestor of that node.

Every such tree begins life as an unapplied singleton which obviously
satisfies the above properties.

The only ways we modify trees preserve these properties:

	1. We may add a new child, but only after first verifying that it
	   conflicts with all of its ancestors.
	2. We may remove the root of a tree, creating a new singleton
	   tree from the root and N new trees rooted in the immediate
	   children.
	3. If the root of a tree is not currently an applied lock, we may
	   apply it (if possible).
	4. We may upgrade the root of the tree (either extend its range,
	   or upgrade its entire range from read to write).

When an applied lock is modified in a way that reduces or downgrades any
part of its range, we remove all its children (2 above).

For each of those child trees: if the root of the tree applies, we do so
(3).  If it doesn't, it must conflict with some applied lock.  We remove
all of its children (2), and add it is a new leaf to the tree rooted in
the applied lock (1).  We then repeat the process recursively with those
children.

Something like that.

--b.

> 
> NeilBrown
> 
> >
> > --b.
> >
> >> 
> >> Reported-and-tested-by: Martin Wilck <mwilck@suse.de>
> >> Signed-off-by: NeilBrown <neilb@suse.com>
> >> ---
> >>  fs/locks.c |   29 +++++++++++++++++++++++------
> >>  1 file changed, 23 insertions(+), 6 deletions(-)
> >> 
> >> diff --git a/fs/locks.c b/fs/locks.c
> >> index 802d5853acd5..1b0eac6b2918 100644
> >> --- a/fs/locks.c
> >> +++ b/fs/locks.c
> >> @@ -715,11 +715,25 @@ static void locks_delete_block(struct file_lock *waiter)
> >>   * fl_blocked list itself is protected by the blocked_lock_lock, but by ensuring
> >>   * that the flc_lock is also held on insertions we can avoid taking the
> >>   * blocked_lock_lock in some cases when we see that the fl_blocked list is empty.
> >> + *
> >> + * Rather than just adding to the list, we check for conflicts with any existing
> >> + * waiters, and add beneath any waiter that blocks the new waiter.
> >> + * Thus wakeups don't happen until needed.
> >>   */
> >>  static void __locks_insert_block(struct file_lock *blocker,
> >> -					struct file_lock *waiter)
> >> +				 struct file_lock *waiter,
> >> +				 bool conflict(struct file_lock *,
> >> +					       struct file_lock *))
> >>  {
> >> +	struct file_lock *fl;
> >>  	BUG_ON(!list_empty(&waiter->fl_block));
> >> +
> >> +new_blocker:
> >> +	list_for_each_entry(fl, &blocker->fl_blocked, fl_block)
> >> +		if (conflict(fl, waiter)) {
> >> +			blocker =  fl;
> >> +			goto new_blocker;
> >> +		}
> >>  	waiter->fl_blocker = blocker;
> >>  	list_add_tail(&waiter->fl_block, &blocker->fl_blocked);
> >>  	if (IS_POSIX(blocker) && !IS_OFDLCK(blocker))
> >> @@ -734,10 +748,12 @@ static void __locks_insert_block(struct file_lock *blocker,
> >>  
> >>  /* Must be called with flc_lock held. */
> >>  static void locks_insert_block(struct file_lock *blocker,
> >> -					struct file_lock *waiter)
> >> +			       struct file_lock *waiter,
> >> +			       bool conflict(struct file_lock *,
> >> +					     struct file_lock *))
> >>  {
> >>  	spin_lock(&blocked_lock_lock);
> >> -	__locks_insert_block(blocker, waiter);
> >> +	__locks_insert_block(blocker, waiter, conflict);
> >>  	spin_unlock(&blocked_lock_lock);
> >>  }
> >>  
> >> @@ -996,7 +1012,7 @@ static int flock_lock_inode(struct inode *inode, struct file_lock *request)
> >>  		if (!(request->fl_flags & FL_SLEEP))
> >>  			goto out;
> >>  		error = FILE_LOCK_DEFERRED;
> >> -		locks_insert_block(fl, request);
> >> +		locks_insert_block(fl, request, flock_locks_conflict);
> >>  		goto out;
> >>  	}
> >>  	if (request->fl_flags & FL_ACCESS)
> >> @@ -1071,7 +1087,8 @@ static int posix_lock_inode(struct inode *inode, struct file_lock *request,
> >>  			spin_lock(&blocked_lock_lock);
> >>  			if (likely(!posix_locks_deadlock(request, fl))) {
> >>  				error = FILE_LOCK_DEFERRED;
> >> -				__locks_insert_block(fl, request);
> >> +				__locks_insert_block(fl, request,
> >> +						     posix_locks_conflict);
> >>  			}
> >>  			spin_unlock(&blocked_lock_lock);
> >>  			goto out;
> >> @@ -1542,7 +1559,7 @@ int __break_lease(struct inode *inode, unsigned int mode, unsigned int type)
> >>  		break_time -= jiffies;
> >>  	if (break_time == 0)
> >>  		break_time++;
> >> -	locks_insert_block(fl, new_fl);
> >> +	locks_insert_block(fl, new_fl, leases_conflict);
> >>  	trace_break_lease_block(inode, new_fl);
> >>  	spin_unlock(&ctx->flc_lock);
> >>  	percpu_up_read_preempt_enable(&file_rwsem);
> >> 

