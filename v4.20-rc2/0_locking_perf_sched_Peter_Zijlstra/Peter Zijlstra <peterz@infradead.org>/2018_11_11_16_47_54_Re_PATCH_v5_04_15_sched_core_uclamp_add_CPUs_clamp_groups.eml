Return-Path: <linux-kernel-owner@vger.kernel.org>
Delivered-To: unknown
Received: from pop3.zju.edu.cn (124.160.105.205:110) by
  likexu-MOBL1.ccr.corp.intel.com with POP3; 12 Nov 2018 00:39:53 -0000
Received: from icoremail.net (unknown [209.85.214.169])
	by mail-app2 (Coremail) with SMTP id by_KCgD3_wtkXehb6NR2AQ--.35829S3;
	Mon, 12 Nov 2018 00:48:37 +0800 (CST)
Received: from mail-pl1-f169.google.com (unknown [209.85.214.169])
	by mx2.icoremail.net (Coremail) with SMTP id AQAAfwBnPjpjXehbwnotAA--.4214S3;
	Mon, 12 Nov 2018 00:48:35 +0800 (CST)
Received: by mail-pl1-f169.google.com with SMTP id r3-v6so2400056pls.12
        for <xuliker@zju.edu.cn>; Sun, 11 Nov 2018 08:48:35 -0800 (PST)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20161025;
        h=x-gm-message-state:delivered-to:dkim-signature:date:from:to:cc
         :subject:message-id:references:mime-version:content-disposition
         :in-reply-to:user-agent:sender:precedence:list-id;
        bh=RPBSh1w3SI/Ppyu+2+E9IV871NnwVbPJRYWjthThOw4=;
        b=Phs+lxalkW20ucWdZZqOimH/gQ9f3kOvFvxWoc2XxsHXo9080D9CEqstu7jJqnQxzX
         2Tj7b901hxVoE1lM0HVxe/4ZTsWPMzJM6f5v94sijuexHYHL4qJ8vYC7ymSvRT7gD0Cg
         IpLChiGHN9fOp2QyCNSp81GvblFAMnvpyyhr+tvsHcQ1bB3s13Zv6AFtntQWMlNQEKlb
         XWU7aopemTDbIvSBw2RbasX/mRzKEMZQ3kRC9g4/MfbrLY/phgxjqj4f6TwJBNuDuW2v
         HpliIvAxAKbTZIpaxOYMp4Z7Y9YuSqgxv2BIvcHItM7Nb/rFBcClagxvceZBr2w89Aj6
         8NeQ==
X-Gm-Message-State: AGRZ1gLw8lvYSq+P32WSZ8MtCANIZNI3yF9RTIJVeULTTMju8MynZh+r
	RXaWpqnhMPD9mRCOSl1WsoMQqK0MnuhUA0cb4Bc/VlpQaBjrHWk=
X-Received: by 2002:a17:902:560f:: with SMTP id h15-v6mr13873690pli.160.1541954914987;
        Sun, 11 Nov 2018 08:48:34 -0800 (PST)
X-Forwarded-To: xuliker@zju.edu.cn
X-Forwarded-For: liker.xu@gmail.com xuliker@zju.edu.cn
Delivered-To: liker.xu@gmail.com
Received: by 2002:a17:90a:c304:0:0:0:0 with SMTP id g4-v6csp2275391pjt;
        Sun, 11 Nov 2018 08:48:34 -0800 (PST)
X-Google-Smtp-Source: AJdET5cd4U9BsFnmzydt1c96x+2ox3MWWfzddZ1/Yy0PQYwR54Mi3tir5vADAYzFh34W+WMHXSma
X-Received: by 2002:a63:ac02:: with SMTP id v2-v6mr14550562pge.414.1541954914125;
        Sun, 11 Nov 2018 08:48:34 -0800 (PST)
ARC-Seal: i=1; a=rsa-sha256; t=1541954914; cv=none;
        d=google.com; s=arc-20160816;
        b=gPTWGL7SmvOsn8Ce5obAU0VsUKtMMS2KcnLIz09VtSSPLcyUN9PCnw2ilODHe4teoS
         96SnaS4aqXqa/ULzLx9WVPx1gHy2AjwRokjcTiwQPUZl49fvNU6YmUE4yxXds5jnkb/+
         WRnnGrzQPbrBw74eYvcXWen8M3GF3eonKrylUTaN+gMMnGfSr4B9wQ8MgyrZqhlEAZ4D
         WGkHfpUymEhrNBdDovFZxck+pLwwn/WOAS0veAO+e436bLB0A0A5hZ8B1+QBOUmmLPcG
         qY9Vjeqmlh4XKqGoSl85o48aSz0yxl3pCNoOlVyhtQ5VS/jWaoWqRbePPwPQujoPqHZT
         zZcg==
ARC-Message-Signature: i=1; a=rsa-sha256; c=relaxed/relaxed; d=google.com; s=arc-20160816;
        h=list-id:precedence:sender:user-agent:in-reply-to
         :content-disposition:mime-version:references:message-id:subject:cc
         :to:from:date:dkim-signature;
        bh=RPBSh1w3SI/Ppyu+2+E9IV871NnwVbPJRYWjthThOw4=;
        b=bjD+KH1N0C+V34UK8eJjdnieF9o1hRgNZZ22f25fv9Q5kxENXbXhOeSsuaIeCF3937
         wF/Hw7RpTToW1SQQk4ijcTQ+w/0Sadq4UnrT492jyIVCXg89tJhDJkBc1JmEe4L9UecU
         ozYd2yhYOjvQORa/u3biRGzdpNAtwMfhrfpette4f45Yn4rSZy6R0nGLHYok69A9VQTG
         k9n2rZSQ1cz5+k3BCcKQDG0Q0egXbL6u0VNTJm97rxAmp0xTZ+q/I0ZVUBivTf8RldCU
         T2nTKXmKYONNlt31AjelCLUbfq50Pgn/weRJK3Zcf65HmXImNyY7/+LV/+iYOzjda1Ei
         X85A==
ARC-Authentication-Results: i=1; mx.google.com;
       dkim=fail header.i=@infradead.org header.s=merlin.20170209 header.b=sHsRnEm9;
       spf=pass (google.com: best guess record for domain of linux-kernel-owner@vger.kernel.org designates 209.132.180.67 as permitted sender) smtp.mailfrom=linux-kernel-owner@vger.kernel.org
Received: from vger.kernel.org (vger.kernel.org. [209.132.180.67])
        by mx.google.com with ESMTP id f2-v6si14710473plr.333.2018.11.11.08.48.20;
        Sun, 11 Nov 2018 08:48:34 -0800 (PST)
Received-SPF: pass (google.com: best guess record for domain of linux-kernel-owner@vger.kernel.org designates 209.132.180.67 as permitted sender) client-ip=209.132.180.67;
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
        id S1729250AbeKLChJ (ORCPT <rfc822;berg.ding@gmail.com> + 99 others);
        Sun, 11 Nov 2018 21:37:09 -0500
Received: from merlin.infradead.org ([205.233.59.134]:56710 "EHLO
        merlin.infradead.org" rhost-flags-OK-OK-OK-OK) by vger.kernel.org
        with ESMTP id S1728378AbeKLChI (ORCPT
        <rfc822;linux-kernel@vger.kernel.org>);
        Sun, 11 Nov 2018 21:37:08 -0500
DKIM-Signature: v=1; a=rsa-sha256; q=dns/txt; c=relaxed/relaxed;
        d=infradead.org; s=merlin.20170209; h=In-Reply-To:Content-Type:MIME-Version:
        References:Message-ID:Subject:Cc:To:From:Date:Sender:Reply-To:
        Content-Transfer-Encoding:Content-ID:Content-Description:Resent-Date:
        Resent-From:Resent-Sender:Resent-To:Resent-Cc:Resent-Message-ID:List-Id:
        List-Help:List-Unsubscribe:List-Subscribe:List-Post:List-Owner:List-Archive;
         bh=RPBSh1w3SI/Ppyu+2+E9IV871NnwVbPJRYWjthThOw4=; b=sHsRnEm9Zs0g6tsBcY64PDgrJ
        2BmWgp6vcGqt4ZzzX52kxGaLHqkiYtv1VnscMMQAbs30d9DteCCt5LU5V6EzIr3AHc7867hkPvl0A
        RCVlQdJS4xxpivQ4BtAzXA8mpPhmz4HDOxexIZVx1g4pIRkMHOF7oXuGTSql8yQIQESEQO33YbuVT
        V2yDGYcXr83oXQISUQLvaAqGrQeTZfCiiofxtvJ3o83OPcyZou0byz8MffeKcNuYuhEmJPSrfozIV
        ppT6lBHFn0d4WVAipqlN6ypIDmJ4SyXq7Offx4kXd7yKUXRawi/XYuElkS0GPniZMAHV93P2jxCga
        yDYfWleUA==;
Received: from [64.114.255.97] (helo=worktop)
        by merlin.infradead.org with esmtpsa (Exim 4.90_1 #2 (Red Hat Linux))
        id 1gLstx-0000Ai-F9; Sun, 11 Nov 2018 16:47:57 +0000
Received: by worktop (Postfix, from userid 1000)
        id E93836E061A; Sun, 11 Nov 2018 17:47:54 +0100 (CET)
Date: Sun, 11 Nov 2018 17:47:54 +0100
From: Peter Zijlstra <peterz@infradead.org>
To: Patrick Bellasi <patrick.bellasi@arm.com>
Cc: linux-kernel@vger.kernel.org, linux-pm@vger.kernel.org,
        Ingo Molnar <mingo@redhat.com>, Tejun Heo <tj@kernel.org>,
        "Rafael J . Wysocki" <rafael.j.wysocki@intel.com>,
        Vincent Guittot <vincent.guittot@linaro.org>,
        Viresh Kumar <viresh.kumar@linaro.org>,
        Paul Turner <pjt@google.com>,
        Quentin Perret <quentin.perret@arm.com>,
        Dietmar Eggemann <dietmar.eggemann@arm.com>,
        Morten Rasmussen <morten.rasmussen@arm.com>,
        Juri Lelli <juri.lelli@redhat.com>,
        Todd Kjos <tkjos@google.com>,
        Joel Fernandes <joelaf@google.com>,
        Steve Muckle <smuckle@google.com>,
        Suren Baghdasaryan <surenb@google.com>
Subject: Re: [PATCH v5 04/15] sched/core: uclamp: add CPU's clamp groups
 refcounting
Message-ID: <20181111164754.GA3038@worktop>
References: <20181029183311.29175-1-patrick.bellasi@arm.com>
 <20181029183311.29175-6-patrick.bellasi@arm.com>
MIME-Version: 1.0
Content-Type: text/plain; charset=us-ascii
Content-Disposition: inline
In-Reply-To: <20181029183311.29175-6-patrick.bellasi@arm.com>
User-Agent: Mutt/1.5.22.1 (2013-10-16)
Sender: liker.xu+caf_=xuliker=zju.edu.cn@gmail.com
Precedence: bulk
List-ID: <linux-kernel.vger.kernel.org>
X-Mailing-List: linux-kernel@vger.kernel.org
X-CM-TRANSID: AQAAfwBnPjpjXehbwnotAA--.4214S3
Authentication-Results: mail-app2; spf=pass smtp.mail=liker.xu+caf_=xu
	liker=zju.edu.cn@gmail.com;
X-Coremail-Antispam: 1UD129KBjvJXoWxXFyruF43AFyUWF43tF13Jwb_yoWrZw43pr
	Z8Xw17Jayqga4DKry7G3yF93WFqw18Jws2grW8tFyDXw1a9F13CF1xtr4UZrW3AF4Dt3Wa
	vF4fZr48Gw4DAF7anT9S1TB71UUUUUUqnTZGkaVYY2UrUUUUjbIjqfuFe4nvWSU8nxnvy2
	9KBjDU0xBIdaVrnRJUUUBab7Iv0xC_Zr1lb4IE77IF4wAFF20E14v26r1j6r4UM7CIcVAF
	z4kK6r1j6r18M28lY4IEw2IIxxk0rwA2F7IY1VAKz4vEj48ve4kI8wA2z4x0Y4vE2Ix0cI
	8IcVAFwI0_Xr0_Ar1l84ACjcxK6xIIjxv20xvEc7CjxVAFwI0_Gr0_Cr1l84ACjcxK6I8E
	87Iv67AKxVW8Jr0_Cr1UM28EF7xvwVC2z280aVCY1x0267AKxVW8Jr0_Cr1UM2AIxVAIcx
	kEcVAq07x20xvEncxIr21l5I8CrVACY4xI64kE6c02F40Ex7xfMcIj6xIIjxv20xvE14v2
	6r1j6r18McIj6I8E87Iv67AKxVWUJVW8JwAm72CE4IkC6x0Yz7v_Jr0_Gr1l7I0Y6sxI4w
	CY1x0264kExVAvwVAq07x20xylc7Ca8VAvwVCFzxkY4VCF77xAMxkIecxEwVCI4VWUMxkI
	7II2jI8vz4vEwIxGrwCYIxAIcVC0I7IYx2IY67AKxVWUJVWUCwCYIxAIcVC0I7IYx2IY6x
	kF7I0E14v26r1j6r4UMxvI42IY6I8E87Iv67AKxVWUJVW8JwCYIxAIcVC2z280aVCY1x02
	67AKxVWUJVW8JwCF04k20xvY0x0EwIxGrwCF04k20xvEw4C26cxK6c8Ij28IcwCF72vE77
	IF4wCFx2IqxVCFs4IE7xkEbVWUJVW8JwC20s026c02F40E14v26r1j6r18MI8I3I0E7480
	Y4vE14v26r106r1rMI8E67AF67kF1VAFwI0_GFv_WrylIxkGc2Ij64vIr41lIxAIcVCF04
	k26cxKx2IYs7xG6r1I6r4UYxBIdaVFxhVjvjDU0xZFpf9x07b5Z2-UUUUU=

On Mon, Oct 29, 2018 at 06:32:59PM +0000, Patrick Bellasi wrote:
> +static inline void uclamp_cpu_update(struct rq *rq, unsigned int clamp_id)
> +{
> +	unsigned int group_id;
> +	int max_value = 0;
> +
> +	for (group_id = 0; group_id < UCLAMP_GROUPS; ++group_id) {
> +		if (!rq->uclamp.group[clamp_id][group_id].tasks)
> +			continue;
> +		/* Both min and max clamps are MAX aggregated */
> +		if (max_value < rq->uclamp.group[clamp_id][group_id].value)
> +			max_value = rq->uclamp.group[clamp_id][group_id].value;

		max_value = max(max_value, rq->uclamp.group[clamp_id][group_id].value);

> +		if (max_value >= SCHED_CAPACITY_SCALE)
> +			break;
> +	}
> +	rq->uclamp.value[clamp_id] = max_value;
> +}
> +
> +/**
> + * uclamp_cpu_get_id(): increase reference count for a clamp group on a CPU
> + * @p: the task being enqueued on a CPU
> + * @rq: the CPU's rq where the clamp group has to be reference counted
> + * @clamp_id: the clamp index to update
> + *
> + * Once a task is enqueued on a CPU's rq, the clamp group currently defined by
> + * the task's uclamp::group_id is reference counted on that CPU.
> + */
> +static inline void uclamp_cpu_get_id(struct task_struct *p, struct rq *rq,
> +				     unsigned int clamp_id)
> +{
> +	unsigned int group_id;
> +
> +	if (unlikely(!p->uclamp[clamp_id].mapped))
> +		return;
> +
> +	group_id = p->uclamp[clamp_id].group_id;
> +	p->uclamp[clamp_id].active = true;
> +
> +	rq->uclamp.group[clamp_id][group_id].tasks += 1;

	++
> +
> +	if (rq->uclamp.value[clamp_id] < p->uclamp[clamp_id].value)
> +		rq->uclamp.value[clamp_id] = p->uclamp[clamp_id].value;

	rq->uclamp.value[clamp_id] = max(rq->uclamp.value[clamp_id],
					 p->uclamp[clamp_id].value);

> +}
> +
> +/**
> + * uclamp_cpu_put_id(): decrease reference count for a clamp group on a CPU
> + * @p: the task being dequeued from a CPU
> + * @rq: the CPU's rq from where the clamp group has to be released
> + * @clamp_id: the clamp index to update
> + *
> + * When a task is dequeued from a CPU's rq, the CPU's clamp group reference
> + * counted by the task is released.
> + * If this was the last task reference coutning the current max clamp group,
> + * then the CPU clamping is updated to find the new max for the specified
> + * clamp index.
> + */
> +static inline void uclamp_cpu_put_id(struct task_struct *p, struct rq *rq,
> +				     unsigned int clamp_id)
> +{
> +	unsigned int clamp_value;
> +	unsigned int group_id;
> +
> +	if (unlikely(!p->uclamp[clamp_id].mapped))
> +		return;
> +
> +	group_id = p->uclamp[clamp_id].group_id;
> +	p->uclamp[clamp_id].active = false;
> +
	SCHED_WARN_ON(!rq->uclamp.group[clamp_id][group_id].tasks);

> +	if (likely(rq->uclamp.group[clamp_id][group_id].tasks))
> +		rq->uclamp.group[clamp_id][group_id].tasks -= 1;

	--

> +#ifdef CONFIG_SCHED_DEBUG
> +	else {
> +		WARN(1, "invalid CPU[%d] clamp group [%u:%u] refcount\n",
> +		     cpu_of(rq), clamp_id, group_id);
> +	}
> +#endif

> +
> +	if (likely(rq->uclamp.group[clamp_id][group_id].tasks))
> +		return;
> +
> +	clamp_value = rq->uclamp.group[clamp_id][group_id].value;
> +#ifdef CONFIG_SCHED_DEBUG
> +	if (unlikely(clamp_value > rq->uclamp.value[clamp_id])) {
> +		WARN(1, "invalid CPU[%d] clamp group [%u:%u] value\n",
> +		     cpu_of(rq), clamp_id, group_id);
> +	}
> +#endif

	SCHED_WARN_ON(clamp_value > rq->uclamp.value[clamp_id]);

> +	if (clamp_value >= rq->uclamp.value[clamp_id])
> +		uclamp_cpu_update(rq, clamp_id);
> +}

> @@ -866,6 +1020,28 @@ static void uclamp_group_get(struct uclamp_se *uc_se, unsigned int clamp_id,
>  	if (res != uc_map_old.data)
>  		goto retry;
>  
> +	/* Ensure each CPU tracks the correct value for this clamp group */
> +	if (likely(uc_map_new.se_count > 1))
> +		goto done;
> +	for_each_possible_cpu(cpu) {

yuck yuck yuck.. why!?

> +		struct uclamp_cpu *uc_cpu = &cpu_rq(cpu)->uclamp;
> +
> +		/* Refcounting is expected to be always 0 for free groups */
> +		if (unlikely(uc_cpu->group[clamp_id][group_id].tasks)) {
> +			uc_cpu->group[clamp_id][group_id].tasks = 0;
> +#ifdef CONFIG_SCHED_DEBUG
> +			WARN(1, "invalid CPU[%d] clamp group [%u:%u] refcount\n",
> +			     cpu, clamp_id, group_id);
> +#endif

		SCHED_WARN_ON();

> +		}
> +
> +		if (uc_cpu->group[clamp_id][group_id].value == clamp_value)
> +			continue;
> +		uc_cpu->group[clamp_id][group_id].value = clamp_value;
> +	}
> +
> +done:
> +
>  	/* Update SE's clamp values and attach it to new clamp group */
>  	uc_se->value = clamp_value;
>  	uc_se->group_id = group_id;
