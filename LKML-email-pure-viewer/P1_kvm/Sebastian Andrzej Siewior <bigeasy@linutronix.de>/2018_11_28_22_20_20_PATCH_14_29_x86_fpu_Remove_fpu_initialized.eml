Return-Path: <linux-kernel-owner@vger.kernel.org>
Delivered-To: unknown
Received: from linux.intel.com (10.54.29.200:995) by likexu-workstation with
  POP3-SSL; 29 Nov 2018 08:41:53 -0000
X-Original-To: like.xu@linux.intel.com
Delivered-To: like.xu@linux.intel.com
Received: from orsmga003.jf.intel.com (orsmga003.jf.intel.com [10.7.209.27])
	(using TLSv1.2 with cipher ECDHE-RSA-AES256-GCM-SHA384 (256/256 bits))
	(No client certificate requested)
	by linux.intel.com (Postfix) with ESMTPS id 6CB13580322;
	Wed, 28 Nov 2018 14:26:08 -0800 (PST)
Received: from fmsmga102.fm.intel.com ([10.1.193.69])
  by orsmga003-1.jf.intel.com with ESMTP/TLS/DHE-RSA-AES256-GCM-SHA384; 28 Nov 2018 14:26:07 -0800
X-SG-BADATTACHMENTNOREPLY: True
IronPort-PHdr: =?us-ascii?q?9a23=3ACmUu9BHotFE3SUjNKkXPSJ1GYnF86YWxBRYc798d?=
 =?us-ascii?q?s5kLTJ75o8SzbnLW6fgltlLVR4KTs6sC17KG9fi4EUU7or+5+EgYd5JNUxJXwe?=
 =?us-ascii?q?43pCcHRPC/NEvgMfTxZDY7FskRHHVs/nW8LFQHUJ2mPw6arXK99yMdFQviPgRp?=
 =?us-ascii?q?OOv1BpTSj8Oq3Oyu5pHfeQpFiCa+bL9oMBm6sRjau9ULj4dlNqs/0AbCrGFSe+?=
 =?us-ascii?q?RRy2NoJFaTkAj568yt4pNt8Dletuw4+cJYXqr0Y6o3TbpDDDQ7KG81/9HktQPC?=
 =?us-ascii?q?TQSU+HQRVHgdnwdSDAjE6BH6WYrxsjf/u+Fg1iSWIdH6QLYpUjm58axlVAHnhz?=
 =?us-ascii?q?sGNz4h8WHYlMpwjL5AoBm8oxBz2pPYbJ2JOPZ7eK7WYNEUSndbXstJVyJPHJ6y?=
 =?us-ascii?q?YYUMAeQGP+lYoYbyqVQVrRumBwShH//jxzxSi3Pqx6A2z/gtHAfb1wIgBdIOt3?=
 =?us-ascii?q?HUoc3oOqgMSu+61rLIzSnCb/xM3zf29ZTFchY8rvGWXLN/b8jRwlQyGQPEkFqR?=
 =?us-ascii?q?p43lPzSP1u8QtGWU9OtgVe2xhGE9sAFwoiOixsMtionPm4IV1krE9SJ/wIY0Kt?=
 =?us-ascii?q?y0UlN0bsC9HZZWqiqUNJN2T9s8T210vCs20KAKtJClcCQQ1ZgqxALTZ+aGfoWK?=
 =?us-ascii?q?+h7vSemcLDZiiH55Yr6zmRi//Eu6xuD+SsW51ktBoDBfndnWrH8N0gTe6siZRf?=
 =?us-ascii?q?t5+UeswSiP1w/N5eFeO0w0lrTUK4QnwrEukpofq0PDHjX5mEnuja+WcFsr+vSw?=
 =?us-ascii?q?5uj5frnrooWQO5J6hw3gKKgih8+yDfgiPgUPXWWX4eG826fi/U39TrVKlPo2kq?=
 =?us-ascii?q?zBvZDeJMQboLO5AgBM3oYg9Rm/FTGm38ocnXUeK1JEdhSHgJbzO1zVPvD4Aumw?=
 =?us-ascii?q?g062nDdo2f/GJLvhDYvJLnTZl7fhZ7l951ZGyAUv1dBf+45UCrYZLfL3W0/xt8?=
 =?us-ascii?q?LXAgU2Mgyp2OvnDNR91oUDWWOAGKOZMaXSsUOW6eIrOeWDeIgVuDPlIfg/+/Hu?=
 =?us-ascii?q?lWM5mUMafaSx3ZsYcnG4Huh8LEWee3bsgsoBHn0MvgoxV+HqjFyCUThOZ3e9Ra?=
 =?us-ascii?q?485zc7CJ64AofHXIyinLuB3CKjFJ1Mem9GEkyMEWvvd4icWfcMbzydLtVikjwD?=
 =?us-ascii?q?U7ihTYgh2AqqtA/7zbpnM+XV9jcZtZLlyNh6+enTmQsu+jxzCsSXy3uNQH1snm?=
 =?us-ascii?q?MUWz8227hyrlZmyleD1qh4gOZUFcZJ6PNLSQo6MZ/cz+pnC9H9QA7Bf9GJSEq4?=
 =?us-ascii?q?TdWiGz0+UtUxw9oWaUZnB9qilgzD3zatA7INlLyEHpo0/rjY33jwPcl9zXnG2b?=
 =?us-ascii?q?Ilj1knRMtPKGKnirR+9wjVG47GjUGZm7y2eqQb2S7H7H2DwnaWvEFETA5wVr3I?=
 =?us-ascii?q?Um0FaUvIs9v1/EPCQKWoCbQ8LARBz8mOKq9Jat3siVVLX/PjONXYY2KslGa8Hx?=
 =?us-ascii?q?eIxrWQbIX0f2URxjnSCE8BkwoL53aJKRA+Bju9o2LZFDFhCEjgY13y/uVkqHO0?=
 =?us-ascii?q?VEk0zxqUYE1nzLe1/h8VhfqBS/IcxL4EuSEhqylqE1a5xd7ZF92Apw95dqVGfd?=
 =?us-ascii?q?w9+EtH1X7etwFlIpygLqVihlkCcwR3v0LizQl3Bp9HkcgwqHMqzQxyKa2D3VNF?=
 =?us-ascii?q?djOY243wO7LNJmnz+hCvd7DZ2lXE3NmK/acP7ewyq0//swGxCkoi73Jn3sFP3H?=
 =?us-ascii?q?uY+JrLAxQdUJLrXkks6hh1uqvVYi8+54PTy31hKq20sj7E29I0C+op0Begf9FD?=
 =?us-ascii?q?MKyaEA/+CdEVB8+rKOYygVimcgoEPPxO9K4zJ86nd+aG1LS3M+p6nTOmjX5I4I?=
 =?us-ascii?q?Zy0k+X8yp8S+jI34sKwv2C3wuHUSv8g0mlsszthY9EYjQSFHKlySf4HI5RerFy?=
 =?us-ascii?q?fYETBGe0Is242s9xh4TwVH5f7lKjAU0J2NWoeRaLc1PyxwlQ2lkJrny9niu4yS?=
 =?us-ascii?q?d5kzUorqqZwSzPzP7udBsBOm5XWmZiiU3gLpSzj9AfREKodRQmlAO55UbmwKhW?=
 =?us-ascii?q?vKR+L2jJTUZIZST2NHxiUq2ru7qGYs5P7o4osCpNXOS9Z1CaVqDyox8A3yz/GG?=
 =?us-ascii?q?tewSgxdyu2tZXhgxx6lGWdIW5xrHXDY8FwxhTf5NvGSf5KxDUGRyp4iTjRBlei?=
 =?us-ascii?q?Odmk5tGUl5bFsuCjWGOtTJxTcS/3zYyesCu3/3FlARq6n/qrgN3oDRA60TPn19?=
 =?us-ascii?q?ltTSjJrAzzYo7x26S4MOJneFJlBFv968p8B4F/nZE8hJAW2XgGmJqV+WALnnv0?=
 =?us-ascii?q?MdVewaj+dmYCRSYXw97J5wjowE5jIWiIx47jVnWd39FuZ9+1Ym4N3iI97sZKCL?=
 =?us-ascii?q?qb7bBenCt1pEa4ohzVYfRngjgdzv4u4mYAg+4VoAot0jmdArcKEEldPCzslA6H?=
 =?us-ascii?q?48qwrapJf2avbaa/1FBlkt+/FrGCrRpRWHL4epckAC9x4d9zMFPK0H3v9I7kfM?=
 =?us-ascii?q?PcYs4Uth2Rix3AlfRaKIotlvoWgipqIX79vXogy+IhjB1hx5e6vJWcK2V2/aK0?=
 =?us-ascii?q?GRpYNjzzZ8MO9TDhl6densCK34+xGpVtACkEXJztTfiwCjIdqeznNxqSED07sn?=
 =?us-ascii?q?qUAqDQHQib6Ed7tX7PF42rOmqTJHkYy9ViWRacKFZegAASQDU1gJo5Ghq2y8zm?=
 =?us-ascii?q?dUdz/ioR6ULgqhtQ1uJoMAHyUmXFqwetdDg0U4KTLAZM4gFB+kfVMtGe7uRpEC?=
 =?us-ascii?q?FD5ZChqA2NKmqGZwVHF20JW0qEB0z9Mbmq/9XP7++YBu+mJfvUfbqOsfBeV+uP?=
 =?us-ascii?q?xZ+30opm+CuMNtySPnZ4Cf03wFFDXXd/G8TWgDgPTy0XlyTQb8+Uvhu8+yt3rt?=
 =?us-ascii?q?yh//TvQg7g+YyPC75KO9V15x+2mbuDN/KXhCthKTZXyJIMxXzLyLgexlISiDtu?=
 =?us-ascii?q?dz6iEbsery7NUbnQl7RTDx4abSNzKcRJ47g93glLJc7UlNf12qRkgf4yDldPTU?=
 =?us-ascii?q?bhld2xZcwWP2G9M0vKC1yWNLudPz3E3cH2bbm4Sb1Rl+hUsxywuTCGE07sJDiD?=
 =?us-ascii?q?lj/pVwyxPuFIli2UIBteuISleBZ3FWfjVM7magG8MNJvkT02wLg0imnWOmIGLT?=
 =?us-ascii?q?d8c11CrruL4CNcg/V/HXFB73V/IemFnSaZ8/fXKpIMvfR3BSR0kvpQ4G4mxLtN?=
 =?us-ascii?q?8CFEWPt1lTPSr9F0pVGml+iPyjx/XxtPqjZEnoSLvUp5NKXd95lAX2vE/R0X4W?=
 =?us-ascii?q?WRDRQKu8VqCtn1t69MzdjPkfG7FDAX99PS4NtZBMXOLs+DGGQuPACvGzPOCgYB?=
 =?us-ascii?q?CzmxOjLxnUtYxcqf/HSOspkzrNDFnpYUWLJZHGc0G+wbDV4tSNYDL5p+RSIMlb?=
 =?us-ascii?q?+dkdIS4ny/vF/dSZMJ7dj8SvuODKC3e36ihr5eak5NmOugIA=3D=3D?=
X-IronPort-Anti-Spam-Filtered: true
X-IronPort-Anti-Spam-Result: =?us-ascii?q?A0ANAACdFf9bh0O0hNFkHAEBAQQBAQcEA?=
 =?us-ascii?q?QGBUQcBAQsBg2snjBFfiylSBoFJaJZGFIFYMxMBh24iNAkNAQMBAQEBAQECARM?=
 =?us-ascii?q?BAQEIDQkIKS+CNiQBgmIDAwECJAsBRgYJAQFQA1QZBYMcgXUNBagTM4oqh2uEK?=
 =?us-ascii?q?xEGeIEHgRGCXYUehXMCiR8KgW6FVI8wCYERkBUjiWOHMpoOgg0zGggcFIMngic?=
 =?us-ascii?q?Xjh4+ATKBBQEBjWMBAQ?=
X-IPAS-Result: =?us-ascii?q?A0ANAACdFf9bh0O0hNFkHAEBAQQBAQcEAQGBUQcBAQsBg2s?=
 =?us-ascii?q?njBFfiylSBoFJaJZGFIFYMxMBh24iNAkNAQMBAQEBAQECARMBAQEIDQkIKS+CN?=
 =?us-ascii?q?iQBgmIDAwECJAsBRgYJAQFQA1QZBYMcgXUNBagTM4oqh2uEKxEGeIEHgRGCXYU?=
 =?us-ascii?q?ehXMCiR8KgW6FVI8wCYERkBUjiWOHMpoOgg0zGggcFIMngicXjh4+ATKBBQEBj?=
 =?us-ascii?q?WMBAQ?=
X-IronPort-AV: E=Sophos;i="5.56,292,1539673200"; 
   d="scan'208";a="54760955"
X-Amp-Result: SKIPPED(no attachment in message)
X-Amp-File-Uploaded: False
Received: from vger.kernel.org ([209.132.180.67])
  by mtab.intel.com with ESMTP; 28 Nov 2018 14:26:05 -0800
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
        id S1727012AbeK2JYX (ORCPT <rfc822;like.xu@linux.intel.com>
        + 23 others); Thu, 29 Nov 2018 04:24:23 -0500
Received: from Galois.linutronix.de ([146.0.238.70]:33138 "EHLO
        Galois.linutronix.de" rhost-flags-OK-OK-OK-OK) by vger.kernel.org
        with ESMTP id S1726734AbeK2JYW (ORCPT
        <rfc822;linux-kernel@vger.kernel.org>);
        Thu, 29 Nov 2018 04:24:22 -0500
Received: from localhost ([127.0.0.1] helo=bazinga.breakpoint.cc)
        by Galois.linutronix.de with esmtp (Exim 4.80)
        (envelope-from <bigeasy@linutronix.de>)
        id 1gS8Cg-0001GX-JS; Wed, 28 Nov 2018 23:21:07 +0100
From: Sebastian Andrzej Siewior <bigeasy@linutronix.de>
To: linux-kernel@vger.kernel.org
Cc: x86@kernel.org, Andy Lutomirski <luto@kernel.org>,
        Paolo Bonzini <pbonzini@redhat.com>,
        =?UTF-8?q?Radim=20Kr=C4=8Dm=C3=A1=C5=99?= <rkrcmar@redhat.com>,
        kvm@vger.kernel.org, "Jason A. Donenfeld" <Jason@zx2c4.com>,
        Rik van Riel <riel@surriel.com>,
        Dave Hansen <dave.hansen@linux.intel.com>,
        Sebastian Andrzej Siewior <bigeasy@linutronix.de>
Subject: [PATCH 14/29] x86/fpu: Remove fpu->initialized
Date: Wed, 28 Nov 2018 23:20:20 +0100
Message-Id: <20181128222035.2996-15-bigeasy@linutronix.de>
X-Mailer: git-send-email 2.20.0.rc1
In-Reply-To: <20181128222035.2996-1-bigeasy@linutronix.de>
References: <20181128222035.2996-1-bigeasy@linutronix.de>
MIME-Version: 1.0
Content-Transfer-Encoding: 8bit
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: <linux-kernel.vger.kernel.org>
X-Mailing-List: linux-kernel@vger.kernel.org

The `initialized' member of the fpu struct is always set to one user
tasks and zero for kernel tasks. This avoids saving/restoring the FPU
registers for kernel threads.

I expect that fpu->initialized is always 1 and the 0 case has been
removed or is not important. For instance fpu__drop() sets the value to
zero and its caller call either fpu__initialize() (which would
set it back to one) or don't return to userland.

The context switch code (switch_fpu_prepare() + switch_fpu_finish())
can't unconditionally save/restore registers for kernel threads. I have
no idea what will happen if we restore a zero FPU context for the kernel
thread (since it never was initialized). Also it has been agreed that
for PKRU we don't want a random state (inherited from the previous task)
but a deterministic one.

For kernel_fpu_begin() (+end) the situation is similar: The kernel test
bot told me, that EFI with runtime services uses this before
alternatives_patched is true. Which means that this function is used too
early and it wasn't the case before.

For those two cases current->mm is used to determine between user &
kernel thread. For kernel_fpu_begin() we skip save/restore of the FPU
registers.
During the context switch into a kernel thread we don't do anything.
There is no reason to save the FPU state of a kernel thread.

Signed-off-by: Sebastian Andrzej Siewior <bigeasy@linutronix.de>
---
 arch/x86/ia32/ia32_signal.c         | 17 +++-----
 arch/x86/include/asm/fpu/internal.h | 15 +++----
 arch/x86/include/asm/fpu/types.h    |  9 ----
 arch/x86/include/asm/trace/fpu.h    |  5 +--
 arch/x86/kernel/fpu/core.c          | 68 ++++++++---------------------
 arch/x86/kernel/fpu/init.c          |  2 -
 arch/x86/kernel/fpu/regset.c        | 19 ++------
 arch/x86/kernel/fpu/xstate.c        |  2 -
 arch/x86/kernel/process_32.c        |  4 +-
 arch/x86/kernel/process_64.c        |  4 +-
 arch/x86/kernel/signal.c            | 17 +++-----
 arch/x86/mm/pkeys.c                 |  7 +--
 12 files changed, 49 insertions(+), 120 deletions(-)

diff --git a/arch/x86/ia32/ia32_signal.c b/arch/x86/ia32/ia32_signal.c
index 86b1341cba9ac..eb215ac5d9f46 100644
--- a/arch/x86/ia32/ia32_signal.c
+++ b/arch/x86/ia32/ia32_signal.c
@@ -216,8 +216,7 @@ static void __user *get_sigframe(struct ksignal *ksig, struct pt_regs *regs,
 				 size_t frame_size,
 				 void __user **fpstate)
 {
-	struct fpu *fpu = &current->thread.fpu;
-	unsigned long sp;
+	unsigned long sp, fx_aligned, math_size;
 
 	/* Default to using normal stack */
 	sp = regs->sp;
@@ -231,15 +230,11 @@ static void __user *get_sigframe(struct ksignal *ksig, struct pt_regs *regs,
 		 ksig->ka.sa.sa_restorer)
 		sp = (unsigned long) ksig->ka.sa.sa_restorer;
 
-	if (fpu->initialized) {
-		unsigned long fx_aligned, math_size;
-
-		sp = fpu__alloc_mathframe(sp, 1, &fx_aligned, &math_size);
-		*fpstate = (struct _fpstate_32 __user *) sp;
-		if (copy_fpstate_to_sigframe(*fpstate, (void __user *)fx_aligned,
-				    math_size) < 0)
-			return (void __user *) -1L;
-	}
+	sp = fpu__alloc_mathframe(sp, 1, &fx_aligned, &math_size);
+	*fpstate = (struct _fpstate_32 __user *) sp;
+	if (copy_fpstate_to_sigframe(*fpstate, (void __user *)fx_aligned,
+				     math_size) < 0)
+		return (void __user *) -1L;
 
 	sp -= frame_size;
 	/* Align the stack pointer according to the i386 ABI,
diff --git a/arch/x86/include/asm/fpu/internal.h b/arch/x86/include/asm/fpu/internal.h
index 1d0e043bfc447..932b4577e2f0f 100644
--- a/arch/x86/include/asm/fpu/internal.h
+++ b/arch/x86/include/asm/fpu/internal.h
@@ -527,7 +527,7 @@ static inline void fpregs_activate(struct fpu *fpu)
 static inline void
 switch_fpu_prepare(struct fpu *old_fpu, int cpu)
 {
-	if (static_cpu_has(X86_FEATURE_FPU) && old_fpu->initialized) {
+	if (static_cpu_has(X86_FEATURE_FPU) && current->mm) {
 		if (!copy_fpregs_to_fpstate(old_fpu))
 			old_fpu->last_cpu = -1;
 		else
@@ -535,8 +535,7 @@ switch_fpu_prepare(struct fpu *old_fpu, int cpu)
 
 		/* But leave fpu_fpregs_owner_ctx! */
 		trace_x86_fpu_regs_deactivated(old_fpu);
-	} else
-		old_fpu->last_cpu = -1;
+	}
 }
 
 /*
@@ -549,12 +548,12 @@ switch_fpu_prepare(struct fpu *old_fpu, int cpu)
  */
 static inline void switch_fpu_finish(struct fpu *new_fpu, int cpu)
 {
-	bool preload = static_cpu_has(X86_FEATURE_FPU) &&
-		       new_fpu->initialized;
+	if (static_cpu_has(X86_FEATURE_FPU)) {
+		if (!fpregs_state_valid(new_fpu, cpu)) {
+			if (current->mm)
+				copy_kernel_to_fpregs(&new_fpu->state);
+		}
 
-	if (preload) {
-		if (!fpregs_state_valid(new_fpu, cpu))
-			copy_kernel_to_fpregs(&new_fpu->state);
 		fpregs_activate(new_fpu);
 	}
 }
diff --git a/arch/x86/include/asm/fpu/types.h b/arch/x86/include/asm/fpu/types.h
index 202c53918ecfa..c5a6edd92de4f 100644
--- a/arch/x86/include/asm/fpu/types.h
+++ b/arch/x86/include/asm/fpu/types.h
@@ -293,15 +293,6 @@ struct fpu {
 	 */
 	unsigned int			last_cpu;
 
-	/*
-	 * @initialized:
-	 *
-	 * This flag indicates whether this context is initialized: if the task
-	 * is not running then we can restore from this context, if the task
-	 * is running then we should save into this context.
-	 */
-	unsigned char			initialized;
-
 	/*
 	 * @state:
 	 *
diff --git a/arch/x86/include/asm/trace/fpu.h b/arch/x86/include/asm/trace/fpu.h
index 069c04be15076..bd65f6ba950f8 100644
--- a/arch/x86/include/asm/trace/fpu.h
+++ b/arch/x86/include/asm/trace/fpu.h
@@ -13,22 +13,19 @@ DECLARE_EVENT_CLASS(x86_fpu,
 
 	TP_STRUCT__entry(
 		__field(struct fpu *, fpu)
-		__field(bool, initialized)
 		__field(u64, xfeatures)
 		__field(u64, xcomp_bv)
 		),
 
 	TP_fast_assign(
 		__entry->fpu		= fpu;
-		__entry->initialized	= fpu->initialized;
 		if (boot_cpu_has(X86_FEATURE_OSXSAVE)) {
 			__entry->xfeatures = fpu->state.xsave.header.xfeatures;
 			__entry->xcomp_bv  = fpu->state.xsave.header.xcomp_bv;
 		}
 	),
-	TP_printk("x86/fpu: %p initialized: %d xfeatures: %llx xcomp_bv: %llx",
+	TP_printk("x86/fpu: %p xfeatures: %llx xcomp_bv: %llx",
 			__entry->fpu,
-			__entry->initialized,
 			__entry->xfeatures,
 			__entry->xcomp_bv
 	)
diff --git a/arch/x86/kernel/fpu/core.c b/arch/x86/kernel/fpu/core.c
index e43296854e379..3a4668c9d24f1 100644
--- a/arch/x86/kernel/fpu/core.c
+++ b/arch/x86/kernel/fpu/core.c
@@ -101,7 +101,7 @@ static void __kernel_fpu_begin(void)
 
 	kernel_fpu_disable();
 
-	if (fpu->initialized) {
+	if (current->mm) {
 		/*
 		 * Ignore return value -- we don't care if reg state
 		 * is clobbered.
@@ -116,7 +116,7 @@ static void __kernel_fpu_end(void)
 {
 	struct fpu *fpu = &current->thread.fpu;
 
-	if (fpu->initialized)
+	if (current->mm)
 		copy_kernel_to_fpregs(&fpu->state);
 
 	kernel_fpu_enable();
@@ -147,10 +147,9 @@ void fpu__save(struct fpu *fpu)
 
 	preempt_disable();
 	trace_x86_fpu_before_save(fpu);
-	if (fpu->initialized) {
-		if (!copy_fpregs_to_fpstate(fpu)) {
-			copy_kernel_to_fpregs(&fpu->state);
-		}
+
+	if (!copy_fpregs_to_fpstate(fpu)) {
+		copy_kernel_to_fpregs(&fpu->state);
 	}
 	trace_x86_fpu_after_save(fpu);
 	preempt_enable();
@@ -190,7 +189,7 @@ int fpu__copy(struct fpu *dst_fpu, struct fpu *src_fpu)
 {
 	dst_fpu->last_cpu = -1;
 
-	if (!src_fpu->initialized || !static_cpu_has(X86_FEATURE_FPU))
+	if (!static_cpu_has(X86_FEATURE_FPU))
 		return 0;
 
 	WARN_ON_FPU(src_fpu != &current->thread.fpu);
@@ -227,14 +226,10 @@ static void fpu__initialize(struct fpu *fpu)
 {
 	WARN_ON_FPU(fpu != &current->thread.fpu);
 
-	if (!fpu->initialized) {
-		fpstate_init(&fpu->state);
-		trace_x86_fpu_init_state(fpu);
+	fpstate_init(&fpu->state);
+	trace_x86_fpu_init_state(fpu);
 
-		trace_x86_fpu_activate_state(fpu);
-		/* Safe to do for the current task: */
-		fpu->initialized = 1;
-	}
+	trace_x86_fpu_activate_state(fpu);
 }
 
 /*
@@ -247,32 +242,20 @@ static void fpu__initialize(struct fpu *fpu)
  *
  * - or it's called for stopped tasks (ptrace), in which case the
  *   registers were already saved by the context-switch code when
- *   the task scheduled out - we only have to initialize the registers
- *   if they've never been initialized.
+ *   the task scheduled out.
  *
  * If the task has used the FPU before then save it.
  */
 void fpu__prepare_read(struct fpu *fpu)
 {
-	if (fpu == &current->thread.fpu) {
+	if (fpu == &current->thread.fpu)
 		fpu__save(fpu);
-	} else {
-		if (!fpu->initialized) {
-			fpstate_init(&fpu->state);
-			trace_x86_fpu_init_state(fpu);
-
-			trace_x86_fpu_activate_state(fpu);
-			/* Safe to do for current and for stopped child tasks: */
-			fpu->initialized = 1;
-		}
-	}
 }
 
 /*
  * This function must be called before we write a task's fpstate.
  *
- * If the task has used the FPU before then invalidate any cached FPU registers.
- * If the task has not used the FPU before then initialize its fpstate.
+ * Invalidate any cached FPU registers.
  *
  * After this function call, after registers in the fpstate are
  * modified and the child task has woken up, the child task will
@@ -289,17 +272,8 @@ void fpu__prepare_write(struct fpu *fpu)
 	 */
 	WARN_ON_FPU(fpu == &current->thread.fpu);
 
-	if (fpu->initialized) {
-		/* Invalidate any cached state: */
-		__fpu_invalidate_fpregs_state(fpu);
-	} else {
-		fpstate_init(&fpu->state);
-		trace_x86_fpu_init_state(fpu);
-
-		trace_x86_fpu_activate_state(fpu);
-		/* Safe to do for stopped child tasks: */
-		fpu->initialized = 1;
-	}
+	/* Invalidate any cached state: */
+	__fpu_invalidate_fpregs_state(fpu);
 }
 
 /*
@@ -316,17 +290,13 @@ void fpu__drop(struct fpu *fpu)
 	preempt_disable();
 
 	if (fpu == &current->thread.fpu) {
-		if (fpu->initialized) {
-			/* Ignore delayed exceptions from user space */
-			asm volatile("1: fwait\n"
-				     "2:\n"
-				     _ASM_EXTABLE(1b, 2b));
-			fpregs_deactivate(fpu);
-		}
+		/* Ignore delayed exceptions from user space */
+		asm volatile("1: fwait\n"
+			     "2:\n"
+			     _ASM_EXTABLE(1b, 2b));
+		fpregs_deactivate(fpu);
 	}
 
-	fpu->initialized = 0;
-
 	trace_x86_fpu_dropped(fpu);
 
 	preempt_enable();
diff --git a/arch/x86/kernel/fpu/init.c b/arch/x86/kernel/fpu/init.c
index 6abd83572b016..20d8fa7124c77 100644
--- a/arch/x86/kernel/fpu/init.c
+++ b/arch/x86/kernel/fpu/init.c
@@ -239,8 +239,6 @@ static void __init fpu__init_system_ctx_switch(void)
 
 	WARN_ON_FPU(!on_boot_cpu);
 	on_boot_cpu = 0;
-
-	WARN_ON_FPU(current->thread.fpu.initialized);
 }
 
 /*
diff --git a/arch/x86/kernel/fpu/regset.c b/arch/x86/kernel/fpu/regset.c
index 5dbc099178a88..d652b939ccfb5 100644
--- a/arch/x86/kernel/fpu/regset.c
+++ b/arch/x86/kernel/fpu/regset.c
@@ -15,16 +15,12 @@
  */
 int regset_fpregs_active(struct task_struct *target, const struct user_regset *regset)
 {
-	struct fpu *target_fpu = &target->thread.fpu;
-
-	return target_fpu->initialized ? regset->n : 0;
+	return regset->n;
 }
 
 int regset_xregset_fpregs_active(struct task_struct *target, const struct user_regset *regset)
 {
-	struct fpu *target_fpu = &target->thread.fpu;
-
-	if (boot_cpu_has(X86_FEATURE_FXSR) && target_fpu->initialized)
+	if (boot_cpu_has(X86_FEATURE_FXSR))
 		return regset->n;
 	else
 		return 0;
@@ -370,16 +366,9 @@ int fpregs_set(struct task_struct *target, const struct user_regset *regset,
 int dump_fpu(struct pt_regs *regs, struct user_i387_struct *ufpu)
 {
 	struct task_struct *tsk = current;
-	struct fpu *fpu = &tsk->thread.fpu;
-	int fpvalid;
 
-	fpvalid = fpu->initialized;
-	if (fpvalid)
-		fpvalid = !fpregs_get(tsk, NULL,
-				      0, sizeof(struct user_i387_ia32_struct),
-				      ufpu, NULL);
-
-	return fpvalid;
+	return !fpregs_get(tsk, NULL, 0, sizeof(struct user_i387_ia32_struct),
+			   ufpu, NULL);
 }
 EXPORT_SYMBOL(dump_fpu);
 
diff --git a/arch/x86/kernel/fpu/xstate.c b/arch/x86/kernel/fpu/xstate.c
index 359564beab5c3..a85f4139f663d 100644
--- a/arch/x86/kernel/fpu/xstate.c
+++ b/arch/x86/kernel/fpu/xstate.c
@@ -892,8 +892,6 @@ const void *get_xsave_field_ptr(int xsave_state)
 {
 	struct fpu *fpu = &current->thread.fpu;
 
-	if (!fpu->initialized)
-		return NULL;
 	/*
 	 * fpu__save() takes the CPU's xstate registers
 	 * and saves them off to the 'fpu memory buffer.
diff --git a/arch/x86/kernel/process_32.c b/arch/x86/kernel/process_32.c
index b8a935adc96fc..5c99e49c0d392 100644
--- a/arch/x86/kernel/process_32.c
+++ b/arch/x86/kernel/process_32.c
@@ -292,10 +292,10 @@ __switch_to(struct task_struct *prev_p, struct task_struct *next_p)
 	if (prev->gs | next->gs)
 		lazy_load_gs(next->gs);
 
-	switch_fpu_finish(next_fpu, cpu);
-
 	this_cpu_write(current_task, next_p);
 
+	switch_fpu_finish(next_fpu, cpu);
+
 	/* Load the Intel cache allocation PQR MSR. */
 	intel_rdt_sched_in();
 
diff --git a/arch/x86/kernel/process_64.c b/arch/x86/kernel/process_64.c
index cf2c157714594..4fd0dfa5bd83e 100644
--- a/arch/x86/kernel/process_64.c
+++ b/arch/x86/kernel/process_64.c
@@ -604,14 +604,14 @@ __switch_to(struct task_struct *prev_p, struct task_struct *next_p)
 
 	x86_fsgsbase_load(prev, next);
 
-	switch_fpu_finish(next_fpu, cpu);
-
 	/*
 	 * Switch the PDA and FPU contexts.
 	 */
 	this_cpu_write(current_task, next_p);
 	this_cpu_write(cpu_current_top_of_stack, task_top_of_stack(next_p));
 
+	switch_fpu_finish(next_fpu, cpu);
+
 	/* Reload sp0. */
 	update_task_stack(next_p);
 
diff --git a/arch/x86/kernel/signal.c b/arch/x86/kernel/signal.c
index 92a3b312a53c4..2687e698c31fc 100644
--- a/arch/x86/kernel/signal.c
+++ b/arch/x86/kernel/signal.c
@@ -246,7 +246,7 @@ get_sigframe(struct k_sigaction *ka, struct pt_regs *regs, size_t frame_size,
 	unsigned long sp = regs->sp;
 	unsigned long buf_fx = 0;
 	int onsigstack = on_sig_stack(sp);
-	struct fpu *fpu = &current->thread.fpu;
+	int ret;
 
 	/* redzone */
 	if (IS_ENABLED(CONFIG_X86_64))
@@ -265,11 +265,9 @@ get_sigframe(struct k_sigaction *ka, struct pt_regs *regs, size_t frame_size,
 		sp = (unsigned long) ka->sa.sa_restorer;
 	}
 
-	if (fpu->initialized) {
-		sp = fpu__alloc_mathframe(sp, IS_ENABLED(CONFIG_X86_32),
-					  &buf_fx, &math_size);
-		*fpstate = (void __user *)sp;
-	}
+	sp = fpu__alloc_mathframe(sp, IS_ENABLED(CONFIG_X86_32),
+				  &buf_fx, &math_size);
+	*fpstate = (void __user *)sp;
 
 	sp = align_sigframe(sp - frame_size);
 
@@ -281,8 +279,8 @@ get_sigframe(struct k_sigaction *ka, struct pt_regs *regs, size_t frame_size,
 		return (void __user *)-1L;
 
 	/* save i387 and extended state */
-	if (fpu->initialized &&
-	    copy_fpstate_to_sigframe(*fpstate, (void __user *)buf_fx, math_size) < 0)
+	ret = copy_fpstate_to_sigframe(*fpstate, (void __user *)buf_fx, math_size);
+	if (ret < 0)
 		return (void __user *)-1L;
 
 	return (void __user *)sp;
@@ -763,8 +761,7 @@ handle_signal(struct ksignal *ksig, struct pt_regs *regs)
 		/*
 		 * Ensure the signal handler starts with the new fpu state.
 		 */
-		if (fpu->initialized)
-			fpu__clear(fpu);
+		fpu__clear(fpu);
 	}
 	signal_setup_done(failed, ksig, stepping);
 }
diff --git a/arch/x86/mm/pkeys.c b/arch/x86/mm/pkeys.c
index 047a77f6a10cb..05bb9a44eb1c3 100644
--- a/arch/x86/mm/pkeys.c
+++ b/arch/x86/mm/pkeys.c
@@ -39,17 +39,12 @@ int __execute_only_pkey(struct mm_struct *mm)
 	 * dance to set PKRU if we do not need to.  Check it
 	 * first and assume that if the execute-only pkey is
 	 * write-disabled that we do not have to set it
-	 * ourselves.  We need preempt off so that nobody
-	 * can make fpregs inactive.
+	 * ourselves.
 	 */
-	preempt_disable();
 	if (!need_to_set_mm_pkey &&
-	    current->thread.fpu.initialized &&
 	    !__pkru_allows_read(read_pkru(), execute_only_pkey)) {
-		preempt_enable();
 		return execute_only_pkey;
 	}
-	preempt_enable();
 
 	/*
 	 * Set up PKRU so that it denies access for everything
-- 
2.20.0.rc1

