Return-Path: <linux-kernel-owner@vger.kernel.org>
Delivered-To: unknown
Received: from linux.intel.com (10.54.29.200:995) by likexu-workstation with
  POP3-SSL; 29 Nov 2018 08:41:43 -0000
X-Original-To: like.xu@linux.intel.com
Delivered-To: like.xu@linux.intel.com
Received: from fmsmga001.fm.intel.com (fmsmga001.fm.intel.com [10.253.24.23])
	(using TLSv1.2 with cipher ECDHE-RSA-AES256-GCM-SHA384 (256/256 bits))
	(No client certificate requested)
	by linux.intel.com (Postfix) with ESMTPS id CA0EC5803ED;
	Wed, 28 Nov 2018 14:21:41 -0800 (PST)
Received: from fmsmga103.fm.intel.com ([10.1.193.90])
  by fmsmga001-1.fm.intel.com with ESMTP/TLS/DHE-RSA-AES256-GCM-SHA384; 28 Nov 2018 14:21:41 -0800
X-SG-BADATTACHMENTNOREPLY: True
IronPort-PHdr: =?us-ascii?q?9a23=3A5JdTAR22ebg+zbDRsmDT+DRfVm0co7zxezQtwd8Z?=
 =?us-ascii?q?segSI/3xwZ3uMQTl6Ol3ixeRBMOHs6IC07KempujcFRI2YyGvnEGfc4EfD4+ou?=
 =?us-ascii?q?JSoTYdBtWYA1bwNv/gYn9yNs1DUFh44yPzahANS47xaFLIv3K98yMZFAnhOgpp?=
 =?us-ascii?q?POT1HZPZg9iq2+yo9JDffwZFiCChbb9uMR67sRjfus4KjIV4N60/0AHJonxGe+?=
 =?us-ascii?q?RXwWNnO1eelAvi68mz4ZBu7T1et+ou+MBcX6r6eb84TaFDAzQ9L281/szrugLd?=
 =?us-ascii?q?QgaJ+3ART38ZkhtMAwjC8RH6QpL8uTb0u+ZhxCWXO9D9QKsqUjq+8ahkVB7oiD?=
 =?us-ascii?q?8GNzEn9mHXltdwh79frB64uhBz35LYbISTOfFjfK3SYMkaSHJBUMhPSiJPDICy?=
 =?us-ascii?q?YYwNAOoPMulXs4bzp0AWrRa8HgSsGODixyVUinLswaE30eIsGhzG0gw6GNIOtW?=
 =?us-ascii?q?zZosjrO6gJS++117XIzTTZYPNQxDzw9I7IfQ07ofCNQ71wc9fax1QuFwzbgFSQ?=
 =?us-ascii?q?qIvlPymI3ekKqGeb7uVgWvy1hG48qwB8uTyvxsYqionUmoIV0FfE9SN4wIc6P9?=
 =?us-ascii?q?G3VVB0bMeiHZBNtC+aL5N7Tt0+T2xsoio217MLtYChcCQXy5kr2wTTZv2FfoSQ?=
 =?us-ascii?q?/x7uW+ecLS1kiH5/Zr6yiRW//VKix+HgUMS/zUxEoTBfktbWs3AAzxzT5daDSv?=
 =?us-ascii?q?t65kqhxzmP2B7J6u1eIkA7i7DbK5g/zb40jJYTtl7DHiDulEX3iq+ZaFkk9/C2?=
 =?us-ascii?q?5+j7ZrjqvIKQOoFqhg3kL6gjmdCzDf45PwUMR2Sb/P6z1Lzn/U33WrVKifg2n7?=
 =?us-ascii?q?HdsJDbI8Qbu6G4DxZW0ok98Ra/CSmp0NABkXkAIlNFfgyIj5LyNlHQL/D3E+2/?=
 =?us-ascii?q?j06vkDh13fDGOKPuApHXInjEirfhcq5x61RAxwor0dBf+5VUB6kFIPLyWU/+qs?=
 =?us-ascii?q?bUDxAkMwGvx+bnCdN91p4RWG6VA6+ZNr/SvkGM5u41P+aMY4oVsi7nK/c5//7u?=
 =?us-ascii?q?kWM5mVgFcKmpx5QXaWy4Ee5hI0mDYXrsn80OEWEFvgclSOzqiVuCUSNcZnqoXq?=
 =?us-ascii?q?I84C07B5yiDYvZWo+th7mB1j+hHpJKfmBGFkyMEXDweoWGXPcDdjieIsxmkjwC?=
 =?us-ascii?q?U7ihTJQs1RWvtA/81rpmIfDY+iwetZL/ytd14/ffmg019TxxF86dyX2CT3lonm?=
 =?us-ascii?q?MUQD87xLpwoVd9yleE0qh0meZYGsZR5/5SVgc6NJjcz/F1CtzoWwLBeMuJR0ii?=
 =?us-ascii?q?Qtm8HT4xSdcxyccUY0lhA9WikgzD3y2yDr8WjbOLAoY48qbd33frIcZ9xG3L1K?=
 =?us-ascii?q?0gj1kgX8tOOneqhq959wjPGYHJl1+VmLqtdaQZxCTN7nuMzXKSvEFEVw59SbjK?=
 =?us-ascii?q?UmoBZkTIt9j55lnNT7m1Cbs5NAtNzsqCKqhPat3tllhGQPbjONLDY2O+gWuwBB?=
 =?us-ascii?q?CIxq+SY4ruYWkSwCLdCE0cmQAJ4XmGLRQ+Bjumo2/GETNhD0zvbF32/el+sny7?=
 =?us-ascii?q?SFQ0wB+Mb0B607q1+xgVheGTSv8J37IEvjshpCtwHFqnw93WDN+ArRJ7fKpAed?=
 =?us-ascii?q?M9/EtH1WXBugxhP5ygKqdihkIecwV3pU/uyw97CoJakcgurXMqygVyJLmc0FNA?=
 =?us-ascii?q?cTOYwJ/xNqfWKmn04BCgdarW1kvC39aR/6cF8O44pEn7vAG1Ckoi9G1q3MNR03?=
 =?us-ascii?q?SC6ZTFEgoTXYjqXUYq6hd1vbfaYio654PKznBsNai0sjnf29MmHuclyxCgf8tB?=
 =?us-ascii?q?P6OADgP9D8oaB822Iuwwh1epdg4EPPxV9KMsP8KmauGK17KxMOdhnDKpl2JH4I?=
 =?us-ascii?q?9m30KI9ip8TPPI3pkfz/GZ2AuHSynzjFO7vs/rnoBEYCkYHnCjxij8GI5Reqpy?=
 =?us-ascii?q?cJ4RCWevP8K43M9+iIPqW3JC8l6sGUkG2M6wdRWOdVP92RBf2loNoXygnyu11D?=
 =?us-ascii?q?h0kzAvrqqC0y3C2eXidBwbOmFVQGlul0vjIY+xj9oCRkincxAplAe55Ub936Va?=
 =?us-ascii?q?pKV/I3PTQEtSZCj2MmdiX7C0trqDZc5P9ZwpvT9WUOS6fVCVVLr9rwEG3CPkGm?=
 =?us-ascii?q?tU3Co7eC2yupXlgxx6j3qQLHRpo3rDesFwxhDf6MbHRfFL3ToGRyh4iT/JCVi6?=
 =?us-ascii?q?JNSp+dSUl5HesuGxTW6hV5tTcTX1woOErie0+WpqARinlfCphtLnCRQ60TP819?=
 =?us-ascii?q?RyVSTHthH8bpPp16S7N+JqZU1oBF7668pnFYByiIowhJcM2XcEgpWZ52YIkWD2?=
 =?us-ascii?q?Md9Dw6LxcGINRSIXw97S+AXl21dsLnOTy4L5S3WS2M1hZ9ahb2MS2yI96d1KCa?=
 =?us-ascii?q?iO4LxFmyt1vkS3rQbLbfdhmTcdzOMk6GQGjOERpAot0iKdD6gXHUlZPizjjQ6E?=
 =?us-ascii?q?7t6go6VMeGagb6Kw21FgktC7A7GPuQVcWHf/epc/Ei589MR/MFTQ0HLt7oHoYs?=
 =?us-ascii?q?XfbdUWtheMiRfPk/BVKI4tlvoNnSdnJWX9vXg/x+86lxNu24y6vJOcK2Vs56+5?=
 =?us-ascii?q?Bh9YNjvoZ8Ic4D3tjKBentqI0ICrBJluBjILXJ7wR/KyDD0SrejnNxqJEDAksX?=
 =?us-ascii?q?iUA73fHQuC6Et8q3LPDoumN3WWJHkf0NVjSwORJE1ZgAAIQjo6moQ1GRytxMzk?=
 =?us-ascii?q?aE15/Cwe5kbkqhtQzeJlLxv/XX3apAi2cTc4UoSfIABV7gFf5EfVLMqe4fhoHy?=
 =?us-ascii?q?xD+p2hrQqNKnGUZghSDGEJXFCECE7nPrW0+dbA9O2YDPKkL/TSebWOtfBeV/CQ?=
 =?us-ascii?q?yJOv1Ytm4i+MNtiVMXlkFfE7wU1DXXZ2G8nCnzUPSioXlz/CbsKBpRe8/DF3od?=
 =?us-ascii?q?678PjxRA3v4o6PAaNIMdpz4xC2nbuDN+mIiSZ5NzlY15AMxXzJyLQF314SkSZu?=
 =?us-ascii?q?dzazHrQaqC7NV7ndmqtWDx4ddiNyO9FE76M63glRJ8Hbjsn52aJ/jv4wE11FT0?=
 =?us-ascii?q?Dumtm1ZcwWJGGwLEnIBFuQO7ScOzLKw9v7Yae9SbBLiOVUthuwuSuUEkP5PzSD?=
 =?us-ascii?q?kSXpWA6rMe1WkC6bOxlespmnchlxEWjjUM7mahqjPd9rjD02xKc4iW/QOWEAMT?=
 =?us-ascii?q?hzbUVNo6aU7SNZhPV/BmNA4mBkLemChyaW8e3YJowKvvtsByR+j/ha72giy7tJ?=
 =?us-ascii?q?8CFEQ+R4mSvIod5oplGmk++PxSJmURpOsDlLgo2LsF5mOaXY8JlARHnF8AgM7W?=
 =?us-ascii?q?WWFxQFud9lBsfztKBXz9ic3J70fTND9c/EuMgRHc7ZLOqZP3c7dxnkAjjZCE0C?=
 =?us-ascii?q?VzH4G3vYghlmnfub7WGUp55yg57ggogDSPdgVVEqF/QAQhBvHdMPKYxmdjcll6?=
 =?us-ascii?q?OHlskO5Gr4oBSHF5YShYzOSv/HWaanEz2el7QRIkJQmb4=3D?=
X-IronPort-Anti-Spam-Filtered: true
X-IronPort-Anti-Spam-Result: =?us-ascii?q?A0ANAACCE/9bh0O0hNFkHAEBAQQBAQcEA?=
 =?us-ascii?q?QGBUQcBAQsBg2sng3mIGF+LKVIGgUmSN4R3gXMsEwGHbiI0CQ0BAwEBAQEBAQI?=
 =?us-ascii?q?BEwEBAQgNCQgpL4I2JAGCYgMDAQIgBAsBRgYJAQEkAiYCAgNUGQWDHIF1DQWnH?=
 =?us-ascii?q?XwziiqBC4ZghCsRBniBB4ERh02DSoJXAokFIYFxlQQJgRGJGYZ8I4ljhzIsmWK?=
 =?us-ascii?q?CDTMaCBwUgyeCJxcSjgw+ATKBBQEBixgNFweCIAEB?=
X-IPAS-Result: =?us-ascii?q?A0ANAACCE/9bh0O0hNFkHAEBAQQBAQcEAQGBUQcBAQsBg2s?=
 =?us-ascii?q?ng3mIGF+LKVIGgUmSN4R3gXMsEwGHbiI0CQ0BAwEBAQEBAQIBEwEBAQgNCQgpL?=
 =?us-ascii?q?4I2JAGCYgMDAQIgBAsBRgYJAQEkAiYCAgNUGQWDHIF1DQWnHXwziiqBC4ZghCs?=
 =?us-ascii?q?RBniBB4ERh02DSoJXAokFIYFxlQQJgRGJGYZ8I4ljhzIsmWKCDTMaCBwUgyeCJ?=
 =?us-ascii?q?xcSjgw+ATKBBQEBixgNFweCIAEB?=
X-IronPort-AV: E=Sophos;i="5.56,292,1539673200"; 
   d="scan'208";a="53757954"
X-Amp-Result: SKIPPED(no attachment in message)
X-Amp-File-Uploaded: False
Received: from vger.kernel.org ([209.132.180.67])
  by mtab.intel.com with ESMTP; 28 Nov 2018 14:21:40 -0800
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
        id S1727406AbeK2JYp (ORCPT <rfc822;like.xu@linux.intel.com>
        + 23 others); Thu, 29 Nov 2018 04:24:45 -0500
Received: from Galois.linutronix.de ([146.0.238.70]:33247 "EHLO
        Galois.linutronix.de" rhost-flags-OK-OK-OK-OK) by vger.kernel.org
        with ESMTP id S1727223AbeK2JYo (ORCPT
        <rfc822;linux-kernel@vger.kernel.org>);
        Thu, 29 Nov 2018 04:24:44 -0500
Received: from localhost ([127.0.0.1] helo=bazinga.breakpoint.cc)
        by Galois.linutronix.de with esmtp (Exim 4.80)
        (envelope-from <bigeasy@linutronix.de>)
        id 1gS8D2-0001GX-W6; Wed, 28 Nov 2018 23:21:29 +0100
From: Sebastian Andrzej Siewior <bigeasy@linutronix.de>
To: linux-kernel@vger.kernel.org
Cc: x86@kernel.org, Andy Lutomirski <luto@kernel.org>,
        Paolo Bonzini <pbonzini@redhat.com>,
        =?UTF-8?q?Radim=20Kr=C4=8Dm=C3=A1=C5=99?= <rkrcmar@redhat.com>,
        kvm@vger.kernel.org, "Jason A. Donenfeld" <Jason@zx2c4.com>,
        Rik van Riel <riel@surriel.com>,
        Dave Hansen <dave.hansen@linux.intel.com>,
        Sebastian Andrzej Siewior <bigeasy@linutronix.de>
Subject: [PATCH 27/29] x86/fpu: Let __fpu__restore_sig() restore the !32bit+fxsr frame from kernel memory
Date: Wed, 28 Nov 2018 23:20:33 +0100
Message-Id: <20181128222035.2996-28-bigeasy@linutronix.de>
X-Mailer: git-send-email 2.20.0.rc1
In-Reply-To: <20181128222035.2996-1-bigeasy@linutronix.de>
References: <20181128222035.2996-1-bigeasy@linutronix.de>
MIME-Version: 1.0
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: 8bit
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: <linux-kernel.vger.kernel.org>
X-Mailing-List: linux-kernel@vger.kernel.org

The !32bit+fxsr case loads the new state from user memory. In case we
restore the FPU state on return to userland we can't do this. It would
be required to disable preemption in order to avoid a context switch
which would set TIF_NEED_FPU_LOAD. If this happens before the "restore"
operation then the loaded registers would become volatile.

Disabling preemption while accessing user memory requires to disable the
pagefault handler. An error during XRSTOR would then mean that either a
page fault occured (and we have to retry with enabled page fault
handler) or a #GP occured because the xstate is bogus (after all the
sig-handler can modify it).

In order to avoid that mess, copy the FPU state from userland, validate
it and then load it. The copy_users_â€¦() helper are basically the old
helper except that they operate on kernel memory and the fault handler
just sets the error value and the caller handles it.

Signed-off-by: Sebastian Andrzej Siewior <bigeasy@linutronix.de>
---
 arch/x86/include/asm/fpu/internal.h | 32 ++++++++++-----
 arch/x86/kernel/fpu/signal.c        | 62 +++++++++++++++++++++++------
 2 files changed, 71 insertions(+), 23 deletions(-)

diff --git a/arch/x86/include/asm/fpu/internal.h b/arch/x86/include/asm/fpu/internal.h
index 1e038b7357485..9fb2b8b811d22 100644
--- a/arch/x86/include/asm/fpu/internal.h
+++ b/arch/x86/include/asm/fpu/internal.h
@@ -118,6 +118,21 @@ extern void fpstate_sanitize_xstate(struct fpu *fpu);
 	err;								\
 })
 
+#define kernel_insn_norestore(insn, output, input...)			\
+({									\
+	int err;							\
+	asm volatile("1:" #insn "\n\t"					\
+		     "2:\n"						\
+		     ".section .fixup,\"ax\"\n"				\
+		     "3:  movl $-1,%[err]\n"				\
+		     "    jmp  2b\n"					\
+		     ".previous\n"					\
+		     _ASM_EXTABLE(1b, 3b)				\
+		     : [err] "=r" (err), output				\
+		     : "0"(0), input);					\
+	err;								\
+})
+
 #define kernel_insn(insn, output, input...)				\
 	asm volatile("1:" #insn "\n\t"					\
 		     "2:\n"						\
@@ -138,15 +153,15 @@ static inline void copy_kernel_to_fxregs(struct fxregs_state *fx)
 	}
 }
 
-static inline int copy_user_to_fxregs(struct fxregs_state __user *fx)
+static inline int copy_users_to_fxregs(struct fxregs_state *fx)
 {
 	if (IS_ENABLED(CONFIG_X86_32))
-		return user_insn(fxrstor %[fx], "=m" (*fx), [fx] "m" (*fx));
+		return kernel_insn_norestore(fxrstor %[fx], "=m" (*fx), [fx] "m" (*fx));
 	else if (IS_ENABLED(CONFIG_AS_FXSAVEQ))
-		return user_insn(fxrstorq %[fx], "=m" (*fx), [fx] "m" (*fx));
+		return kernel_insn_norestore(fxrstorq %[fx], "=m" (*fx), [fx] "m" (*fx));
 
 	/* See comment in copy_fxregs_to_kernel() below. */
-	return user_insn(rex64/fxrstor (%[fx]), "=m" (*fx), [fx] "R" (fx),
+	return kernel_insn_norestore(rex64/fxrstor (%[fx]), "=m" (*fx), [fx] "R" (fx),
 			  "m" (*fx));
 }
 
@@ -155,9 +170,9 @@ static inline void copy_kernel_to_fregs(struct fregs_state *fx)
 	kernel_insn(frstor %[fx], "=m" (*fx), [fx] "m" (*fx));
 }
 
-static inline int copy_user_to_fregs(struct fregs_state __user *fx)
+static inline int copy_users_to_fregs(struct fregs_state *fx)
 {
-	return user_insn(frstor %[fx], "=m" (*fx), [fx] "m" (*fx));
+	return kernel_insn_norestore(frstor %[fx], "=m" (*fx), [fx] "m" (*fx));
 }
 
 static inline void copy_fxregs_to_kernel(struct fpu *fpu)
@@ -337,16 +352,13 @@ static inline void copy_kernel_to_xregs(struct xregs_state *xstate, u64 mask)
 /*
  * Restore xstate from user space xsave area.
  */
-static inline int copy_user_to_xregs(struct xregs_state __user *buf, u64 mask)
+static inline int copy_users_to_xregs(struct xregs_state *xstate, u64 mask)
 {
-	struct xregs_state *xstate = ((__force struct xregs_state *)buf);
 	u32 lmask = mask;
 	u32 hmask = mask >> 32;
 	int err;
 
-	stac();
 	XSTATE_OP(XRSTOR, xstate, lmask, hmask, err);
-	clac();
 
 	return err;
 }
diff --git a/arch/x86/kernel/fpu/signal.c b/arch/x86/kernel/fpu/signal.c
index c66356b168b39..339a8c113517e 100644
--- a/arch/x86/kernel/fpu/signal.c
+++ b/arch/x86/kernel/fpu/signal.c
@@ -217,7 +217,8 @@ sanitize_restored_xstate(union fpregs_state *state,
 		 */
 		xsave->i387.mxcsr &= mxcsr_feature_mask;
 
-		convert_to_fxsr(&state->fxsave, ia32_env);
+		if (ia32_env)
+			convert_to_fxsr(&state->fxsave, ia32_env);
 	}
 }
 
@@ -299,28 +300,63 @@ static int __fpu__restore_sig(void __user *buf, void __user *buf_fx, int size)
 		kfree(tmp);
 		return err;
 	} else {
+		union fpregs_state *state;
+		void *tmp;
 		int ret;
 
+		tmp = kzalloc(sizeof(*state) + fpu_kernel_xstate_size + 64, GFP_KERNEL);
+		if (!tmp)
+			return -ENOMEM;
+		state = PTR_ALIGN(tmp, 64);
+
 		/*
 		 * For 64-bit frames and 32-bit fsave frames, restore the user
 		 * state to the registers directly (with exceptions handled).
 		 */
-		if (use_xsave()) {
-			if ((unsigned long)buf_fx % 64 || fx_only) {
+		if ((unsigned long)buf_fx % 64)
+			fx_only = 1;
+
+		if (use_xsave() && !fx_only) {
+			u64 init_bv = xfeatures_mask & ~xfeatures;
+
+			if (using_compacted_format()) {
+				ret = copy_user_to_xstate(&state->xsave, buf_fx);
+			} else {
+				ret = __copy_from_user(&state->xsave, buf_fx, state_size);
+
+				if (!ret && state_size > offsetof(struct xregs_state, header))
+					ret = validate_xstate_header(&state->xsave.header);
+			}
+			if (ret)
+				goto err_out;
+			sanitize_restored_xstate(state, NULL, xfeatures,
+						 fx_only);
+
+			if (unlikely(init_bv))
+				copy_kernel_to_xregs(&init_fpstate.xsave, init_bv);
+			ret = copy_users_to_xregs(&state->xsave, xfeatures);
+
+		} else if (use_fxsr()) {
+			ret = __copy_from_user(&state->fxsave, buf_fx, state_size);
+			if (ret)
+				goto err_out;
+
+			if (use_xsave()) {
 				u64 init_bv = xfeatures_mask & ~XFEATURE_MASK_FPSSE;
 				copy_kernel_to_xregs(&init_fpstate.xsave, init_bv);
-				ret = copy_user_to_fxregs(buf_fx);
-			} else {
-				u64 init_bv = xfeatures_mask & ~xfeatures;
-				if (unlikely(init_bv))
-					copy_kernel_to_xregs(&init_fpstate.xsave, init_bv);
-				ret = copy_user_to_xregs(buf_fx, xfeatures);
 			}
-		} else if (use_fxsr()) {
-			ret = copy_user_to_fxregs(buf_fx);
-		} else
-			ret = copy_user_to_fregs(buf_fx);
+			state->fxsave.mxcsr &= mxcsr_feature_mask;
 
+			ret = copy_users_to_fxregs(&state->fxsave);
+		} else {
+			ret = __copy_from_user(&state->fsave, buf_fx, state_size);
+			if (ret)
+				goto err_out;
+			ret = copy_users_to_fregs(buf_fx);
+		}
+
+err_out:
+		kfree(tmp);
 		if (ret) {
 			fpu__clear(fpu);
 			return -1;
-- 
2.20.0.rc1

