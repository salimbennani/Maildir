Return-Path: <qemu-devel-bounces+like.xu=linux.intel.com@nongnu.org>
Delivered-To: unknown
Received: from linux.intel.com (10.54.29.200:995) by likexu-workstation with
  POP3-SSL; 24 Nov 2018 12:36:50 -0000
X-Original-To: like.xu@linux.intel.com
Delivered-To: like.xu@linux.intel.com
Received: from orsmga004.jf.intel.com (orsmga004.jf.intel.com [10.7.209.38])
	(using TLSv1.2 with cipher ECDHE-RSA-AES256-GCM-SHA384 (256/256 bits))
	(No client certificate requested)
	by linux.intel.com (Postfix) with ESMTPS id B54F358037D
	for <like.xu@linux.intel.com>; Fri, 23 Nov 2018 10:30:12 -0800 (PST)
Received: from orsmga101.jf.intel.com ([10.7.208.22])
  by orsmga004-1.jf.intel.com with ESMTP/TLS/DHE-RSA-AES256-GCM-SHA384; 23 Nov 2018 10:30:12 -0800
IronPort-PHdr: =?us-ascii?q?9a23=3AsbSvlhMI73BxWUT4hfAl6mtUPXoX/o7sNwtQ0KIM?=
 =?us-ascii?q?zox0K/z7r8bcNUDSrc9gkEXOFd2Cra4c26yO6+jJYi8p2d65qncMcZhBBVcuqP?=
 =?us-ascii?q?49uEgeOvODElDxN/XwbiY3T4xoXV5h+GynYwAOQJ6tL1LdrWev4jEMBx7xKRR6?=
 =?us-ascii?q?JvjvGo7Vks+7y/2+94fcbglUhzexe69+IAmrpgjNq8cahpdvJLwswRXTuHtIfO?=
 =?us-ascii?q?pWxWJsJV2Nmhv3+9m98p1+/SlOovwt78FPX7n0cKQ+VrxYES8pM3sp683xtBnM?=
 =?us-ascii?q?VhWA630BWWgLiBVIAgzF7BbnXpfttybxq+Rw1DWGMcDwULs5Qiqp4bt1RxD0iS?=
 =?us-ascii?q?cHLz85/3/Risxsl6JQvRatqwViz4LIfI2ZMfxzdb7fc9wHX2pMRshfWSxfDI2/?=
 =?us-ascii?q?YYsAAPYOMvtaoIbzulUOtRmzCwujCe/yxDJEmmH53bYh3uQ9DQ3LxhAsE84UvX?=
 =?us-ascii?q?jKqtj+KaccUfqyzKnN1TjPYf1Y2S3n5IPVfB4uu++MXbNtfsHM1UQvExnKjlON?=
 =?us-ascii?q?ooLkPjOV0v8CvHaB7+p8W+6klmkqpBx+ojiuwscjkZfGhpgJyl3f7yV23ps6Jd?=
 =?us-ascii?q?2iR05ne9KrDJxQtySDOoZwX8gsQHlotT4kxrEaupO3ZjUGxIkkyhLFdfCKfYiF?=
 =?us-ascii?q?7gj+WOuTOTt0mm5pdbalixqv/0Ws1PfwWtS33VtEtCZJjNrBu3YQ3BLJ8MeHUO?=
 =?us-ascii?q?Fy/kK51DaPyQ/T7uZELFgwlaraMJ4h3qUwmoAcsUTFAy/6gkL2jLWZdkk8++io?=
 =?us-ascii?q?7froYqn+q5OCK4N5iRvyPrkzlsG8G+g0LAYDUmiB9eih1rDv5Uj5T69Ljv0ynK?=
 =?us-ascii?q?nZqpfaJcEDq66gHQBV15sj5w+iADi4ztQXg30HIEtedxKAkojpPU3BL+7jDfu4?=
 =?us-ascii?q?h1SskTRryO7cMrzuH5XANnzDkLbnfbZg5E9Q0gszzdZD551KDrENOu78Wkj0tN?=
 =?us-ascii?q?HDCB85NAq0w+nhCNVgzI8eXniPAqCBPKPIrVCI/v4vI/WLZIINvDb9Kvsl6OD0?=
 =?us-ascii?q?gX42hF8QZq2p3ZoRaHClEfVqOUSZYXzwgtgfFWcGpBYxTOvviA7KbDhIenznX7?=
 =?us-ascii?q?4g/ippT8WiDJzfXcarh7qO2jr9GYdZIWVPC1SJGHGvcJ2YWvAKc2WLL8p81zAJ?=
 =?us-ascii?q?S7WlGLInzgyk4Qrzyr57KbjN9ygF8J7uytVxovfejAw/7iBcCcOb3GeQCWZukT?=
 =?us-ascii?q?QTWjU00atj9FF70UqJyqNigvZVRuBUsstAVQM9fbTbyf57DdG6DhrLedGbSVCn?=
 =?us-ascii?q?as+rDTE4UpQ6xNpYMGhnHND3xDzZmWKGCqEUm/SiAJUyuo3d23L8Pdo3gyLK26?=
 =?us-ascii?q?glhVQ8XuNVOGGmj7I5/A/WUd2a236FnrqnIPxPlBXG832OmC/X5BlV?=
X-IronPort-Anti-Spam-Filtered: true
X-IronPort-Anti-Spam-Result: =?us-ascii?q?A0ATAACMRvhbhxHrdtBjHAEBAQQBAQcEA?=
 =?us-ascii?q?QGBUQcBAQsBgTCCTxOMEV+LIYINiQuOMIFsGxgUiFoiNAkNAQMBAQEBAQECARM?=
 =?us-ascii?q?BAQEKCwkIGw4vgjYFAgMaAQaCWwEBAQECAQECJBMMCikDAgEBAgYBAQoOBwMJH?=
 =?us-ascii?q?QgDAQsFDTwKCQWDHIFqAw0IAQSoBDOHdA2CGYwJEQaBQD+BEYMSglaIAwKJI5Y?=
 =?us-ascii?q?xLgcCAo4CgyAjCoFPhQuCbYc3jk2GMYMygUaCDXAVgyeCJxcSjgpBMYEHHIoOg?=
 =?us-ascii?q?XcBAQ?=
X-IPAS-Result: =?us-ascii?q?A0ATAACMRvhbhxHrdtBjHAEBAQQBAQcEAQGBUQcBAQsBgTC?=
 =?us-ascii?q?CTxOMEV+LIYINiQuOMIFsGxgUiFoiNAkNAQMBAQEBAQECARMBAQEKCwkIGw4vg?=
 =?us-ascii?q?jYFAgMaAQaCWwEBAQECAQECJBMMCikDAgEBAgYBAQoOBwMJHQgDAQsFDTwKCQW?=
 =?us-ascii?q?DHIFqAw0IAQSoBDOHdA2CGYwJEQaBQD+BEYMSglaIAwKJI5YxLgcCAo4CgyAjC?=
 =?us-ascii?q?oFPhQuCbYc3jk2GMYMygUaCDXAVgyeCJxcSjgpBMYEHHIoOgXcBAQ?=
X-IronPort-AV: E=Sophos;i="5.56,270,1539673200"; 
   d="scan'208";a="42017351"
X-Amp-Result: UNSCANNABLE
X-Amp-File-Uploaded: False
Unscannable: 2
Received: from lists.gnu.org ([208.118.235.17])
  by mtab.intel.com with ESMTP/TLS/AES256-SHA; 23 Nov 2018 10:30:11 -0800
Received: from localhost ([::1]:53858 helo=lists.gnu.org)
	by lists.gnu.org with esmtp (Exim 4.71)
	(envelope-from <qemu-devel-bounces+like.xu=linux.intel.com@nongnu.org>)
	id 1gQGDT-0003iW-49
	for like.xu@linux.intel.com; Fri, 23 Nov 2018 13:30:11 -0500
Received: from eggs.gnu.org ([2001:4830:134:3::10]:34488)
	by lists.gnu.org with esmtp (Exim 4.71)
	(envelope-from <dgilbert@redhat.com>) id 1gQGCt-0003hF-AO
	for qemu-devel@nongnu.org; Fri, 23 Nov 2018 13:29:36 -0500
Received: from Debian-exim by eggs.gnu.org with spam-scanned (Exim 4.71)
	(envelope-from <dgilbert@redhat.com>) id 1gQGCq-0000mH-27
	for qemu-devel@nongnu.org; Fri, 23 Nov 2018 13:29:35 -0500
Received: from mx1.redhat.com ([209.132.183.28]:45072)
	by eggs.gnu.org with esmtps (TLS1.0:DHE_RSA_AES_256_CBC_SHA1:32)
	(Exim 4.71) (envelope-from <dgilbert@redhat.com>) id 1gQGCp-0000kX-Q8
	for qemu-devel@nongnu.org; Fri, 23 Nov 2018 13:29:32 -0500
Received: from smtp.corp.redhat.com (int-mx03.intmail.prod.int.phx2.redhat.com
	[10.5.11.13])
	(using TLSv1.2 with cipher AECDH-AES256-SHA (256/256 bits))
	(No client certificate requested)
	by mx1.redhat.com (Postfix) with ESMTPS id D8C5A3001E73;
	Fri, 23 Nov 2018 18:29:30 +0000 (UTC)
Received: from work-vm (unknown [10.36.118.34])
	by smtp.corp.redhat.com (Postfix) with ESMTPS id 5FD7B614DB;
	Fri, 23 Nov 2018 18:29:22 +0000 (UTC)
Date: Fri, 23 Nov 2018 18:29:19 +0000
From: "Dr. David Alan Gilbert" <dgilbert@redhat.com>
To: Paolo Bonzini <pbonzini@redhat.com>
Message-ID: <20181123182918.GI2373@work-vm>
References: <20181122072028.22819-1-xiaoguangrong@tencent.com>
	<20181122072028.22819-4-xiaoguangrong@tencent.com>
	<20181123181717.GH2373@work-vm>
	<ec42ec4b-652d-807e-2d88-94a2d52e9cec@redhat.com>
MIME-Version: 1.0
Content-Type: text/plain; charset=us-ascii
Content-Disposition: inline
In-Reply-To: <ec42ec4b-652d-807e-2d88-94a2d52e9cec@redhat.com>
User-Agent: Mutt/1.10.1 (2018-07-13)
X-Scanned-By: MIMEDefang 2.79 on 10.5.11.13
X-Greylist: Sender IP whitelisted, not delayed by milter-greylist-4.5.16
	(mx1.redhat.com [10.5.110.47]);
	Fri, 23 Nov 2018 18:29:31 +0000 (UTC)
X-detected-operating-system: by eggs.gnu.org: GNU/Linux 2.2.x-3.x [generic]
	[fuzzy]
X-Received-From: 209.132.183.28
Subject: Re: [Qemu-devel] [PATCH v3 3/5] migration: use threaded workqueue
 for compression
X-BeenThere: qemu-devel@nongnu.org
X-Mailman-Version: 2.1.21
Precedence: list
List-Id: <qemu-devel.nongnu.org>
List-Unsubscribe: <https://lists.nongnu.org/mailman/options/qemu-devel>,
	<mailto:qemu-devel-request@nongnu.org?subject=unsubscribe>
List-Archive: <http://lists.nongnu.org/archive/html/qemu-devel/>
List-Post: <mailto:qemu-devel@nongnu.org>
List-Help: <mailto:qemu-devel-request@nongnu.org?subject=help>
List-Subscribe: <https://lists.nongnu.org/mailman/listinfo/qemu-devel>,
	<mailto:qemu-devel-request@nongnu.org?subject=subscribe>
Cc: kvm@vger.kernel.org, mst@redhat.com, mtosatti@redhat.com,
	Xiao Guangrong <xiaoguangrong@tencent.com>,
	qemu-devel@nongnu.org, peterx@redhat.com, quintela@redhat.com,
	wei.w.wang@intel.com, cota@braap.org, guangrong.xiao@gmail.com,
	jiang.biao2@zte.com.cn
Errors-To: qemu-devel-bounces+like.xu=linux.intel.com@nongnu.org
Sender: "Qemu-devel" <qemu-devel-bounces+like.xu=linux.intel.com@nongnu.org>

* Paolo Bonzini (pbonzini@redhat.com) wrote:
> On 23/11/18 19:17, Dr. David Alan Gilbert wrote:
> > * guangrong.xiao@gmail.com (guangrong.xiao@gmail.com) wrote:
> >> From: Xiao Guangrong <xiaoguangrong@tencent.com>
> >>
> >> Adapt the compression code to the threaded workqueue
> >>
> >> Signed-off-by: Xiao Guangrong <xiaoguangrong@tencent.com>
> >> ---
> >>  migration/ram.c | 308 ++++++++++++++++++++------------------------------------
> >>  1 file changed, 110 insertions(+), 198 deletions(-)
> >>
> >> diff --git a/migration/ram.c b/migration/ram.c
> >> index 7e7deec4d8..254c08f27b 100644
> >> --- a/migration/ram.c
> >> +++ b/migration/ram.c
> >> @@ -57,6 +57,7 @@
> >>  #include "qemu/uuid.h"
> >>  #include "savevm.h"
> >>  #include "qemu/iov.h"
> >> +#include "qemu/threaded-workqueue.h"
> >>  
> >>  /***********************************************************/
> >>  /* ram save/restore */
> >> @@ -349,22 +350,6 @@ typedef struct PageSearchStatus PageSearchStatus;
> >>  
> >>  CompressionStats compression_counters;
> >>  
> >> -struct CompressParam {
> >> -    bool done;
> >> -    bool quit;
> >> -    bool zero_page;
> >> -    QEMUFile *file;
> >> -    QemuMutex mutex;
> >> -    QemuCond cond;
> >> -    RAMBlock *block;
> >> -    ram_addr_t offset;
> >> -
> >> -    /* internally used fields */
> >> -    z_stream stream;
> >> -    uint8_t *originbuf;
> >> -};
> >> -typedef struct CompressParam CompressParam;
> >> -
> >>  struct DecompressParam {
> >>      bool done;
> >>      bool quit;
> >> @@ -377,15 +362,6 @@ struct DecompressParam {
> >>  };
> >>  typedef struct DecompressParam DecompressParam;
> >>  
> >> -static CompressParam *comp_param;
> >> -static QemuThread *compress_threads;
> >> -/* comp_done_cond is used to wake up the migration thread when
> >> - * one of the compression threads has finished the compression.
> >> - * comp_done_lock is used to co-work with comp_done_cond.
> >> - */
> >> -static QemuMutex comp_done_lock;
> >> -static QemuCond comp_done_cond;
> >> -/* The empty QEMUFileOps will be used by file in CompressParam */
> >>  static const QEMUFileOps empty_ops = { };
> >>  
> >>  static QEMUFile *decomp_file;
> >> @@ -394,125 +370,6 @@ static QemuThread *decompress_threads;
> >>  static QemuMutex decomp_done_lock;
> >>  static QemuCond decomp_done_cond;
> >>  
> >> -static bool do_compress_ram_page(QEMUFile *f, z_stream *stream, RAMBlock *block,
> >> -                                 ram_addr_t offset, uint8_t *source_buf);
> >> -
> >> -static void *do_data_compress(void *opaque)
> >> -{
> >> -    CompressParam *param = opaque;
> >> -    RAMBlock *block;
> >> -    ram_addr_t offset;
> >> -    bool zero_page;
> >> -
> >> -    qemu_mutex_lock(&param->mutex);
> >> -    while (!param->quit) {
> >> -        if (param->block) {
> >> -            block = param->block;
> >> -            offset = param->offset;
> >> -            param->block = NULL;
> >> -            qemu_mutex_unlock(&param->mutex);
> >> -
> >> -            zero_page = do_compress_ram_page(param->file, &param->stream,
> >> -                                             block, offset, param->originbuf);
> >> -
> >> -            qemu_mutex_lock(&comp_done_lock);
> >> -            param->done = true;
> >> -            param->zero_page = zero_page;
> >> -            qemu_cond_signal(&comp_done_cond);
> >> -            qemu_mutex_unlock(&comp_done_lock);
> >> -
> >> -            qemu_mutex_lock(&param->mutex);
> >> -        } else {
> >> -            qemu_cond_wait(&param->cond, &param->mutex);
> >> -        }
> >> -    }
> >> -    qemu_mutex_unlock(&param->mutex);
> >> -
> >> -    return NULL;
> >> -}
> >> -
> >> -static void compress_threads_save_cleanup(void)
> >> -{
> >> -    int i, thread_count;
> >> -
> >> -    if (!migrate_use_compression() || !comp_param) {
> >> -        return;
> >> -    }
> >> -
> >> -    thread_count = migrate_compress_threads();
> >> -    for (i = 0; i < thread_count; i++) {
> >> -        /*
> >> -         * we use it as a indicator which shows if the thread is
> >> -         * properly init'd or not
> >> -         */
> >> -        if (!comp_param[i].file) {
> >> -            break;
> >> -        }
> >> -
> >> -        qemu_mutex_lock(&comp_param[i].mutex);
> >> -        comp_param[i].quit = true;
> >> -        qemu_cond_signal(&comp_param[i].cond);
> >> -        qemu_mutex_unlock(&comp_param[i].mutex);
> >> -
> >> -        qemu_thread_join(compress_threads + i);
> >> -        qemu_mutex_destroy(&comp_param[i].mutex);
> >> -        qemu_cond_destroy(&comp_param[i].cond);
> >> -        deflateEnd(&comp_param[i].stream);
> >> -        g_free(comp_param[i].originbuf);
> >> -        qemu_fclose(comp_param[i].file);
> >> -        comp_param[i].file = NULL;
> >> -    }
> >> -    qemu_mutex_destroy(&comp_done_lock);
> >> -    qemu_cond_destroy(&comp_done_cond);
> >> -    g_free(compress_threads);
> >> -    g_free(comp_param);
> >> -    compress_threads = NULL;
> >> -    comp_param = NULL;
> >> -}
> >> -
> >> -static int compress_threads_save_setup(void)
> >> -{
> >> -    int i, thread_count;
> >> -
> >> -    if (!migrate_use_compression()) {
> >> -        return 0;
> >> -    }
> >> -    thread_count = migrate_compress_threads();
> >> -    compress_threads = g_new0(QemuThread, thread_count);
> >> -    comp_param = g_new0(CompressParam, thread_count);
> >> -    qemu_cond_init(&comp_done_cond);
> >> -    qemu_mutex_init(&comp_done_lock);
> >> -    for (i = 0; i < thread_count; i++) {
> >> -        comp_param[i].originbuf = g_try_malloc(TARGET_PAGE_SIZE);
> >> -        if (!comp_param[i].originbuf) {
> >> -            goto exit;
> >> -        }
> >> -
> >> -        if (deflateInit(&comp_param[i].stream,
> >> -                        migrate_compress_level()) != Z_OK) {
> >> -            g_free(comp_param[i].originbuf);
> >> -            goto exit;
> >> -        }
> >> -
> >> -        /* comp_param[i].file is just used as a dummy buffer to save data,
> >> -         * set its ops to empty.
> >> -         */
> >> -        comp_param[i].file = qemu_fopen_ops(NULL, &empty_ops);
> >> -        comp_param[i].done = true;
> >> -        comp_param[i].quit = false;
> >> -        qemu_mutex_init(&comp_param[i].mutex);
> >> -        qemu_cond_init(&comp_param[i].cond);
> >> -        qemu_thread_create(compress_threads + i, "compress",
> >> -                           do_data_compress, comp_param + i,
> >> -                           QEMU_THREAD_JOINABLE);
> >> -    }
> >> -    return 0;
> >> -
> >> -exit:
> >> -    compress_threads_save_cleanup();
> >> -    return -1;
> >> -}
> >> -
> >>  /* Multiple fd's */
> >>  
> >>  #define MULTIFD_MAGIC 0x11223344U
> >> @@ -1909,12 +1766,25 @@ exit:
> >>      return zero_page;
> >>  }
> >>  
> >> +struct CompressData {
> >> +    /* filled by migration thread.*/
> >> +    RAMBlock *block;
> >> +    ram_addr_t offset;
> >> +
> >> +    /* filled by compress thread. */
> >> +    QEMUFile *file;
> >> +    z_stream stream;
> >> +    uint8_t *originbuf;
> >> +    bool zero_page;
> >> +};
> >> +typedef struct CompressData CompressData;
> >> +
> >>  static void
> >> -update_compress_thread_counts(const CompressParam *param, int bytes_xmit)
> >> +update_compress_thread_counts(CompressData *cd, int bytes_xmit)
> > 
> > Keep the const?
> >>  {
> >>      ram_counters.transferred += bytes_xmit;
> >>  
> >> -    if (param->zero_page) {
> >> +    if (cd->zero_page) {
> >>          ram_counters.duplicate++;
> >>          return;
> >>      }
> >> @@ -1924,81 +1794,123 @@ update_compress_thread_counts(const CompressParam *param, int bytes_xmit)
> >>      compression_counters.pages++;
> >>  }
> >>  
> >> +static int compress_thread_data_init(void *request)
> >> +{
> >> +    CompressData *cd = request;
> >> +
> >> +    cd->originbuf = g_try_malloc(TARGET_PAGE_SIZE);
> >> +    if (!cd->originbuf) {
> >> +        return -1;
> >> +    }
> >> +
> >> +    if (deflateInit(&cd->stream, migrate_compress_level()) != Z_OK) {
> >> +        g_free(cd->originbuf);
> >> +        return -1;
> >> +    }
> > 
> > Please print errors if you fail in any case so we can easily tell what
> > happened.
> > 
> >> +    cd->file = qemu_fopen_ops(NULL, &empty_ops);
> >> +    return 0;
> >> +}
> >> +
> >> +static void compress_thread_data_fini(void *request)
> >> +{
> >> +    CompressData *cd = request;
> >> +
> >> +    qemu_fclose(cd->file);
> >> +    deflateEnd(&cd->stream);
> >> +    g_free(cd->originbuf);
> >> +}
> >> +
> >> +static void compress_thread_data_handler(void *request)
> >> +{
> >> +    CompressData *cd = request;
> >> +
> >> +    /*
> >> +     * if compression fails, it will be indicated by
> >> +     * migrate_get_current()->to_dst_file.
> >> +     */
> >> +    cd->zero_page = do_compress_ram_page(cd->file, &cd->stream, cd->block,
> >> +                                         cd->offset, cd->originbuf);
> >> +}
> >> +
> >> +static void compress_thread_data_done(void *request)
> >> +{
> >> +    CompressData *cd = request;
> >> +    RAMState *rs = ram_state;
> >> +    int bytes_xmit;
> >> +
> >> +    bytes_xmit = qemu_put_qemu_file(rs->f, cd->file);
> >> +    update_compress_thread_counts(cd, bytes_xmit);
> >> +}
> >> +
> >> +static const ThreadedWorkqueueOps compress_ops = {
> >> +    .thread_request_init = compress_thread_data_init,
> >> +    .thread_request_uninit = compress_thread_data_fini,
> >> +    .thread_request_handler = compress_thread_data_handler,
> >> +    .thread_request_done = compress_thread_data_done,
> >> +    .request_size = sizeof(CompressData),
> >> +};
> >> +
> >> +static Threads *compress_threads;
> >> +
> >>  static bool save_page_use_compression(RAMState *rs);
> >>  
> >>  static void flush_compressed_data(RAMState *rs)
> >>  {
> >> -    int idx, len, thread_count;
> >> -
> >>      if (!save_page_use_compression(rs)) {
> >>          return;
> >>      }
> >> -    thread_count = migrate_compress_threads();
> >>  
> >> -    qemu_mutex_lock(&comp_done_lock);
> >> -    for (idx = 0; idx < thread_count; idx++) {
> >> -        while (!comp_param[idx].done) {
> >> -            qemu_cond_wait(&comp_done_cond, &comp_done_lock);
> >> -        }
> >> -    }
> >> -    qemu_mutex_unlock(&comp_done_lock);
> >> +    threaded_workqueue_wait_for_requests(compress_threads);
> >> +}
> >>  
> >> -    for (idx = 0; idx < thread_count; idx++) {
> >> -        qemu_mutex_lock(&comp_param[idx].mutex);
> >> -        if (!comp_param[idx].quit) {
> >> -            len = qemu_put_qemu_file(rs->f, comp_param[idx].file);
> >> -            /*
> >> -             * it's safe to fetch zero_page without holding comp_done_lock
> >> -             * as there is no further request submitted to the thread,
> >> -             * i.e, the thread should be waiting for a request at this point.
> >> -             */
> >> -            update_compress_thread_counts(&comp_param[idx], len);
> >> -        }
> >> -        qemu_mutex_unlock(&comp_param[idx].mutex);
> >> +static void compress_threads_save_cleanup(void)
> >> +{
> >> +    if (!compress_threads) {
> >> +        return;
> >>      }
> >> +
> >> +    threaded_workqueue_destroy(compress_threads);
> >> +    compress_threads = NULL;
> >>  }
> >>  
> >> -static inline void set_compress_params(CompressParam *param, RAMBlock *block,
> >> -                                       ram_addr_t offset)
> >> +static int compress_threads_save_setup(void)
> >>  {
> >> -    param->block = block;
> >> -    param->offset = offset;
> >> +    if (!migrate_use_compression()) {
> >> +        return 0;
> >> +    }
> >> +
> >> +    compress_threads = threaded_workqueue_create("compress",
> >> +                                migrate_compress_threads(),
> >> +                                DEFAULT_THREAD_REQUEST_NR, &compress_ops);
> >> +    return compress_threads ? 0 : -1;
> >>  }
> >>  
> >>  static int compress_page_with_multi_thread(RAMState *rs, RAMBlock *block,
> >>                                             ram_addr_t offset)
> >>  {
> >> -    int idx, thread_count, bytes_xmit = -1, pages = -1;
> >> +    CompressData *cd;
> >>      bool wait = migrate_compress_wait_thread();
> >>  
> >> -    thread_count = migrate_compress_threads();
> >> -    qemu_mutex_lock(&comp_done_lock);
> >>  retry:
> >> -    for (idx = 0; idx < thread_count; idx++) {
> >> -        if (comp_param[idx].done) {
> >> -            comp_param[idx].done = false;
> >> -            bytes_xmit = qemu_put_qemu_file(rs->f, comp_param[idx].file);
> >> -            qemu_mutex_lock(&comp_param[idx].mutex);
> >> -            set_compress_params(&comp_param[idx], block, offset);
> >> -            qemu_cond_signal(&comp_param[idx].cond);
> >> -            qemu_mutex_unlock(&comp_param[idx].mutex);
> >> -            pages = 1;
> >> -            update_compress_thread_counts(&comp_param[idx], bytes_xmit);
> >> -            break;
> >> +    cd = threaded_workqueue_get_request(compress_threads);
> >> +    if (!cd) {
> >> +        /*
> >> +         * wait for the free thread if the user specifies
> >> +         * 'compress-wait-thread', otherwise we will post
> >> +         *  the page out in the main thread as normal page.
> >> +         */
> >> +        if (wait) {
> >> +            cpu_relax();
> >> +            goto retry;
> > 
> > Is there nothing better we can use to wait without eating CPU time?
> 
> There is a mechanism to wait without eating CPU time in the data
> structure, but it makes sense to busy wait.  There are 4 threads in the
> workqueue, so you have to compare 1/4th of the time spent compressing a
> page, with the trip into the kernel to wake you up.  You're adding 20%
> CPU usage, but I'm not surprised it's worthwhile.

Hmm OK; in that case it does at least need a comment because it's a bit
odd, and we should watch out how that scales - I guess it's less of
an overhead the more threads you use.

Dave

> Paolo
> 
--
Dr. David Alan Gilbert / dgilbert@redhat.com / Manchester, UK

