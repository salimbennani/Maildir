Return-Path: <qemu-devel-bounces+like.xu=linux.intel.com@nongnu.org>
Delivered-To: unknown
Received: from linux.intel.com (10.54.29.200:995) by likexu-workstation with
  POP3-SSL; 27 Nov 2018 22:03:21 -0000
X-Original-To: like.xu@linux.intel.com
Delivered-To: like.xu@linux.intel.com
Received: from orsmga003.jf.intel.com (orsmga003.jf.intel.com [10.7.209.27])
	(using TLSv1.2 with cipher ECDHE-RSA-AES256-GCM-SHA384 (256/256 bits))
	(No client certificate requested)
	by linux.intel.com (Postfix) with ESMTPS id A472A58041B
	for <like.xu@linux.intel.com>; Tue, 27 Nov 2018 05:41:13 -0800 (PST)
Received: from fmsmga101.fm.intel.com ([10.1.193.65])
  by orsmga003-1.jf.intel.com with ESMTP/TLS/DHE-RSA-AES256-GCM-SHA384; 27 Nov 2018 05:41:13 -0800
IronPort-PHdr: =?us-ascii?q?9a23=3AKGwfxRAWYF++AFT6rsHgUyQJP3N1i/DPJgcQr6Af?=
 =?us-ascii?q?oPdwSP37osSwAkXT6L1XgUPTWs2DsrQY07qQ6/iocFdDyK7JiGoFfp1IWk1Nou?=
 =?us-ascii?q?QttCtkPvS4D1bmJuXhdS0wEZcKflZk+3amLRodQ56mNBXdrXKo8DEdBAj0OxZr?=
 =?us-ascii?q?KeTpAI7SiNm82/yv95HJbAhEmDmwbaluIBmqsA7cqtQYjYx+J6gr1xDHuGFIe+?=
 =?us-ascii?q?NYxWNpIVKcgRPx7dqu8ZBg7ipdpesv+9ZPXqvmcas4S6dYDCk9PGAu+MLrrxjD?=
 =?us-ascii?q?QhCR6XYaT24bjwBHAwnB7BH9Q5fxri73vfdz1SWGIcH7S60/VC+85Kl3VhDnlC?=
 =?us-ascii?q?YHNyY48G7JjMxwkLlbqw+lqxBm3oLYfJ2ZOP94c6jAf90VWHBBU95NWCNOAo2z?=
 =?us-ascii?q?bYUBAeUCM+ZWsYfzoEYArQO8CAeuC+7j1zFFimPo0q0hyOkhDRjG3Ak8E9IOrH?=
 =?us-ascii?q?jZrtP4P7oSX+Cvy6nIyC3OYu1W2Tfn6YjIaQwhofaUXbJwb8Xa1FQgGB3YhVue?=
 =?us-ascii?q?qIzlOS2a2fgNs2ia6eprSOWihHMmqwF3vDeg2scsiojPho8O0FDL6zh2wIYvKt?=
 =?us-ascii?q?2kUkJ0fdmkEJ5JuiycKoB4TMQiQ2RytyY7zL0LoYW7fDQQx5s7xB7fbOKHfJaS?=
 =?us-ascii?q?4hLtUOaRJjl5iGh5d7K4gha/91WrxO7kVsSszlpGsilInsPRunwQ1BHf8NaLR/?=
 =?us-ascii?q?V980u7xDqC1Rjf5+JHLEwuiKbWKIAtzqQtmpcSrEjPBCH7lUrwgaSLbEsr4PKo?=
 =?us-ascii?q?5P7iYrj+pp+TKYt0igbmP6Qqm8y/Gvg4MhMUU2iU/+S8yafv/UrjQLVFlvE2k6?=
 =?us-ascii?q?/Zv47GJckDuKK1HwxY3pw+5xqiDDqqysoUkHcHIV5fZR6KjZDlO1TUL/D5Cfe/?=
 =?us-ascii?q?jU6skDBux/3eJ73uHJDNLmXanLj8Y7l99VBTyA4qwd9E4JJUF7cBL+7tVU/qs9?=
 =?us-ascii?q?DYCh45Mw+qzOr9B9R9y5sTWWaOAq+fLaPTvkWE5uMpI+mQeoAVvCzxJOQi5/7r?=
 =?us-ascii?q?lnI5n1gdfa+m3ZsRdXC0BPNmI1+WYXb0mNcODX8KvhYiTOztkFCCVT9TZ3WsUK?=
 =?us-ascii?q?4m6TA7FZmrDYPCRoCrnbyA0z23HpxQZmBaFF+MFW3keJmDW/cJO2qvJNR8mGkE?=
 =?us-ascii?q?SaS5UN1mkhWvrxPhjbxgKOXS52sfr52k0dF04+jak1Y17SB1CMKGlHiASnwxkm?=
 =?us-ascii?q?4WSjtl4aZkvEYoz16C1bR/0eVVEMEW6/5XXwN/L5PF0uFhF/j0XQTOeMrPT0yp?=
 =?us-ascii?q?Fc67CzM8Rc5k3tkVfkxmEM+jhB2Q4y3/M74ckPSkGZUy/bjb2Xe5c8lgwnDJzq?=
 =?us-ascii?q?4ngB82Q8JIHWKjj697sQPUAtiavV+ekvOBdb4dxzLK7GeOhWaD9G1ZVgN7UaTD?=
 =?us-ascii?q?FSQTZ03bptT44GvYQrOuAKhhOQxEn53RYpBWY8Hk2A0VDMzoP87TNifowz+9?=
X-IronPort-Anti-Spam-Filtered: true
X-IronPort-Anti-Spam-Result: =?us-ascii?q?A0ADAQAaSP1bhxHrdtBbCRwBAQEEAQEHB?=
 =?us-ascii?q?AEBgWWBMSqBDwOBJoN5iHeNECWJD45FgWMOAQEYDQeDekaEOCI4EgEDAQEBAQE?=
 =?us-ascii?q?BAgETAQEBCgsJCBsOIwyCNgUCAxoBBoJbAQEBAQIBAQIXCQQfCikDAgEBAgYBA?=
 =?us-ascii?q?QoVAwICIgQCAgMBHRMBBQEcBhMFglFLAYFpAw0IAQMBCpk3PIsNfDOELQEWD22?=
 =?us-ascii?q?CQw2CFwUSeYg6gkgXgX+BEScME4JMgleBbxEqgwQxgiYCiQMaBgGFfBCBNY5SJ?=
 =?us-ascii?q?y4JhnyDLYNbgywYgVmFC4JuECaHA41GgQqGZYJbAgQCBAUCBQ8hgTyBdk0jFWU?=
 =?us-ascii?q?BgkE+gWkXg0qKVHGBB4tzgXcBAQ?=
X-IPAS-Result: =?us-ascii?q?A0ADAQAaSP1bhxHrdtBbCRwBAQEEAQEHBAEBgWWBMSqBDwO?=
 =?us-ascii?q?BJoN5iHeNECWJD45FgWMOAQEYDQeDekaEOCI4EgEDAQEBAQEBAgETAQEBCgsJC?=
 =?us-ascii?q?BsOIwyCNgUCAxoBBoJbAQEBAQIBAQIXCQQfCikDAgEBAgYBAQoVAwICIgQCAgM?=
 =?us-ascii?q?BHRMBBQEcBhMFglFLAYFpAw0IAQMBCpk3PIsNfDOELQEWD22CQw2CFwUSeYg6g?=
 =?us-ascii?q?kgXgX+BEScME4JMgleBbxEqgwQxgiYCiQMaBgGFfBCBNY5SJy4JhnyDLYNbgyw?=
 =?us-ascii?q?YgVmFC4JuECaHA41GgQqGZYJbAgQCBAUCBQ8hgTyBdk0jFWUBgkE+gWkXg0qKV?=
 =?us-ascii?q?HGBB4tzgXcBAQ?=
X-IronPort-AV: E=Sophos;i="5.56,286,1539673200"; 
   d="scan'208";a="64162135"
X-Amp-Result: SKIPPED(no attachment in message)
X-Amp-File-Uploaded: False
Received: from lists.gnu.org ([208.118.235.17])
  by mga01b.intel.com with ESMTP/TLS/AES256-SHA; 27 Nov 2018 05:41:11 -0800
Received: from localhost ([::1]:42435 helo=lists.gnu.org)
	by lists.gnu.org with esmtp (Exim 4.71)
	(envelope-from <qemu-devel-bounces+like.xu=linux.intel.com@nongnu.org>)
	id 1gRdbz-00020c-BM
	for like.xu@linux.intel.com; Tue, 27 Nov 2018 08:41:11 -0500
Received: from eggs.gnu.org ([2001:4830:134:3::10]:54783)
	by lists.gnu.org with esmtp (Exim 4.71)
	(envelope-from <dinechin@redhat.com>) id 1gRcnt-0000I8-P1
	for qemu-devel@nongnu.org; Tue, 27 Nov 2018 07:49:28 -0500
Received: from Debian-exim by eggs.gnu.org with spam-scanned (Exim 4.71)
	(envelope-from <dinechin@redhat.com>) id 1gRcnq-0007rO-DX
	for qemu-devel@nongnu.org; Tue, 27 Nov 2018 07:49:25 -0500
Received: from mail-wm1-f65.google.com ([209.85.128.65]:37027)
	by eggs.gnu.org with esmtps (TLS1.0:RSA_AES_128_CBC_SHA1:16)
	(Exim 4.71) (envelope-from <dinechin@redhat.com>) id 1gRcnq-0007qG-3J
	for qemu-devel@nongnu.org; Tue, 27 Nov 2018 07:49:22 -0500
Received: by mail-wm1-f65.google.com with SMTP id g67so8596720wmd.2
	for <qemu-devel@nongnu.org>; Tue, 27 Nov 2018 04:49:21 -0800 (PST)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
	d=1e100.net; s=20161025;
	h=x-gm-message-state:mime-version:subject:from:in-reply-to:date:cc
	:content-transfer-encoding:message-id:references:to;
	bh=zW6+BmUOmjfc791R5B2xumknZWQiOwC/3+nhgsS2To0=;
	b=tkvY34XBEy7QjiuPeo2HHpRqj1QHTHPbf8h/j53VS+qIeMgB5H1i+fbZnUjwt6VYVv
	T94CUZYE96LXC7QduoUDe4xymegcuuzXI+crgCP97h5tgYJRveVc+hFSyabOM3Wlzglj
	U/FidtA9b7fRTJkIknqYlCIq7Zw8umwwu8IuuQUan7ehSdPi0tkXdw9RsOJeZ/NzT9T4
	qihZzskbi9mbHLXmLf6kCDmqXpirjsqIyTK5mNUDpH50o74/RxhthAT2v1aGupOQ8FAF
	DPfWHy4ZtL+ppePi3za6g+Q11YqUclcmtKiJxm4wlnHDG6ZsP7SZJvJhwAKqD4JogjcP
	FjcQ==
X-Gm-Message-State: AGRZ1gK14jGfXXxSQ2mEhQhaojt6wRQjOfdrwwFqKGBSDVjf7r2+CnRm
	0Az1IbHlqQpnNSpDH34jX/bqQQ==
X-Google-Smtp-Source: AJdET5eg08SILkA13pxiGWKGvwfsM3f8gNAc2iagjMFVOMDrdgIdrwHQmTVr482Q11uFt+TUzNzL0g==
X-Received: by 2002:a1c:8fc2:: with SMTP id r185mr27187238wmd.54.1543322959764;
	Tue, 27 Nov 2018 04:49:19 -0800 (PST)
Received: from [192.168.77.22] (val06-1-88-182-161-34.fbx.proxad.net.
	[88.182.161.34]) by smtp.gmail.com with ESMTPSA id
	v19sm4361605wrd.46.2018.11.27.04.49.15
	(version=TLS1_2 cipher=ECDHE-RSA-AES128-GCM-SHA256 bits=128/128);
	Tue, 27 Nov 2018 04:49:18 -0800 (PST)
Content-Type: text/plain;
	charset=utf-8
Mime-Version: 1.0 (Mac OS X Mail 11.5 \(3445.9.1\))
From: Christophe de Dinechin <dinechin@redhat.com>
In-Reply-To: <20181122072028.22819-3-xiaoguangrong@tencent.com>
Date: Tue, 27 Nov 2018 13:49:13 +0100
Content-Transfer-Encoding: quoted-printable
Message-Id: <BB9071C9-5BED-4763-99B3-7083B8EB49CF@redhat.com>
References: <20181122072028.22819-1-xiaoguangrong@tencent.com>
	<20181122072028.22819-3-xiaoguangrong@tencent.com>
To: Xiao Guangrong <guangrong.xiao@gmail.com>
X-Mailer: Apple Mail (2.3445.9.1)
X-detected-operating-system: by eggs.gnu.org: GNU/Linux 2.2.x-3.x [generic]
	[fuzzy]
X-Received-From: 209.85.128.65
X-Mailman-Approved-At: Tue, 27 Nov 2018 08:40:39 -0500
Subject: Re: [Qemu-devel] [PATCH v3 2/5] util: introduce threaded workqueue
X-BeenThere: qemu-devel@nongnu.org
X-Mailman-Version: 2.1.21
Precedence: list
List-Id: <qemu-devel.nongnu.org>
List-Unsubscribe: <https://lists.nongnu.org/mailman/options/qemu-devel>,
	<mailto:qemu-devel-request@nongnu.org?subject=unsubscribe>
List-Archive: <http://lists.nongnu.org/archive/html/qemu-devel/>
List-Post: <mailto:qemu-devel@nongnu.org>
List-Help: <mailto:qemu-devel-request@nongnu.org?subject=help>
List-Subscribe: <https://lists.nongnu.org/mailman/listinfo/qemu-devel>,
	<mailto:qemu-devel-request@nongnu.org?subject=subscribe>
Cc: kvm@vger.kernel.org, mst@redhat.com, mtosatti@redhat.com,
	Xiao Guangrong <xiaoguangrong@tencent.com>, dgilbert@redhat.com,
	peterx@redhat.com, qemu-devel@nongnu.org, quintela@redhat.com,
	wei.w.wang@intel.com, cota@braap.org, jiang.biao2@zte.com.cn,
	Paolo Bonzini <pbonzini@redhat.com>
Errors-To: qemu-devel-bounces+like.xu=linux.intel.com@nongnu.org
Sender: "Qemu-devel" <qemu-devel-bounces+like.xu=linux.intel.com@nongnu.org>

(I did not finish the review, but decided to send what I already had).


> On 22 Nov 2018, at 08:20, guangrong.xiao@gmail.com wrote:
>=20
> From: Xiao Guangrong <xiaoguangrong@tencent.com>
>=20
> This modules implements the lockless and efficient threaded workqueue.

I=E2=80=99m not entirely convinced that it=E2=80=99s either =
=E2=80=9Clockless=E2=80=9D or =E2=80=9Cefficient=E2=80=9D
in the current iteration. I believe that it=E2=80=99s relatively easy to =
fix, though.

>=20
> Three abstracted objects are used in this module:
> - Request.
>     It not only contains the data that the workqueue fetches out
>    to finish the request but also offers the space to save the result
>    after the workqueue handles the request.
>=20
>    It's flowed between user and workqueue. The user fills the request
>    data into it when it is owned by user. After it is submitted to the
>    workqueue, the workqueue fetched data out and save the result into
>    it after the request is handled.

fetched -> fetches
save -> saves

>=20
>    All the requests are pre-allocated and carefully partitioned =
between
>    threads so there is no contention on the request, that make threads
>    be parallel as much as possible.

That sentence confused me (it=E2=80=99s also in a comment in the text).
I think I=E2=80=99m mostly confused by =E2=80=9Cthere is no =
contention=E2=80=9D. Perhaps you
meant =E2=80=9Cso as to avoid contention if possible=E2=80=9D? If there =
is a reason
why there would never be any contention even if requests arrive faster =
than
completions, I did not figure it out.

I personally see serious contention on the fields in the Threads =
structure,
for example, but also possibly on the targets of the =E2=80=9Cmodulo=E2=80=
=9D operation in
thread_find_free_request. Specifically, if three CPUs are entering
thread_find_free_request at the same time, they will all run the same
loop and all, presumably, =E2=80=9Cattack=E2=80=9D the same memory =
locations.

Sorry if I mis-read the code, but at the moment, it does not seem to
avoid contention as intended. I don=E2=80=99t see how it could without =
having
some way to discriminate between CPUs to start with, which I did not =
find.


>=20
> - User, i.e, the submitter
>    It's the one fills the request and submits it to the workqueue,
the one -> the one who
>    the result will be collected after it is handled by the work queue.
>=20
>    The user can consecutively submit requests without waiting the =
previous
waiting -> waiting for
>    requests been handled.
>    It only supports one submitter, you should do serial submission by
>    yourself if you want more, e.g, use lock on you side.

I=E2=80=99m also confused by this last statement. The proposal purports
to be =E2=80=9Clockless=E2=80=9D, which I read as working correctly =
without a lock=E2=80=A6
Reading the code, I indeed see issues if different threads
try to place requests at the same time. So I believe the word
=E2=80=9Clockless=E2=80=9D is a bit misleading.

>=20
> - Workqueue, i.e, thread
>    Each workqueue is represented by a running thread that fetches
>    the request submitted by the user, do the specified work and save
>    the result to the request.
>=20
> Signed-off-by: Xiao Guangrong <xiaoguangrong@tencent.com>
> ---
> include/qemu/threaded-workqueue.h | 106 +++++++++
> util/Makefile.objs                |   1 +
> util/threaded-workqueue.c         | 463 =
++++++++++++++++++++++++++++++++++++++
> 3 files changed, 570 insertions(+)
> create mode 100644 include/qemu/threaded-workqueue.h
> create mode 100644 util/threaded-workqueue.c
>=20
> diff --git a/include/qemu/threaded-workqueue.h =
b/include/qemu/threaded-workqueue.h
> new file mode 100644
> index 0000000000..e0ede496d0
> --- /dev/null
> +++ b/include/qemu/threaded-workqueue.h
> @@ -0,0 +1,106 @@
> +/*
> + * Lockless and Efficient Threaded Workqueue Abstraction
> + *
> + * Author:
> + *   Xiao Guangrong <xiaoguangrong@tencent.com>
> + *
> + * Copyright(C) 2018 Tencent Corporation.
> + *
> + * This work is licensed under the terms of the GNU LGPL, version 2.1 =
or later.
> + * See the COPYING.LIB file in the top-level directory.
> + */
> +
> +#ifndef QEMU_THREADED_WORKQUEUE_H
> +#define QEMU_THREADED_WORKQUEUE_H
> +
> +#include "qemu/queue.h"
> +#include "qemu/thread.h"
> +
> +/*
> + * This modules implements the lockless and efficient threaded =
workqueue.
> + *
> + * Three abstracted objects are used in this module:
> + * - Request.
> + *   It not only contains the data that the workqueue fetches out
> + *   to finish the request but also offers the space to save the =
result
> + *   after the workqueue handles the request.
> + *
> + *   It's flowed between user and workqueue. The user fills the =
request
> + *   data into it when it is owned by user. After it is submitted to =
the
> + *   workqueue, the workqueue fetched data out and save the result =
into
> + *   it after the request is handled.
> + *
> + *   All the requests are pre-allocated and carefully partitioned =
between
> + *   threads so there is no contention on the request, that make =
threads
> + *   be parallel as much as possible.
> + *
> + * - User, i.e, the submitter
> + *   It's the one fills the request and submits it to the workqueue,
> + *   the result will be collected after it is handled by the work =
queue.
> + *
> + *   The user can consecutively submit requests without waiting the =
previous
> + *   requests been handled.
> + *   It only supports one submitter, you should do serial submission =
by
> + *   yourself if you want more, e.g, use lock on you side.
> + *
> + * - Workqueue, i.e, thread
> + *   Each workqueue is represented by a running thread that fetches
> + *   the request submitted by the user, do the specified work and =
save
> + *   the result to the request.
> + */
> +
> +typedef struct Threads Threads;
> +
> +struct ThreadedWorkqueueOps {
> +    /* constructor of the request */
> +    int (*thread_request_init)(void *request);
> +    /*  destructor of the request */
> +    void (*thread_request_uninit)(void *request);
> +
> +    /* the handler of the request that is called by the thread */
> +    void (*thread_request_handler)(void *request);
> +    /* called by the user after the request has been handled */
> +    void (*thread_request_done)(void *request);
> +
> +    size_t request_size;
> +};
> +typedef struct ThreadedWorkqueueOps ThreadedWorkqueueOps;
> +
> +/* the default number of requests that thread need handle */
> +#define DEFAULT_THREAD_REQUEST_NR 4
> +/* the max number of requests that thread need handle */
> +#define MAX_THREAD_REQUEST_NR     (sizeof(uint64_t) * BITS_PER_BYTE)
> +
> +/*
> + * create a threaded queue. Other APIs will work on the Threads it =
returned
> + *
> + * @name: the identity of the workqueue which is used to construct =
the name
> + *    of threads only
> + * @threads_nr: the number of threads that the workqueue will create
> + * @thread_requests_nr: the number of requests that each single =
thread will
> + *    handle
> + * @ops: the handlers of the request
> + *
> + * Return NULL if it failed
> + */
> +Threads *threaded_workqueue_create(const char *name, unsigned int =
threads_nr,
> +                                   unsigned int thread_requests_nr,
> +                                   const ThreadedWorkqueueOps *ops);
> +void threaded_workqueue_destroy(Threads *threads);
> +
> +/*
> + * find a free request where the user can store the data that is =
needed to
> + * finish the request
> + *
> + * If all requests are used up, return NULL
> + */
> +void *threaded_workqueue_get_request(Threads *threads);

Using void * to represent the payload makes it easy to get
the wrong pointer in there without the compiler noticing.
Consider adding a type for the payload?


> +/* submit the request and notify the thread */
> +void threaded_workqueue_submit_request(Threads *threads, void =
*request);
> +
> +/*
> + * wait all threads to complete the request to make sure there is no
> + * previous request exists
> + */
> +void threaded_workqueue_wait_for_requests(Threads *threads);
> +#endif
> diff --git a/util/Makefile.objs b/util/Makefile.objs
> index 0820923c18..f26dfe5182 100644
> --- a/util/Makefile.objs
> +++ b/util/Makefile.objs
> @@ -50,5 +50,6 @@ util-obj-y +=3D range.o
> util-obj-y +=3D stats64.o
> util-obj-y +=3D systemd.o
> util-obj-y +=3D iova-tree.o
> +util-obj-y +=3D threaded-workqueue.o
> util-obj-$(CONFIG_LINUX) +=3D vfio-helpers.o
> util-obj-$(CONFIG_OPENGL) +=3D drm.o
> diff --git a/util/threaded-workqueue.c b/util/threaded-workqueue.c
> new file mode 100644
> index 0000000000..2ab37cee8d
> --- /dev/null
> +++ b/util/threaded-workqueue.c
> @@ -0,0 +1,463 @@
> +/*
> + * Lockless and Efficient Threaded Workqueue Abstraction


> + *
> + * Author:
> + *   Xiao Guangrong <xiaoguangrong@tencent.com>
> + *
> + * Copyright(C) 2018 Tencent Corporation.
> + *
> + * This work is licensed under the terms of the GNU LGPL, version 2.1 =
or later.
> + * See the COPYING.LIB file in the top-level directory.
> + */
> +
> +#include "qemu/osdep.h"
> +#include "qemu/bitmap.h"
> +#include "qemu/threaded-workqueue.h"
> +
> +#define SMP_CACHE_BYTES 64

+1 on comments already made by others

> +
> +/*
> + * the request representation which contains the internally used mete =
data,

mete -> meta

> + * it is the header of user-defined data.
> + *
> + * It should be aligned to the nature size of CPU.
> + */
> +struct ThreadRequest {
> +    /*
> +     * the request has been handled by the thread and need the user
> +     * to fetch result out.
> +     */
> +    uint8_t done;
> +
> +    /*
> +     * the index to Thread::requests.
> +     * Save it to the padding space although it can be calculated at =
runtime.
> +     */
> +    uint8_t request_index;

So no more than 256?

This is blocked by MAX_THREAD_REQUEST_NR test at the beginning
of threaded_workqueue_create, but I would make it more explicit either
with a compile-time assert that MAX_THREAD_REQUEST_NR is
below UINT8_MAX, or by adding a second test for UINT8_MAX in
threaded_workqueue_create.

Also, an obvious extension would be to make bitmaps into arrays.

Do you think someone would want to use the package to assign
requests per CPU or per VCPU? If so, that could quickly go above 64.


> +
> +    /* the index to Threads::per_thread_data */
> +    unsigned int thread_index;

Don=E2=80=99t you want to use a size_t for that?

> +} QEMU_ALIGNED(sizeof(unsigned long));

Nit: the alignment type is inconsistent with that given
to QEMU_BUILD_BUG_ON in threaded_workqueue_create.
(long vs. unsigned long).

Also, why is the alignment required? Aren=E2=80=99t you more interested
in cache-line alignment?


> +typedef struct ThreadRequest ThreadRequest;


> +
> +struct ThreadLocal {
> +    struct Threads *threads;
> +
> +    /* the index of the thread */
> +    int self;

Why signed?

> +
> +    /* thread is useless and needs to exit */
> +    bool quit;
> +
> +    QemuThread thread;
> +
> +    void *requests;
> +
> +   /*
> +     * the bit in these two bitmaps indicates the index of the =
=EF=BC=A0requests
> +     * respectively. If it's the same, the corresponding request is =
free
> +     * and owned by the user, i.e, where the user fills a request. =
Otherwise,
> +     * it is valid and owned by the thread, i.e, where the thread =
fetches
> +     * the request and write the result.
> +     */
> +
> +    /* after the user fills the request, the bit is flipped. */
> +    uint64_t request_fill_bitmap QEMU_ALIGNED(SMP_CACHE_BYTES);

I believe you are trying to ensure that data accessed from multiple CPUs
is on different cache lines. As others have pointed out, the real value =
for
SMP_CACHE_BYTES can only be known at run-time. So this is not really
helping. Also, the ThreadLocal structure itself is not necessarily =
aligned
within struct Threads. Therefore, it=E2=80=99s possible that =
=E2=80=9Crequests=E2=80=9D for example
could be on the same cache line as request_fill_bitmap if planets align
the wrong way.

In order to mitigate these effects, I would group the data that the user
writes and the data that the thread writes, i.e. reorder declarations,
put request_fill_bitmap and request_valid_ev together, and try
to put them in the same cache line so that only one cache line is =
invalidated
from within mark_request_valid instead of two.

Then you end up with a single alignment directive instead of 4, to
separate requests from completions.

That being said, I=E2=80=99m not sure why you use a bitmap here. What is =
the
expected benefit relative to atomic lists (which would also make it =
really
lock-free)?

> +    /* after handles the request, the thread flips the bit. */
> +    uint64_t request_done_bitmap QEMU_ALIGNED(SMP_CACHE_BYTES);
> +
> +    /*
> +     * the event used to wake up the thread whenever a valid request =
has
> +     * been submitted
> +     */
> +    QemuEvent request_valid_ev QEMU_ALIGNED(SMP_CACHE_BYTES);
> +
> +    /*
> +     * the event is notified whenever a request has been completed
> +     * (i.e, become free), which is used to wake up the user
> +     */
> +    QemuEvent request_free_ev QEMU_ALIGNED(SMP_CACHE_BYTES);
> +};
> +typedef struct ThreadLocal ThreadLocal;


> +
> +/*
> + * the main data struct represents multithreads which is shared by
> + * all threads
> + */
> +struct Threads {
> +    /* the request header, ThreadRequest, is contained */
> +    unsigned int request_size;

size_t?

> +    unsigned int thread_requests_nr;
> +    unsigned int threads_nr;
> +
> +    /* the request is pushed to the thread with round-robin manner */
> +    unsigned int current_thread_index;
> +
> +    const ThreadedWorkqueueOps *ops;


> +
> +    ThreadLocal per_thread_data[0];
> +};
> +typedef struct Threads Threads;
> +
> +static ThreadRequest *index_to_request(ThreadLocal *thread, int =
request_index)
> +{
> +    ThreadRequest *request;
> +
> +    request =3D thread->requests + request_index * =
thread->threads->request_size;
> +    assert(request->request_index =3D=3D request_index);
> +    assert(request->thread_index =3D=3D thread->self);
> +    return request;
> +}
> +
> +static int request_to_index(ThreadRequest *request)
> +{
> +    return request->request_index;
> +}
> +
> +static int request_to_thread_index(ThreadRequest *request)
> +{
> +    return request->thread_index;
> +}
> +
> +/*
> + * free request: the request is not used by any thread, however, it =
might
> + *   contain the result need the user to call thread_request_done()

might contain the result -> might still contain the result
result need the user to call -> result. The user needs to call

> + *
> + * valid request: the request contains the request data and it's =
committed
> + *   to the thread, i,e. it's owned by thread.
> + */
> +static uint64_t get_free_request_bitmap(Threads *threads, ThreadLocal =
*thread)
> +{
> +    uint64_t request_fill_bitmap, request_done_bitmap, result_bitmap;
> +
> +    request_fill_bitmap =3D =
atomic_rcu_read(&thread->request_fill_bitmap);
> +    request_done_bitmap =3D =
atomic_rcu_read(&thread->request_done_bitmap);
> +    bitmap_xor(&result_bitmap, &request_fill_bitmap, =
&request_done_bitmap,
> +               threads->thread_requests_nr);
> +
> +    /*
> +     * paired with smp_wmb() in mark_request_free() to make sure that =
we
> +     * read request_done_bitmap before fetching the result out.
> +     */
> +    smp_rmb();
> +
> +    return result_bitmap;
> +}

It seems that this part would be much simpler to understand using atomic =
lists.

> +
> +static ThreadRequest
> +*find_thread_free_request(Threads *threads, ThreadLocal *thread)
> +{
> +    uint64_t result_bitmap =3D get_free_request_bitmap(threads, =
thread);
> +    int index;
> +
> +    index  =3D find_first_zero_bit(&result_bitmap, =
threads->thread_requests_nr);
> +    if (index >=3D threads->thread_requests_nr) {
> +        return NULL;
> +    }
> +
> +    return index_to_request(thread, index);
> +}
> +
> +static ThreadRequest *threads_find_free_request(Threads *threads)
> +{
> +    ThreadLocal *thread;
> +    ThreadRequest *request;
> +    int cur_thread, thread_index;
> +
> +    cur_thread =3D threads->current_thread_index % =
threads->threads_nr;
> +    thread_index =3D cur_thread;
> +    do {
> +        thread =3D threads->per_thread_data + thread_index++;
> +        request =3D find_thread_free_request(threads, thread);
> +        if (request) {
> +            break;
> +        }
> +        thread_index %=3D threads->threads_nr;
> +    } while (thread_index !=3D cur_thread);
> +
> +    return request;
> +}
> +
> +/*
> + * the change bit operation combined with READ_ONCE and WRITE_ONCE =
which
> + * only works on single uint64_t width
> + */
> +static void change_bit_once(long nr, uint64_t *addr)
> +{
> +    uint64_t value =3D atomic_rcu_read(addr) ^ BIT_MASK(nr);
> +
> +    atomic_rcu_set(addr, value);
> +}
> +
> +static void mark_request_valid(Threads *threads, ThreadRequest =
*request)
> +{
> +    int thread_index =3D request_to_thread_index(request);
> +    int request_index =3D request_to_index(request);
> +    ThreadLocal *thread =3D threads->per_thread_data + thread_index;
> +
> +    /*
> +     * paired with smp_rmb() in find_first_valid_request_index() to =
make
> +     * sure the request has been filled before the bit is flipped =
that
> +     * will make the request be visible to the thread
> +     */
> +    smp_wmb();
> +
> +    change_bit_once(request_index, &thread->request_fill_bitmap);
> +    qemu_event_set(&thread->request_valid_ev);
> +}
> +
> +static int thread_find_first_valid_request_index(ThreadLocal *thread)
> +{
> +    Threads *threads =3D thread->threads;
> +    uint64_t request_fill_bitmap, request_done_bitmap, result_bitmap;
> +    int index;
> +
> +    request_fill_bitmap =3D =
atomic_rcu_read(&thread->request_fill_bitmap);
> +    request_done_bitmap =3D =
atomic_rcu_read(&thread->request_done_bitmap);
> +    bitmap_xor(&result_bitmap, &request_fill_bitmap, =
&request_done_bitmap,
> +               threads->thread_requests_nr);
> +    /*
> +     * paired with smp_wmb() in mark_request_valid() to make sure =
that
> +     * we read request_fill_bitmap before fetch the request out.
> +     */
> +    smp_rmb();
> +
> +    index =3D find_first_bit(&result_bitmap, =
threads->thread_requests_nr);
> +    return index >=3D threads->thread_requests_nr ? -1 : index;
> +}
> +
> +static void mark_request_free(ThreadLocal *thread, ThreadRequest =
*request)
> +{
> +    int index =3D request_to_index(request);
> +
> +    /*
> +     * smp_wmb() is implied in change_bit_atomic() that is paired =
with
> +     * smp_rmb() in get_free_request_bitmap() to make sure the result
> +     * has been saved before the bit is flipped.
> +     */
> +    change_bit_atomic(index, &thread->request_done_bitmap);
> +    qemu_event_set(&thread->request_free_ev);
> +}
> +
> +/* retry to see if there is available request before actually go to =
wait. */
> +#define BUSY_WAIT_COUNT 1000
> +
> +static ThreadRequest *
> +thread_busy_wait_for_request(ThreadLocal *thread)
> +{
> +    int index, count =3D 0;
> +
> +    for (count =3D 0; count < BUSY_WAIT_COUNT; count++) {
> +        index =3D thread_find_first_valid_request_index(thread);
> +        if (index >=3D 0) {
> +            return index_to_request(thread, index);
> +        }
> +
> +        cpu_relax();
> +    }
> +
> +    return NULL;
> +}
> +
> +static void *thread_run(void *opaque)
> +{
> +    ThreadLocal *self_data =3D (ThreadLocal *)opaque;
> +    Threads *threads =3D self_data->threads;
> +    void (*handler)(void *request) =3D =
threads->ops->thread_request_handler;
> +    ThreadRequest *request;
> +
> +    for ( ; !atomic_read(&self_data->quit); ) {
> +        qemu_event_reset(&self_data->request_valid_ev);
> +
> +        request =3D thread_busy_wait_for_request(self_data);
> +        if (!request) {
> +            qemu_event_wait(&self_data->request_valid_ev);
> +            continue;
> +        }
> +
> +        assert(!request->done);
> +
> +        handler(request + 1);
> +        request->done =3D true;
> +        mark_request_free(self_data, request);
> +    }
> +
> +    return NULL;
> +}
> +
> +static void uninit_thread_requests(ThreadLocal *thread, int free_nr)
> +{
> +    Threads *threads =3D thread->threads;
> +    ThreadRequest *request =3D thread->requests;
> +    int i;
> +
> +    for (i =3D 0; i < free_nr; i++) {
> +        threads->ops->thread_request_uninit(request + 1);
> +        request =3D (void *)request + threads->request_size;

Despite GCC=E2=80=99s tolerance for it and rather lengthy debates,
pointer arithmetic on void * is illegal in C [1].

Consider using char * arithmetic, and using macros such as:

#define request_to_payload(req) (((ThreadRequest *) req) + 1)
#define payload_to_request(req) (((ThreadRequest *) req) - 1)
#define request_to_next(req,threads) ((ThreadRequest *) ((char *) req) + =
threads->request_size))

where appropriate, that would clarify the intent.

[1] =
https://stackoverflow.com/questions/3523145/pointer-arithmetic-for-void-po=
inter-in-c

> +    }
> +    g_free(thread->requests);
> +}
> +
> +static int init_thread_requests(ThreadLocal *thread)
> +{
> +    Threads *threads =3D thread->threads;
> +    ThreadRequest *request;
> +    int ret, i, thread_reqs_size;
> +
> +    thread_reqs_size =3D threads->thread_requests_nr * =
threads->request_size;
> +    thread_reqs_size =3D QEMU_ALIGN_UP(thread_reqs_size, =
SMP_CACHE_BYTES);
> +    thread->requests =3D g_malloc0(thread_reqs_size);
> +
> +    request =3D thread->requests;
> +    for (i =3D 0; i < threads->thread_requests_nr; i++) {
> +        ret =3D threads->ops->thread_request_init(request + 1);
> +        if (ret < 0) {
> +            goto exit;
> +        }
> +
> +        request->request_index =3D i;
> +        request->thread_index =3D thread->self;
> +        request =3D (void *)request + threads->request_size;

Pointer arithmetic on void * is illegal in C, see above.

> +    }
> +    return 0;
> +
> +exit:
> +    uninit_thread_requests(thread, i);
> +    return -1;
> +}
> +
> +static void uninit_thread_data(Threads *threads, int free_nr)
> +{
> +    ThreadLocal *thread_local =3D threads->per_thread_data;

thread_local is a keyword in C++11. I would avoid it as a name,
consider replacing with =E2=80=9Cper_thread_data=E2=80=9D as in struct =
Threads?


> +    int i;
> +
> +    for (i =3D 0; i < free_nr; i++) {
> +        thread_local[i].quit =3D true;
> +        qemu_event_set(&thread_local[i].request_valid_ev);
> +        qemu_thread_join(&thread_local[i].thread);
> +        qemu_event_destroy(&thread_local[i].request_valid_ev);
> +        qemu_event_destroy(&thread_local[i].request_free_ev);
> +        uninit_thread_requests(&thread_local[i], =
threads->thread_requests_nr);
> +    }
> +}
> +
> +static int
> +init_thread_data(Threads *threads, const char *thread_name, int =
thread_nr)
> +{
> +    ThreadLocal *thread_local =3D threads->per_thread_data;
> +    char *name;
> +    int i;
> +
> +    for (i =3D 0; i < thread_nr; i++) {
> +        thread_local[i].threads =3D threads;
> +        thread_local[i].self =3D i;
> +
> +        if (init_thread_requests(&thread_local[i]) < 0) {
> +            goto exit;
> +        }
> +
> +        qemu_event_init(&thread_local[i].request_free_ev, false);
> +        qemu_event_init(&thread_local[i].request_valid_ev, false);
> +
> +        name =3D g_strdup_printf("%s/%d", thread_name, =
thread_local[i].self);
> +        qemu_thread_create(&thread_local[i].thread, name,
> +                           thread_run, &thread_local[i], =
QEMU_THREAD_JOINABLE);
> +        g_free(name);
> +    }
> +    return 0;
> +
> +exit:
> +    uninit_thread_data(threads, i);
> +    return -1;
> +}
> +
> +Threads *threaded_workqueue_create(const char *name, unsigned int =
threads_nr,
> +                                   unsigned int thread_requests_nr,
> +                                   const ThreadedWorkqueueOps *ops)
> +{
> +    Threads *threads;
> +
> +    if (threads_nr > MAX_THREAD_REQUEST_NR) {
> +        return NULL;
> +    }
> +
> +    threads =3D g_malloc0(sizeof(*threads) + threads_nr * =
sizeof(ThreadLocal));
> +    threads->ops =3D ops;
> +    threads->threads_nr =3D threads_nr;
> +    threads->thread_requests_nr =3D thread_requests_nr;
> +
> +    QEMU_BUILD_BUG_ON(!QEMU_IS_ALIGNED(sizeof(ThreadRequest), =
sizeof(long)));
> +    threads->request_size =3D threads->ops->request_size;
> +    threads->request_size =3D QEMU_ALIGN_UP(threads->request_size, =
sizeof(long));
> +    threads->request_size +=3D sizeof(ThreadRequest);
> +
> +    if (init_thread_data(threads, name, threads_nr) < 0) {
> +        g_free(threads);
> +        return NULL;
> +    }
> +
> +    return threads;
> +}
> +
> +void threaded_workqueue_destroy(Threads *threads)
> +{
> +    uninit_thread_data(threads, threads->threads_nr);
> +    g_free(threads);
> +}
> +
> +static void request_done(Threads *threads, ThreadRequest *request)
> +{
> +    if (!request->done) {
> +        return;
> +    }
> +
> +    threads->ops->thread_request_done(request + 1);
> +    request->done =3D false;
> +}
> +
> +void *threaded_workqueue_get_request(Threads *threads)
> +{
> +    ThreadRequest *request;
> +
> +    request =3D threads_find_free_request(threads);
> +    if (!request) {
> +        return NULL;
> +    }
> +
> +    request_done(threads, request);
> +    return request + 1;
> +}
> +
> +void threaded_workqueue_submit_request(Threads *threads, void =
*request)
> +{
> +    ThreadRequest *req =3D request - sizeof(ThreadRequest);

Pointer arithmetic on void *=E2=80=A6

Please consider rewriting as:

	ThreadRequest *req =3D (ThreadRequest *) request - 1;

which achieves the same objective, is legal C, and is the symmetric
counterpart of =E2=80=9Creturn request + 1=E2=80=9D above.


> +    int thread_index =3D request_to_thread_index(request);
> +
> +    assert(!req->done);
> +    mark_request_valid(threads, req);
> +    threads->current_thread_index =3D thread_index  + 1;
> +}
> +
> +void threaded_workqueue_wait_for_requests(Threads *threads)
> +{
> +    ThreadLocal *thread;
> +    uint64_t result_bitmap;
> +    int thread_index, index =3D 0;
> +
> +    for (thread_index =3D 0; thread_index < threads->threads_nr; =
thread_index++) {
> +        thread =3D threads->per_thread_data + thread_index;
> +        index =3D 0;
> +retry:
> +        qemu_event_reset(&thread->request_free_ev);
> +        result_bitmap =3D get_free_request_bitmap(threads, thread);
> +
> +        for (; index < threads->thread_requests_nr; index++) {
> +            if (test_bit(index, &result_bitmap)) {
> +                qemu_event_wait(&thread->request_free_ev);
> +                goto retry;
> +            }
> +
> +            request_done(threads, index_to_request(thread, index));
> +        }
> +    }
> +}
> --=20
> 2.14.5



