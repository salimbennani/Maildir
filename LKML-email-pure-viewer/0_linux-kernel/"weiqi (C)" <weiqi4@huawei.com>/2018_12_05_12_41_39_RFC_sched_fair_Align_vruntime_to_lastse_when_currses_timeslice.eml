Return-Path: <linux-kernel-owner@vger.kernel.org>
Delivered-To: unknown
Received: from linux.intel.com (10.54.29.200:995) by likexu-workstation with
  POP3-SSL; 06 Dec 2018 08:52:09 -0000
X-Original-To: like.xu@linux.intel.com
Delivered-To: like.xu@linux.intel.com
Received: from orsmga003.jf.intel.com (orsmga003.jf.intel.com [10.7.209.27])
	(using TLSv1.2 with cipher ECDHE-RSA-AES256-GCM-SHA384 (256/256 bits))
	(No client certificate requested)
	by linux.intel.com (Postfix) with ESMTPS id 246965804C1;
	Wed,  5 Dec 2018 04:41:47 -0800 (PST)
Received: from fmsmga101.fm.intel.com ([10.1.193.65])
  by orsmga003-1.jf.intel.com with ESMTP/TLS/DHE-RSA-AES256-GCM-SHA384; 05 Dec 2018 04:41:46 -0800
X-SG-BADATTACHMENTNOREPLY: True
IronPort-PHdr: =?us-ascii?q?9a23=3AvFKfGBTtgc1YmdaFz602jhBxXdpsv+yvbD5Q0YIu?=
 =?us-ascii?q?jvd0So/mwa64YRSBt8tkgFKBZ4jH8fUM07OQ7/iwHzRYqb+681k6OKRWUBEEjc?=
 =?us-ascii?q?hE1ycBO+WiTXPBEfjxciYhF95DXlI2t1uyMExSBdqsLwaK+i764jEdAAjwOhRo?=
 =?us-ascii?q?LerpBIHSk9631+ev8JHPfglEnjWwba9xIRmssQndqtQdjJd/JKo21hbHuGZDdf?=
 =?us-ascii?q?5MxWNvK1KTnhL86dm18ZV+7SleuO8v+tBZX6nicKs2UbJXDDI9M2Ao/8LrrgXM?=
 =?us-ascii?q?TRGO5nQHTGoblAdDDhXf4xH7WpfxtTb6tvZ41SKHM8D6Uaw4VDK/5KpwVhTmlD?=
 =?us-ascii?q?kIOCI48GHPi8x/kqRboA66pxdix4LYeZyZOOZicq/Ye94RWGhPUdtLVyFZHI2y?=
 =?us-ascii?q?b5YBAekPM+lWoIbyu1QArRqlBQm0Bu7i0SNIi3zs0KEmz+gsHwPL0Qo9FNwOqn?=
 =?us-ascii?q?TUq9D1Ob8cXeG70qbIzCzDb/JL0jv59oXEdx4tquyLULN+b8XRyFAvFwLKg1iL?=
 =?us-ascii?q?qYzlIima1+oTvGia9eZvSeWvi2s+pgx3vzOhxd8sh5HXio4Jzl3I7zh1zYgrKd?=
 =?us-ascii?q?GiVUJ2YsKoHIFRuiyYL4d6X98uT3t1tCs4yLAKo5q2cSsQxJkkyBPTc/OKfoiS?=
 =?us-ascii?q?7h79W+ucJS10iGx4dL6hnRq+7EytxvD6W8KpylhFtDBFncPJtn0V1xzc9MyHSv?=
 =?us-ascii?q?xl80e/1jaAyRrT5vtHIU8qj6rbLYAuwroqmpoUq0TDETf6mETwjKCIakUp4vak?=
 =?us-ascii?q?5/jjb7n8u5OROZF4hhvjPqkthsCzG+U1PwoWU2ie4+u81bnj/UPjQLVNi/07iq?=
 =?us-ascii?q?3ZsJHcJcQGqa+1GgxV3Zg56xa5ETim1M0UnX4JLVJDZh2HlZPkO0/BIP/mF/ez?=
 =?us-ascii?q?mVesnylxx/DAILLhBo/BLn/ZkLfuZbp98VJTyBIvzdBD4JJZErUBIPPwWkDvrt?=
 =?us-ascii?q?DZAQI5Pheww+bmDtV9y4wfVXiOAq+fLKPdr1uI6vgzLOmLYY8foCz9JOQ95/7y?=
 =?us-ascii?q?kX85nkcQfamz0psWdHC3BPNmL1+ZYXrxmNgBF2gKsxE6TOzrjl2CTDFSa2yzX6?=
 =?us-ascii?q?I6+jE0FoamAZ3fSYCqhbyLxD27EYFOZmBaFlCMFm/ld4eDW/gSci6SIchhkjoC?=
 =?us-ascii?q?VbimUIIh0RCutAnny7toNObU+ysYtY7929hx/eHciRYy9TlsBcSHz26NV310nn?=
 =?us-ascii?q?8PRzIuxq9/ukx9ylCA0aRimfxXD95T6uhNUgc7M57c0uN7B8rzWgLHYteGVlKm?=
 =?us-ascii?q?Ts+6DjE2S9I728UObFplG9W+khDD2DKnA7wPmLyNHpA09qPc0GL3J8Zy0HvG0K?=
 =?us-ascii?q?ghj187QspAL2Gmh6h/9xTNCI7NiUmWi6GqdaEE1i7X6GiD1XaOvF1fUANoTKrK?=
 =?us-ascii?q?R24faVXModT5/EzCSaSuBqohMgdGzc6CKa5KatnygFVCRffjPsneYm2rl2exAx?=
 =?us-ascii?q?aI2q2DbI7wd2oB2yXdDVAOkxoP8naeKQg+GiChrnrDAzN0C1LgfVng8elkp3O9?=
 =?us-ascii?q?VU870QeKYlZl17q0/B4VmPOdR+kS3rICpCcutTF0EEyh0NLRDtqKvxBhc7lEYd?=
 =?us-ascii?q?Mh/FdH0nrUtxB8PpylKKBiml4ecgRts0PyzRl3DZ9AkcwrrHMswwp/MqaY0FJH?=
 =?us-ascii?q?dzOF0pH8ILzXKm/u/B+xb67awE3R0NGT+q0X8vQ3t03jvB21Fkol63hoyd1V3G?=
 =?us-ascii?q?WT55rUDAseS4n+Ulsq+BdgobHaYS49553P2H1oMKm0tCLC2t0zCOskzBagY8lQ?=
 =?us-ascii?q?MKeeGADuFM0aAtCkKPY2lFixchIEIOdS+bY0PsO7bfeJxLSnPedgnD28i2RH75?=
 =?us-ascii?q?tw0kaN9yp6V+7J0IwJw/Ce3gubSTj8iE2tvdzwmYBBfTsSBHawyTD4BI5NYa1/?=
 =?us-ascii?q?ZZwLCWayLMKt3NVxmpntV2Re9FG9HVMG2daldgaIYFz5wAJfy14XoXuhmSajyz?=
 =?us-ascii?q?x0kjcprreQ3SDUwuTicgYHNXBPRGV4kVjsJo20hcgAXEe0dwgpiAel5UHiyqlb?=
 =?us-ascii?q?paRzNWnSTV1TfyjrKWFvSa+wtruEY85S55IkqyRXUOKgYV+ETr7xuQcV0yTmH2?=
 =?us-ascii?q?FG3jA0aymquonlnxx9kG+dLmx8rGDaecFzwhfT/sfcSuRS3joFRSl4jyfYBl6n?=
 =?us-ascii?q?Mtmt/NWUkYrDs++kW2KgUJ1TbTfkzYeauCSn4m1qBAW1n+qvld3/DQg6zSj72s?=
 =?us-ascii?q?FqVCrSqxbweIvr16W8Me98ekloBVn869d1G41kk4swgo0Q1mYehpmP4XUHlmLz?=
 =?us-ascii?q?O81B2a3idHoNWSILw9nN7QjmwkJjL2iFx4LkVnqHxMthaMK3YmcX2iI78sBLB7?=
 =?us-ascii?q?2Y7L1CnStpvFW4qRjdbuR6njcY0fEu8mIVg/kVuAoxySWQGrUSHUhbPSP2jRiJ?=
 =?us-ascii?q?4c6xrL5LZGmxa7i/z1RxncquDLyZpgFcWXD5eootHCNq78V/Nk7M32P36o3+ZN?=
 =?us-ascii?q?bQatcTvAWOkxjcl+hVNI4xlv0SiCp7PmL9uGcpyu8hghxowJG6p5OHK2R28aK9?=
 =?us-ascii?q?Ax5YMCD1ZswJ9jHsi6ZegtiZ34S1Epp9HTULWYPiTei0HzIKqfTnKwGOHSUnpX?=
 =?us-ascii?q?iBHrrfGRKf5F1ir3LSCJ2rM3CXJH8EzdRtXhWdJUpfgBwKUzU+hJI2CgeqxMn5?=
 =?us-ascii?q?ekdj+j8R/kL4qgdLyu9wNRnwSGLfqxmzajsuVJiTNhlW7hxB50fIN8yR9PlzEj?=
 =?us-ascii?q?pc/p2gqgyNN2Oaax5JDWEPRkyLGVTjMqOy6tnH9uiSHvC+IOfWYbWStexeUO+F?=
 =?us-ascii?q?xJKo0ot75jaMK9+APn94A/0g3UpDW395Ft/dmzUOTSwXii3MY9SapBe65i14sM?=
 =?us-ascii?q?S//O73VwLo4IuFE6FSPsl3+xCqnaeDMPadhCZnJjZZ1ZMMxn7IxKIc3F4IjCFu?=
 =?us-ascii?q?eCeiEa4dtS7WV6/Qnq5XDxgGayJ8LsdI7qQ83hVTNs7fkN/6yrl4jvstAVdfSV?=
 =?us-ascii?q?Phgt2pZdANI2ylLlzHGV2ENK6YKjzL2c33ZaK8RKZUjOVVsR2wpDmaH1XiPjSF?=
 =?us-ascii?q?iznmSRSvPftQgyGcORxUoJu9fQp1CWj/UNLmbQW2MMN2jT0z27E7mmnGOnIcMT?=
 =?us-ascii?q?didUNAtbmQ7SJegvViFG1N9HtlLe+YmymH6+nUMIoZsfxuAi5sjeJV/Gw6y6dJ?=
 =?us-ascii?q?7CFDXPF0mDHdrthro1GnlOmA0jtmUBpUpTZNi4KGpkFiOaTf9pldVnfI5hMN7W?=
 =?us-ascii?q?OMCxsUo9tpEMHgu6dVyouHqKWmfDND9c/EuMgRHc7ZLOqZP3c7dxnkAjjZCE0C?=
 =?us-ascii?q?VzH9cSnnilBQirmg93+RtYQgo9C4gJcSR6VJfF0zGOkTBklsEJoFOpghDR0+lr?=
 =?us-ascii?q?vOxtEF5GO/5Fn6BY8S6o/KV+uTXd3vNT+GgLgCbBwNl+CrZb8PP5H2jhQxImJx?=
 =?us-ascii?q?m57HTg+JBYhA?=
X-IronPort-Anti-Spam-Filtered: true
X-IronPort-Anti-Spam-Result: =?us-ascii?q?A0ApAAASxwdch0O0hNFkHgEGBwaBUQkLA?=
 =?us-ascii?q?YNrMYNvlCeBYEGXOIIHKwGHUiI0CQ0BAwEBAQEBAQIBEwEBAQgNCQgpL4I2JAG?=
 =?us-ascii?q?CaQIgBAsBBScgCQIkAiYCAgNaAQwIAQEBgxyCAgWkbXwzhUCEa4ELixOCFoERJ?=
 =?us-ascii?q?4pwglcCgSoBjwWQJgYDApE6BhiJYBCHPgEsiF2JDIZpgUaCDXCBboFPgiYXjio?=
 =?us-ascii?q?yAQGBNQEBAQ6JcIEcAwEB?=
X-IPAS-Result: =?us-ascii?q?A0ApAAASxwdch0O0hNFkHgEGBwaBUQkLAYNrMYNvlCeBYEG?=
 =?us-ascii?q?XOIIHKwGHUiI0CQ0BAwEBAQEBAQIBEwEBAQgNCQgpL4I2JAGCaQIgBAsBBScgC?=
 =?us-ascii?q?QIkAiYCAgNaAQwIAQEBgxyCAgWkbXwzhUCEa4ELixOCFoERJ4pwglcCgSoBjwW?=
 =?us-ascii?q?QJgYDApE6BhiJYBCHPgEsiF2JDIZpgUaCDXCBboFPgiYXjioyAQGBNQEBAQ6Jc?=
 =?us-ascii?q?IEcAwEB?=
X-IronPort-AV: E=Sophos;i="5.56,317,1539673200"; 
   d="scan'208";a="65415227"
X-Amp-Result: SKIPPED(no attachment in message)
X-Amp-File-Uploaded: False
Received: from vger.kernel.org ([209.132.180.67])
  by mga01b.intel.com with ESMTP; 05 Dec 2018 04:41:45 -0800
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
        id S1727700AbeLEMlm (ORCPT <rfc822;like.xu@linux.intel.com>
        + 23 others); Wed, 5 Dec 2018 07:41:42 -0500
Received: from szxga05-in.huawei.com ([45.249.212.191]:15641 "EHLO huawei.com"
        rhost-flags-OK-OK-OK-FAIL) by vger.kernel.org with ESMTP
        id S1726918AbeLEMlm (ORCPT <rfc822;linux-kernel@vger.kernel.org>);
        Wed, 5 Dec 2018 07:41:42 -0500
Received: from DGGEMS402-HUB.china.huawei.com (unknown [172.30.72.58])
        by Forcepoint Email with ESMTP id AAA7CDF9C0495;
        Wed,  5 Dec 2018 20:41:38 +0800 (CST)
Received: from [10.177.98.84] (10.177.98.84) by smtp.huawei.com (10.3.19.202)
 with Microsoft SMTP Server (TLS) id 14.3.408.0; Wed, 5 Dec 2018 20:41:39
 +0800
To: <linux-kernel@vger.kernel.org>,
        Peter Zijlstra <peterz@infradead.org>
From: "weiqi (C)" <weiqi4@huawei.com>
Subject: [RFC] sched/fair: Align vruntime to last_se when curr_se's timeslice
 run out
Message-ID: <f4f56ab5-8f9e-9ee4-4db8-370bc4aa2556@huawei.com>
Date: Wed, 5 Dec 2018 20:41:39 +0800
User-Agent: Mozilla/5.0 (Windows NT 6.1; WOW64; rv:45.0) Gecko/20100101
 Thunderbird/45.8.0
MIME-Version: 1.0
Content-Type: text/plain; charset="UTF-8"; format=flowed
Content-Transfer-Encoding: 8bit
X-Originating-IP: [10.177.98.84]
X-CFilter-Loop: Reflected
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: <linux-kernel.vger.kernel.org>
X-Mailing-List: linux-kernel@vger.kernel.org

Hello,
I measuring the cfs scheduling delay, and found that
when a cfs_rq contains multiple tasks, it does not guarantee
every se of this cfs_rq can get a changce to run within
  one sched_latency period. Assume that there are three se
  A, B, and C in cfs_rq, and the default sched_latency=24ms.
In ideal state, A, B, and C take turns to get 8ms, The timing is:
  A(8ms) -> B(8ms) -> C(8ms) -> A(8ms) -> B(8ms) -> C(8ms) ....
So, the delay for each task is approximately 16ms.

However, check_preempt_tick() is the clock interrupt granularity,
and the clock interrupt may also have an indeterminate fine delay,
so the time slice actually expires relative
  to the ideal expiration time delay uncertain time.
This may result in a timing of :
      A -> B -> C -> B -> C -> A
which increases the scheduling delay of A to 32ms.


The more extreme scenario is wakeup sleepers. If a sleeper task
  wakes up to a cpu, its vruntime will be sched_latency/2 less
  than cfs_rq->min_vruntime /* place_entity() function do this */
In the scene of the above A, B, C cycle time slice,
a sleeper thread D woken up
D->vruntime = cfs_rq->min_vruntime - sched_latency/2
then the timing of the pick_task may be:

A(8ms)->B(8ms)->C(8ms)->D(6ms)->D(6ms)->D(6ms,then dequeue)->C(8ms)-> 
B(8ms)->A

causing A's scheduling delay to reach 50ms
so, I make changes to check_preempt_tick()：

diff --git a/kernel/sched/fair.c b/kernel/sched/fair.c
index ee271bb..1f61b9c 100644
--- a/kernel/sched/fair.c
+++ b/kernel/sched/fair.c
@@ -4020,7 +4020,23 @@ static void clear_buddies(struct cfs_rq *cfs_rq, 
struct sched_entity *se)
         ideal_runtime = sched_slice(cfs_rq, curr);
         delta_exec = curr->sum_exec_runtime - curr->prev_sum_exec_runtime;
         if (delta_exec > ideal_runtime) {
+               struct rb_node *next = NULL;
+               struct rb_node *right_most = NULL;
+               struct sched_entity *last;
                 resched_curr(rq_of(cfs_rq));
+
+                /* always set to max vruntime */
+                if (cfs_rq->nr_running > 1) {
+                        next = &curr->run_node;
+                        do {
+                                right_most = next;
+                                next = rb_next(next);
+                        } while (next);
+
+                        last = rb_entry(right_most,
+                                         struct sched_entity, run_node);
+                        curr->vruntime = last->vruntime + 1; // maybe 
+1 is not needed
+                }
+
                 /*
                  * The current task ran long enough, ensure it doesn't get
                  * re-elected due to buddy favours.


In this way, time sliced task in one sched_latency period will not get 
runtime again,
And for wake sleeper, it can meet the needs of wake-up preemption, and 
this will not let it
take too much time in a scheduling period.

I wrote a small press program, bind it to 12 cpus, this program wake up 
36 sub-processes
  every second and each sub-process work 120ms, looping all the time..
I‘ve tested on linux-stable 4.20-rc1 kernel, the maximum delay of press 
program is about 80ms.
After applying the above modifications, the maximum delay is stable at 27ms.
