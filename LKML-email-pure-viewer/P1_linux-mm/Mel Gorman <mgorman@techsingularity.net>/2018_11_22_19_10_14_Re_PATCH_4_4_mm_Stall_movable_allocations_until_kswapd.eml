Return-Path: <linux-kernel-owner@vger.kernel.org>
Delivered-To: unknown
Received: from linux.intel.com (10.54.29.200:995) by likexu-workstation with
  POP3-SSL; 23 Nov 2018 08:30:59 -0000
X-Original-To: like.xu@linux.intel.com
Delivered-To: like.xu@linux.intel.com
Received: from fmsmga002.fm.intel.com (fmsmga002.fm.intel.com [10.253.24.26])
	(using TLSv1.2 with cipher ECDHE-RSA-AES256-GCM-SHA384 (256/256 bits))
	(No client certificate requested)
	by linux.intel.com (Postfix) with ESMTPS id D2E4D580460;
	Thu, 22 Nov 2018 11:10:23 -0800 (PST)
Received: from fmsmga105.fm.intel.com ([10.1.193.10])
  by fmsmga002-1.fm.intel.com with ESMTP/TLS/DHE-RSA-AES256-GCM-SHA384; 22 Nov 2018 11:10:23 -0800
X-SG-BADATTACHMENTNOREPLY: True
IronPort-PHdr: =?us-ascii?q?9a23=3AjLHshhJgDeXoAmVKFtmcpTZWNBhigK39O0sv0rFi?=
 =?us-ascii?q?tYgULvrzrarrMEGX3/hxlliBBdydt6oUzbKO+4nbGkU4qa6bt34DdJEeHzQksu?=
 =?us-ascii?q?4x2zIaPcieFEfgJ+TrZSFpVO5LVVti4m3peRMNQJW2aFLduGC94iAPERvjKwV1?=
 =?us-ascii?q?Ov71GonPhMiryuy+4ZLebxlLiTanfb9+MAi9oBnMuMURnYZsMLs6xAHTontPde?=
 =?us-ascii?q?RWxGdoKkyWkh3h+Mq+/4Nt/jpJtf45+MFOTav1f6IjTbxFFzsmKHw65NfqtRbY?=
 =?us-ascii?q?UwSC4GYXX3gMnRpJBwjF6wz6Xov0vyDnuOdxxDWWMMvrRr0vRz+s87lkRwPpiC?=
 =?us-ascii?q?cfNj427mfXitBrjKlGpB6tvgFzz5LIbI2QMvd1Y6HTcs4ARWdZUMhfVzJPDJ6/?=
 =?us-ascii?q?YYsBAOUOIftXoIvzqFsVtRuzBxKhBP/zxjJSmnP6wbc33uAnHArb3AIgBdUOsH?=
 =?us-ascii?q?HModvyKqgSVf2+wqjPzTXZavNZwzH945XPfxAkrvGMWqhwcc/LxkkpDA7Fkkuf?=
 =?us-ascii?q?ppDlPzOO1+QNtWeb7/dkVe21kW4nqh1xozi1yscqlIbJmpsYx1bZ/it62IY4Pc?=
 =?us-ascii?q?O0RFJ/bNK+DZdduT+WO5FrTs4hX21koic3x78etZO4YSQG0okryhzFZ/CZc4WF?=
 =?us-ascii?q?7QjvWPuNLTp+mXlrYqiwhwyo/kil0uD8Vte70FJNriddjNnMuW4C1wbJ5siEVP?=
 =?us-ascii?q?R95EGh1iiL1wzJ7eFEO080mbLaK54n3LEwioIevVrfEiLygkn6kaGbels+9uS1?=
 =?us-ascii?q?6Onrfq/qq56eOoNsjwHxKKUumsixAeQiNQgOWnCW+eC91L3l4E34T6xGjv4ona?=
 =?us-ascii?q?nDtpDVO8Abqre+Aw5b1IYs9Qy/Aiy40NQXg3YHNkhJeBGZgIjzPVHBPvT4Ae24?=
 =?us-ascii?q?g1S2nzdn3+rGMaH5ApXRMnjDl6/sfbJ8605f1gU/199e549PB7EFIfLzXFLxtd?=
 =?us-ascii?q?PCAh84NQy03/joCNFn2owCXmKPB7eTMLnOvl+Q+uIvP+6MaZcVuDnnKvgl++Th?=
 =?us-ascii?q?jXgjlV8dYKmmx50XaH+jE/RiIkWZZ2fsg9gbHWcLuAo+UPLliFmYXTFPYHayWr?=
 =?us-ascii?q?o25isnB4K+EYfDWoetjaSD3Ce8AJJafGNGCleKEXfucIWJQPMMaCOUIs98nT0I?=
 =?us-ascii?q?T7mhS4k91R6wsA/20aZoLu3R+icAr5LsyMB15/HPlRE17TF7Fd+d02GKT2F3hG?=
 =?us-ascii?q?8IXSU53KJkrEx5y1eD17V4gvNCGdxS4fNJThk1NZrGw+NmDNDyXxrLfs2VR1a+?=
 =?us-ascii?q?XtWmHTYxQ8oyw9AUZUZxAdGijhHZ0CqsDL8YjLiLBJ0y8qLB0Hn9Pcd9y3Da1K?=
 =?us-ascii?q?Y/i1kqWNdANWqjhqRn7QjcG5bJk1mFl6atbakTwTTC9HmdwmaUvEFXSghwUb7b?=
 =?us-ascii?q?UnAZYUfWqdf55kbGT7K1DbQnMw1BydONK6dQa93pi0lGS+nnONjEf22xnGKwDw?=
 =?us-ascii?q?6SxryQdIrqZ3kd3CLFBUcZiQ8T42iJORI+Bii7pWLeFyJhFVT0bkPo8Ol+rm67?=
 =?us-ascii?q?T0AuwwGLaU1hy6S6+hoPifOATPMT26oOuD09pDVsAFa9w9XWBsKcpwpgeaVcZs?=
 =?us-ascii?q?894FdH1G7DqwxxJJugL7pmhl4fdQR3sFjj1xF2CoVGjMgro2kmzAt0KaKEzlxB?=
 =?us-ascii?q?cymU0oz3Or3SMmPy5gyga7bK2lHC19ab4r0A6PAmpFTsog6oFlAu/G5609ZIyX?=
 =?us-ascii?q?Sc4JbKDA0MUZ/qVkY39h56p6zVYyUn5oPU02FsPrewsjPYx90pA+4lwA66f9hD?=
 =?us-ascii?q?KKOECBPyE8oCCsmuNewmgUSmYggFPeBS7qE0OcymeuCC2K6qOuZggT2ngX5G4I?=
 =?us-ascii?q?B7zkKD6S58RvTU0JYCxvGSxhGHWCvkjFe9rsD3nphJZSsTHmWj0yfkHpNeZqpo?=
 =?us-ascii?q?cYYNF2iuOcy3ysxiiJH3X35X6UCsB0kB2M+vYheSa1393QtN1UUYu3CnmC24zy?=
 =?us-ascii?q?BqnDEttKaQwCvOw+H6fhodJmFLXHVijUvrIYWsj9EaXVKkbggzmBu++Eb6wbNW?=
 =?us-ascii?q?pKB+L2nVXEdJcDL6L2BkUqusqLWCZ9RD548vsSVSSO68e0yVSqbhoxsG1CPuB2?=
 =?us-ascii?q?leyyohdzGpuZX5mAZ2iHmHI3Zwr3rZeMdwygnZ5NHHQf5R3zwGRDR3iDXNB1i8?=
 =?us-ascii?q?OcWp8suQl5vZru++UGehXIVJcSb31YOAqDe75WpyDBy/hf+zncfrEQo70S/9zN?=
 =?us-ascii?q?RqUSTIrBDhYojkzai6MORnflV2C1/48cZ1BoZ+ko4ojpEKxXcanomV/WYAkWrr?=
 =?us-ascii?q?MtVUw6P+YGANRT4W2dHV5gfl1VZnLnKIwYL5S3qcztFgZ9m8fmMZxCY949pWB6?=
 =?us-ascii?q?eT6bxOhTF1rUagrQLNffh9mS8Qyf4v6H4Zme4FogQswTuGArAOA0ZYJzfjmAqS?=
 =?us-ascii?q?79Cxt6hXYGevcb6t1Etxh9yhDbeCoh1CV3b9YJstAShw7sBnOlLWzHLz8p3keM?=
 =?us-ascii?q?XXbd8Lqh2UlBLAg/JUKZ0rkPoKmDFnOXn8vXA+z+47jBpu3Yy1vYSdKmVt+r65?=
 =?us-ascii?q?DQBcNjHve8wT/TTth75EnsmKx4CvAolhGjITUZTzV/2oFzYSten9OwaKDT0xsX?=
 =?us-ascii?q?ObGbvZHQ+C50ZqtXPPE5a3N36JIHkV18ltRB6YJEZHmgAbQC06noIlFgCt3MHh?=
 =?us-ascii?q?cl125jUP6V7jsBdM1vhkNxriUmfcuQeobC07SIOEIRpS7wFC4VrVMMOE4uJyGS?=
 =?us-ascii?q?FY4oOurAiXJmOHYARICHkDWlaYCFD7Irmu+d7A/vCYB+q5MvvOeKiOpvZYV/uS?=
 =?us-ascii?q?3pKv1Y1m/zmXO8WLP3liCeA720VZUXB4HcTZhysASygNmy3RaM6boQ+2+jdroc?=
 =?us-ascii?q?Cn7PTrRAXv6JOPC7RMMNVv+BO2gaaZO+6TniZ5LjlY2Y0WxX/V07gSx1oSiyBo?=
 =?us-ascii?q?dzmwHrUMry/NTKTMmqBJCx4XcT98NMxN76gkxAlCJdbbis/p1r5/lvM6EUpFWk?=
 =?us-ascii?q?f7ms63Zc0GOWW9NFLcCUaPNbSGIyDLws7tbaO9T71QkPtbtxmqtTmHFE/jOyyJ?=
 =?us-ascii?q?lyP1WBC3LeFMkCabMQRCuIG8dxZhE3TsQMj6ZR27LtB3iyY7wbk1hnPMKG4dPi?=
 =?us-ascii?q?Jwc0JLrr2M8yxYhu9zFHBG7npgNeOEgTqW7/HEKpYKtvtmGiR1mPhc4HQ/yrtV?=
 =?us-ascii?q?6jlLRf11mCTIqN5urEqrku2OyjphTRpPpSxHhIONvUV+J6rZ8oNMVmrD/BIIvi?=
 =?us-ascii?q?2sDEE0o9J+FtzquqQY4NHFl6u7fClI+tjX9OMHGtPZbsmVZikPKx3sTRvZCEMq?=
 =?us-ascii?q?SiSuPGeX00lSl+uX/3u9spUxqoPtnpUTTrZBVUAkUPUXFhI2T5Q5PJ5rU2Z8wv?=
 =?us-ascii?q?agh8kS6C/79UGJSQ=3D=3D?=
X-IronPort-Anti-Spam-Filtered: true
X-IronPort-Anti-Spam-Result: =?us-ascii?q?A0AYAAAB/vZbh0O0hNFiGwEBAQEDAQEBB?=
 =?us-ascii?q?wMBAQGBUwQBAQELAYFagXsEEo0WiyGCDRSBCpYcgjIBiEsHIjYHDQEDAQEBAQE?=
 =?us-ascii?q?BAgETAQEBCA0JCCkvgjYkAYJhAQEBAQIBAQIkPhQFAQkBAQoOCgkTBwsDDAVJG?=
 =?us-ascii?q?IJRS4F6CAQBqhYzGgKKAowJF4FAP4ERghR+hFiGAQKIf4ISlHEJiimGeyOJdQO?=
 =?us-ascii?q?HEJl9CIF+TS4KgyiCJhcSjgpBgTUBAQGKCIJJAwEB?=
X-IPAS-Result: =?us-ascii?q?A0AYAAAB/vZbh0O0hNFiGwEBAQEDAQEBBwMBAQGBUwQBAQE?=
 =?us-ascii?q?LAYFagXsEEo0WiyGCDRSBCpYcgjIBiEsHIjYHDQEDAQEBAQEBAgETAQEBCA0JC?=
 =?us-ascii?q?CkvgjYkAYJhAQEBAQIBAQIkPhQFAQkBAQoOCgkTBwsDDAVJGIJRS4F6CAQBqhY?=
 =?us-ascii?q?zGgKKAowJF4FAP4ERghR+hFiGAQKIf4ISlHEJiimGeyOJdQOHEJl9CIF+TS4Kg?=
 =?us-ascii?q?yiCJhcSjgpBgTUBAQGKCIJJAwEB?=
X-IronPort-AV: E=Sophos;i="5.56,266,1539673200"; 
   d="scan'208";a="139243816"
X-Amp-Result: UNKNOWN
X-Amp-Original-Verdict: FILE UNKNOWN
X-Amp-File-Uploaded: False
Received: from vger.kernel.org ([209.132.180.67])
  by mtab.intel.com with ESMTP; 22 Nov 2018 11:10:22 -0800
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
        id S2406619AbeKWFvA (ORCPT <rfc822;like.xu@linux.intel.com>
        + 23 others); Fri, 23 Nov 2018 00:51:00 -0500
Received: from outbound-smtp04.blacknight.com ([81.17.249.35]:35864 "EHLO
        outbound-smtp04.blacknight.com" rhost-flags-OK-OK-OK-OK)
        by vger.kernel.org with ESMTP id S1726009AbeKWFvA (ORCPT
        <rfc822;linux-kernel@vger.kernel.org>);
        Fri, 23 Nov 2018 00:51:00 -0500
Received: from mail.blacknight.com (pemlinmail01.blacknight.ie [81.17.254.10])
        by outbound-smtp04.blacknight.com (Postfix) with ESMTPS id 30F4B98B5A
        for <linux-kernel@vger.kernel.org>; Thu, 22 Nov 2018 19:10:16 +0000 (UTC)
Received: (qmail 8975 invoked from network); 22 Nov 2018 19:10:16 -0000
Received: from unknown (HELO techsingularity.net) (mgorman@techsingularity.net@[37.228.229.69])
  by 81.17.254.9 with ESMTPSA (AES256-SHA encrypted, authenticated); 22 Nov 2018 19:10:16 -0000
Date: Thu, 22 Nov 2018 19:10:14 +0000
From: Mel Gorman <mgorman@techsingularity.net>
To: Vlastimil Babka <vbabka@suse.cz>
Cc: Linux-MM <linux-mm@kvack.org>,
        Andrew Morton <akpm@linux-foundation.org>,
        David Rientjes <rientjes@google.com>,
        Andrea Arcangeli <aarcange@redhat.com>,
        Zi Yan <zi.yan@cs.rutgers.edu>,
        Michal Hocko <mhocko@kernel.org>,
        LKML <linux-kernel@vger.kernel.org>
Subject: Re: [PATCH 4/4] mm: Stall movable allocations until kswapd
 progresses during serious external fragmentation event
Message-ID: <20181122191014.GM23260@techsingularity.net>
References: <20181121101414.21301-1-mgorman@techsingularity.net>
 <20181121101414.21301-5-mgorman@techsingularity.net>
 <35ea6691-e819-5581-7d32-39c1abfbe775@suse.cz>
MIME-Version: 1.0
Content-Type: text/plain; charset=iso-8859-15
Content-Disposition: inline
In-Reply-To: <35ea6691-e819-5581-7d32-39c1abfbe775@suse.cz>
User-Agent: Mutt/1.10.1 (2018-07-13)
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: <linux-kernel.vger.kernel.org>
X-Mailing-List: linux-kernel@vger.kernel.org

On Thu, Nov 22, 2018 at 06:02:10PM +0100, Vlastimil Babka wrote:
> On 11/21/18 11:14 AM, Mel Gorman wrote:
> > An event that potentially causes external fragmentation problems has
> > already been described but there are degrees of severity.  A "serious"
> > event is defined as one that steals a contiguous range of pages of an order
> > lower than fragment_stall_order (PAGE_ALLOC_COSTLY_ORDER by default). If a
> > movable allocation request that is allowed to sleep needs to steal a small
> > block then it schedules until kswapd makes progress or a timeout passes.
> > The watermarks are also boosted slightly faster so that kswapd makes
> > greater effort to reclaim enough pages to avoid the fragmentation event.
> > 
> > This stall is not guaranteed to avoid serious fragmentation events.
> > If memory pressure is high enough, the pages freed by kswapd may be
> > reallocated or the free pages may not be in pageblocks that contain
> > only movable pages. Furthermore an allocation request that cannot stall
> > (e.g. atomic allocations) or unmovable/reclaimable allocations will still
> > proceed without stalling.
> 
> Not doing this for unmovable/reclaimable allocations is kinda disadvantage?
> 

Yes, but this series is primarily aimed at when movable allocations are
causing the fragmentation. We stall so that there are compaction targets
due to reclaimed pages. The same does not apply to unmovable and
reclaimable pages because they cannot compact so sure, we can stall, but
I cannot see how it would help.

> >  ==============================================================
> >  
> > +fragment_stall_order
> > +
> > +External fragmentation control is managed on a pageblock level where the
> > +page allocator tries to avoid mixing pages of different mobility within page
> > +blocks (e.g. order 9 on 64-bit x86). If external fragmentation is perfectly
> > +controlled then a THP allocation will often succeed up to the number of
> > +movable pageblocks in the system as reported by /proc/pagetypeinfo.
> > +
> > +When memory is low, the system may have to mix pageblocks and will wake
> > +kswapd to try control future fragmentation. fragment_stall_order controls if
> > +the allocating task will stall if possible until kswapd makes some progress
> > +in preference to fragmenting the system. This incurs a small stall penalty
> > +in exchange for future success at allocating huge pages. If the stalls
> > +are undesirable and high-order allocations are irrelevant then this can
> > +be disabled by writing 0 to the tunable. Writing the pageblock order will
> > +strongly (but not perfectly) control external fragmentation.
> > +
> > +The default will stall for fragmenting allocations smaller than the
> > +PAGE_ALLOC_COSTLY_ORDER (defined as order-3 at the time of writing).
> 
> Perhaps be more explicit that steals of orders strictly lower than given
> value will stall? So for the default order-3, the sysctl value is 4,
> which might confuse somebody.
> 

I'll clarify it.

> > +
> > @@ -2130,9 +2131,10 @@ static bool can_steal_fallback(unsigned int order, int start_mt)
> >  	return false;
> >  }
> >  
> > +
> > +static void stall_fragmentation(struct zone *pzone)
> > +{
> > +	DEFINE_WAIT(wait);
> > +	long remaining = 0;
> > +	long timeout = HZ/50;
> > +	pg_data_t *pgdat = pzone->zone_pgdat;
> > +
> > +	if (current->flags & PF_MEMALLOC)
> > +		return;
> > +
> > +	boost_watermark(pzone, true);
> 
> Should zone->lock be taken around this to make watermark_boost
> adjustment safe? Similar to balance_pgdat().
> 

Yeah, that was a relatively late adjustment. The risk is low but it's
possible best to be safe. I'm not super-keen that zone->lock protects
this but that lock already protects more than it should and there is
little motivation to split it just yet.

> > +	prepare_to_wait(&pgdat->pfmemalloc_wait, &wait, TASK_INTERRUPTIBLE);
> > +	if (waitqueue_active(&pgdat->kswapd_wait))
> > +		wake_up_interruptible(&pgdat->kswapd_wait);
> > +	remaining = schedule_timeout(timeout);
> > +	finish_wait(&pgdat->pfmemalloc_wait, &wait);
> > +	if (remaining != timeout) {
> > +		trace_mm_fragmentation_stall(pgdat->node_id,
> > +			jiffies_to_usecs(timeout - remaining));
> > +		count_vm_event(FRAGMENTSTALL);
> > +	}
> >  }
> >  
> 
> > @@ -4186,6 +4234,14 @@ __alloc_pages_slowpath(gfp_t gfp_mask, unsigned int order,
> >  	 */
> >  	alloc_flags = gfp_to_alloc_flags(gfp_mask);
> >  
> > +	/*
> > +	 * Consider stalling on heavy for movable allocations in preference to
> > +	 * fragmenting unmovable/reclaimable pageblocks.
> > +	 */
> > +	if ((gfp_mask & (__GFP_MOVABLE|__GFP_DIRECT_RECLAIM)) ==
> > +			(__GFP_MOVABLE|__GFP_DIRECT_RECLAIM))
> > +		alloc_flags |= ALLOC_FRAGMENT_STALL;
> 
> Surprised that this only has effect in the slowpath, i.e. when
> watermarks are below 'low'. If it's intended (to not stall that much I
> suppose) maybe explain the rationale in the changelog?
> 

Well, it's the same path when stalls can happen on direct reclaim so I
didn't think it needed to be explicitly called out. The slowpath is also
the "we can stall if the context allows" path so this is checking that
it's a compatible cont3xt.

> Thanks for the series, Mel, hope the results are still optimistic after
> some of the fixes that might unfortunately limit its impact :)
> 

Preliminary results indicate they are slightly worse but slightly worse
than 90+% is still better than nothing so I'm reasonably optimistic!

Thanks for the careful review and catching a lot of issues!

-- 
Mel Gorman
SUSE Labs
