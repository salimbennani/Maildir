Return-Path: <linux-kernel-owner@vger.kernel.org>
Delivered-To: unknown
Received: from linux.intel.com (10.54.29.200:995) by i7-8700 with POP3-SSL;
  12 Dec 2018 19:43:45 -0000
X-Original-To: like.xu@linux.intel.com
Delivered-To: like.xu@linux.intel.com
Received: from fmsmga001.fm.intel.com (fmsmga001.fm.intel.com [10.253.24.23])
	(using TLSv1.2 with cipher ECDHE-RSA-AES256-GCM-SHA384 (256/256 bits))
	(No client certificate requested)
	by linux.intel.com (Postfix) with ESMTPS id 766A15803DC;
	Wed, 12 Dec 2018 01:49:18 -0800 (PST)
Received: from fmsmga103.fm.intel.com ([10.1.193.90])
  by fmsmga001-1.fm.intel.com with ESMTP/TLS/DHE-RSA-AES256-GCM-SHA384; 12 Dec 2018 01:49:18 -0800
X-SG-BADATTACHMENTNOREPLY: True
IronPort-PHdr: =?us-ascii?q?9a23=3AvKhVpRdIe/WiuvRyGPn6+usLlGMj4u6mDksu8pMi?=
 =?us-ascii?q?zoh2WeGdxc6+bBSN2/xhgRfzUJnB7Loc0qyK6/CmATRIyK3CmUhKSIZLWR4BhJ?=
 =?us-ascii?q?detC0bK+nBN3fGKuX3ZTcxBsVIWQwt1Xi6NU9IBJS2PAWK8TW94jEIBxrwKxd+?=
 =?us-ascii?q?KPjrFY7OlcS30P2594HObwlSizexfbB/IA+qoQnNq8IbnZZsJqEtxxXTv3BGYf?=
 =?us-ascii?q?5WxWRmJVKSmxbz+MK994N9/ipTpvws6ddOXb31cKokQ7NYCi8mM30u683wqRbD?=
 =?us-ascii?q?VwqP6WACXWgQjxFFHhLK7BD+Xpf2ryv6qu9w0zSUMMHqUbw5Xymp4rx1QxH0li?=
 =?us-ascii?q?gIKz858HnWisNuiqJbvAmhrAF7z4LNfY2ZKOZycqbbcNgHR2ROQ9xRWjRPDI28?=
 =?us-ascii?q?cYUBEugOPehfoYbypFUBsRSwBRK0BO7t0TJImnz70Lcm3+k7DQ3KwgotFM8Ovn?=
 =?us-ascii?q?TOq9X1Mb8fX+evw6nS0TXDbvVW0irg5ofUchAgr/CMUq9ufsrf0kkvFAPEhUiX?=
 =?us-ascii?q?pIz+IzyV1uoMs2mG4OV+W+KvkG0nqgFqrzey2MggkIjJiZkQylze6Sp5x4M1KM?=
 =?us-ascii?q?S+RUVmYtCkCINduz+GO4ZyWM8uXm9ltDggxrEbupO3YDIGxZUlyhLHb/GLaZWE?=
 =?us-ascii?q?7xL9WOqLPzt0mWxpdKiiixuz/kWtzPD3WNOu31ZQtCVFl8HBtnAT2BzX7ciKUu?=
 =?us-ascii?q?V9/ki/1jaVzQzT6f9LIVoylaXFL54t2LkwloAcsUjbHy/2nlv5jLOOe0k65uSl?=
 =?us-ascii?q?7/7rbqjoq5OCLYN4lwLzPrg0lsG+A+k0Kg0OUHKa+eS42r3j50r5QLBSg/0yk6?=
 =?us-ascii?q?nZto3aJMsCqq66HQBVyIAj5Ai7Dzu/19QZk38HI0xfeB+ckYjpNE/BIOriAfe8?=
 =?us-ascii?q?nVusijFryO7CPrH7BZXNNHfDnK/7fblh805c1BYzzddH6pJQC7EBI+z8VlX+td?=
 =?us-ascii?q?zFFRI5Nw20w+D6CNRyzI8eWGSPArOHP6PWq1OH+uUvI+yUbo8PpDn9M+Ql5+Lp?=
 =?us-ascii?q?jXIhmV8SZ6ip3YcNZ3C/BPhmI1iZbmDqgtcOCmoKugs+TOr3iFyNSzJTZnCyX7?=
 =?us-ascii?q?4i6TE/Eo6pEYDDRoW1irybwCi7BoFWZnxBCl2UE3focJuLV+0PaCKVJM9hlDsE?=
 =?us-ascii?q?WKOlS48g0xGuqQD7x6BmLurS5i0Xq5bj2MJp6O3UkBE47SZ0ANiF02GRU2F0mX?=
 =?us-ascii?q?sFSCUt3KB/pkx9yU2P0bJijPxaDtFT4/JJUgEnNZ/T1eB6CtbyWh7fcdeNUlqp?=
 =?us-ascii?q?XtKmATQpRNIr39AOe1p9G8mljh3b3CqlGbkVm6aPBJw16K3c2XfxKt15y3bH0q?=
 =?us-ascii?q?khklYnTtFONW2gmq5w6QzTC5TVnEWekqagbb4c0zLV9Gef0WqOu1lVXxNqXqXb?=
 =?us-ascii?q?Q38TfEvWos7/5kPZUbCuD7MrMg9Cyc6HLqtHcdnpjVRARPf+N9XSeWOxm2GsBR?=
 =?us-ascii?q?mWwrOAdpble2IY3C/FEkgLjxgT/WqaNQg5HiquvnjRDCJwGl71Y0Pj6+9+qGil?=
 =?us-ascii?q?QU8y1AyKa0xh17yo+h8an/CcSvUT3q4atyclsTl7AFG939fOAdqauwVhZLlcYc?=
 =?us-ascii?q?864FpfyWLZtgl9Ppu8L6Bihl8SaRh3s1np1xVtDoVAkM4qrHwxwQp2KKKY1k5B?=
 =?us-ascii?q?djyC0ZDxPL3XNnf9/BS1Z6HK3VHe1c6c+r0T5/Qgt1XjoAapG1I4/HVjzdZU3G?=
 =?us-ascii?q?WT55XQAAUJTJL+T1w49x55p7HdfCkw/IfU1XxqMampvT7OwdMpBO05yhm+e9dT?=
 =?us-ascii?q?Kr+LFAj3E8cCHcihNPQqm0S1bhIDJO1T9LM0M9m6ePec2a+rPPxvnDSpjWlc5I?=
 =?us-ascii?q?B900SM9zdzS+LS3pYFxe2Y0RWDVzvmkFihtcX3k5heZT4OBmq/1TTkBIlJa61o?=
 =?us-ascii?q?fIYEFX2hI9eqydV5nZLtXWBX9ESiB18fxMCmYx6SYEHj0g1K0kQXp2eqmS+5zz?=
 =?us-ascii?q?xyjjEoobCT3C3Iw+T+ahUHPnRHS3VljVfpOYK0lcwVXFC0bwg1kxuo/Ub7x6lB?=
 =?us-ascii?q?qKV/NWXTWlpIfy7tImFmU6uwsKeCYsFV5JMptyVXTPqzYVSARrHhpBsa1jvpH3?=
 =?us-ascii?q?FCyzAjazGqppL5kgR4iG2HNnZzr3nZecZqyRfE/tPcRv1R3jsARCZmjznaHVy8?=
 =?us-ascii?q?P9iv/dWJmJbPqOG+V2S9VpJNdSnn15+PtCy+5WdyGx2wg+izmsH7EQg9ySL618?=
 =?us-ascii?q?NlVSLSoBb+Y4nr0b+3MeZmfkluGV/95NB2GoB4kossmp4Q3WIWiYmS/XoCiW3z?=
 =?us-ascii?q?K8lU2bribHoRQj4G293V7xLk2EF5LnKJ2pj2VnOSwsZ6Y9m6Y2UW2j8y7sxQCa?=
 =?us-ascii?q?eU6qBEkjVxolaisQ3RZv19lC8HyfQy8H4an/0JuA01wyWYA7ASHlNXMTbilhuW?=
 =?us-ascii?q?9NC+sLtYZHy0freuzkp+ksusDLWDogFaRXb4dY0uHS527sVjLl3M1Gf/5Z3jeN?=
 =?us-ascii?q?nVddgTrAGbkw/cj+hJL5I8juYKhS1iOW7nvHwq0eg7jQF13ZGhvYiKMGFt/KO/?=
 =?us-ascii?q?Ah5FOTz5fcIT+jfxjalAmsaaxZygHpJkGj8TRpvnUeqoEC4OtfTgLwuBCyczqn?=
 =?us-ascii?q?CfGbrCBwOf7FpmomnLE5CqMXGXOXYYwc9jRBmbOExQngQUUC8mkZ4+EwCg3Nbh?=
 =?us-ascii?q?f1th5jAN+l74rQNByuByOBn6TGjfvx2kaisuRJicMRpW7RxC50HPPsyF9e9zGy?=
 =?us-ascii?q?BY/pu8rA2CMGCbZgJIDX0XVUyAHVzsIr6u5dzY+eiCGuW+N+fOYamJqeFGV/aI?=
 =?us-ascii?q?wo+v0pJ7/zmWMMWDJGJiD/o92kpMRn15H8XZmzMSSy0YjS7NbsibpAui9S1ztM?=
 =?us-ascii?q?yw7PPrWAf374uVF7RSKclv+wyxgaqbN+6fmid5KTVb1pMN33PIy6If3Fkdiy5w?=
 =?us-ascii?q?bTmtDK8AuDXJTKLRnK9XEhEaZzlyNMtO86IzwA1NNdTHhdPy075yluQ1BEtdVV?=
 =?us-ascii?q?z9hsGpYtQHLHugNFzcHkaEKrSHKSfPw8H2eq68TbxQjONJtxy/ozqbEknjPiid?=
 =?us-ascii?q?mDntTRygLeZMjCSDNhxEpI69agptCXTkTN/+dh27Mdp3gScqzrEumnzKNXATMT?=
 =?us-ascii?q?5nfkNJr72Q6z5Yg/plF2xA6HplMfeLmyKD4+bELZYWtONhAj5omOJC/HQ617xV?=
 =?us-ascii?q?4TlERfNvnivSq99uo1e+neiOyjpoShxOqjlQiYKPvEViP7jZ95ZaVXbF+hIN8X?=
 =?us-ascii?q?ufCxAQq9R5Dd3vvvMY9t+avaT/OX9m7s7T+MoGHMvVYJaDLWYmGRnkAjjZCE0C?=
 =?us-ascii?q?VzH9Zk/FgEkItfiI6nyT5qMxqoftlJcAUbxKHAguHfMFC0hoEscBMb97U3Ulm7?=
 =?us-ascii?q?vdh8kNsynt5CLNTdlX68iUHsmZBu/ifXPA1eFJ?=
X-IronPort-Anti-Spam-Filtered: true
X-IronPort-Anti-Spam-Result: =?us-ascii?q?A0AFAAA32BBch0O0hNFjGwEBAQEDAQEBB?=
 =?us-ascii?q?wMBAQGBUQYBAQELAQGDaieMFF+LM4INFGiIF45AFIFYGQEBGBMBhzoiNAkNAQM?=
 =?us-ascii?q?BAQEBAQECARMBAQEIDQkIKS9CAQ4BgWQkAYJhAQEBAQIBAQIPIAEHPwUBCQEBC?=
 =?us-ascii?q?g4EBgklAwwSByEOBhMFFAmCf4FqAw0IAwEBmxSJWAEBAYIdiAcNghyMPBeBf4E?=
 =?us-ascii?q?RghRJNYJXgW+GFgKLLpUrLgmNNXCDJSMKAoFQiEOHJSyOfIlqAgQGBQITAYFGg?=
 =?us-ascii?q?g5wgzyCJAMXjh5xAYEEAQEhgTqIfyqCIwEB?=
X-IPAS-Result: =?us-ascii?q?A0AFAAA32BBch0O0hNFjGwEBAQEDAQEBBwMBAQGBUQYBAQE?=
 =?us-ascii?q?LAQGDaieMFF+LM4INFGiIF45AFIFYGQEBGBMBhzoiNAkNAQMBAQEBAQECARMBA?=
 =?us-ascii?q?QEIDQkIKS9CAQ4BgWQkAYJhAQEBAQIBAQIPIAEHPwUBCQEBCg4EBgklAwwSByE?=
 =?us-ascii?q?OBhMFFAmCf4FqAw0IAwEBmxSJWAEBAYIdiAcNghyMPBeBf4ERghRJNYJXgW+GF?=
 =?us-ascii?q?gKLLpUrLgmNNXCDJSMKAoFQiEOHJSyOfIlqAgQGBQITAYFGgg5wgzyCJAMXjh5?=
 =?us-ascii?q?xAYEEAQEhgTqIfyqCIwEB?=
X-IronPort-AV: E=Sophos;i="5.56,343,1539673200"; 
   d="scan'208";a="55565834"
X-Amp-Result: SKIPPED(no attachment in message)
X-Amp-File-Uploaded: False
Received: from vger.kernel.org ([209.132.180.67])
  by mtab.intel.com with ESMTP; 12 Dec 2018 01:49:16 -0800
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
        id S1726976AbeLLJtN (ORCPT <rfc822;like.xu@linux.intel.com>
        + 23 others); Wed, 12 Dec 2018 04:49:13 -0500
Received: from mx0a-001b2d01.pphosted.com ([148.163.156.1]:47760 "EHLO
        mx0a-001b2d01.pphosted.com" rhost-flags-OK-OK-OK-OK)
        by vger.kernel.org with ESMTP id S1726869AbeLLJtM (ORCPT
        <rfc822;linux-kernel@vger.kernel.org>);
        Wed, 12 Dec 2018 04:49:12 -0500
Received: from pps.filterd (m0098394.ppops.net [127.0.0.1])
        by mx0a-001b2d01.pphosted.com (8.16.0.22/8.16.0.22) with SMTP id wBC9lODP042295
        for <linux-kernel@vger.kernel.org>; Wed, 12 Dec 2018 04:49:11 -0500
Received: from e06smtp02.uk.ibm.com (e06smtp02.uk.ibm.com [195.75.94.98])
        by mx0a-001b2d01.pphosted.com with ESMTP id 2pax824yrp-1
        (version=TLSv1.2 cipher=AES256-GCM-SHA384 bits=256 verify=NOT)
        for <linux-kernel@vger.kernel.org>; Wed, 12 Dec 2018 04:49:10 -0500
Received: from localhost
        by e06smtp02.uk.ibm.com with IBM ESMTP SMTP Gateway: Authorized Use Only! Violators will be prosecuted
        for <linux-kernel@vger.kernel.org> from <schwidefsky@de.ibm.com>;
        Wed, 12 Dec 2018 09:49:07 -0000
Received: from b06cxnps4076.portsmouth.uk.ibm.com (9.149.109.198)
        by e06smtp02.uk.ibm.com (192.168.101.132) with IBM ESMTP SMTP Gateway: Authorized Use Only! Violators will be prosecuted;
        (version=TLSv1/SSLv3 cipher=AES256-GCM-SHA384 bits=256/256)
        Wed, 12 Dec 2018 09:49:02 -0000
Received: from d06av23.portsmouth.uk.ibm.com (d06av23.portsmouth.uk.ibm.com [9.149.105.59])
        by b06cxnps4076.portsmouth.uk.ibm.com (8.14.9/8.14.9/NCO v10.0) with ESMTP id wBC9n1eq2883888
        (version=TLSv1/SSLv3 cipher=DHE-RSA-AES256-GCM-SHA384 bits=256 verify=FAIL);
        Wed, 12 Dec 2018 09:49:02 GMT
Received: from d06av23.portsmouth.uk.ibm.com (unknown [127.0.0.1])
        by IMSVA (Postfix) with ESMTP id D5BA0A4059;
        Wed, 12 Dec 2018 09:49:01 +0000 (GMT)
Received: from d06av23.portsmouth.uk.ibm.com (unknown [127.0.0.1])
        by IMSVA (Postfix) with ESMTP id 60C30A4040;
        Wed, 12 Dec 2018 09:49:01 +0000 (GMT)
Received: from mschwideX1 (unknown [9.152.212.164])
        by d06av23.portsmouth.uk.ibm.com (Postfix) with ESMTP;
        Wed, 12 Dec 2018 09:49:01 +0000 (GMT)
Date: Wed, 12 Dec 2018 10:49:00 +0100
From: Martin Schwidefsky <schwidefsky@de.ibm.com>
To: Andy Lutomirski <luto@kernel.org>
Cc: Igor Stoppa <igor.stoppa@gmail.com>,
        linux-arch <linux-arch@vger.kernel.org>,
        linux-s390 <linux-s390@vger.kernel.org>,
        Heiko Carstens <heiko.carstens@de.ibm.com>,
        Benjamin Herrenschmidt <benh@kernel.crashing.org>,
        Kees Cook <keescook@chromium.org>,
        Matthew Wilcox <willy@infradead.org>,
        Igor Stoppa <igor.stoppa@huawei.com>,
        Nadav Amit <nadav.amit@gmail.com>,
        Peter Zijlstra <peterz@infradead.org>,
        Dave Hansen <dave.hansen@linux.intel.com>,
        linux-integrity <linux-integrity@vger.kernel.org>,
        Kernel Hardening <kernel-hardening@lists.openwall.com>,
        Linux-MM <linux-mm@kvack.org>,
        LKML <linux-kernel@vger.kernel.org>
Subject: Re: [PATCH 2/6] __wr_after_init: write rare for static allocation
In-Reply-To: <CALCETrVvoui0vksdt0Y9rdGL5ipEn_FtSXVVUFdH03ZC93cy_A@mail.gmail.com>
References: <20181204121805.4621-1-igor.stoppa@huawei.com>
        <20181204121805.4621-3-igor.stoppa@huawei.com>
        <CALCETrVvoui0vksdt0Y9rdGL5ipEn_FtSXVVUFdH03ZC93cy_A@mail.gmail.com>
X-Mailer: Claws Mail 3.13.2 (GTK+ 2.24.30; x86_64-pc-linux-gnu)
MIME-Version: 1.0
X-TM-AS-GCONF: 00
x-cbid: 18121209-0008-0000-0000-000002A03472
X-IBM-AV-DETECTION: SAVI=unused REMOTE=unused XFE=unused
x-cbparentid: 18121209-0009-0000-0000-0000220AB01B
Message-Id: <20181212104900.0af52c34@mschwideX1>
Content-Type: text/plain; charset=US-ASCII
Content-Transfer-Encoding: 8bit
X-Proofpoint-Virus-Version: vendor=fsecure engine=2.50.10434:,, definitions=2018-12-12_03:,,
 signatures=0
X-Proofpoint-Spam-Details: rule=outbound_notspam policy=outbound score=0 priorityscore=1501
 malwarescore=0 suspectscore=0 phishscore=0 bulkscore=0 spamscore=0
 clxscore=1015 lowpriorityscore=0 mlxscore=0 impostorscore=0
 mlxlogscore=999 adultscore=0 classifier=spam adjust=0 reason=mlx
 scancount=1 engine=8.0.1-1810050000 definitions=main-1812120086
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: <linux-kernel.vger.kernel.org>
X-Mailing-List: linux-kernel@vger.kernel.org

On Wed, 5 Dec 2018 15:13:56 -0800
Andy Lutomirski <luto@kernel.org> wrote:

> I added some s390 and powerpc people.
> 
> On Tue, Dec 4, 2018 at 4:18 AM Igor Stoppa <igor.stoppa@gmail.com> wrote:
> >
> > Implementation of write rare for statically allocated data, located in a
> > specific memory section through the use of the __write_rare label.
> >
> > The basic functions are:
> > - wr_memset(): write rare counterpart of memset()
> > - wr_memcpy(): write rare counterpart of memcpy()
> > - wr_assign(): write rare counterpart of the assignment ('=') operator
> > - wr_rcu_assign_pointer(): write rare counterpart of rcu_assign_pointer()
> >
> > The implementation is based on code from Andy Lutomirski and Nadav Amit
> > for patching the text on x86 [here goes reference to commits, once merged]
> >
> > The modification of write protected data is done through an alternate
> > mapping of the same pages, as writable.
> > This mapping is local to each core and is active only for the duration
> > of each write operation.
> > Local interrupts are disabled, while the alternate mapping is active.
> >
> > In theory, it could introduce a non-predictable delay, in a preemptible
> > system, however the amount of data to be altered is likely to be far
> > smaller than a page.
> >
> > Signed-off-by: Igor Stoppa <igor.stoppa@huawei.com>
> >
> > CC: Andy Lutomirski <luto@amacapital.net>
> > CC: Nadav Amit <nadav.amit@gmail.com>
> > CC: Matthew Wilcox <willy@infradead.org>
> > CC: Peter Zijlstra <peterz@infradead.org>
> > CC: Kees Cook <keescook@chromium.org>
> > CC: Dave Hansen <dave.hansen@linux.intel.com>
> > CC: linux-integrity@vger.kernel.org
> > CC: kernel-hardening@lists.openwall.com
> > CC: linux-mm@kvack.org
> > CC: linux-kernel@vger.kernel.org
> > ---
> >  include/linux/prmem.h | 133 ++++++++++++++++++++++++++++++++++++++++++
> >  init/main.c           |   2 +
> >  mm/Kconfig            |   4 ++
> >  mm/Makefile           |   1 +
> >  mm/prmem.c            | 124 +++++++++++++++++++++++++++++++++++++++
> >  5 files changed, 264 insertions(+)
> >  create mode 100644 include/linux/prmem.h
> >  create mode 100644 mm/prmem.c
> >
> > diff --git a/include/linux/prmem.h b/include/linux/prmem.h
> > new file mode 100644
> > index 000000000000..b0131c1f5dc0
> > --- /dev/null
> > +++ b/include/linux/prmem.h
> > @@ -0,0 +1,133 @@
> > +/* SPDX-License-Identifier: GPL-2.0 */
> > +/*
> > + * prmem.h: Header for memory protection library
> > + *
> > + * (C) Copyright 2018 Huawei Technologies Co. Ltd.
> > + * Author: Igor Stoppa <igor.stoppa@huawei.com>
> > + *
> > + * Support for:
> > + * - statically allocated write rare data
> > + */
> > +
> > +#ifndef _LINUX_PRMEM_H
> > +#define _LINUX_PRMEM_H
> > +
> > +#include <linux/set_memory.h>
> > +#include <linux/mm.h>
> > +#include <linux/vmalloc.h>
> > +#include <linux/string.h>
> > +#include <linux/slab.h>
> > +#include <linux/mutex.h>
> > +#include <linux/compiler.h>
> > +#include <linux/irqflags.h>
> > +
> > +/**
> > + * memtst() - test n bytes of the source to match the c value
> > + * @p: beginning of the memory to test
> > + * @c: byte to compare against
> > + * @len: amount of bytes to test
> > + *
> > + * Returns 0 on success, non-zero otherwise.
> > + */
> > +static inline int memtst(void *p, int c, __kernel_size_t len)
> > +{
> > +       __kernel_size_t i;
> > +
> > +       for (i = 0; i < len; i++) {
> > +               u8 d =  *(i + (u8 *)p) - (u8)c;
> > +
> > +               if (unlikely(d))
> > +                       return d;
> > +       }
> > +       return 0;
> > +}
> > +
> > +
> > +#ifndef CONFIG_PRMEM
> > +
> > +static inline void *wr_memset(void *p, int c, __kernel_size_t len)
> > +{
> > +       return memset(p, c, len);
> > +}
> > +
> > +static inline void *wr_memcpy(void *p, const void *q, __kernel_size_t size)
> > +{
> > +       return memcpy(p, q, size);
> > +}
> > +
> > +#define wr_assign(var, val)    ((var) = (val))
> > +
> > +#define wr_rcu_assign_pointer(p, v)    \
> > +       rcu_assign_pointer(p, v)
> > +
> > +#else
> > +
> > +enum wr_op_type {
> > +       WR_MEMCPY,
> > +       WR_MEMSET,
> > +       WR_RCU_ASSIGN_PTR,
> > +       WR_OPS_NUMBER,
> > +};
> > +
> > +void *__wr_op(unsigned long dst, unsigned long src, __kernel_size_t len,
> > +             enum wr_op_type op);
> > +
> > +/**
> > + * wr_memset() - sets n bytes of the destination to the c value
> > + * @p: beginning of the memory to write to
> > + * @c: byte to replicate
> > + * @len: amount of bytes to copy
> > + *
> > + * Returns true on success, false otherwise.
> > + */
> > +static inline void *wr_memset(void *p, int c, __kernel_size_t len)
> > +{
> > +       return __wr_op((unsigned long)p, (unsigned long)c, len, WR_MEMSET);
> > +}
> > +
> > +/**
> > + * wr_memcpy() - copyes n bytes from source to destination
> > + * @dst: beginning of the memory to write to
> > + * @src: beginning of the memory to read from
> > + * @n_bytes: amount of bytes to copy
> > + *
> > + * Returns pointer to the destination
> > + */
> > +static inline void *wr_memcpy(void *p, const void *q, __kernel_size_t size)
> > +{
> > +       return __wr_op((unsigned long)p, (unsigned long)q, size, WR_MEMCPY);
> > +}
> > +
> > +/**
> > + * wr_assign() - sets a write-rare variable to a specified value
> > + * @var: the variable to set
> > + * @val: the new value
> > + *
> > + * Returns: the variable
> > + *
> > + * Note: it might be possible to optimize this, to use wr_memset in some
> > + * cases (maybe with NULL?).
> > + */
> > +
> > +#define wr_assign(var, val) ({                 \
> > +       typeof(var) tmp = (typeof(var))val;     \
> > +                                               \
> > +       wr_memcpy(&var, &tmp, sizeof(var));     \
> > +       var;                                    \
> > +})
> > +
> > +/**
> > + * wr_rcu_assign_pointer() - initialize a pointer in rcu mode
> > + * @p: the rcu pointer
> > + * @v: the new value
> > + *
> > + * Returns the value assigned to the rcu pointer.
> > + *
> > + * It is provided as macro, to match rcu_assign_pointer()
> > + */
> > +#define wr_rcu_assign_pointer(p, v) ({                                 \
> > +       __wr_op((unsigned long)&p, v, sizeof(p), WR_RCU_ASSIGN_PTR);    \
> > +       p;                                                              \
> > +})
> > +#endif
> > +#endif
> > diff --git a/init/main.c b/init/main.c
> > index a461150adfb1..a36f2e54f937 100644
> > --- a/init/main.c
> > +++ b/init/main.c
> > @@ -498,6 +498,7 @@ void __init __weak thread_stack_cache_init(void)
> >  void __init __weak mem_encrypt_init(void) { }
> >
> >  void __init __weak poking_init(void) { }
> > +void __init __weak wr_poking_init(void) { }
> >
> >  bool initcall_debug;
> >  core_param(initcall_debug, initcall_debug, bool, 0644);
> > @@ -734,6 +735,7 @@ asmlinkage __visible void __init start_kernel(void)
> >         delayacct_init();
> >
> >         poking_init();
> > +       wr_poking_init();
> >         check_bugs();
> >
> >         acpi_subsystem_init();
> > diff --git a/mm/Kconfig b/mm/Kconfig
> > index d85e39da47ae..9b09339c027f 100644
> > --- a/mm/Kconfig
> > +++ b/mm/Kconfig
> > @@ -142,6 +142,10 @@ config ARCH_DISCARD_MEMBLOCK
> >  config MEMORY_ISOLATION
> >         bool
> >
> > +config PRMEM
> > +       def_bool n
> > +       depends on STRICT_KERNEL_RWX && X86_64
> > +
> >  #
> >  # Only be set on architectures that have completely implemented memory hotplug
> >  # feature. If you are not sure, don't touch it.
> > diff --git a/mm/Makefile b/mm/Makefile
> > index d210cc9d6f80..ef3867c16ce0 100644
> > --- a/mm/Makefile
> > +++ b/mm/Makefile
> > @@ -58,6 +58,7 @@ obj-$(CONFIG_SPARSEMEM)       += sparse.o
> >  obj-$(CONFIG_SPARSEMEM_VMEMMAP) += sparse-vmemmap.o
> >  obj-$(CONFIG_SLOB) += slob.o
> >  obj-$(CONFIG_MMU_NOTIFIER) += mmu_notifier.o
> > +obj-$(CONFIG_PRMEM) += prmem.o
> >  obj-$(CONFIG_KSM) += ksm.o
> >  obj-$(CONFIG_PAGE_POISONING) += page_poison.o
> >  obj-$(CONFIG_SLAB) += slab.o
> > diff --git a/mm/prmem.c b/mm/prmem.c
> > new file mode 100644
> > index 000000000000..e8ab76701831
> > --- /dev/null
> > +++ b/mm/prmem.c
> > @@ -0,0 +1,124 @@
> > +// SPDX-License-Identifier: GPL-2.0
> > +/*
> > + * prmem.c: Memory Protection Library
> > + *
> > + * (C) Copyright 2017-2018 Huawei Technologies Co. Ltd.
> > + * Author: Igor Stoppa <igor.stoppa@huawei.com>
> > + */
> > +
> > +#include <linux/mm.h>
> > +#include <linux/string.h>
> > +#include <linux/compiler.h>
> > +#include <linux/slab.h>
> > +#include <linux/mmu_context.h>
> > +#include <linux/rcupdate.h>
> > +#include <linux/prmem.h>
> > +
> > +static __ro_after_init bool wr_ready;
> > +static __ro_after_init struct mm_struct *wr_poking_mm;
> > +static __ro_after_init unsigned long wr_poking_base;
> > +
> > +/*
> > + * The following two variables are statically allocated by the linker
> > + * script at the the boundaries of the memory region (rounded up to
> > + * multiples of PAGE_SIZE) reserved for __wr_after_init.
> > + */
> > +extern long __start_wr_after_init;
> > +extern long __end_wr_after_init;
> > +
> > +static inline bool is_wr_after_init(unsigned long ptr, __kernel_size_t size)
> > +{
> > +       unsigned long start = (unsigned long)&__start_wr_after_init;
> > +       unsigned long end = (unsigned long)&__end_wr_after_init;
> > +       unsigned long low = ptr;
> > +       unsigned long high = ptr + size;
> > +
> > +       return likely(start <= low && low <= high && high <= end);
> > +}
> > +
> > +
> > +void *__wr_op(unsigned long dst, unsigned long src, __kernel_size_t len,
> > +             enum wr_op_type op)
> > +{  
> 
> You might end up wanting something like:
> 
> #ifdef __arch_wr_op
> return __arch_wr_op(...);
> #endif
> 
> if an arch (s390? powerpc?) decides to have a totally different
> implementation of this.
> 
> Hi s390 and powerpc people: it would be nice if this generic
> implementation *worked* on your architectures and that it will allow
> you to add some straightforward way to add a better arch-specific
> implementation if you think that would be better.

As the code is right now I can guarantee that it will not work on s390.

> > +       temporary_mm_state_t prev;
> > +       unsigned long flags;
> > +       unsigned long offset;
> > +       unsigned long wr_poking_addr;
> > +
> > +       /* Confirm that the writable mapping exists. */
> > +       BUG_ON(!wr_ready);
> > +
> > +       if (WARN_ONCE(op >= WR_OPS_NUMBER, "Invalid WR operation.") ||
> > +           WARN_ONCE(!is_wr_after_init(dst, len), "Invalid WR range."))
> > +               return (void *)dst;
> > +
> > +       offset = dst - (unsigned long)&__start_wr_after_init;
> > +       wr_poking_addr = wr_poking_base + offset;
> > +       local_irq_save(flags);
> > +       prev = use_temporary_mm(wr_poking_mm);
> > +
> > +       kasan_disable_current();
> > +       if (op == WR_MEMCPY)
> > +               memcpy((void *)wr_poking_addr, (void *)src, len);
> > +       else if (op == WR_MEMSET)
> > +               memset((u8 *)wr_poking_addr, (u8)src, len);
> > +       else if (op == WR_RCU_ASSIGN_PTR)
> > +               /* generic version of rcu_assign_pointer */
> > +               smp_store_release((void **)wr_poking_addr,
> > +                                 RCU_INITIALIZER((void **)src));
> > +       kasan_enable_current();  
> 
> Hmm.  I suspect this will explode quite badly on sane architectures
> like s390.  (In my book, despite how weird s390 is, it has a vastly
> nicer model of "user" memory than any other architecture I know
> of...).  I think you should use copy_to_user(), etc, instead.  I'm not
> entirely sure what the best smp_store_release() replacement is.
> Making this change may also mean you can get rid of the
> kasan_disable_current().

use_temporary_mm() replaces the *user* mm, for s390 this is completely
independent from the kernel mm (different control register cr1 vs cr7).
The wr_poking_addr is not available when running in the kernel address
space.

> > +
> > +       barrier(); /* XXX redundant? */  
> 
> I think it's redundant.  If unuse_temporary_mm() allows earlier stores
> to hit the wrong address space, then something is very very wrong, and
> something is also very very wrong if the optimizer starts moving
> stores across a function call that is most definitely a barrier.
> 
> > +
> > +       unuse_temporary_mm(prev);
> > +       /* XXX make the verification optional? */
> > +       if (op == WR_MEMCPY)
> > +               BUG_ON(memcmp((void *)dst, (void *)src, len));
> > +       else if (op == WR_MEMSET)
> > +               BUG_ON(memtst((void *)dst, (u8)src, len));
> > +       else if (op == WR_RCU_ASSIGN_PTR)
> > +               BUG_ON(*(unsigned long *)dst != src);  
> 
> Hmm.  If you allowed cmpxchg or even plain xchg, then these bug_ons
> would be thoroughly buggy, but maybe they're okay.  But they should,
> at most, be WARN_ON_ONCE(), given that you can trigger them by writing
> the same addresses from two threads at once, and this isn't even
> entirely obviously bogus given the presence of smp_store_release().
> 
> > +       local_irq_restore(flags);
> > +       return (void *)dst;
> > +}
> > +
> > +struct mm_struct *copy_init_mm(void);
> > +void __init wr_poking_init(void)
> > +{
> > +       unsigned long start = (unsigned long)&__start_wr_after_init;
> > +       unsigned long end = (unsigned long)&__end_wr_after_init;
> > +       unsigned long i;
> > +       unsigned long wr_range;
> > +
> > +       wr_poking_mm = copy_init_mm();
> > +       BUG_ON(!wr_poking_mm);
> > +
> > +       /* XXX What if it's too large to fit in the task unmapped mem? */
> > +       wr_range = round_up(end - start, PAGE_SIZE);
> > +
> > +       /* Randomize the poking address base*/
> > +       wr_poking_base = TASK_UNMAPPED_BASE +
> > +               (kaslr_get_random_long("Write Rare Poking") & PAGE_MASK) %
> > +               (TASK_SIZE - (TASK_UNMAPPED_BASE + wr_range));

The wr_poking_base address is a user space address, no? This will be usable
only with the uaccess primitives on s390.

> > +
> > +       /* Create alternate mapping for the entire wr_after_init range. */
> > +       for (i = start; i < end; i += PAGE_SIZE) {
> > +               struct page *page;
> > +               spinlock_t *ptl;
> > +               pte_t pte;
> > +               pte_t *ptep;
> > +               unsigned long wr_poking_addr;
> > +
> > +               BUG_ON(!(page = virt_to_page(i)));
> > +               wr_poking_addr = i - start + wr_poking_base;
> > +
> > +               /* The lock is not needed, but avoids open-coding. */
> > +               ptep = get_locked_pte(wr_poking_mm, wr_poking_addr, &ptl);
> > +               VM_BUG_ON(!ptep);
> > +
> > +               pte = mk_pte(page, PAGE_KERNEL);
> > +               set_pte_at(wr_poking_mm, wr_poking_addr, ptep, pte);
> > +               spin_unlock(ptl);
> > +       }
> > +       wr_ready = true;
> > +}
> > --
> > 2.19.1
> >  
> 


-- 
blue skies,
   Martin.

"Reality continues to ruin my life." - Calvin.

