Return-Path: <linux-kernel-owner@vger.kernel.org>
Delivered-To: unknown
Received: from linux.intel.com (10.54.29.200:995) by likexu-workstation with
  POP3-SSL; 12 Dec 2018 08:53:29 -0000
X-Original-To: like.xu@linux.intel.com
Delivered-To: like.xu@linux.intel.com
Received: from orsmga008.jf.intel.com (orsmga008.jf.intel.com [10.7.209.65])
	(using TLSv1.2 with cipher ECDHE-RSA-AES256-GCM-SHA384 (256/256 bits))
	(No client certificate requested)
	by linux.intel.com (Postfix) with ESMTPS id 6B0D858079D;
	Tue, 11 Dec 2018 09:41:08 -0800 (PST)
Received: from fmsmga103.fm.intel.com ([10.1.193.90])
  by orsmga008-1.jf.intel.com with ESMTP/TLS/DHE-RSA-AES256-GCM-SHA384; 11 Dec 2018 09:41:07 -0800
X-SG-BADATTACHMENTNOREPLY: True
IronPort-PHdr: =?us-ascii?q?9a23=3AXjx3UxQe3P50wy7PH1AhvOqWJNpsv+yvbD5Q0YIu?=
 =?us-ascii?q?jvd0So/mwa64YRWOt8tkgFKBZ4jH8fUM07OQ7/iwHzRYqb+681k6OKRWUBEEjc?=
 =?us-ascii?q?hE1ycBO+WiTXPBEfjxciYhF95DXlI2t1uyMExSBdqsLwaK+i764jEdAAjwOhRo?=
 =?us-ascii?q?LerpBIHSk9631+ev8JHPfglEnjWwba9xIRmssQndqtQdjJd/JKo21hbHuGZDdf?=
 =?us-ascii?q?5MxWNvK1KTnhL86dm18ZV+7SleuO8v+tBZX6nicKs2UbJXDDI9M2Ao/8LrrgXM?=
 =?us-ascii?q?TRGO5nQHTGoblAdDDhXf4xH7WpfxtTb6tvZ41SKHM8D6Uaw4VDK/5KpwVhTmlD?=
 =?us-ascii?q?kIOCI48GHPi8x/kqRboA66pxdix4LYeZyZOOZicq/Ye94RWGhPUdtLVyFZDI2y?=
 =?us-ascii?q?b5UBAfcbPeZWoIbyu0YBohmwCgevH+Pv0j1Fi2Tq3aEmyektDR3K0RY+E98IrX?=
 =?us-ascii?q?/arM/1NKAXUe2twqXG1y/Mb+5S2Tzg54bEaA0qr/aQUrx1b8XRz08vGB3Fj1me?=
 =?us-ascii?q?tIfoOCuV2f4Qs2if6upvSeGvhnUjqwFwpDiv28gthpPIho0Oz1DI7zl2wIEwJd?=
 =?us-ascii?q?ChTkNwfN2qEINIui2EK4d7RtkuT3xmtSok0LEKpJ22cDQQxJkmxRPTc/iKf5KK?=
 =?us-ascii?q?7x7/TuqcIil0iGhrdb+8gRu57FKuxffmVsau1VZHtipFncfItnAKzxHT9MeHRe?=
 =?us-ascii?q?Vn/ku72jaAyRrT6udaLkAwj6bbLIQhwrEompoSt0TMADP2lV3ogKOKckgo4PWk?=
 =?us-ascii?q?5ur5brn8u5ORNJN4hhv/P6ksgsC/BP43MgkKX2iV4+S807jj8FX9QLVLiP02j6?=
 =?us-ascii?q?bYvInZJcsFvK65BRFa0oI65xa4ATam1soXnWMcIVJbdxKIkZLpN0vNIP/mF/e/?=
 =?us-ascii?q?hUqjkDNxy/DBJL3hDY3BLmLfn7f5YbZ990lcxRI3zdBe5JJbFKsNIf3uWkLqsN?=
 =?us-ascii?q?zYDxk5MxG7wur9CdV90J8eVnyLAqODLKzStlqI7Po1I+aQfI8VpCr9K/896v7u?=
 =?us-ascii?q?l3A5mEMdcrOu3ZcNaHC4A+5pI0OWYXf3htcBEGEKvhcxTeDwiV2CVyJTaGi2X6?=
 =?us-ascii?q?4m+j47D4emB5/ZRo+xmLyBwDu7HppOa2BEDVCDD23kd4aDW/cKbiKSJdRskjgF?=
 =?us-ascii?q?VbinVo8g2guitA78y7p7MOXU/jcUuo7k1Nhw/+fTjw099SRoD8SB1GGAV3t7nn?=
 =?us-ascii?q?gIRz8x36Bzu1Z9xU2B0aVjh/xYFNpT5+5GUwsgNJ7cyfB6BM72Wg7bYtiJT1Om?=
 =?us-ascii?q?SM28AT4tVtIx38MOY0FlFtWhlB/D2TCmA7sUl7ORApw0/bnR33zwJ8Z71nbH27?=
 =?us-ascii?q?Mtj1ggQstTK2KmgrRz+BTUB47Mi0+ZjbqldbwA3C7R82eO1XeBs1tGUAFuS6nF?=
 =?us-ascii?q?XWoQZk3Nrdvn4EPOSLuuCbciMgtF0sOCLqpKatv0jVRJXvvjOdLeY36vlGe0Hx?=
 =?us-ascii?q?qH2rSMbI/ycWUHwCrdEFQEkxwU/XueKAcxHDmhrHzEADxuD13vZVjs/vd4qH6g?=
 =?us-ascii?q?Sk80zgeKb1Bu1rav+x4Vg+CcRO0X3r4epCghrDB0Fk6n393KE9qAuxZhfKJEbN?=
 =?us-ascii?q?Mh4VdH0GXZtxB9Pp2gNaximkQScwNtv0Pq1hV3DIpAnNMurHMrygpyNK2Z3ElA?=
 =?us-ascii?q?dzOewZD/JLnXJnPu8xCobq7cwkve38qO+qcT9PQ4rE3usxutFkU8/HRozdlU32?=
 =?us-ascii?q?GH6ZXXEQUdS5TxUkUw9xhkvLzaZig954XJ1XxjK6W0sznC2843C+sh0BqvY9Bf?=
 =?us-ascii?q?MKacHg/oD8IaH9SuKPAtm1WxbhMEIfpe+7IuM8Knd/uJwqirPOl7kTKijGRH5p?=
 =?us-ascii?q?19002W+yp9TO7Iw4gKw/WC0gSbUDf8iU+rstrrloBceTESAm2/xDD+BI5QeqJ9?=
 =?us-ascii?q?Z5wLBnqpI8GtwNVxmYTtW39B+FG/HVwG3NKmdgSIb1z62w1dzkAXoX2hmSulwD?=
 =?us-ascii?q?14iTAprqyD3CPQx+TubgYIOmlORGN6l1fjPZC0j8wGXEivdwUolBql6Vz6xqRB?=
 =?us-ascii?q?v6R/Mm/TTFxMfyj3KWFiT6SxuqCDY85J9JMnryFXXP6gblCdT773uwEa3D/7H2?=
 =?us-ascii?q?tC2DA7cCmnupfjkBxgi2KdL3FzoGDCec5qxhff593cRfhP0ToAXyR4jTjXBl6h?=
 =?us-ascii?q?P9im59mUlpHDsvygWGKlTJFcbS7rzYaYviuh+WJqGQG/n+y0mtD/EQk1yyj728?=
 =?us-ascii?q?NoVSXJqhbxeY3r16W8MeJ6cUhkHl7868xmGo5glos8no0f2X8fhp+N53oIjX/z?=
 =?us-ascii?q?MclH2aL5dHcNRiQEw9/P7AjlxU1sNHSJx43iW3WZw8thYcS6Y2wM1iI86cBKFL?=
 =?us-ascii?q?mb7LhekSRppVq4qBrbYeJhkTcF1fsu9HkajvkMuAoszSWSGKoeHEdGMiz3ixSH?=
 =?us-ascii?q?8cq+o75Ja2a1fri9z05+ndGnDLGfrQBQQnf5epE+HSBu6sVzKk7D0Hr26ov8Yt?=
 =?us-ascii?q?nfccoTtgGIkxfHl+VVNJUxlv8QiStmI239u2Aly/UgjRxvxpy6uImHK2Nw/KO2?=
 =?us-ascii?q?GBJYNzv1Z98N9THpl6pRgsGW34W3FJV7BjoLRIfoTe6vED8KrvvoLQGOEDkhqn?=
 =?us-ascii?q?uBHbrfABSS6ENnr3LJDpCqOGubJHgfzdV+WhadIFZTjxwTXDU/hpQ5DBylxNT9?=
 =?us-ascii?q?cEdl4TAc/lz4pQFJyu12LBnzSHvfqB2rajcpS5ifMRxW4RtZ50rONcye7+RzHz?=
 =?us-ascii?q?xX/5G7rQyNLHCbaBpMDW0TRkOEAFXjNKG05dbc6+iYGva+L/zWbLSOruxeSu6I?=
 =?us-ascii?q?xY+13Ytg5TqMLcKPPn9tD/Ag3kpDXHZ5G9nWmjkVSiwXkT7NYNCfpBum5iJ3qc?=
 =?us-ascii?q?W/+uzxWA3z/YuPF6dSMdJ39hC2n6iDNu2QhCV4KTpC1ZMM33jIyLcB014IliFu?=
 =?us-ascii?q?bCKgEbABtS7LUaLRlbVbDx8dayNvKsRI67gw0RVKOc7ektn1zKJ3juYpC1dZUl?=
 =?us-ascii?q?zsgtumZdERLGGnKlzGBFyHNLCHJTDQx8H3YKW8SaBfjelOth2wvyqbHFHnPjiZ?=
 =?us-ascii?q?izbpUBWvO/lWjC6HJBxepJ29chF1BGj/TdLmbwe3P8NtgTIqwb07mHXKOHUYMT?=
 =?us-ascii?q?h9dUNNs7KR4TlZgvV5B2xO8H5lIfOYlCae6unSMowWvudzAiRoi+Ja52w3yrtP?=
 =?us-ascii?q?4yFCQfx1mS3SocZvolGmiOaPzDVnXQFKqjZKgoKLoEpjNb/Y9plGRXbL4hYN4X?=
 =?us-ascii?q?+MBBQNots2QuHo7ptdwNHUiKP6Ln9r9d7O78YeT/PVJd2GN2BpZRDoFzPdFxot?=
 =?us-ascii?q?ST+tKH3FgEpcgLee+yvGlJUironQn88WQ6JfUVc2PvcbDFl1Wt0IJdF8WTZ3v6?=
 =?us-ascii?q?SciZtC3XOjqFH8Ao1/tbPKUPSfEL+nfC6QkL1BbBggxbL+MJRVN4f+nUdlbw8p?=
 =?us-ascii?q?z8zxB0PMUIUV8WVaZQgurRAIqSAmQw=3D=3D?=
X-IronPort-Anti-Spam-Filtered: true
X-IronPort-Anti-Spam-Result: =?us-ascii?q?A0ADAACh9Q9ch0O0hNFkGgEBAQEBAgEBA?=
 =?us-ascii?q?QEHAgEBAQGBUgQBAQEBCwGDayeMc4sxgg0UkkKEfIFzEgEBGBMBhy4iNQgNAQM?=
 =?us-ascii?q?BAQEBAQECARMBAQEIDQkIKS+CNiQBgmIBAQEDAQIPFRM/BgkBAQoYCSUDDAUYM?=
 =?us-ascii?q?RMFHYJ/ggIDAps0iVgBAQGBajOFMYR9jDsRBoFAP4EQAYMSilwCiTuBcIURkD8?=
 =?us-ascii?q?HAgKRRAsYkUAsmGACBAYFAhMBgUgCggpwFYIIgR+CJxeOPlGBBQEBIYpCAQE?=
X-IPAS-Result: =?us-ascii?q?A0ADAACh9Q9ch0O0hNFkGgEBAQEBAgEBAQEHAgEBAQGBUgQ?=
 =?us-ascii?q?BAQEBCwGDayeMc4sxgg0UkkKEfIFzEgEBGBMBhy4iNQgNAQMBAQEBAQECARMBA?=
 =?us-ascii?q?QEIDQkIKS+CNiQBgmIBAQEDAQIPFRM/BgkBAQoYCSUDDAUYMRMFHYJ/ggIDAps?=
 =?us-ascii?q?0iVgBAQGBajOFMYR9jDsRBoFAP4EQAYMSilwCiTuBcIURkD8HAgKRRAsYkUAsm?=
 =?us-ascii?q?GACBAYFAhMBgUgCggpwFYIIgR+CJxeOPlGBBQEBIYpCAQE?=
X-IronPort-AV: E=Sophos;i="5.56,343,1539673200"; 
   d="scan'208";a="55459046"
X-Amp-Result: UNKNOWN
X-Amp-Original-Verdict: FILE UNKNOWN
X-Amp-File-Uploaded: False
Received: from vger.kernel.org ([209.132.180.67])
  by mtab.intel.com with ESMTP; 11 Dec 2018 09:41:05 -0800
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
        id S1726658AbeLKRlD (ORCPT <rfc822;like.xu@linux.intel.com>
        + 23 others); Tue, 11 Dec 2018 12:41:03 -0500
Received: from mx0a-001b2d01.pphosted.com ([148.163.156.1]:55248 "EHLO
        mx0a-001b2d01.pphosted.com" rhost-flags-OK-OK-OK-OK)
        by vger.kernel.org with ESMTP id S1726241AbeLKRlC (ORCPT
        <rfc822;linux-kernel@vger.kernel.org>);
        Tue, 11 Dec 2018 12:41:02 -0500
Received: from pps.filterd (m0098404.ppops.net [127.0.0.1])
        by mx0a-001b2d01.pphosted.com (8.16.0.22/8.16.0.22) with SMTP id wBBHZWYk070012
        for <linux-kernel@vger.kernel.org>; Tue, 11 Dec 2018 12:41:01 -0500
Received: from e16.ny.us.ibm.com (e16.ny.us.ibm.com [129.33.205.206])
        by mx0a-001b2d01.pphosted.com with ESMTP id 2pag955bu9-1
        (version=TLSv1.2 cipher=AES256-GCM-SHA384 bits=256 verify=NOT)
        for <linux-kernel@vger.kernel.org>; Tue, 11 Dec 2018 12:41:01 -0500
Received: from localhost
        by e16.ny.us.ibm.com with IBM ESMTP SMTP Gateway: Authorized Use Only! Violators will be prosecuted
        for <linux-kernel@vger.kernel.org> from <paulmck@linux.vnet.ibm.com>;
        Tue, 11 Dec 2018 17:41:00 -0000
Received: from b01cxnp22035.gho.pok.ibm.com (9.57.198.25)
        by e16.ny.us.ibm.com (146.89.104.203) with IBM ESMTP SMTP Gateway: Authorized Use Only! Violators will be prosecuted;
        (version=TLSv1/SSLv3 cipher=AES256-GCM-SHA384 bits=256/256)
        Tue, 11 Dec 2018 17:40:57 -0000
Received: from b01ledav003.gho.pok.ibm.com (b01ledav003.gho.pok.ibm.com [9.57.199.108])
        by b01cxnp22035.gho.pok.ibm.com (8.14.9/8.14.9/NCO v10.0) with ESMTP id wBBHeuMQ18940092
        (version=TLSv1/SSLv3 cipher=DHE-RSA-AES256-GCM-SHA384 bits=256 verify=FAIL);
        Tue, 11 Dec 2018 17:40:56 GMT
Received: from b01ledav003.gho.pok.ibm.com (unknown [127.0.0.1])
        by IMSVA (Postfix) with ESMTP id 9F441B205F;
        Tue, 11 Dec 2018 17:40:56 +0000 (GMT)
Received: from b01ledav003.gho.pok.ibm.com (unknown [127.0.0.1])
        by IMSVA (Postfix) with ESMTP id 6FB0FB2064;
        Tue, 11 Dec 2018 17:40:56 +0000 (GMT)
Received: from paulmck-ThinkPad-W541 (unknown [9.70.82.38])
        by b01ledav003.gho.pok.ibm.com (Postfix) with ESMTP;
        Tue, 11 Dec 2018 17:40:56 +0000 (GMT)
Received: by paulmck-ThinkPad-W541 (Postfix, from userid 1000)
        id 862CF16C2A9B; Tue, 11 Dec 2018 09:40:56 -0800 (PST)
Date: Tue, 11 Dec 2018 09:40:56 -0800
From: "Paul E. McKenney" <paulmck@linux.ibm.com>
To: Sebastian Andrzej Siewior <bigeasy@linutronix.de>
Cc: linux-kernel@vger.kernel.org,
        Lai Jiangshan <jiangshanlai@gmail.com>,
        Josh Triplett <josh@joshtriplett.org>,
        Steven Rostedt <rostedt@goodmis.org>,
        Mathieu Desnoyers <mathieu.desnoyers@efficios.com>,
        Joel Fernandes <joel@joelfernandes.org>, tglx@linutronix.de
Subject: Re: [PATCH] srcu: Remove srcu_queue_delayed_work_on()
Reply-To: paulmck@linux.ibm.com
References: <20181211111238.13474-1-bigeasy@linutronix.de>
MIME-Version: 1.0
Content-Type: text/plain; charset=us-ascii
Content-Disposition: inline
In-Reply-To: <20181211111238.13474-1-bigeasy@linutronix.de>
User-Agent: Mutt/1.5.21 (2010-09-15)
X-TM-AS-GCONF: 00
x-cbid: 18121117-0072-0000-0000-000003D7D313
X-IBM-SpamModules-Scores: 
X-IBM-SpamModules-Versions: BY=3.00010214; HX=3.00000242; KW=3.00000007;
 PH=3.00000004; SC=3.00000270; SDB=6.01130301; UDB=6.00582089; IPR=6.00910434;
 MB=3.00024656; MTD=3.00000008; XFM=3.00000015; UTC=2018-12-11 17:40:59
X-IBM-AV-DETECTION: SAVI=unused REMOTE=unused XFE=unused
x-cbparentid: 18121117-0073-0000-0000-00004A688C44
Message-Id: <20181211174056.GM4170@linux.ibm.com>
X-Proofpoint-Virus-Version: vendor=fsecure engine=2.50.10434:,, definitions=2018-12-11_05:,,
 signatures=0
X-Proofpoint-Spam-Details: rule=outbound_notspam policy=outbound score=0 priorityscore=1501
 malwarescore=0 suspectscore=0 phishscore=0 bulkscore=0 spamscore=0
 clxscore=1015 lowpriorityscore=0 mlxscore=0 impostorscore=0
 mlxlogscore=999 adultscore=0 classifier=spam adjust=0 reason=mlx
 scancount=1 engine=8.0.1-1810050000 definitions=main-1812110158
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: <linux-kernel.vger.kernel.org>
X-Mailing-List: linux-kernel@vger.kernel.org

On Tue, Dec 11, 2018 at 12:12:38PM +0100, Sebastian Andrzej Siewior wrote:
> srcu_queue_delayed_work_on() disables preemption (and therefore CPU
> hotplug in RCU's case) and then checks based on its own accounting if a
> CPU is online. If the CPU is online it uses queue_delayed_work_on()
> otherwise it fallbacks to queue_delayed_work().
> The problem here is that queue_work() on -RT does not work with disabled
> preemption.
> 
> queue_work_on() works also on an offlined CPU. queue_delayed_work_on()
> has the problem that it is possible to program a timer on an offlined
> CPU. This timer will fire once the CPU is online again. But until then,
> the timer remains programmed and nothing will happen.
> 
> Add a local timer which will fire (as requested per delay) on the local
> CPU and then enqueue the work on the specific CPU.
> 
> RCUtorture testing with SRCU-P for 24h showed no problems.
> 
> Signed-off-by: Sebastian Andrzej Siewior <bigeasy@linutronix.de>

Queued and pushed, thank you!

						Thanx, Paul

> ---
>  include/linux/srcutree.h |  3 ++-
>  kernel/rcu/srcutree.c    | 57 ++++++++++++++++++----------------------
>  kernel/rcu/tree.c        |  4 ---
>  kernel/rcu/tree.h        |  8 ------
>  4 files changed, 27 insertions(+), 45 deletions(-)
> 
> diff --git a/include/linux/srcutree.h b/include/linux/srcutree.h
> index 6f292bd3e7db7..0faa978c98807 100644
> --- a/include/linux/srcutree.h
> +++ b/include/linux/srcutree.h
> @@ -45,7 +45,8 @@ struct srcu_data {
>  	unsigned long srcu_gp_seq_needed;	/* Furthest future GP needed. */
>  	unsigned long srcu_gp_seq_needed_exp;	/* Furthest future exp GP. */
>  	bool srcu_cblist_invoking;		/* Invoking these CBs? */
> -	struct delayed_work work;		/* Context for CB invoking. */
> +	struct timer_list delay_work;		/* Delay for CB invoking */
> +	struct work_struct work;		/* Context for CB invoking. */
>  	struct rcu_head srcu_barrier_head;	/* For srcu_barrier() use. */
>  	struct srcu_node *mynode;		/* Leaf srcu_node. */
>  	unsigned long grpmask;			/* Mask for leaf srcu_node */
> diff --git a/kernel/rcu/srcutree.c b/kernel/rcu/srcutree.c
> index 3600d88d8956b..7f041f2435df9 100644
> --- a/kernel/rcu/srcutree.c
> +++ b/kernel/rcu/srcutree.c
> @@ -58,6 +58,7 @@ static bool __read_mostly srcu_init_done;
>  static void srcu_invoke_callbacks(struct work_struct *work);
>  static void srcu_reschedule(struct srcu_struct *ssp, unsigned long delay);
>  static void process_srcu(struct work_struct *work);
> +static void srcu_delay_timer(struct timer_list *t);
>  
>  /* Wrappers for lock acquisition and release, see raw_spin_lock_rcu_node(). */
>  #define spin_lock_rcu_node(p)					\
> @@ -156,7 +157,8 @@ static void init_srcu_struct_nodes(struct srcu_struct *ssp, bool is_static)
>  			snp->grphi = cpu;
>  		}
>  		sdp->cpu = cpu;
> -		INIT_DELAYED_WORK(&sdp->work, srcu_invoke_callbacks);
> +		INIT_WORK(&sdp->work, srcu_invoke_callbacks);
> +		timer_setup(&sdp->delay_work, srcu_delay_timer, 0);
>  		sdp->ssp = ssp;
>  		sdp->grpmask = 1 << (cpu - sdp->mynode->grplo);
>  		if (is_static)
> @@ -386,13 +388,19 @@ void _cleanup_srcu_struct(struct srcu_struct *ssp, bool quiesced)
>  	} else {
>  		flush_delayed_work(&ssp->work);
>  	}
> -	for_each_possible_cpu(cpu)
> +	for_each_possible_cpu(cpu) {
> +		struct srcu_data *sdp = per_cpu_ptr(ssp->sda, cpu);
> +
>  		if (quiesced) {
> -			if (WARN_ON(delayed_work_pending(&per_cpu_ptr(ssp->sda, cpu)->work)))
> +			if (WARN_ON(timer_pending(&sdp->delay_work)))
> +				return; /* Just leak it! */
> +			if (WARN_ON(work_pending(&sdp->work)))
>  				return; /* Just leak it! */
>  		} else {
> -			flush_delayed_work(&per_cpu_ptr(ssp->sda, cpu)->work);
> +			del_timer_sync(&sdp->delay_work);
> +			flush_work(&sdp->work);
>  		}
> +	}
>  	if (WARN_ON(rcu_seq_state(READ_ONCE(ssp->srcu_gp_seq)) != SRCU_STATE_IDLE) ||
>  	    WARN_ON(srcu_readers_active(ssp))) {
>  		pr_info("%s: Active srcu_struct %p state: %d\n",
> @@ -463,39 +471,23 @@ static void srcu_gp_start(struct srcu_struct *ssp)
>  	WARN_ON_ONCE(state != SRCU_STATE_SCAN1);
>  }
>  
> -/*
> - * Track online CPUs to guide callback workqueue placement.
> - */
> -DEFINE_PER_CPU(bool, srcu_online);
>  
> -void srcu_online_cpu(unsigned int cpu)
> +static void srcu_delay_timer(struct timer_list *t)
>  {
> -	WRITE_ONCE(per_cpu(srcu_online, cpu), true);
> +	struct srcu_data *sdp = container_of(t, struct srcu_data, delay_work);
> +
> +	queue_work_on(sdp->cpu, rcu_gp_wq, &sdp->work);
>  }
>  
> -void srcu_offline_cpu(unsigned int cpu)
> -{
> -	WRITE_ONCE(per_cpu(srcu_online, cpu), false);
> -}
> -
> -/*
> - * Place the workqueue handler on the specified CPU if online, otherwise
> - * just run it whereever.  This is useful for placing workqueue handlers
> - * that are to invoke the specified CPU's callbacks.
> - */
> -static bool srcu_queue_delayed_work_on(int cpu, struct workqueue_struct *wq,
> -				       struct delayed_work *dwork,
> +static void srcu_queue_delayed_work_on(struct srcu_data *sdp,
>  				       unsigned long delay)
>  {
> -	bool ret;
> +	if (!delay) {
> +		queue_work_on(sdp->cpu, rcu_gp_wq, &sdp->work);
> +		return;
> +	}
>  
> -	preempt_disable();
> -	if (READ_ONCE(per_cpu(srcu_online, cpu)))
> -		ret = queue_delayed_work_on(cpu, wq, dwork, delay);
> -	else
> -		ret = queue_delayed_work(wq, dwork, delay);
> -	preempt_enable();
> -	return ret;
> +	timer_reduce(&sdp->delay_work, jiffies + delay);
>  }
>  
>  /*
> @@ -504,7 +496,7 @@ static bool srcu_queue_delayed_work_on(int cpu, struct workqueue_struct *wq,
>   */
>  static void srcu_schedule_cbs_sdp(struct srcu_data *sdp, unsigned long delay)
>  {
> -	srcu_queue_delayed_work_on(sdp->cpu, rcu_gp_wq, &sdp->work, delay);
> +	srcu_queue_delayed_work_on(sdp, delay);
>  }
>  
>  /*
> @@ -1186,7 +1178,8 @@ static void srcu_invoke_callbacks(struct work_struct *work)
>  	struct srcu_data *sdp;
>  	struct srcu_struct *ssp;
>  
> -	sdp = container_of(work, struct srcu_data, work.work);
> +	sdp = container_of(work, struct srcu_data, work);
> +
>  	ssp = sdp->ssp;
>  	rcu_cblist_init(&ready_cbs);
>  	spin_lock_irq_rcu_node(sdp);
> diff --git a/kernel/rcu/tree.c b/kernel/rcu/tree.c
> index be67a1bcba1da..86538c72cae90 100644
> --- a/kernel/rcu/tree.c
> +++ b/kernel/rcu/tree.c
> @@ -3361,8 +3361,6 @@ int rcutree_online_cpu(unsigned int cpu)
>  	raw_spin_lock_irqsave_rcu_node(rnp, flags);
>  	rnp->ffmask |= rdp->grpmask;
>  	raw_spin_unlock_irqrestore_rcu_node(rnp, flags);
> -	if (IS_ENABLED(CONFIG_TREE_SRCU))
> -		srcu_online_cpu(cpu);
>  	if (rcu_scheduler_active == RCU_SCHEDULER_INACTIVE)
>  		return 0; /* Too early in boot for scheduler work. */
>  	sync_sched_exp_online_cleanup(cpu);
> @@ -3387,8 +3385,6 @@ int rcutree_offline_cpu(unsigned int cpu)
>  	raw_spin_unlock_irqrestore_rcu_node(rnp, flags);
>  
>  	rcutree_affinity_setting(cpu, cpu);
> -	if (IS_ENABLED(CONFIG_TREE_SRCU))
> -		srcu_offline_cpu(cpu);
>  	return 0;
>  }
>  
> diff --git a/kernel/rcu/tree.h b/kernel/rcu/tree.h
> index 0ab060c8e9a71..e27fb27e087df 100644
> --- a/kernel/rcu/tree.h
> +++ b/kernel/rcu/tree.h
> @@ -456,11 +456,3 @@ static void rcu_bind_gp_kthread(void);
>  static bool rcu_nohz_full_cpu(void);
>  static void rcu_dynticks_task_enter(void);
>  static void rcu_dynticks_task_exit(void);
> -
> -#ifdef CONFIG_SRCU
> -void srcu_online_cpu(unsigned int cpu);
> -void srcu_offline_cpu(unsigned int cpu);
> -#else /* #ifdef CONFIG_SRCU */
> -void srcu_online_cpu(unsigned int cpu) { }
> -void srcu_offline_cpu(unsigned int cpu) { }
> -#endif /* #else #ifdef CONFIG_SRCU */
> -- 
> 2.20.0.rc2
> 

