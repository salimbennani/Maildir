Return-Path: <linux-kernel-owner@vger.kernel.org>
Delivered-To: unknown
Received: from linux.intel.com (10.54.29.200:995) by i7-8700 with POP3-SSL;
  18 Dec 2018 08:47:13 -0000
X-Original-To: like.xu@linux.intel.com
Delivered-To: like.xu@linux.intel.com
Received: from fmsmga006.fm.intel.com (fmsmga006.fm.intel.com [10.253.24.20])
	(using TLSv1.2 with cipher ECDHE-RSA-AES256-GCM-SHA384 (256/256 bits))
	(No client certificate requested)
	by linux.intel.com (Postfix) with ESMTPS id BD9DD5805CF;
	Mon, 17 Dec 2018 08:56:25 -0800 (PST)
Received: from fmsmga102.fm.intel.com ([10.1.193.69])
  by fmsmga006-1.fm.intel.com with ESMTP/TLS/DHE-RSA-AES256-GCM-SHA384; 17 Dec 2018 08:56:25 -0800
X-SG-BADATTACHMENTNOREPLY: True
IronPort-PHdr: =?us-ascii?q?9a23=3AWvcNwB/57+fms/9uRHKM819IXTAuvvDOBiVQ1KB9?=
 =?us-ascii?q?1u0TIJqq85mqBkHD//Il1AaPAd2Lraocw8Pt8InYEVQa5piAtH1QOLdtbDQizf?=
 =?us-ascii?q?ssogo7HcSeAlf6JvO5JwYzHcBFSUM3tyrjaRsdF8nxfUDdrWOv5jAOBBr/KRB1?=
 =?us-ascii?q?JuPoEYLOksi7ze+/94HQbglSmDaxfa55IQmrownWqsQYm5ZpJLwryhvOrHtIeu?=
 =?us-ascii?q?BWyn1tKFmOgRvy5dq+8YB6/ShItP0v68BPUaPhf6QlVrNYFygpM3o05MLwqxbO?=
 =?us-ascii?q?SxaE62YGXWUXlhpIBBXF7A3/U5zsvCb2qvZx1S+HNsDtU7s6RSqt4LtqSB/wiS?=
 =?us-ascii?q?cIKTg58H3MisdtiK5XuQ+tqwBjz4LRZoyeKfhwcb7Hfd4CWGRPQMhRWSxCDI2y?=
 =?us-ascii?q?YYQAAOgOMvpXoYnmv1sDrwCzBRWuCe711jNEmnH70K883u88EQ/GxgsgH9cWvX?=
 =?us-ascii?q?vbttr1MLkdUeapzKnJyzXIcu5Y1iv96IjObB8hoOyDUqxqccHMzkQvCRnKjlGO?=
 =?us-ascii?q?pozjIzOV1+INv3KA7+V8VeKvjXAoqwBsrTex3MchkZPGhpgQylze6Sp5x4M1KM?=
 =?us-ascii?q?S+RUVmYtCkCINduz+GO4ZyWM8uXm9ltDggxrEbupO3YDIGxZUlyhLHdfCLboqF?=
 =?us-ascii?q?7gj+WOuePTt0nm9pdK6iixqo80Ws1uvxXdSu3llQtCpKiNzMu2gN1xPN7siHTe?=
 =?us-ascii?q?Nw/lmu2TmRzQDf8OJELl4ulardNZEhxqQ8lp0JsUTMBiP2mUP2g7GKdkg85OSk?=
 =?us-ascii?q?9+Dqbq/7qpKSKYN4kBzyP6cylsClAOk1MBACX22B9uS90L3j81f5QLJPjvAulq?=
 =?us-ascii?q?nZsZbaJdkUp6KgAA9azJwj6xChADeiydgYmncGLFRbdxKdlIXpJV7OL+7iDful?=
 =?us-ascii?q?gFSjji1rx/bYMb3lGJnNKWLDkLj5cbZn90Fc0BYzzcxY559MDrEBIfHzVVHruN?=
 =?us-ascii?q?3XEx80KAi0w+fhCNVg2YISQ2OPAqmFMKzMtV+E/P4gI+6JZIUNojbyN+Al5+Ly?=
 =?us-ascii?q?jX8+gVIdfbOm3ZoLaH+iGfRqOUWZYWf2jdcHHmcHpQ4+TO3siF2fXj9ffXeyX6?=
 =?us-ascii?q?Qg5j4lDIKqF5vMRoeogLaZxie0AoVWZnxaClCLCXrodYKEVOkWZCKRJc9hlDoE?=
 =?us-ascii?q?Vb+6Ro8l1BGushL6yrV9IurV/C0YqYzs1Nxv6+LPkhEy8CR+D96B3GGVU2F0gm?=
 =?us-ascii?q?QISics06BkoUx9zVSD3bJig/NCF9xe/PdJUgY8NZ7BwO12EdHyWgTdftiXTFaq?=
 =?us-ascii?q?WMmpATY0Ttgp2d8Bf159G8m+jhDExyeqAKUal7qRCJww86LTxX7xJ8lmxnbC1a?=
 =?us-ascii?q?khiUQmQ8RVOW2ngK5/6xbcB4rTn0qFkKaqcLwW3DTR+2eb0WqOoEZYXRZtXqrf?=
 =?us-ascii?q?Q3AQeFHardTj6UPEVL+hF7InPgxFyc6BL6tKbsbkjVFHRPflJdTfbHi9m2a2BR?=
 =?us-ascii?q?aU2LyMaJDmdHka3CXYEEIEiRwc/W6aNQgiASesu3/RAyZwFV3xeU/s8fNxqHWg?=
 =?us-ascii?q?TkAqyQGHdElh17uz+h4Iiv2QUfIT3rQYuCg/rzV4Bkqy39XTC9CYvQpuYL1cYc?=
 =?us-ascii?q?8h4FdAzW/Zqw19PpmnL6B+hl4fcx57v1/02xVwEIVAlckqrHUlzAdpLaKY0VVB?=
 =?us-ascii?q?dy6X3JzqO73XLHXy8w6ra6LMxl7e19OW8L8V6Psks1XjoB2pFk06/np919lazX?=
 =?us-ascii?q?Sd6YvKDQYISp3xT1s4+AJ8p7HZZSk9+ZjZ1XltMamyrz/D1MglBOojyha8Ydhf?=
 =?us-ascii?q?NLmIGxP1E80fH8KuMvAlm0C1bhIYO+Bf7K41P968e/SawqKqPeZgkyigjWRI+4?=
 =?us-ascii?q?191kOM9yxhSu/HxZoFwveY3heZWDf4lluursf3mYVcbzEIAmW/0TTkBJJWZqBq?=
 =?us-ascii?q?Z4YLCHuhLNetxtpjgJ7hQXhY+0C5B1MHwcOmZQCdb1jg0gJOz0QXpnqnlDC8zz?=
 =?us-ascii?q?x1lTEps6We0DbPw+TkaBoIJGpLSHN+glfrJIi+l8oaU1Swbwg1iBul4l73xqha?=
 =?us-ascii?q?pKhlL2jfW1xIfzXwL2x5Vquwt7yCY9NA6Z8ysCVXVvi8bk6eSrLnvxQa1CbjFX?=
 =?us-ascii?q?NExD8nbzGqpon5nxtihWKfNnlztnnZecJ3xRvF/9zTX/1R3jkHRCl+lzbXAEOx?=
 =?us-ascii?q?P92o/dWSipfCvfqyV2OnVp1PbybryZmMuze85W1vGRe/hey8msX7EQgm1i/2z9?=
 =?us-ascii?q?lrWj/PrBrmYInr1qK6PPljfklpAl/89sV7Fpt/kos2mJEfx3waio+J8noAlGf5?=
 =?us-ascii?q?Kc9b1r7mbHoRWT4LxMbY4Av/101iNH6Jx5/5WW+bwstufNS6ZmIW2iQg78FFEq?=
 =?us-ascii?q?uU7bpEnTdrrVq8tw7eff99njIFw/s09HEam/0JuBYqziiFB7ASHEpYMjb2mxWG?=
 =?us-ascii?q?8d++t7lXa3i1cberykV+h9+hAaqGogFdXnb5Z5gjETVx7sV5LFLDznnz5pv4d9?=
 =?us-ascii?q?nXaNIZrgeUnAvYj+hJNJIxkeIHhTZgOWL4p3EkyvQ0jRpz3ZGhp4iHKn5g/Ka4?=
 =?us-ascii?q?Ah5eKz30aNkf+jDrjaZCgMmW25qjEYlmGjUORJHoV+6nECoOtfT7MAaDCCYzpW?=
 =?us-ascii?q?2cGbrbAA+T8kNmr2/UHpCvNnGXImQZzNp4SBmcIkxfnB4bXDEgkpElEQCqwdTr?=
 =?us-ascii?q?cF1l6TAJ+l74thxMx/pqNxblV2fQuhyoZi0oSJSFLxpW8wJC51rTMcOE9eJ+BC?=
 =?us-ascii?q?VY/pynrAyQJW2XfQVIDWcVWkOaA1DvJKWh5d7F8+KAHOqxM+POYamSqexZT/qJ?=
 =?us-ascii?q?xZWv0pZ//zaRLMqPOGNuD+Y82kpFUnB0AMDZmzQJSywKmCPBdc+bpBGg+iJpqs?=
 =?us-ascii?q?Cz6ujkWAXq5YGXEbtdLc1v+wyqgaeEL+OQhDh2KTdb1pMPxH/E0rsf3EQViyFh?=
 =?us-ascii?q?aTatC6kAtTXWQaLUm69XCQMbaixpOMtJ6aI8whdCOcrBhtzp0b54i+Y/C01ZWl?=
 =?us-ascii?q?z5hsGpecsKLnmnO1PaH0mLLqqJJD3Rz8HzYKOxUrlQjORStx2ttjeXCU7jPjKf?=
 =?us-ascii?q?lzb3UxCjK/1DjCaePBZGooGybg5tCXT/TNLhchC7LN53jTgszbIonH/FKW4cPi?=
 =?us-ascii?q?Z6c05Wqr2Q7CVYguhwGmBb73plK/WElDid7+XCNpkWtv5rCDxul+1G+HQ616dV?=
 =?us-ascii?q?7CZcSf11giTSqNtuo1CgkuaXyztnUABBqjBEhI+QuUViOKPZ9oRPWHre/RIN63?=
 =?us-ascii?q?mQBAoOp9d/FtLvvKVQmZDzk/fNKTFJ/tTIteQBBtTIL97PZGQgNxHkHiKSAxYE?=
 =?us-ascii?q?USKsKUnbhkpUivbU8Wea+NxyspXwlYAcYr5dWkY8Gv4TBgJiBtNGaJJ2WDwjub?=
 =?us-ascii?q?2WlsgF4Ty5thaVDMFbuI3XE/GfG/PiLB6HgrReIRgF27X1KcIULIKo9VZlbwxE?=
 =?us-ascii?q?lYDHHVbRW5h2qS1nYw44rV8FpGZ3SmA1x0PjLBim4HkeFPK5hDY/kA44auMoom?=
 =?us-ascii?q?S/q2wrL0bH8XNj2HI6ns/o1HXIKGb8?=
X-IronPort-Anti-Spam-Filtered: true
X-IronPort-Anti-Spam-Result: =?us-ascii?q?A0A1AADJ1Bdch0O0hNFkHAEBAQQBAQcEA?=
 =?us-ascii?q?QGBUwUBAQsBg2sng3yUEIFgLRSXRBSBXywTAYdWIjYHDQEDAQEBAQEBAgETAQE?=
 =?us-ascii?q?BCgsJCCkvgjYkAYJhAQEBAQIBAQILFQQ+FAUBCQEBChgCAiYCAgNUBgEMBgIBA?=
 =?us-ascii?q?QGDHYF5CAQBqA98M4VAhGGBC4szgVc/gTiCa4Rqgx+CVwKJQoZSkQUHAoIkBIg?=
 =?us-ascii?q?lhwceigSHTok8kXUGggFNI4M8kFs/AQExgQUBAY1vAQE?=
X-IPAS-Result: =?us-ascii?q?A0A1AADJ1Bdch0O0hNFkHAEBAQQBAQcEAQGBUwUBAQsBg2s?=
 =?us-ascii?q?ng3yUEIFgLRSXRBSBXywTAYdWIjYHDQEDAQEBAQEBAgETAQEBCgsJCCkvgjYkA?=
 =?us-ascii?q?YJhAQEBAQIBAQILFQQ+FAUBCQEBChgCAiYCAgNUBgEMBgIBAQGDHYF5CAQBqA9?=
 =?us-ascii?q?8M4VAhGGBC4szgVc/gTiCa4Rqgx+CVwKJQoZSkQUHAoIkBIglhwceigSHTok8k?=
 =?us-ascii?q?XUGggFNI4M8kFs/AQExgQUBAY1vAQE?=
X-IronPort-AV: E=Sophos;i="5.56,366,1539673200"; 
   d="scan'208";a="57216138"
X-Amp-Result: SKIPPED(no attachment in message)
X-Amp-File-Uploaded: False
Received: from vger.kernel.org ([209.132.180.67])
  by mtab.intel.com with ESMTP; 17 Dec 2018 08:56:22 -0800
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
        id S1727893AbeLQQ4V (ORCPT <rfc822;like.xu@linux.intel.com>
        + 23 others); Mon, 17 Dec 2018 11:56:21 -0500
Received: from usa-sjc-mx-foss1.foss.arm.com ([217.140.101.70]:60102 "EHLO
        foss.arm.com" rhost-flags-OK-OK-OK-OK) by vger.kernel.org with ESMTP
        id S1726657AbeLQQ4V (ORCPT <rfc822;linux-kernel@vger.kernel.org>);
        Mon, 17 Dec 2018 11:56:21 -0500
Received: from usa-sjc-imap-foss1.foss.arm.com (unknown [10.72.51.249])
        by usa-sjc-mx-foss1.foss.arm.com (Postfix) with ESMTP id B10EBA78;
        Mon, 17 Dec 2018 08:56:20 -0800 (PST)
Received: from [10.1.194.37] (e113632-lin.cambridge.arm.com [10.1.194.37])
        by usa-sjc-imap-foss1.foss.arm.com (Postfix) with ESMTPSA id C091A3F575;
        Mon, 17 Dec 2018 08:56:19 -0800 (PST)
Subject: Re: [PATCH v2 3/3] sched/fair: fix unnecessary increase of balance
 interval
To: Vincent Guittot <vincent.guittot@linaro.org>, peterz@infradead.org,
        mingo@kernel.org, linux-kernel@vger.kernel.org
Cc: Morten.Rasmussen@arm.com
References: <1544803317-7610-1-git-send-email-vincent.guittot@linaro.org>
 <1544803317-7610-4-git-send-email-vincent.guittot@linaro.org>
From: Valentin Schneider <valentin.schneider@arm.com>
Message-ID: <f6443ca2-3e82-d4eb-deb8-2aff44c618e2@arm.com>
Date: Mon, 17 Dec 2018 16:56:18 +0000
User-Agent: Mozilla/5.0 (X11; Linux x86_64; rv:60.0) Gecko/20100101
 Thunderbird/60.2.1
MIME-Version: 1.0
In-Reply-To: <1544803317-7610-4-git-send-email-vincent.guittot@linaro.org>
Content-Type: text/plain; charset=utf-8
Content-Language: en-GB
Content-Transfer-Encoding: 7bit
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: <linux-kernel.vger.kernel.org>
X-Mailing-List: linux-kernel@vger.kernel.org

Hi Vincent,

About time I had a look at this one...

On 14/12/2018 16:01, Vincent Guittot wrote:
> In case of active balance, we increase the balance interval to cover
> pinned tasks cases not covered by all_pinned logic.

AFAIUI the balance increase is there to have plenty of time to
stop the task before going through another load_balance().

Seeing as there is a cpus_allowed check that leads to

    env.flags |= LBF_ALL_PINNED;
    goto out_one_pinned;

in the active balancing part of load_balance(), the condition you're
changing should never be hit when we have pinned tasks. So you may want
to rephrase that bit.

> Neverthless, the active
> migration triggered by asym packing should be treated as the normal
> unbalanced case and reset the interval to default value otherwise active
> migration for asym_packing can be easily delayed for hundreds of ms
> because of this all_pinned detection mecanism.

Mmm so it's not exactly clear why we need this change. If we double the
interval because of a pinned task we wanted to active balance, well it's
just regular pinned task issues and we can't do much about it.

The only scenario I can think of is if you had a workload where you wanted
to do an active balance in several successive load_balance(), in which case
you would keep increasing the interval even though you do migrate a task
every time (which would harm every subsequent active_balance).

In that case every active_balance "user" (pressured CPU, misfit) is
affected, so maybe what we want is something like this:

-----8<-----
@@ -9136,13 +9149,11 @@ static int load_balance(int this_cpu, struct rq *this_rq,
                sd->balance_interval = sd->min_interval;
        } else {
                /*
-                * If we've begun active balancing, start to back off. This
-                * case may not be covered by the all_pinned logic if there
-                * is only 1 task on the busy runqueue (because we don't call
-                * detach_tasks).
+                * If we've begun active balancing, start to back off.
+                * Don't increase too much in case we have more active balances
+                * coming up.
                 */
-               if (sd->balance_interval < sd->max_interval)
-                       sd->balance_interval *= 2;
+               sd->balance_interval = 2 * sd->min_interval;
        }
 
        goto out;
----->8-----

Maybe we want a larger threshold - truth be told, it all depends on how
long the cpu stopper can take and if that delay increase is still relevant
nowadays.

> 
> Signed-off-by: Vincent Guittot <vincent.guittot@linaro.org>
> ---
>  kernel/sched/fair.c | 27 +++++++++++++++------------
>  1 file changed, 15 insertions(+), 12 deletions(-)
> 
> diff --git a/kernel/sched/fair.c b/kernel/sched/fair.c
> index 9591e7a..487287e 100644
> --- a/kernel/sched/fair.c
> +++ b/kernel/sched/fair.c
> @@ -8857,21 +8857,24 @@ static struct rq *find_busiest_queue(struct lb_env *env,
>   */
>  #define MAX_PINNED_INTERVAL	512
>  
> +static inline bool
> +asym_active_balance(struct lb_env *env)
> +{
> +	/*
> +	 * ASYM_PACKING needs to force migrate tasks from busy but
> +	 * lower priority CPUs in order to pack all tasks in the
> +	 * highest priority CPUs.
> +	 */
> +	return env->idle != CPU_NOT_IDLE && (env->sd->flags & SD_ASYM_PACKING) &&
> +	       sched_asym_prefer(env->dst_cpu, env->src_cpu);
> +}
> +
>  static int need_active_balance(struct lb_env *env)
>  {
>  	struct sched_domain *sd = env->sd;
>  
> -	if (env->idle != CPU_NOT_IDLE) {
> -
> -		/*
> -		 * ASYM_PACKING needs to force migrate tasks from busy but
> -		 * lower priority CPUs in order to pack all tasks in the
> -		 * highest priority CPUs.
> -		 */
> -		if ((sd->flags & SD_ASYM_PACKING) &&
> -		    sched_asym_prefer(env->dst_cpu, env->src_cpu))
> -			return 1;
> -	}
> +	if (asym_active_balance(env))
> +		return 1;
>  
>  	/*
>  	 * The dst_cpu is idle and the src_cpu CPU has only 1 CFS task.
> @@ -9150,7 +9153,7 @@ static int load_balance(int this_cpu, struct rq *this_rq,
>  	} else
>  		sd->nr_balance_failed = 0;
>  
> -	if (likely(!active_balance)) {
> +	if (likely(!active_balance) || asym_active_balance(&env)) {

AFAICT this makes us reset the interval whenever we do an asym packing
active balance (if the task is pinned we would goto out_one_pinned).
This goes against the logic I had understood so far and that I explained
higher up.

>  		/* We were unbalanced, so reset the balancing interval */
>  		sd->balance_interval = sd->min_interval;
>  	} else {
> 
