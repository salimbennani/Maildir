Return-Path: <linux-kernel-owner@vger.kernel.org>
Delivered-To: unknown
Received: from linux.intel.com (10.54.29.200:995) by likexu-workstation with
  POP3-SSL; 03 Dec 2018 20:24:25 -0000
X-Original-To: like.xu@linux.intel.com
Delivered-To: like.xu@linux.intel.com
Received: from fmsmga005.fm.intel.com (fmsmga005.fm.intel.com [10.253.24.32])
	(using TLSv1.2 with cipher ECDHE-RSA-AES256-GCM-SHA384 (256/256 bits))
	(No client certificate requested)
	by linux.intel.com (Postfix) with ESMTPS id B7931580578;
	Mon,  3 Dec 2018 01:57:44 -0800 (PST)
Received: from fmsmga102.fm.intel.com ([10.1.193.69])
  by fmsmga005-1.fm.intel.com with ESMTP/TLS/DHE-RSA-AES256-GCM-SHA384; 03 Dec 2018 01:57:44 -0800
X-SG-BADATTACHMENTNOREPLY: True
IronPort-PHdr: =?us-ascii?q?9a23=3AL/eEvBIEzN5V/3PA1tmcpTZWNBhigK39O0sv0rFi?=
 =?us-ascii?q?tYgULvTyrarrMEGX3/hxlliBBdydt6oUzbKO+4nbGkU4qa6bt34DdJEeHzQksu?=
 =?us-ascii?q?4x2zIaPcieFEfgJ+TrZSFpVO5LVVti4m3peRMNQJW2aFLduGC94iAPERvjKwV1?=
 =?us-ascii?q?Ov71GonPhMiryuy+4ZLebxlLiTanfb9+MAi9oBnMuMURnYZsMLs6xAHTontPde?=
 =?us-ascii?q?RWxGdoKkyWkh3h+Mq+/4Nt/jpJtf45+MFOTav1f6IjTbxFFzsmKHw65NfqtRbY?=
 =?us-ascii?q?UwSC4GYXX3gMnRpJBwjF6wz6Xov0vyDnuOdxxDWWMMvrRr0yRD+s7bpkSAXwhS?=
 =?us-ascii?q?kHKTA37W/ZhM93gq1ZrhKuqBNxw5XMYIyXL/dyYqDQcMkGSWdbQspdSypMCZ68?=
 =?us-ascii?q?YYsVCOoBOP5VoZLgp1QQqxu+GQisBOXywTFSmHD2x7c63Po9EQrb2wEgBs8Ov2?=
 =?us-ascii?q?rSrNXpNacSV/q5zLHWwjXZdfNZxyv95ZPSfRA7pPGAR65/cc3UyUQ2EQ7Ok1ae?=
 =?us-ascii?q?qZT9Mj+LyugAt3KX4/duWO6xkWIrtgJ8riS1ysotiITFnpwZxk3G+Clj3Yo4Ks?=
 =?us-ascii?q?G0RFRmbdK4DZdcrSOXO5dwT8g/WW9nojw6xacDuZOjfCgF1pAnxxnHZvyZfIiH?=
 =?us-ascii?q?/AjjWPySIThmnnJlfqywhxKo/Uin0O38WdG40FdMriVbjtnBrm4B2wDX58SdV/?=
 =?us-ascii?q?dw8Fmt1SyS2w3Q9u1IO0E5mKjDJ54k2LEwl54TsUrZHi/xnUX7lKuWdkQi+ui1?=
 =?us-ascii?q?5OXre7bmqYGGN49ylA7+Nr0imsuxAOQ+LAcORXOW+fqz1LL95031WrZKgeMskq?=
 =?us-ascii?q?nfrp/aId4XpqmjAw9ayooj8QqwDy+60NQEmnkKNFZFeBOEj4f3IV3PL+34AOy7?=
 =?us-ascii?q?g1Stljdr2v/HMqfgApXLMnjMjrPhcaxh5E5bzQo51cpf6I5MCrEdPPLzXVf8tN?=
 =?us-ascii?q?zCAR84Lwy72eHnBM991oMDQ22PBKCZPbjWsV+J4OIvPuaNaJUUuDb7N/gq+fru?=
 =?us-ascii?q?gWUlll8aeKmjxYEXZ2ygHvR6P0WZZmLhgtUGEWgUpAY+T+vqiFuEUT5UfHuyW6?=
 =?us-ascii?q?M85jcmCIOpF4vDR4atgKCf0ye/BJFZemdGClWUG3fya4qEQ+sMaD6VIsJ5iDME?=
 =?us-ascii?q?TrihS4gi1R20rg/10bhnI/HQ+i0Zs5Ljydd06/fSlRE06Tx7EcCd33uRQGFzm2?=
 =?us-ascii?q?MCXyU207xnoUxh1leD1rB1g/9CGtxV/f9JVgY6OoTaz+x1EN3yXgPBftGUSFep?=
 =?us-ascii?q?WNmmADcxTs4vzN8KeUpyB9KijhXb1SqwH7AVj6CLBIAz8q/Ewnf+Pdh9xGjc2K?=
 =?us-ascii?q?khlVYmRNBPOnOghqJ48wjTBIvJk0GCmqaudKQc2jPN9WiZwWqPukFYTBB/UaHf?=
 =?us-ascii?q?UX8DYUvWqMzz5lneQL+2FbQnLgxBxNafJaRQdN3mk09KRPf5N9TYeGK+hWGwCA?=
 =?us-ascii?q?2MxrONaorqZmoc0D/cCEgCjwAc43KGORIiCSempmLUFCZuGk73Y0Pw7el+r2u2?=
 =?us-ascii?q?TlM1zwGPaE1hy7q1+x4PifyAUf8T2agEuCMgqzVyE1awxNbWC9uGpwp8c6RQe9?=
 =?us-ascii?q?I94FFb1W3HswxxJICvL6dnhlQGaQR4o1vu1wlrCoVHicUltncqwxR9KK2G0FJN?=
 =?us-ascii?q?bSiX3Y3tNbLNLGny/xeva7DN11Ha0daW/LoP6fsip1XiugGpClQt83F939ZJ1H?=
 =?us-ascii?q?uc443ADBAOXpLpTkY36x96qqnaYykg/Y/byWdgMKi0sjDY3dIpC/AoyhKhf9dZ?=
 =?us-ascii?q?LaOFGxX+E8wcB8iyNuMqn0KlYQ4DPOBX7KQ0Jd+pd+Oa2K63O+ZthCimjWVb74?=
 =?us-ascii?q?9nyEKD6i18RvTO35kb2fGY3xKLWCvmg1elr8/4h5pEZTYUHmekzSjkBYhRZrB9?=
 =?us-ascii?q?fIoRCGeuJdG3yct6h5L3R3FY81ujDUsc2MC1YRqSc0D93QpI2EUXoHyrgyu5wy?=
 =?us-ascii?q?ZvkzE0qKqSxyjOw+XkdBoaNW9HXmhijVHwIYeqi9AWRlSnbw8slBG9/0b127Bb?=
 =?us-ascii?q?pLhjL2nUWUpIfTL5L3thUquzsbqOedVP54krsSVUUeS8Z06VSrjmrhse0iPjGX?=
 =?us-ascii?q?ZexT8hezGrvJX5gwJ1iGaHIHlvq3rZfNl6xQ3D69zEWf5Rwj0GSTF4iDbNAViw?=
 =?us-ascii?q?Jdup/dSSl5rYtuC+VmShVoBccCXxzIOAsje76nNuARGlg/+zndjnGxAg0SDnz9?=
 =?us-ascii?q?lqSTnIrBHkb4nozau6MPhrfkl1BFDm7cp6FZpzko8xhJEWxHgbiY+Z/XsBkWfv?=
 =?us-ascii?q?L9pb3bjyY2YKRT4O29TV+hTq2FV/LnKVwIL0TnCdwspiZ9ageG8X1Dwy79tWCK?=
 =?us-ascii?q?iK9rxLhjV6okC3rQ/KZfh9nzEdyeYh6XIAguEJvhYtwTuZArwIAUZYOinsnQyS?=
 =?us-ascii?q?79+itKVXeHqvcb+o2UpimtChCauOowBGV3b/Z5ciBjRw7sRkPVLI0X3z7Jzked?=
 =?us-ascii?q?bKYdISsB2UjwnPj+xPJJ0tkfoKgDJtOXjhsn091+47kRtu0Imhs4edLGVt+L+5?=
 =?us-ascii?q?DgRcNj3ofM4T/jDtjaBDnseZxYyvH5NhGikVU5vsV/6nDDUStfH/PQaUDDI8sm?=
 =?us-ascii?q?ubGabYHQKH6kdptXfPHI6wN32NOHkV19ZiRASeJExChgAbRi46k4U9FgCrwszh?=
 =?us-ascii?q?bUh46ioQ5l7+thtD1OZoOwPjXWfYoQeici00R4SHLBpK8gFC4F/YMMyZ7uJuBi?=
 =?us-ascii?q?FY44eurAqXJmyAYARIC24JV1eAB1DiOLmu+NbB//KZBuq4M/vBf7GOpfZCWPeP?=
 =?us-ascii?q?wJKlypFm8CqUNsWTInliCOU22kpdUnB4GMTZmDQPRzYUlyLXaM6bqwmz+jdqrs?=
 =?us-ascii?q?Ck6/nrXAPv5Y2SC7pdK9lv+ha2gbudOO6Unip2NTFY1pYUz3/S1LcfxEISiz1p?=
 =?us-ascii?q?dzS1C7sAqDXCTLjOla5XFRIbbyJzOdBM76I92AlNJMHahsn01r5+kv46FVNFWU?=
 =?us-ascii?q?b9lcGuYMwAO3u9O0/fBEaXKLSGIiXGw932YaO5U7FfkP9YuAGwuTmFFU/uJTCD?=
 =?us-ascii?q?lzjvVxCyPuBAliCbPBpCuI6jdhZhE3TsTNXjahejKt94kSU2waEohnPNLWMdMS?=
 =?us-ascii?q?Jzc0VIrr2R6yNXmvR+G2xb4XpjIumJgCKZ7+jeKpYLvvpnGCV0l+RG4Hskz7tZ?=
 =?us-ascii?q?9j1LRPtwmHiaktk7u1y6n/Od4jthXgBHpjtCiMSMp0omcb/b6bFaW2nV5xUG7m?=
 =?us-ascii?q?TWDRkW45NhC9vyq+VTx8LJmabbNjhP6ZTX8NEaCsySL9iIdDIlMBz0CHvMCSMb?=
 =?us-ascii?q?QjOxc2LSnUpQlLeV7HLGgII9r83VhZcIVr5dHGQ4DOkXFgwxBcEPJot2WHU8nK?=
 =?us-ascii?q?SBgdIg7GC76hLWQZMJ7dj8SvuODKC3e36ihr5eak5QzA=3D=3D?=
X-IronPort-Anti-Spam-Filtered: true
X-IronPort-Anti-Spam-Result: =?us-ascii?q?A0AuAACr/QRch0O0hNFiHgEGBwaBUggLA?=
 =?us-ascii?q?YFVghYnmjtolkyBcywTAYgCIjUIDQEDAQEBAQEBAgETAQEBCgsJCCkvgjYigmU?=
 =?us-ascii?q?DAwECJAsBRgYJAQFQA1QHEgWDHIICBAGlazOKHodtgnyBM4FXP4ERghRJhRqFd?=
 =?us-ascii?q?wKgQAcCgh8EiA+GfyORJokEkTEBggozGiODPJBbPwEBMYEFAQGKbAEB?=
X-IPAS-Result: =?us-ascii?q?A0AuAACr/QRch0O0hNFiHgEGBwaBUggLAYFVghYnmjtolky?=
 =?us-ascii?q?BcywTAYgCIjUIDQEDAQEBAQEBAgETAQEBCgsJCCkvgjYigmUDAwECJAsBRgYJA?=
 =?us-ascii?q?QFQA1QHEgWDHIICBAGlazOKHodtgnyBM4FXP4ERghRJhRqFdwKgQAcCgh8EiA+?=
 =?us-ascii?q?GfyORJokEkTEBggozGiODPJBbPwEBMYEFAQGKbAEB?=
X-IronPort-AV: E=Sophos;i="5.56,310,1539673200"; 
   d="scan'208";a="55257907"
X-Amp-Result: SKIPPED(no attachment in message)
X-Amp-File-Uploaded: False
Received: from vger.kernel.org ([209.132.180.67])
  by mtab.intel.com with ESMTP; 03 Dec 2018 01:57:43 -0800
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
        id S1726335AbeLCJ57 (ORCPT <rfc822;like.xu@linux.intel.com>
        + 23 others); Mon, 3 Dec 2018 04:57:59 -0500
Received: from foss.arm.com ([217.140.101.70]:32942 "EHLO foss.arm.com"
        rhost-flags-OK-OK-OK-OK) by vger.kernel.org with ESMTP
        id S1725888AbeLCJ57 (ORCPT <rfc822;linux-kernel@vger.kernel.org>);
        Mon, 3 Dec 2018 04:57:59 -0500
Received: from usa-sjc-imap-foss1.foss.arm.com (unknown [10.72.51.249])
        by usa-sjc-mx-foss1.foss.arm.com (Postfix) with ESMTP id 8E73B80D;
        Mon,  3 Dec 2018 01:57:39 -0800 (PST)
Received: from queper01-lin.cambridge.arm.com (queper01-lin.cambridge.arm.com [10.1.195.48])
        by usa-sjc-imap-foss1.foss.arm.com (Postfix) with ESMTPSA id 720583F59C;
        Mon,  3 Dec 2018 01:57:35 -0800 (PST)
From: Quentin Perret <quentin.perret@arm.com>
To: peterz@infradead.org, rjw@rjwysocki.net,
        linux-kernel@vger.kernel.org, linux-pm@vger.kernel.org
Cc: gregkh@linuxfoundation.org, mingo@redhat.com,
        dietmar.eggemann@arm.com, morten.rasmussen@arm.com,
        chris.redpath@arm.com, patrick.bellasi@arm.com,
        valentin.schneider@arm.com, vincent.guittot@linaro.org,
        thara.gopinath@linaro.org, viresh.kumar@linaro.org,
        tkjos@google.com, joel@joelfernandes.org, smuckle@google.com,
        adharmap@codeaurora.org, skannan@codeaurora.org,
        pkondeti@codeaurora.org, juri.lelli@redhat.com,
        edubezval@gmail.com, srinivas.pandruvada@linux.intel.com,
        currojerez@riseup.net, javi.merino@kernel.org,
        quentin.perret@arm.com
Subject: [PATCH v10 14/15] sched/fair: Select an energy-efficient CPU on task wake-up
Date: Mon,  3 Dec 2018 09:56:27 +0000
Message-Id: <20181203095628.11858-15-quentin.perret@arm.com>
X-Mailer: git-send-email 2.19.2
In-Reply-To: <20181203095628.11858-1-quentin.perret@arm.com>
References: <20181203095628.11858-1-quentin.perret@arm.com>
MIME-Version: 1.0
Content-Transfer-Encoding: 8bit
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: <linux-kernel.vger.kernel.org>
X-Mailing-List: linux-kernel@vger.kernel.org

If an Energy Model (EM) is available and if the system isn't
overutilized, re-route waking tasks into an energy-aware placement
algorithm. The selection of an energy-efficient CPU for a task
is achieved by estimating the impact on system-level active energy
resulting from the placement of the task on the CPU with the highest
spare capacity in each performance domain. This strategy spreads tasks
in a performance domain and avoids overly aggressive task packing. The
best CPU energy-wise is then selected if it saves a large enough amount
of energy with respect to prev_cpu.

Although it has already shown significant benefits on some existing
targets, this approach cannot scale to platforms with numerous CPUs.
This is an attempt to do something useful as writing a fast heuristic
that performs reasonably well on a broad spectrum of architectures isn't
an easy task. As such, the scope of usability of the energy-aware
wake-up path is restricted to systems with the SD_ASYM_CPUCAPACITY flag
set, and where the EM isn't too complex.

Cc: Ingo Molnar <mingo@redhat.com>
Cc: Peter Zijlstra <peterz@infradead.org>
Signed-off-by: Quentin Perret <quentin.perret@arm.com>
---
 kernel/sched/fair.c | 143 +++++++++++++++++++++++++++++++++++++++++++-
 1 file changed, 141 insertions(+), 2 deletions(-)

diff --git a/kernel/sched/fair.c b/kernel/sched/fair.c
index a20018ad9236..d73e7db5976a 100644
--- a/kernel/sched/fair.c
+++ b/kernel/sched/fair.c
@@ -6453,6 +6453,137 @@ compute_energy(struct task_struct *p, int dst_cpu, struct perf_domain *pd)
 	return energy;
 }
 
+/*
+ * find_energy_efficient_cpu(): Find most energy-efficient target CPU for the
+ * waking task. find_energy_efficient_cpu() looks for the CPU with maximum
+ * spare capacity in each performance domain and uses it as a potential
+ * candidate to execute the task. Then, it uses the Energy Model to figure
+ * out which of the CPU candidates is the most energy-efficient.
+ *
+ * The rationale for this heuristic is as follows. In a performance domain,
+ * all the most energy efficient CPU candidates (according to the Energy
+ * Model) are those for which we'll request a low frequency. When there are
+ * several CPUs for which the frequency request will be the same, we don't
+ * have enough data to break the tie between them, because the Energy Model
+ * only includes active power costs. With this model, if we assume that
+ * frequency requests follow utilization (e.g. using schedutil), the CPU with
+ * the maximum spare capacity in a performance domain is guaranteed to be among
+ * the best candidates of the performance domain.
+ *
+ * In practice, it could be preferable from an energy standpoint to pack
+ * small tasks on a CPU in order to let other CPUs go in deeper idle states,
+ * but that could also hurt our chances to go cluster idle, and we have no
+ * ways to tell with the current Energy Model if this is actually a good
+ * idea or not. So, find_energy_efficient_cpu() basically favors
+ * cluster-packing, and spreading inside a cluster. That should at least be
+ * a good thing for latency, and this is consistent with the idea that most
+ * of the energy savings of EAS come from the asymmetry of the system, and
+ * not so much from breaking the tie between identical CPUs. That's also the
+ * reason why EAS is enabled in the topology code only for systems where
+ * SD_ASYM_CPUCAPACITY is set.
+ *
+ * NOTE: Forkees are not accepted in the energy-aware wake-up path because
+ * they don't have any useful utilization data yet and it's not possible to
+ * forecast their impact on energy consumption. Consequently, they will be
+ * placed by find_idlest_cpu() on the least loaded CPU, which might turn out
+ * to be energy-inefficient in some use-cases. The alternative would be to
+ * bias new tasks towards specific types of CPUs first, or to try to infer
+ * their util_avg from the parent task, but those heuristics could hurt
+ * other use-cases too. So, until someone finds a better way to solve this,
+ * let's keep things simple by re-using the existing slow path.
+ */
+
+static int find_energy_efficient_cpu(struct task_struct *p, int prev_cpu)
+{
+	unsigned long prev_energy = ULONG_MAX, best_energy = ULONG_MAX;
+	struct root_domain *rd = cpu_rq(smp_processor_id())->rd;
+	int cpu, best_energy_cpu = prev_cpu;
+	struct perf_domain *head, *pd;
+	unsigned long cpu_cap, util;
+	struct sched_domain *sd;
+
+	rcu_read_lock();
+	pd = rcu_dereference(rd->pd);
+	if (!pd || READ_ONCE(rd->overutilized))
+		goto fail;
+	head = pd;
+
+	/*
+	 * Energy-aware wake-up happens on the lowest sched_domain starting
+	 * from sd_asym_cpucapacity spanning over this_cpu and prev_cpu.
+	 */
+	sd = rcu_dereference(*this_cpu_ptr(&sd_asym_cpucapacity));
+	while (sd && !cpumask_test_cpu(prev_cpu, sched_domain_span(sd)))
+		sd = sd->parent;
+	if (!sd)
+		goto fail;
+
+	sync_entity_load_avg(&p->se);
+	if (!task_util_est(p))
+		goto unlock;
+
+	for (; pd; pd = pd->next) {
+		unsigned long cur_energy, spare_cap, max_spare_cap = 0;
+		int max_spare_cap_cpu = -1;
+
+		for_each_cpu_and(cpu, perf_domain_span(pd), sched_domain_span(sd)) {
+			if (!cpumask_test_cpu(cpu, &p->cpus_allowed))
+				continue;
+
+			/* Skip CPUs that will be overutilized. */
+			util = cpu_util_next(cpu, p, cpu);
+			cpu_cap = capacity_of(cpu);
+			if (cpu_cap * 1024 < util * capacity_margin)
+				continue;
+
+			/* Always use prev_cpu as a candidate. */
+			if (cpu == prev_cpu) {
+				prev_energy = compute_energy(p, prev_cpu, head);
+				best_energy = min(best_energy, prev_energy);
+				continue;
+			}
+
+			/*
+			 * Find the CPU with the maximum spare capacity in
+			 * the performance domain
+			 */
+			spare_cap = cpu_cap - util;
+			if (spare_cap > max_spare_cap) {
+				max_spare_cap = spare_cap;
+				max_spare_cap_cpu = cpu;
+			}
+		}
+
+		/* Evaluate the energy impact of using this CPU. */
+		if (max_spare_cap_cpu >= 0) {
+			cur_energy = compute_energy(p, max_spare_cap_cpu, head);
+			if (cur_energy < best_energy) {
+				best_energy = cur_energy;
+				best_energy_cpu = max_spare_cap_cpu;
+			}
+		}
+	}
+unlock:
+	rcu_read_unlock();
+
+	/*
+	 * Pick the best CPU if prev_cpu cannot be used, or if it saves at
+	 * least 6% of the energy used by prev_cpu.
+	 */
+	if (prev_energy == ULONG_MAX)
+		return best_energy_cpu;
+
+	if ((prev_energy - best_energy) > (prev_energy >> 4))
+		return best_energy_cpu;
+
+	return prev_cpu;
+
+fail:
+	rcu_read_unlock();
+
+	return -1;
+}
+
 /*
  * select_task_rq_fair: Select target runqueue for the waking task in domains
  * that have the 'sd_flag' flag set. In practice, this is SD_BALANCE_WAKE,
@@ -6476,8 +6607,16 @@ select_task_rq_fair(struct task_struct *p, int prev_cpu, int sd_flag, int wake_f
 
 	if (sd_flag & SD_BALANCE_WAKE) {
 		record_wakee(p);
-		want_affine = !wake_wide(p) && !wake_cap(p, cpu, prev_cpu)
-			      && cpumask_test_cpu(cpu, &p->cpus_allowed);
+
+		if (static_branch_unlikely(&sched_energy_present)) {
+			new_cpu = find_energy_efficient_cpu(p, prev_cpu);
+			if (new_cpu >= 0)
+				return new_cpu;
+			new_cpu = prev_cpu;
+		}
+
+		want_affine = !wake_wide(p) && !wake_cap(p, cpu, prev_cpu) &&
+			      cpumask_test_cpu(cpu, &p->cpus_allowed);
 	}
 
 	rcu_read_lock();
-- 
2.19.2

