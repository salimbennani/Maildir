Return-Path: <linux-kernel-owner@vger.kernel.org>
Delivered-To: unknown
Received: from linux.intel.com (10.54.29.200:995) by i7-8700 with POP3-SSL;
  15 Dec 2018 13:06:20 -0000
X-Original-To: like.xu@linux.intel.com
Delivered-To: like.xu@linux.intel.com
Received: from fmsmga001.fm.intel.com (fmsmga001.fm.intel.com [10.253.24.23])
	(using TLSv1.2 with cipher ECDHE-RSA-AES256-GCM-SHA384 (256/256 bits))
	(No client certificate requested)
	by linux.intel.com (Postfix) with ESMTPS id 81A9B58061F;
	Fri, 14 Dec 2018 07:16:28 -0800 (PST)
Received: from fmsmga104.fm.intel.com ([10.1.193.100])
  by fmsmga001-1.fm.intel.com with ESMTP/TLS/DHE-RSA-AES256-GCM-SHA384; 14 Dec 2018 07:16:28 -0800
X-SG-BADATTACHMENTNOREPLY: True
IronPort-PHdr: =?us-ascii?q?9a23=3AcUsJ2xQ4IU5a+GPHm3UCmCrzjNpsv+yvbD5Q0YIu?=
 =?us-ascii?q?jvd0So/mwa64YBGPt8tkgFKBZ4jH8fUM07OQ7/iwHzRYqb+681k6OKRWUBEEjc?=
 =?us-ascii?q?hE1ycBO+WiTXPBEfjxciYhF95DXlI2t1uyMExSBdqsLwaK+i764jEdAAjwOhRo?=
 =?us-ascii?q?LerpBIHSk9631+ev8JHPfglEnjWwba9xIRmssQndqtQdjJd/JKo21hbHuGZDdf?=
 =?us-ascii?q?5MxWNvK1KTnhL86dm18ZV+7SleuO8v+tBZX6nicKs2UbJXDDI9M2Ao/8LrrgXM?=
 =?us-ascii?q?TRGO5nQHTGoblAdDDhXf4xH7WpfxtTb6tvZ41SKHM8D6Uaw4VDK/5KpwVhTmlD?=
 =?us-ascii?q?kIOCI48GHPi8x/kqRboA66pxdix4LYeZyZOOZicq/Ye94RWGhPUdtLVyFZDI2y?=
 =?us-ascii?q?b5UBAfcCM+ZWoIbyu0YBoxS8CgaiH+Pv0j1Fi2Tq3aA5yektDR3K0RY9E98IrX?=
 =?us-ascii?q?/arM/1NKAXUe2tyKfH0y/Db/RT2Tjj9YPGcxQhofCXXbJrb8Xa1E4iFwHKjlWU?=
 =?us-ascii?q?qIzlJCiV2foWvmiB8eVvSOKvhHQ7qw1rvjevwcIsh5DPi4kIyV7E7T10zJgpKd?=
 =?us-ascii?q?C8UkJ3fNCpHIVKuy2HNIZ6XtkuTmBqtSoi1LEKpZq2cDIXxJkp2RLTceGLfouG?=
 =?us-ascii?q?7x75SuqcIjF1j29/dr2lnRa9602gx/X8Vsaq1FZKqTJIksfDtn8TzRzf8MuHRe?=
 =?us-ascii?q?Vn/kenxzmP0xrf6uZeIUA7jabbKpghzaAslpcLr0jPAiv7lF/rgKKYaEko4PWk?=
 =?us-ascii?q?5uf7brn8p5KRNZd4igTkPaQvnsy/D/44Mg8LX2WD/eS81bvj/VD2QblTjf05jL?=
 =?us-ascii?q?PZsJbEKsQfv6K5BAFU0oA95BalFDqmztsYkmcdLF5fexKIkZLpO1fQL/D8F/u/?=
 =?us-ascii?q?hE6skDhzy/DcIrLhGonNLmTEkLr5ebZ96k1cxxQpwdFQ+pJZEbUBIPP1Wk/su9?=
 =?us-ascii?q?3UFB45Mwqow+n5DNVxzJ8RWWWKAqWBKqPdrUeI5v4zI+mLfIIVuCzyK/k55/H0?=
 =?us-ascii?q?in81g18dfbSz0psRZ3C1BfBmI0SfYXrxjdYNC2YKvgwiTOP0jF2OSyJcZ3G3X6?=
 =?us-ascii?q?gk/DE0FJqmDZvfRoCqmLGB3iC7EYNMamBFDVCMF3Hod4KfVvcIaSKSJNJhkzMe?=
 =?us-ascii?q?WbigTY8hyQ+htAvgx7V7KerU/zUStYj/29ht++3TiRYy+CRuAMSG02GNSGJ0kn?=
 =?us-ascii?q?kSRzAs3qByukh9ylaF0ahljP1UD91T5/VVUggkMZ7Q1fB1C9f3WgjZZNeGVE6m?=
 =?us-ascii?q?Qsm6ATE2Vt8xwMUBY0BnF9WmjxDMxSyqA7AOmryPBZw09L/c3nfrK8Z8zXbGyL?=
 =?us-ascii?q?cuj108TsRTMm2mg7Z19xLPCI7Rj0WZi6GqeLwB0yHX6meM03CCvEFCXw52SqXK?=
 =?us-ascii?q?Q3YfakzSrdT640PCS6SjCbAmMgtH1M6DJbFGatzvjVVaWvjjPM7SbH62m2e1HR?=
 =?us-ascii?q?yI3K+DbJL2e2UB2yXQEFULnBoN/XmYLwQ+Bj2uo2TFDDNwE1LieEfs8eh4qHOm?=
 =?us-ascii?q?QU441QCKb0t917Wr/h4Zn+CTS/QW3rgcoicuty10HEqh39LRE9eAuwthfKBbYd?=
 =?us-ascii?q?Mh4FdG1XjVtxBnMpynNaBigl8ecwJ4v0710xV3C4NAkdUlrX8wzQpyL76Y301F?=
 =?us-ascii?q?dz+CwZ/wPbjXIHHo/B+zc67Wxk3e0NGO96gV7PQ3tVrisx+pF0Y46HpnzsRa3G?=
 =?us-ascii?q?Ga5pXJCwoST4n8UkI29xh8urHbbTMx54LS1X1wL6a0tiXO1M4uBOsg0hygZctQ?=
 =?us-ascii?q?MLuYFA/uFM0XH8ivKPEwl1e1dB4FPeBS+7QyP8OpbPaG3K+rPOB9nDOpl2hH4Y?=
 =?us-ascii?q?Z90l6S+Cp4UOLHw5EFw/SA1AudSzj8lEuhstzwmY1cfzESH3awxjL+BIFMYa1+?=
 =?us-ascii?q?Z4ALBnm0I82239lxm4TiW3pF+1G9HVMG38mpdAGWb1z82w1QyEsWrWammSu+0z?=
 =?us-ascii?q?x7jTUporCD0yzJxuTobAAHNXJTRGl+kVfsJpC5jtAbXESybwkljgCl5Vv8x6VA?=
 =?us-ascii?q?oKR/Lm/TQVpHfiTsLmFiVLewuaSGY8JV9JwotiBXWvymYV+GUr79vwca0yT7Em?=
 =?us-ascii?q?tc3j87bTKqupb+nxBgk2KSNnVzrHnYecF22xjf4sfRRfpQ3joAWSl5hiPbBlm6?=
 =?us-ascii?q?P9m149qUk43Pvfy5V2KkTpdTazXkzZuctCun4m1nGR2+kOq0mtH9Ewg60Cn72s?=
 =?us-ascii?q?JuVSXJqhb8f4bq2767MeJhYklnGlv859BmFYF5l4s6nIsQ1mQChpWJ4XoHln/+?=
 =?us-ascii?q?MdZB1qL/dnYNRSMLzMTT4Ajqw0BjKnOJx4TkVnSS2MdhZt+6Yn8I1SI59cxFFK?=
 =?us-ascii?q?CU7LlclytvvlW4tR7RYeR6njoFzPsu6X0ajPsTtAsj0CqdGawSEldCPSP3iRuI?=
 =?us-ascii?q?9d++ob5TZGaud7iwyUV/kcqgDLGEvgFTRnL5do0+Ei9368V1KEjM32Hr6oH4ZN?=
 =?us-ascii?q?nQasoetgGTkxfFleRUKYg+lvwXhSp8ImL9vGYoy+o6jRxowJG7s5KLK2Rr/KKl?=
 =?us-ascii?q?HBFYMif5aN8U+jHolaxehNqZ35izHpV9HTUGRIDnQuivEDIWqPTrLQKOECAnp3?=
 =?us-ascii?q?efGLrfGxKf6Uh8o3LOFZCrK2+YJH0Dwdp+QxmdIVRVgBoIUzUigp45CgeqydTj?=
 =?us-ascii?q?cEhj4zAe+EX4pgFQyu5yNBn/T2TfpBquajguU5iSNx5W7gBE50fIPs2S9ONzHy?=
 =?us-ascii?q?dE/pK/qAyBMHCUZwNNDWsRQEyLG0jjPqWy5dnH6+WZBu2+L+bXYbWTs+NeUe2E?=
 =?us-ascii?q?xYmo0otg8DaBLcGPPnhkD/0m1UtPR3F5G8LFmzoRTywbjT7Cb8mepB2k4C14st?=
 =?us-ascii?q?i/8Oj3WALo/YaPC6VdMdRs+xC1gKePLe2QhDx+KTZXyJwM32LIyKME0V4WiiFu?=
 =?us-ascii?q?cSStELsauS7MSqLQhrFYDxoBZyxvM8tI6ro23hNRNs7DltP1yrl4g+YvBFdYTl?=
 =?us-ascii?q?PhgN+mZMwQL2G5NVPKH0KLNLWAJT3WzMD7e6K8SbtMjOpKsx28oyqUE0jmPj6b?=
 =?us-ascii?q?jTnmSwivMf1QjCGcJBFepIC9chN3BWf/Vt7pdh27P8FxjTAtxb00h3XKNXMTMD?=
 =?us-ascii?q?RmckNNqKGQ4j1cgvllB2NB6X9lJ/GemymF9+nYNooWsfxzDyV0je1a5nE6y7pT?=
 =?us-ascii?q?7C5cRf11mDHdrthho1y9lumPyzxnUAdBqzpRhYKLu1liNrvd9pVaRXnE+xcNvi?=
 =?us-ascii?q?2sDEEmrsVoQvbvuqZWx8KHwK76NjZO29zO+s4bHcLVNISMN393YjTzHzuBLgYf?=
 =?us-ascii?q?SjumfU7bhldGnbnG9HKRr4Mhp7D2lZYOQ6MdX1swQKBJQn95FcAPdc8kFggvlq?=
 =?us-ascii?q?SW2YtRvSKz?=
X-IronPort-Anti-Spam-Filtered: true
X-IronPort-Anti-Spam-Result: =?us-ascii?q?A0AXAABXyBNch0O0hNFlGQEBAQEBAQEBA?=
 =?us-ascii?q?QEBAQcBAQEBAQGBZYFWBYIRjRuNJRSZSisBh0ciOBIBAwEBAQEBAQIBEwEBAQg?=
 =?us-ascii?q?NCQgpL4I2JAGCYQEBAQECAQECCRsLAUYFAQkBAQoOCgklAwwFKSAYGYI4S4F5C?=
 =?us-ascii?q?AWmXjOKLIw+F4FAP4ERgxKEPRCDa4ImAokeITGBRoUUkE4JkU8LGIFdiBY3hyg?=
 =?us-ascii?q?smTWBXYF3MxoIGxWDKIImF447IQEBgTYBARyNGAMBAQ?=
X-IPAS-Result: =?us-ascii?q?A0AXAABXyBNch0O0hNFlGQEBAQEBAQEBAQEBAQcBAQEBAQG?=
 =?us-ascii?q?BZYFWBYIRjRuNJRSZSisBh0ciOBIBAwEBAQEBAQIBEwEBAQgNCQgpL4I2JAGCY?=
 =?us-ascii?q?QEBAQECAQECCRsLAUYFAQkBAQoOCgklAwwFKSAYGYI4S4F5CAWmXjOKLIw+F4F?=
 =?us-ascii?q?AP4ERgxKEPRCDa4ImAokeITGBRoUUkE4JkU8LGIFdiBY3hygsmTWBXYF3MxoIG?=
 =?us-ascii?q?xWDKIImF447IQEBgTYBARyNGAMBAQ?=
X-IronPort-AV: E=Sophos;i="5.56,353,1539673200"; 
   d="scan'208";a="55204197"
X-Amp-Result: UNKNOWN
X-Amp-Original-Verdict: FILE UNKNOWN
X-Amp-File-Uploaded: False
Received: from vger.kernel.org ([209.132.180.67])
  by mtab.intel.com with ESMTP; 14 Dec 2018 07:16:26 -0800
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
        id S1730483AbeLNPNW (ORCPT <rfc822;like.xu@linux.intel.com>
        + 23 others); Fri, 14 Dec 2018 10:13:22 -0500
Received: from mx1.redhat.com ([209.132.183.28]:52878 "EHLO mx1.redhat.com"
        rhost-flags-OK-OK-OK-OK) by vger.kernel.org with ESMTP
        id S1730198AbeLNPNW (ORCPT <rfc822;linux-kernel@vger.kernel.org>);
        Fri, 14 Dec 2018 10:13:22 -0500
Received: from smtp.corp.redhat.com (int-mx04.intmail.prod.int.phx2.redhat.com [10.5.11.14])
        (using TLSv1.2 with cipher AECDH-AES256-SHA (256/256 bits))
        (No client certificate requested)
        by mx1.redhat.com (Postfix) with ESMTPS id 694FE8830E;
        Fri, 14 Dec 2018 15:13:21 +0000 (UTC)
Received: from redhat.com (ovpn-125-82.rdu2.redhat.com [10.10.125.82])
        by smtp.corp.redhat.com (Postfix) with ESMTPS id 7960161295;
        Fri, 14 Dec 2018 15:13:17 +0000 (UTC)
Date: Fri, 14 Dec 2018 10:13:15 -0500
From: Jerome Glisse <jglisse@redhat.com>
To: Dave Chinner <david@fromorbit.com>
Cc: Jan Kara <jack@suse.cz>, John Hubbard <jhubbard@nvidia.com>,
        Matthew Wilcox <willy@infradead.org>,
        Dan Williams <dan.j.williams@intel.com>,
        John Hubbard <john.hubbard@gmail.com>,
        Andrew Morton <akpm@linux-foundation.org>,
        Linux MM <linux-mm@kvack.org>, tom@talpey.com,
        Al Viro <viro@zeniv.linux.org.uk>, benve@cisco.com,
        Christoph Hellwig <hch@infradead.org>,
        Christopher Lameter <cl@linux.com>,
        "Dalessandro, Dennis" <dennis.dalessandro@intel.com>,
        Doug Ledford <dledford@redhat.com>,
        Jason Gunthorpe <jgg@ziepe.ca>,
        Michal Hocko <mhocko@kernel.org>, mike.marciniszyn@intel.com,
        rcampbell@nvidia.com,
        Linux Kernel Mailing List <linux-kernel@vger.kernel.org>,
        linux-fsdevel <linux-fsdevel@vger.kernel.org>
Subject: Re: [PATCH 1/2] mm: introduce put_user_page*(), placeholder versions
Message-ID: <20181214151314.GA3645@redhat.com>
References: <20181207191620.GD3293@redhat.com>
 <3c4d46c0-aced-f96f-1bf3-725d02f11b60@nvidia.com>
 <20181208022445.GA7024@redhat.com>
 <20181210102846.GC29289@quack2.suse.cz>
 <20181212150319.GA3432@redhat.com>
 <20181212214641.GB29416@dastard>
 <20181212215931.GG5037@redhat.com>
 <20181213005119.GD29416@dastard>
 <20181213020229.GN5037@redhat.com>
 <20181214060012.GA10644@dastard>
MIME-Version: 1.0
Content-Type: text/plain; charset=iso-8859-1
Content-Disposition: inline
Content-Transfer-Encoding: 8bit
In-Reply-To: <20181214060012.GA10644@dastard>
User-Agent: Mutt/1.10.1 (2018-07-13)
X-Scanned-By: MIMEDefang 2.79 on 10.5.11.14
X-Greylist: Sender IP whitelisted, not delayed by milter-greylist-4.5.16 (mx1.redhat.com [10.5.110.28]); Fri, 14 Dec 2018 15:13:21 +0000 (UTC)
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: <linux-kernel.vger.kernel.org>
X-Mailing-List: linux-kernel@vger.kernel.org

On Fri, Dec 14, 2018 at 05:00:12PM +1100, Dave Chinner wrote:
> On Wed, Dec 12, 2018 at 09:02:29PM -0500, Jerome Glisse wrote:
> > On Thu, Dec 13, 2018 at 11:51:19AM +1100, Dave Chinner wrote:
> > > On Wed, Dec 12, 2018 at 04:59:31PM -0500, Jerome Glisse wrote:
> > > > On Thu, Dec 13, 2018 at 08:46:41AM +1100, Dave Chinner wrote:
> > > > > On Wed, Dec 12, 2018 at 10:03:20AM -0500, Jerome Glisse wrote:
> > > > > > On Mon, Dec 10, 2018 at 11:28:46AM +0100, Jan Kara wrote:
> > > > > > > On Fri 07-12-18 21:24:46, Jerome Glisse wrote:
> > > > > > > So this approach doesn't look like a win to me over using counter in struct
> > > > > > > page and I'd rather try looking into squeezing HMM public page usage of
> > > > > > > struct page so that we can fit that gup counter there as well. I know that
> > > > > > > it may be easier said than done...
> > > > > > 
> > > > > > So i want back to the drawing board and first i would like to ascertain
> > > > > > that we all agree on what the objectives are:
> > > > > > 
> > > > > >     [O1] Avoid write back from a page still being written by either a
> > > > > >          device or some direct I/O or any other existing user of GUP.
> > > 
> > > IOWs, you need to mark pages being written to by a GUP as
> > > PageWriteback, so all attempts to write the page will block on
> > > wait_on_page_writeback() before trying to write the dirty page.
> > 
> > No you don't and you can't for the simple reasons is that the GUP
> > of some device driver can last days, weeks, months, years ... so
> > it is not something you want to do. Here is what happens today:
> >     - user space submit directio read from a file and writing to
> >       virtual address and the problematic case is when that virtual
> >       address is actualy a mmap of a file itself
> >     - kernel do GUP on the virtual address, if the page has write
> >       permission in the CPU page table mapping then the page
> >       refcount is incremented and the page is return to directio
> >       kernel code that do memcpy
> > 
> >       It means that the page already went through page_mkwrite so
> >       all is fine from fs point of view.
> >       If page does not have write permission then a page fault is
> >       triggered and page_mkwrite will happen and prep the page
> >       accordingly
> 
> Yes, the short term GUP references do the right thing. They aren't
> the issue - the problem is the long term GUP references that dirty
> clean pages without first having called ->page_mkwrite.
> 
> > In the above scheme a page write back might happens after we looked
> > up the page from the CPU page table and before directio finish with
> > memcpy so that the page content during the write back might not be
> > stable. This is a small window for things to go bad and i do not
> > think we know if anybody ever experience a bug because of that.
> > 
> > For other GUP users the flow is the same except that device driver
> > that keep the page around and do continuous dma to it might last
> > days, weeks, months, years ... so for those the race window is big
> > enough for bad things to happen. Jan have report of such bugs.
> 
> i.e. this case.
> 
> GUP faults the page, gets marked dirty, time passes, page
> writeback occurs, it's now mapped clean, time passes, another RDMA
> hits those pages, it calls set_page_dirty() again and things go
> boom.
> 
> Basically, you are saying that the problem here is that writeback
> of a dirty page occurred while there was an active GUP, and that
> you want us to ....
> 
> > So what i am proposing to fix the above is have page_mkclean return
> > a is_pin boolean if page is pin than the fs code use a bounce page
> > to do the write back giving a stable bounce page. More over fs will
> > need to keep around all buffer_head, blocks, ... ie whatever is
> > associated with that file offset so that any latter set_page_dirty
> > would not freak out and would not need to reallocate blocks or do
> > anything heavy weight.
> 
> .... keep the dirty page pinned and never written back until the GUP
> is released.

I am sorry if i am so hard to understand but this is not what i
have in mind. WHat i have in mind is the write back will use a
bounce page so that the page content is stable and dma can keep
happening to the GUPed page while write back make progress. But
the end of write back callback should not free buffer_head or
blocks or anything that was done by the first page_mkwrite so
that another set_page_dirty can happens at anytime after without
the fs code freaking out.


> Which, quite frankly, is insanity.  The whole point of
> ->page_mkwrite() is that we can clean file backed mapped pages at
> any point in time and have the next write access correctly mark it
> dirty again so it can be written back.
> 
> This is *absolutely necessary* for data integrity (i.e. fsync,
> sync(), etc) as well as filesystem management operations (e.g.
> filesystem freeze) to work correctly and not lose data if the system
> crashes or generate corrupt snapshots for backup or migration
> purposes.

Is keeping the result of the first page_mkwrite not doable ? Or
at least avoiding freeing blocks and such so that we can have a
latter lighter page_mkwrite_light that can be call by put_user_page

The thing is we can not stop the DMA on some device and thus we
can not force device do redo a GUP after a write back. Note that
if you said that device must do that and you will not accept any-
thing that do not do that, i am fine with that, this was what i
advocated for in the first place, but it means that a certain
number of device driver will have to regress from user point of
view ie they will not be able to support GUP anymore.

> 
> > We have a separate discussion on what to do about truncate and other
> > fs event that inherently invalidate portion of file so i do not
> > want to complexify present discussion with those but we also have
> > that in mind.
> > 
> > Do you see any fundamental issues with that ? It abides by all
> > existing fs standard AFAICT (you have a page_mkwrite and we ask
> > fs to keep the result of that around).
> 
> The fundamental issue is that ->page_mkwrite must be called on every
> write access to a clean file backed page, not just the first one.
> How long the GUP reference lasts is irrelevant, if the page is clean
> and you need to dirty it, you must call ->page_mkwrite before it is
> marked writeable and dirtied. Every. Time.

I am fine with that then it is just a matter of telling device that
do not abide by mmu notifier that they can not use GUP anymore which
means that it will regress from user point of view. But i am ok with
that.

> 
> > > Think ENOSPC - that has to be handled before we do the DMA, not
> > > after. Before the DMA it is a recoverable error, after the DMA it is
> > > data loss/corruption failure.
> > 
> > Yes agree and i hope that the above explaination properly explains
> > that it would become legal to do set_page_dirty in put_user_page
> > thanks to page_mkclean telling fs code not to recycle anything
> > after write back finish.
> 
> No, page_mkclean doesn't help at all. Every time the page is dirtied
> it may require block allocation (think COW filesystems) and so
> ENOSPC (and block allocation) must be done /before/ the page is
> dirtied. YOU can't just keep re-dirtying the same page and assuming
> that the filesystem will just work with that - that's essentially
> what the current code does with long term GUP references, and that's
> why it's so broken.
> 
> /me is getting tired of explaining the same thing over and over
> again.

Sorry you feel that way, thank you for bearing with me. Like i said
i am fine with telling GUP user that do not abibe by mmu notifier
and thus that keep writing to page after write back that they need
to stop even if it means breaking existing userspace.

Cheers,
Jérôme
