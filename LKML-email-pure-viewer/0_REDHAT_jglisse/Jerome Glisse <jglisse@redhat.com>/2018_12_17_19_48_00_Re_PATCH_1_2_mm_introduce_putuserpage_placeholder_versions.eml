Return-Path: <linux-kernel-owner@vger.kernel.org>
Delivered-To: unknown
Received: from linux.intel.com (10.54.29.200:995) by i7-8700 with POP3-SSL;
  18 Dec 2018 08:49:10 -0000
X-Original-To: like.xu@linux.intel.com
Delivered-To: like.xu@linux.intel.com
Received: from FMSMGA003.fm.intel.com (fmsmga003.fm.intel.com [10.253.24.29])
	(using TLSv1.2 with cipher ECDHE-RSA-AES256-GCM-SHA384 (256/256 bits))
	(No client certificate requested)
	by linux.intel.com (Postfix) with ESMTPS id 642D95805FC;
	Mon, 17 Dec 2018 11:48:11 -0800 (PST)
Received: from fmsmga105.fm.intel.com ([10.1.193.10])
  by FMSMGA003-1.fm.intel.com with ESMTP/TLS/DHE-RSA-AES256-GCM-SHA384; 17 Dec 2018 11:48:10 -0800
X-SG-BADATTACHMENTNOREPLY: True
IronPort-PHdr: =?us-ascii?q?9a23=3A6Hu+OB/6cR+sEP9uRHKM819IXTAuvvDOBiVQ1KB9?=
 =?us-ascii?q?1+wWIJqq85mqBkHD//Il1AaPAd2Lraocw8Pt8InYEVQa5piAtH1QOLdtbDQizf?=
 =?us-ascii?q?ssogo7HcSeAlf6JvO5JwYzHcBFSUM3tyrjaRsdF8nxfUDdrWOv5jAOBBr/KRB1?=
 =?us-ascii?q?JuPoEYLOksi7ze+/94HQbglSmDaxfa55IQmrownWqsQYm5ZpJLwryhvOrHtIeu?=
 =?us-ascii?q?BWyn1tKFmOgRvy5dq+8YB6/ShItP0v68BPUaPhf6QlVrNYFygpM3o05MLwqxbO?=
 =?us-ascii?q?SxaE62YGXWUXlhpIBBXF7A3/U5zsvCb2qvZx1S+HNsDtU7s6RSqt4LtqSB/wiS?=
 =?us-ascii?q?cIKTg58H3MisdtiK5XuQ+tqwBjz4LRZoyeKfhwcb7Hfd4CS2RPXthfWTFCDIOy?=
 =?us-ascii?q?YIQAE/cOM+laoIbzvFsOtRmzCBKwBO7s0DJEmmP60Lcn3+knDArI3BYgH9ULsH?=
 =?us-ascii?q?nMqNv6Kr0SUeewzKbW0D7NbvdW2Tbm6IjTbB8qvPaBXbB/ccrVyEkvDBjFgUuL?=
 =?us-ascii?q?pIz/ITyay+QNvHKH7+Z6Se2vjGsnphh3rzOyxckskpHEipwJxl3A7yl13Yg4Kc?=
 =?us-ascii?q?OiREJmYtOoDIFcuiCYOoduXM8uX2VltDwnxrAIp5K3ZjUGxZcpyhLFdfCKcI6F?=
 =?us-ascii?q?6Q/5WumLOzd3nndldaq/hxms9UigzfXxVte70FlUtCpJiNrMuW4X1xzV9MeHTu?=
 =?us-ascii?q?Fx/kC72TaAzwzT6+dELl4olafDNZIt3ro9moAOvUnNACP6glj6gayKekk+++Wl?=
 =?us-ascii?q?6fzrYrD8qZ+dM490hBv+MqMrmsGnBeQ4Mw4OX3WU+Oil173s41f5QLNUgf0yi6?=
 =?us-ascii?q?XZt57bJcIFqa6jGAJVzIkj5AilDzu809QXg2MHLFRbdxKDlYTpPEvOIP/gAfel?=
 =?us-ascii?q?n1usiCtrx+zBPrD5BpXNL3vDn6n7cbdy9k5R0w4zzdFZ55JJBbANOvPzWknttN?=
 =?us-ascii?q?PGCh81KRC7w+HiCN9lzIMRRXqPArOFMKPVqVKI5vggI+iQZIAPvzbxMfgl5+P0?=
 =?us-ascii?q?gn8/ll8QZq2p3ZoRaHClEfVqOUSZYXzwgtgfFWcGpBYxTOvviFeaSz5ce26yX7?=
 =?us-ascii?q?4g5jE8EI+mD4DDSZ63jLyC2ye7GJtWZmddB1CIEHfocZiEWvgWZCKTJM9hjiIL?=
 =?us-ascii?q?Vby7R4A90hGusRfwy6B7IerM5i0YqZXj2cBv6O3IlREy8j90A96H026XTWF5hW?=
 =?us-ascii?q?cIRz4w3KBirk1x0FaD0a5kg/NGEdxf/e9GUgA/NZTE1ex1F8jyWh7dfteOUFum?=
 =?us-ascii?q?Qc+pATcrQtI1wt8BeUB9G9q5gxDH3iqqBaIVlrORCJw19KLcw2b+J8Jnx3na06?=
 =?us-ascii?q?khikEsQtFTOm2+mq5/6w/TCpbUnEqDiaala74Q3C7X+2eF1mqBokdYXAl0UaXG?=
 =?us-ascii?q?WHAfYlDbrdD45kPEUr+vBq4rMgpHyc6eNKRKbsflgklBRPfmIN7eeX6+m3+sBR?=
 =?us-ascii?q?aUwbOBdJfldH8D3CrDEkQEkxoc/XCdNQcgACesuGbeDD1oFVLybELg6+h+qHWn?=
 =?us-ascii?q?TkAqywGGdVFu172w+hQNn/yTV+sT3q4YuCcmszh0AFe939fRC9qcpwpgfL9QYc?=
 =?us-ascii?q?8n7FdAz2LZsw19PpqvL615gl4ecgJ3v17h1hltC4VAl9Qqo20uzAZoNa2Y11ZB?=
 =?us-ascii?q?fSuC3Z/sIr3XNnXy/Be3ZqHM3lHRztmX9bkP6fgisFrjoRymGVAk83Vk1NlVzW?=
 =?us-ascii?q?CR5pHLDAoUTJLwXVw79xl8p7HGfCY945nY2mFrMamxqjXCwc4mBPM5yha8eNdS?=
 =?us-ascii?q?KKOFFBLoH8IGHcSvKewqlEKvbhILJ+1S8K80P8W7d/qJwqKrPeBgnC64gmRD+o?=
 =?us-ascii?q?xyzkWM9y9kQO7Sw5kF2+2Y3heAVzrkllehs9z4lppeZT4PGWqz0y7kC5BLZq1z?=
 =?us-ascii?q?ZIoEFX2hI8mqydpgnZ7tXHhY+UWnB1MH3s+pZBWTY0b83Q1WyUQYv3inlTGkwD?=
 =?us-ascii?q?xzljEjtrCf0zDWw+T+aBoHPXZGRWljjVv2IYm4lcsaXFWubwUykBul5ED6x7VU?=
 =?us-ascii?q?pahlLmnTR1tIcDbyL214TqSwsb+CadZV6Jw0qSVXTPi8YVeCR77/uRQaySDjH2?=
 =?us-ascii?q?hZxDwhbDGloJb5nx97iGKbMnlzqmHUecVxxRfZ+dzdSuRd3jsARClklzbXAkKw?=
 =?us-ascii?q?MMWu/dWRj53DqPyxV3q9Vp1Pdinm1YOBuzG85WFwAx2/nvazl8bjEQg71y/7yt?=
 =?us-ascii?q?ZrWT/JrBb6fonkyaC6Pfh7cUlvAV/289B6FZ1mkossmJEQ3mAXhpaP8noGi2vz?=
 =?us-ascii?q?Mchb1rj4bHoCXjMLx9/V4A742ExsNH6JxoT5VmmDzctlfdW1fmQW2icl5cBQFK?=
 =?us-ascii?q?iU9KBEnTdyolegqALRYPt9kS0Hxfog9nEamP0JtxQ3ziqGHL8SB0ZYMDfolxSJ?=
 =?us-ascii?q?6dC+sapWaHyucbi2yEpxg9ShAKuerQFbXXbzYo0iEjNo7sVjLFLM12X+6p3jeN?=
 =?us-ascii?q?nVd94StwebkxHdj+hOM5Ixl+EHhS5mOWL7oH0kxPQ3jR1o3ZGmooeHL39h876+?=
 =?us-ascii?q?Ah5dLjf1fd8c+inxjaZCmcabx5ugEY9mGjUPQZvkV/aoEC8JuPTjNgaOFiA8q3?=
 =?us-ascii?q?iBFbreGw+f9Flpr3bVH5+3MHGXIWETzc9+SxmFOExfnAcUUS04npEjEwCl2tfh?=
 =?us-ascii?q?fF1l5jwL5V74txhMyv9uNxblSWfSvwOoajYySJiCIxta9ABC50HJMcOA6uJ/BT?=
 =?us-ascii?q?1X/pqkrAaVMGyUexxIDX0VWkyDH13iPr6u5cTZ8+iFHOW+KeHCYa6JqexYWPeF?=
 =?us-ascii?q?3pav0opg/zaROcSDJHhiD/sn2kVdWXB1AdjWmzIKSyYPjSLCc9abpAug+i1wts?=
 =?us-ascii?q?2/8OrkWAPs5YuMCrteK9Zv+wqxgaeMKeGQnjt5KS1D25MIxH/IzqUf3VEIhyFv?=
 =?us-ascii?q?cTmtDaoPtSrXQK3Mna9XCgYRazlvO8tQ86I8wg5NNNbBhdPozbF4lOA6CldfWV?=
 =?us-ascii?q?zlm8GkfsgKI2C7NFPaC0eHLrWGJTvXw87pZaOwU6FfjOJRtxeoozaUD1fjPiif?=
 =?us-ascii?q?lznuTx2vLeBMjCSBMBNCoo2ybhZtBnblTN/9bh27Mdl3jSA5wLEuh3PKM3IcPi?=
 =?us-ascii?q?Z4c09XsrKQ6iZYiO1lG2Nd9nplMfWEmyGB4ujYMJkWt/5rAiVyl+1C4XU6y6Fa?=
 =?us-ascii?q?7CdLRPFunCvSr9huo0ypk+WVyzpnVgZOpShPhI6RoUpiPqDZpdF8XiPh9Q4R7W?=
 =?us-ascii?q?iPQysLo9BiGpW7pKFUzsnnlaT9Mj5O/tvYu8wGCJ6HBtiANS8DPADuHTOcIw8E?=
 =?us-ascii?q?ViWmfTXdiEhci+qf3meYopgztt7nn59YGewTb0A8Cv5PUhctJ9cFOpoiG2p8yb?=
 =?us-ascii?q?M=3D?=
X-IronPort-Anti-Spam-Filtered: true
X-IronPort-Anti-Spam-Result: =?us-ascii?q?A0AHAAC//Bdch0O0hNFjGQEBAQEBAQEBA?=
 =?us-ascii?q?QEBAQcBAQEBAQGBVAEBAQEBAQsBAYFZghGNG4sZgg0UmUsrAYdWIjcGDQEDAQE?=
 =?us-ascii?q?BAQEBAgETAQEBCgsJCCkvQgEOAYFkJAGCYgECAwECCSYBRgYJAQEKDgoJJQMMB?=
 =?us-ascii?q?SkgGBaCPEuCAQWpWYopjD4XgUA/hCOEbYNNgiYCizaFFZBOCYgWiTkLGIFdiBa?=
 =?us-ascii?q?HXyyZOIFcgXgzGggbFTuCbYImF447IQEBgTYBARyGT4Q4gkwBAQ?=
X-IPAS-Result: =?us-ascii?q?A0AHAAC//Bdch0O0hNFjGQEBAQEBAQEBAQEBAQcBAQEBAQG?=
 =?us-ascii?q?BVAEBAQEBAQsBAYFZghGNG4sZgg0UmUsrAYdWIjcGDQEDAQEBAQEBAgETAQEBC?=
 =?us-ascii?q?gsJCCkvQgEOAYFkJAGCYgECAwECCSYBRgYJAQEKDgoJJQMMBSkgGBaCPEuCAQW?=
 =?us-ascii?q?pWYopjD4XgUA/hCOEbYNNgiYCizaFFZBOCYgWiTkLGIFdiBaHXyyZOIFcgXgzG?=
 =?us-ascii?q?ggbFTuCbYImF447IQEBgTYBARyGT4Q4gkwBAQ?=
X-IronPort-AV: E=Sophos;i="5.56,366,1539673200"; 
   d="scan'208";a="142472782"
X-Amp-Result: UNKNOWN
X-Amp-Original-Verdict: FILE UNKNOWN
X-Amp-File-Uploaded: False
Received: from vger.kernel.org ([209.132.180.67])
  by mtab.intel.com with ESMTP; 17 Dec 2018 11:48:09 -0800
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
        id S1733197AbeLQTsH (ORCPT <rfc822;like.xu@linux.intel.com>
        + 23 others); Mon, 17 Dec 2018 14:48:07 -0500
Received: from mx1.redhat.com ([209.132.183.28]:56336 "EHLO mx1.redhat.com"
        rhost-flags-OK-OK-OK-OK) by vger.kernel.org with ESMTP
        id S1726660AbeLQTsG (ORCPT <rfc822;linux-kernel@vger.kernel.org>);
        Mon, 17 Dec 2018 14:48:06 -0500
Received: from smtp.corp.redhat.com (int-mx07.intmail.prod.int.phx2.redhat.com [10.5.11.22])
        (using TLSv1.2 with cipher AECDH-AES256-SHA (256/256 bits))
        (No client certificate requested)
        by mx1.redhat.com (Postfix) with ESMTPS id 312C346263;
        Mon, 17 Dec 2018 19:48:05 +0000 (UTC)
Received: from redhat.com (ovpn-125-170.rdu2.redhat.com [10.10.125.170])
        by smtp.corp.redhat.com (Postfix) with ESMTPS id 390741001F50;
        Mon, 17 Dec 2018 19:48:02 +0000 (UTC)
Date: Mon, 17 Dec 2018 14:48:00 -0500
From: Jerome Glisse <jglisse@redhat.com>
To: Matthew Wilcox <willy@infradead.org>
Cc: Dave Chinner <david@fromorbit.com>, Jan Kara <jack@suse.cz>,
        John Hubbard <jhubbard@nvidia.com>,
        Dan Williams <dan.j.williams@intel.com>,
        John Hubbard <john.hubbard@gmail.com>,
        Andrew Morton <akpm@linux-foundation.org>,
        Linux MM <linux-mm@kvack.org>, tom@talpey.com,
        Al Viro <viro@zeniv.linux.org.uk>, benve@cisco.com,
        Christoph Hellwig <hch@infradead.org>,
        Christopher Lameter <cl@linux.com>,
        "Dalessandro, Dennis" <dennis.dalessandro@intel.com>,
        Doug Ledford <dledford@redhat.com>,
        Jason Gunthorpe <jgg@ziepe.ca>,
        Michal Hocko <mhocko@kernel.org>, mike.marciniszyn@intel.com,
        rcampbell@nvidia.com,
        Linux Kernel Mailing List <linux-kernel@vger.kernel.org>,
        linux-fsdevel <linux-fsdevel@vger.kernel.org>
Subject: Re: [PATCH 1/2] mm: introduce put_user_page*(), placeholder versions
Message-ID: <20181217194759.GB3341@redhat.com>
References: <20181207191620.GD3293@redhat.com>
 <3c4d46c0-aced-f96f-1bf3-725d02f11b60@nvidia.com>
 <20181208022445.GA7024@redhat.com>
 <20181210102846.GC29289@quack2.suse.cz>
 <20181212150319.GA3432@redhat.com>
 <20181212214641.GB29416@dastard>
 <20181214154321.GF8896@quack2.suse.cz>
 <20181216215819.GC10644@dastard>
 <20181217181148.GA3341@redhat.com>
 <20181217183443.GO10600@bombadil.infradead.org>
MIME-Version: 1.0
Content-Type: text/plain; charset=iso-8859-1
Content-Disposition: inline
Content-Transfer-Encoding: 8bit
In-Reply-To: <20181217183443.GO10600@bombadil.infradead.org>
User-Agent: Mutt/1.10.1 (2018-07-13)
X-Scanned-By: MIMEDefang 2.84 on 10.5.11.22
X-Greylist: Sender IP whitelisted, not delayed by milter-greylist-4.5.16 (mx1.redhat.com [10.5.110.29]); Mon, 17 Dec 2018 19:48:05 +0000 (UTC)
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: <linux-kernel.vger.kernel.org>
X-Mailing-List: linux-kernel@vger.kernel.org

On Mon, Dec 17, 2018 at 10:34:43AM -0800, Matthew Wilcox wrote:
> On Mon, Dec 17, 2018 at 01:11:50PM -0500, Jerome Glisse wrote:
> > On Mon, Dec 17, 2018 at 08:58:19AM +1100, Dave Chinner wrote:
> > > Sure, that's a possibility, but that doesn't close off any race
> > > conditions because there can be DMA into the page in progress while
> > > the page is being bounced, right? AFAICT this ext3+DIF/DIX case is
> > > different in that there is no 3rd-party access to the page while it
> > > is under IO (ext3 arbitrates all access to it's metadata), and so
> > > nothing can actually race for modification of the page between
> > > submission and bouncing at the block layer.
> > > 
> > > In this case, the moment the page is unlocked, anyone else can map
> > > it and start (R)DMA on it, and that can happen before the bio is
> > > bounced by the block layer. So AFAICT, block layer bouncing doesn't
> > > solve the problem of racing writeback and DMA direct to the page we
> > > are doing IO on. Yes, it reduces the race window substantially, but
> > > it doesn't get rid of it.
> > 
> > So the event flow is:
> >     - userspace create object that match a range of virtual address
> >       against a given kernel sub-system (let's say infiniband) and
> >       let's assume that the range is an mmap() of a regular file
> >     - device driver do GUP on the range (let's assume it is a write
> >       GUP) so if the page is not already map with write permission
> >       in the page table than a page fault is trigger and page_mkwrite
> >       happens
> >     - Once GUP return the page to the device driver and once the
> >       device driver as updated the hardware states to allow access
> >       to this page then from that point on hardware can write to the
> >       page at _any_ time, it is fully disconnected from any fs event
> >       like write back, it fully ignore things like page_mkclean
> > 
> > This is how it is to day, we allowed people to push upstream such
> > users of GUP. This is a fact we have to live with, we can not stop
> > hardware access to the page, we can not force the hardware to follow
> > page_mkclean and force a page_mkwrite once write back ends. This is
> > the situation we are inheriting (and i am personnaly not happy with
> > that).
> > 
> > >From my point of view we are left with 2 choices:
> >     [C1] break all drivers that do not abide by the page_mkclean and
> >          page_mkwrite
> >     [C2] mitigate as much as possible the issue
> > 
> > For [C2] the idea is to keep track of GUP per page so we know if we
> > can expect the page to be written to at any time. Here is the event
> > flow:
> >     - driver GUP the page and program the hardware, page is mark as
> >       GUPed
> >     ...
> >     - write back kicks in on the dirty page, lock the page and every
> >       thing as usual , sees it is GUPed and inform the block layer to
> >       use a bounce page
> 
> No.  The solution John, Dan & I have been looking at is to take the
> dirty page off the LRU while it is pinned by GUP.  It will never be
> found for writeback.
> 
> That's not the end of the story though.  Other parts of the kernel (eg
> msync) also need to be taught to stay away from pages which are pinned
> by GUP.  But the idea is that no page gets written back to storage while
> it's pinned by GUP.  Only when the last GUP ends is the page returned
> to the list of dirty pages.
> 
> >     - block layer copy the page to a bounce page effectively creating
> >       a snapshot of what is the content of the real page. This allows
> >       everything in block layer that need stable content to work on
> >       the bounce page (raid, stripping, encryption, ...)
> >     - once write back is done the page is not marked clean but stays
> >       dirty, this effectively disable things like COW for filesystem
> >       and other feature that expect page_mkwrite between write back.
> >       AFAIK it is believe that it is something acceptable
> 
> So none of this is necessary.

With the solution you are proposing we loose GUP fast and we have to
allocate a structure for each page that is under GUP, and the LRU
changes too. Moreover by not writing back there is a greater chance
of data loss.

I will do patches with the mapcount solution that require very little
change and people will be able to choose which solution they prefer.

Personaly i prefer the mapcount solution as it is less invasive.

Cheers,
Jérôme
