Return-Path: <linux-kernel-owner@vger.kernel.org>
Delivered-To: unknown
Received: from linux.intel.com (10.54.29.200:995) by i7-8700 with POP3-SSL;
  13 Dec 2018 08:53:12 -0000
X-Original-To: like.xu@linux.intel.com
Delivered-To: like.xu@linux.intel.com
Received: from fmsmga002.fm.intel.com (fmsmga002.fm.intel.com [10.253.24.26])
	(using TLSv1.2 with cipher ECDHE-RSA-AES256-GCM-SHA384 (256/256 bits))
	(No client certificate requested)
	by linux.intel.com (Postfix) with ESMTPS id BC88D580380;
	Wed, 12 Dec 2018 09:02:33 -0800 (PST)
Received: from orsmga101.jf.intel.com ([10.7.208.22])
  by fmsmga002-1.fm.intel.com with ESMTP/TLS/DHE-RSA-AES256-GCM-SHA384; 12 Dec 2018 09:02:33 -0800
X-SG-BADATTACHMENTNOREPLY: True
IronPort-PHdr: =?us-ascii?q?9a23=3AZcNKYB8ucU/3MP9uRHKM819IXTAuvvDOBiVQ1KB9?=
 =?us-ascii?q?1+wVIJqq85mqBkHD//Il1AaPAd2Lraocw8Pt8InYEVQa5piAtH1QOLdtbDQizf?=
 =?us-ascii?q?ssogo7HcSeAlf6JvO5JwYzHcBFSUM3tyrjaRsdF8nxfUDdrWOv5jAOBBr/KRB1?=
 =?us-ascii?q?JuPoEYLOksi7ze+/94HQbglSmDaxfa55IQmrownWqsQYm5ZpJLwryhvOrHtIeu?=
 =?us-ascii?q?BWyn1tKFmOgRvy5dq+8YB6/ShItP0v68BPUaPhf6QlVrNYFygpM3o05MLwqxbO?=
 =?us-ascii?q?SxaE62YGXWUXlhpIBBXF7A3/U5zsvCb2qvZx1S+HNsDtU7s6RSqt4LtqSB/wiS?=
 =?us-ascii?q?cIKTg58H3MisdtiK5XuQ+tqwBjz4LRZoyeKfhwcb7Hfd4CS2RPXthfWTFCDIOy?=
 =?us-ascii?q?YIQAE/cOM+laoIbzvFsOtRmzCBKwBO7s0DJEmmP60Lcn3+knDArI3BYgH9ULsH?=
 =?us-ascii?q?nMqNv6Kr0SUeewzKbW0D7NbvdW2Tbm6IjTbB8qvPaBXbB/ccrVyEkvDBjFgUuL?=
 =?us-ascii?q?pIz/ITyay+QNvHKH7+Z6Se2vjGsnphh3rzOyxckskpHEipwJxl3A7yl13Yg4Kc?=
 =?us-ascii?q?OiREJmYtOoDIFcuiCYOoduXM8uX2VltDwnxrAIp5K3ZjUGxZcpyhLFdfCKcI6F?=
 =?us-ascii?q?6Q/5WumLOzd3nndldaq/hxms9UigzfXxVte70FlUtCpJiNrMuW4X1xzV9MeHTu?=
 =?us-ascii?q?Fx/kC72TaAzwzT6+dELl4olafDNZIt3ro9moAOvUnNACP6glj6gayKekk+++Wl?=
 =?us-ascii?q?6fzrYrD8qZ+dM490hBv+MqMrmsGnBeQ4Mw4OX3WU+Oil173s41f5QLNUgf0yi6?=
 =?us-ascii?q?XZt57bJcIFqa6jGAJVzIkj5AilDzu809QXg2MHLFRbdxKDlYTpPEvOIP/gAfel?=
 =?us-ascii?q?n1usiCtrx+zBPrD5BpXNL3vDn6n7cbdy9k5R0w4zzdFZ55JJBbANOvPzWknttN?=
 =?us-ascii?q?PGCh81KRC7w+HiCN9lzIMRRXqPArOFMKPVqVKI5vggI+iQZIAPvzbxMfgl5+P0?=
 =?us-ascii?q?gn8/ll8QZq2p3ZoRaHClEfVqOUSZYXzwgtgfFWcGpBYxTOvviFeaSz5ce26yX7?=
 =?us-ascii?q?4g5jE8EI+mD4DDSZ63jLyC2ye7GJtWZmddB1CIEHfocZiEWvgWZCKTJM9hjiIL?=
 =?us-ascii?q?Vby7R4A90hGusRfwy6B7IerM5i0YqZXj2cBv6O3IlREy8j90A96H026XTWF5hW?=
 =?us-ascii?q?cIRz4w3KBirk1x0FaD0a5kg/NGEdxf/e9GUgA/NZTE1ex1F8jyWh7dfteOUFum?=
 =?us-ascii?q?Qc+pATcrQtI1wt8BeUB9G9q5gxDH3iqqBaIVlrORCJw19KLcw2b+J8Jnx3na06?=
 =?us-ascii?q?khikEsQtFTOm2+mq5/6w/TCpbUnEqDiaala74Q3C7X+2eF1mqBokdYXAl0UaXG?=
 =?us-ascii?q?WHAfYlDbrdD45kPEUr+vBq4rMgpHyc6eNKRKbsflgklBRPfmIN7eeX6+m3+sBR?=
 =?us-ascii?q?aUwbOBdJfldH8D3CrDEkQEkxoc/XCdNQcgACesuGbeDD1oFVLybELg6+h+qHWn?=
 =?us-ascii?q?TkAqywGGdVFu172w+hQNn/yTV+sT3q4YuCcmszh0AFe939fRC9qcpwpgfL9QYc?=
 =?us-ascii?q?8n7FdAz2LZsw19PpqvL615gl4ecgJ3v17h1hltC4VAl9Qqo20uzAZoNa2Y11ZB?=
 =?us-ascii?q?fSuC3Z/sIr3XNnXy/Be3ZqHM3lHRztmX9bkP6fgisFrjoRymGVAk83Vk1NlVzW?=
 =?us-ascii?q?CR5pHLDAoUTJLwXVw79xl8p7HGfCY945nY2mFrMamxqjXCwc4mBPM5yha8eNdS?=
 =?us-ascii?q?KKOFFBLoH8IGHcSvKewqlEKvbhILJ+1S8K80P8W7d/qJwqKrPeBgnC64gmRD+o?=
 =?us-ascii?q?xyzkWM9y9kQO7Sw5kF2+2Y3heAVzrkllehs9z4lppeZT4PGWqz0y7kC5BLZq1z?=
 =?us-ascii?q?ZIoEFX2hI8mqydpgnZ7tXHhY+UWnB1MH3s+pZBWTY0b83Q1WyUQYv3inlTGkwD?=
 =?us-ascii?q?xzljEjtrCf0zDWw+T+aBoHPXZGRWljjVv2IYm4lcsaXFWubwUykBul5ED6x7VU?=
 =?us-ascii?q?pahlLmnTR1tIcDbyL214TqSwsb+CadZV6Jw0qSVXTPi8YVeCR77/uRQaySDjH2?=
 =?us-ascii?q?hZxDwhbDGloJb5nx97iGKbMnlzqmHUecVxxRfZ+dzdSuRd3jsARClklzbXAkKw?=
 =?us-ascii?q?MMWu/dWRj53DqPyxV3q9Vp1Pdinm1YOBuzG85WFwAx2/nvazl8bjEQg71y/7yt?=
 =?us-ascii?q?ZrWT/JrBb6fonkyaC6Pfh7cUlvAV/289B6FZ1mkossmJEQ3mAXhpaP8noGi2vz?=
 =?us-ascii?q?Mchb1rj4bHoCXjMLx9/V4A742ExsNH6JxoT5VmmDzctlfdW1fmQW2icl5cBQFK?=
 =?us-ascii?q?iU9KBEnTdyolegqALRYPt9kS0Hxfog9nEamP0JtxQ3ziqGHL8SB0ZYMDfolxSJ?=
 =?us-ascii?q?6dC+sapWaHyucbi2yEpxg9ShAKuerQFbXXbzYo0iEjNo7sVjLFLM12X+6p3jeN?=
 =?us-ascii?q?nVd94StwebkxHdj+hOM5Ixl+EHhS5mOWL7oH0kxPQ3jR1o3ZGmooeHL39h876+?=
 =?us-ascii?q?Ah5dLjf1fd8c+inxjaZCmcabx5ugEY9mGjUPQZvkV/aoEC8JuPTjNgaOFiA8q3?=
 =?us-ascii?q?iBFbreGw+f9Flpr3bVH5+3MHGXIWETzc9+SxmFOExfnAcUUS04npEjEwCl2tfh?=
 =?us-ascii?q?fF1l5jwL5V74txhMyv9uNxblSWfSvwOoajYySJiCIxta9ABC50HJMcOA6uJ/BT?=
 =?us-ascii?q?1X/pqkrAaVMGyUexxIDX0VWkyDH13iPr6u5cTZ8+iFHOW+KeHCYa6JqexYWPeF?=
 =?us-ascii?q?3pav0opg/zaROcSDJHhiD/sn2kVdWXB1AdjWmzIKSyYPjSLCc9abpAug+i1wts?=
 =?us-ascii?q?2/8OrkWAPs5YuMCrteK9Zv+wqxgaeMKeGQnjt5KS1D25MIxH/IzqUf3VEIhyFv?=
 =?us-ascii?q?cTmtDaoPtSrXQK3Mna9XCgYRazlvO8tQ86I8wg5NNNbBhdPozbF4lOA6CldfWV?=
 =?us-ascii?q?zlm8GkfsgKI2C7NFPaC0eHLrWGJTvXw87pZaOwU6FfjOJRtxeoozaUD1fjPiif?=
 =?us-ascii?q?lznuTx2vLeBMjCSBMBNCoo2ybhZtBnblTN/9bh27Mdl3jSA5wLEuh3PKM3IcPi?=
 =?us-ascii?q?Z4c09XsrKQ6iZYiO1lG2Nd9nplMfWEmyGB4ujYMJkWt/5rAiVyl+1C4XU6y6Fa?=
 =?us-ascii?q?7CdLRPFunCvSr9huo0ypk+WVyzpnVgZOpShPhI6RoUpiPqDZpdF8XiPo9RRF0m?=
 =?us-ascii?q?SUDxUDosAtXtHmveZSjMfOkKbyITJZ29PS4cYYQcPTLZTUHmAmNE/LFSTTCQZN?=
 =?us-ascii?q?YjqqLnrSzxhfn/WT7WaYhoI3ppjlhNwFTboNBw99Le8TFkkwRI9KG5xwRD5x1O?=
 =?us-ascii?q?fD1MM=3D?=
X-IronPort-Anti-Spam-Filtered: true
X-IronPort-Anti-Spam-Result: =?us-ascii?q?A0ADAAByPhFch0O0hNFkGQEBAQEBAQEBA?=
 =?us-ascii?q?QEBAQcBAQEBAQGBUwIBAQEBAQsBAYFUghYnjHSLM4INFJc/gXMUGBMBhz4iNgc?=
 =?us-ascii?q?NAQMBAQEBAQECARMBAQEIDQkIKS9CAQ4BgWQkAYJhAQEBAQIBAQIJGwsBRgYJA?=
 =?us-ascii?q?QEKGAklAwwFKSATBRYDgwOBeggFpxkziiyMPBeBQD+BEYMShE2DaYImAokZghe?=
 =?us-ascii?q?FE5BJCZFMCxiBXIgNNocnLJkTgU0OgXkzGggbFTuCbIInF447IQEBMYEFAQEch?=
 =?us-ascii?q?laGDgEB?=
X-IPAS-Result: =?us-ascii?q?A0ADAAByPhFch0O0hNFkGQEBAQEBAQEBAQEBAQcBAQEBAQG?=
 =?us-ascii?q?BUwIBAQEBAQsBAYFUghYnjHSLM4INFJc/gXMUGBMBhz4iNgcNAQMBAQEBAQECA?=
 =?us-ascii?q?RMBAQEIDQkIKS9CAQ4BgWQkAYJhAQEBAQIBAQIJGwsBRgYJAQEKGAklAwwFKSA?=
 =?us-ascii?q?TBRYDgwOBeggFpxkziiyMPBeBQD+BEYMShE2DaYImAokZgheFE5BJCZFMCxiBX?=
 =?us-ascii?q?IgNNocnLJkTgU0OgXkzGggbFTuCbIInF447IQEBMYEFAQEchlaGDgEB?=
X-IronPort-AV: E=Sophos;i="5.56,345,1539673200"; 
   d="scan'208";a="44684524"
X-Amp-Result: UNSCANNABLE
X-Amp-File-Uploaded: False
Unscannable: 2
Received: from vger.kernel.org ([209.132.180.67])
  by mtab.intel.com with ESMTP; 12 Dec 2018 09:02:31 -0800
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
        id S1727900AbeLLRC1 (ORCPT <rfc822;like.xu@linux.intel.com>
        + 23 others); Wed, 12 Dec 2018 12:02:27 -0500
Received: from mx1.redhat.com ([209.132.183.28]:43968 "EHLO mx1.redhat.com"
        rhost-flags-OK-OK-OK-OK) by vger.kernel.org with ESMTP
        id S1726358AbeLLRC1 (ORCPT <rfc822;linux-kernel@vger.kernel.org>);
        Wed, 12 Dec 2018 12:02:27 -0500
Received: from smtp.corp.redhat.com (int-mx01.intmail.prod.int.phx2.redhat.com [10.5.11.11])
        (using TLSv1.2 with cipher AECDH-AES256-SHA (256/256 bits))
        (No client certificate requested)
        by mx1.redhat.com (Postfix) with ESMTPS id E7E76307CEAE;
        Wed, 12 Dec 2018 17:02:25 +0000 (UTC)
Received: from redhat.com (ovpn-124-14.rdu2.redhat.com [10.10.124.14])
        by smtp.corp.redhat.com (Postfix) with ESMTPS id A28CC6012B;
        Wed, 12 Dec 2018 17:02:22 +0000 (UTC)
Date: Wed, 12 Dec 2018 12:02:20 -0500
From: Jerome Glisse <jglisse@redhat.com>
To: Dan Williams <dan.j.williams@intel.com>
Cc: Jan Kara <jack@suse.cz>, John Hubbard <jhubbard@nvidia.com>,
        Matthew Wilcox <willy@infradead.org>,
        John Hubbard <john.hubbard@gmail.com>,
        Andrew Morton <akpm@linux-foundation.org>,
        Linux MM <linux-mm@kvack.org>, tom@talpey.com,
        Al Viro <viro@zeniv.linux.org.uk>, benve@cisco.com,
        Christoph Hellwig <hch@infradead.org>,
        Christopher Lameter <cl@linux.com>,
        "Dalessandro, Dennis" <dennis.dalessandro@intel.com>,
        Doug Ledford <dledford@redhat.com>,
        Jason Gunthorpe <jgg@ziepe.ca>,
        Michal Hocko <mhocko@kernel.org>,
        Mike Marciniszyn <mike.marciniszyn@intel.com>,
        rcampbell@nvidia.com,
        Linux Kernel Mailing List <linux-kernel@vger.kernel.org>,
        linux-fsdevel <linux-fsdevel@vger.kernel.org>
Subject: Re: [PATCH 1/2] mm: introduce put_user_page*(), placeholder versions
Message-ID: <20181212170220.GA5037@redhat.com>
References: <20181205011519.GV10377@bombadil.infradead.org>
 <20181205014441.GA3045@redhat.com>
 <59ca5c4b-fd5b-1fc6-f891-c7986d91908e@nvidia.com>
 <7b4733be-13d3-c790-ff1b-ac51b505e9a6@nvidia.com>
 <20181207191620.GD3293@redhat.com>
 <3c4d46c0-aced-f96f-1bf3-725d02f11b60@nvidia.com>
 <20181208022445.GA7024@redhat.com>
 <20181210102846.GC29289@quack2.suse.cz>
 <20181212150319.GA3432@redhat.com>
 <CAPcyv4go0Xzhz8rXdfscWuXDu83BO9v8WD4upDUJWb7gKzX5OQ@mail.gmail.com>
MIME-Version: 1.0
Content-Type: text/plain; charset=iso-8859-1
Content-Disposition: inline
Content-Transfer-Encoding: 8bit
In-Reply-To: <CAPcyv4go0Xzhz8rXdfscWuXDu83BO9v8WD4upDUJWb7gKzX5OQ@mail.gmail.com>
User-Agent: Mutt/1.10.1 (2018-07-13)
X-Scanned-By: MIMEDefang 2.79 on 10.5.11.11
X-Greylist: Sender IP whitelisted, not delayed by milter-greylist-4.5.16 (mx1.redhat.com [10.5.110.44]); Wed, 12 Dec 2018 17:02:26 +0000 (UTC)
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: <linux-kernel.vger.kernel.org>
X-Mailing-List: linux-kernel@vger.kernel.org

On Wed, Dec 12, 2018 at 08:27:35AM -0800, Dan Williams wrote:
> On Wed, Dec 12, 2018 at 7:03 AM Jerome Glisse <jglisse@redhat.com> wrote:
> >
> > On Mon, Dec 10, 2018 at 11:28:46AM +0100, Jan Kara wrote:
> > > On Fri 07-12-18 21:24:46, Jerome Glisse wrote:
> > > > Another crazy idea, why not treating GUP as another mapping of the page
> > > > and caller of GUP would have to provide either a fake anon_vma struct or
> > > > a fake vma struct (or both for PRIVATE mapping of a file where you can
> > > > have a mix of both private and file page thus only if it is a read only
> > > > GUP) that would get added to the list of existing mapping.
> > > >
> > > > So the flow would be:
> > > >     somefunction_thatuse_gup()
> > > >     {
> > > >         ...
> > > >         GUP(_fast)(vma, ..., fake_anon, fake_vma);
> > > >         ...
> > > >     }
> > > >
> > > >     GUP(vma, ..., fake_anon, fake_vma)
> > > >     {
> > > >         if (vma->flags == ANON) {
> > > >             // Add the fake anon vma to the anon vma chain as a child
> > > >             // of current vma
> > > >         } else {
> > > >             // Add the fake vma to the mapping tree
> > > >         }
> > > >
> > > >         // The existing GUP except that now it inc mapcount and not
> > > >         // refcount
> > > >         GUP_old(..., &nanonymous, &nfiles);
> > > >
> > > >         atomic_add(&fake_anon->refcount, nanonymous);
> > > >         atomic_add(&fake_vma->refcount, nfiles);
> > > >
> > > >         return nanonymous + nfiles;
> > > >     }
> > >
> > > Thanks for your idea! This is actually something like I was suggesting back
> > > at LSF/MM in Deer Valley. There were two downsides to this I remember
> > > people pointing out:
> > >
> > > 1) This cannot really work with __get_user_pages_fast(). You're not allowed
> > > to get necessary locks to insert new entry into the VMA tree in that
> > > context. So essentially we'd loose get_user_pages_fast() functionality.
> > >
> > > 2) The overhead e.g. for direct IO may be noticeable. You need to allocate
> > > the fake tracking VMA, get VMA interval tree lock, insert into the tree.
> > > Then on IO completion you need to queue work to unpin the pages again as you
> > > cannot remove the fake VMA directly from interrupt context where the IO is
> > > completed.
> > >
> > > You are right that the cost could be amortized if gup() is called for
> > > multiple consecutive pages however for small IOs there's no help...
> > >
> > > So this approach doesn't look like a win to me over using counter in struct
> > > page and I'd rather try looking into squeezing HMM public page usage of
> > > struct page so that we can fit that gup counter there as well. I know that
> > > it may be easier said than done...
> >
> > So i want back to the drawing board and first i would like to ascertain
> > that we all agree on what the objectives are:
> >
> >     [O1] Avoid write back from a page still being written by either a
> >          device or some direct I/O or any other existing user of GUP.
> >          This would avoid possible file system corruption.
> >
> >     [O2] Avoid crash when set_page_dirty() is call on a page that is
> >          considered clean by core mm (buffer head have been remove and
> >          with some file system this turns into an ugly mess).
> >
> >     [O3] DAX and the device block problems, ie with DAX the page map in
> >          userspace is the same as the block (persistent memory) and no
> >          filesystem nor block device understand page as block or pinned
> >          block.
> >
> > For [O3] i don't think any pin count would help in anyway. I believe
> > that the current long term GUP API that does not allow GUP of DAX is
> > the only sane solution for now.
> 
> No, that's not a sane solution, it's an emergency hack.

Then how do you want to solve it ? Knowing pin count does not help
you, at least i do not see how that would help and if it does then
my solution allow you to know pin count it is the difference between
real mapping and mapcount value.


> > The real fix would be to teach file-
> > system about DAX/pinned block so that a pinned block is not reuse
> > by filesystem.
> 
> We already have taught filesystems about pinned dax pages, see
> dax_layout_busy_page(). As much as possible I want to eliminate the
> concept of "dax pages" as a special case that gets sprinkled
> throughout the mm.
> 
> > For [O1] and [O2] i believe a solution with mapcount would work. So
> > no new struct, no fake vma, nothing like that. In GUP for file back
> > pages
> 
> With get_user_pages_fast() we don't know that we have a file-backed
> page, because we don't have a vma.

You do not need a vma to know that we have PageAnon() for that so my
solution is just about adding to core GUP page table walker:

    if (!PageAnon(page))
        atomic_inc(&page->mapcount);


Then in put_user_page() you add the opposite. In page_mkclean() you
count the number of real mapping and voilà ... you got an answer for
[O1]. You could use the same count real mapping to get the pin count
in other place that cares about it but i fails to see why the actual
pin count value would matter to any one.

Cheers,
Jérôme
