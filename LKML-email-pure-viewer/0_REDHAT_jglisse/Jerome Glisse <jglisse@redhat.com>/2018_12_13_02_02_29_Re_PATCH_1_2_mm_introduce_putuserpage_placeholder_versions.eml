Return-Path: <linux-kernel-owner@vger.kernel.org>
Delivered-To: unknown
Received: from linux.intel.com (10.54.29.200:995) by i7-8700 with POP3-SSL;
  13 Dec 2018 21:16:48 -0000
X-Original-To: like.xu@linux.intel.com
Delivered-To: like.xu@linux.intel.com
Received: from fmsmga004.fm.intel.com (fmsmga004.fm.intel.com [10.253.24.48])
	(using TLSv1.2 with cipher ECDHE-RSA-AES256-GCM-SHA384 (256/256 bits))
	(No client certificate requested)
	by linux.intel.com (Postfix) with ESMTPS id 34CCA58079C;
	Wed, 12 Dec 2018 18:05:43 -0800 (PST)
Received: from orsmga101.jf.intel.com ([10.7.208.22])
  by fmsmga004-1.fm.intel.com with ESMTP/TLS/DHE-RSA-AES256-GCM-SHA384; 12 Dec 2018 18:05:41 -0800
X-SG-BADATTACHMENTNOREPLY: True
IronPort-PHdr: =?us-ascii?q?9a23=3AtiglbBLB7Sasd1ZWrNmcpTZWNBhigK39O0sv0rFi?=
 =?us-ascii?q?tYgULvnzrarrMEGX3/hxlliBBdydt6oUzbKO+4nbGkU4qa6bt34DdJEeHzQksu?=
 =?us-ascii?q?4x2zIaPcieFEfgJ+TrZSFpVO5LVVti4m3peRMNQJW2aFLduGC94iAPERvjKwV1?=
 =?us-ascii?q?Ov71GonPhMiryuy+4ZLebxlLiTanfb9+MAi9oBnMuMURnYZsMLs6xAHTontPde?=
 =?us-ascii?q?RWxGdoKkyWkh3h+Mq+/4Nt/jpJtf45+MFOTav1f6IjTbxFFzsmKHw65NfqtRbY?=
 =?us-ascii?q?UwSC4GYXX3gMnRpJBwjF6wz6Xov0vyDnuOdxxDWWMMvrRr0vRz+s87lkRwPpiC?=
 =?us-ascii?q?cfNj427mfXitBrjKlGpB6tvgFzz5LIbI2QMvd1Y6HTcs4ARWdZUMhfVzJPDJ6/?=
 =?us-ascii?q?YYsBAOUOIftXoYb/qFQAthu+HQuhCfjzyjJLnHL6wbE23v48HQzAwQcuH8gOsH?=
 =?us-ascii?q?PRrNjtMKkdT/q1zK7NzTrdcvhY2DP96InTchA6v/6HQLV9ccjeyUkrFgPFlU6Q?=
 =?us-ascii?q?ppL+MjOPyOsCrmib4PB8Ve61l2EnrARxryGpy8wxiYfJnpoYxk7Y+Sh92oo5ON?=
 =?us-ascii?q?O1RFBhbdK5E5ZcqzuWOop0T886XW1kpCI3xqcbtZO1YiQG0okryh3RZvCdbYSF?=
 =?us-ascii?q?4RTuX/uLLzhinnJqYre/ig6y8Ue+zu38UdG50EhFriVbiNnArHMN2ALJ6siBVP?=
 =?us-ascii?q?R9+l2t2TGV1wDc8u1EIEY0mrTHK5M53LI8ip4evV7eEiL4hkn6lrKae0Y49uSy?=
 =?us-ascii?q?6unqYK3qppqGOI91jgH+PL4umsu6AekgNggOXm6b+fmz1bH6/k32Xq9Kjvsona?=
 =?us-ascii?q?ndqZzaIsoapqinDA9PyYsj9Rm/ACm80NgCnnkIMkhFeBSZgIjtIV3OJ+r4Dfin?=
 =?us-ascii?q?j1S2jDhr3+zGPqHmApjVKnjDkbThcqhn509T1Qo+1tRf55NSCrEcL/P/QE7xtN?=
 =?us-ascii?q?rEDhAnNwy42froCNJ41okGQ2KAHreZML/OsV+P/u8vI/ODZI4JuDnnLPgp/f7u?=
 =?us-ascii?q?jWIjll8bcqmkxp8XaHG+HvR7LESVe3vsgtEdEWgUugoyVvDliFqHUTRLfXa9Q7?=
 =?us-ascii?q?o85i0nCIKhFYrDRIetj6Kb0Ce4GZ1WYGZGCleXHHfsdoWEXeoMaS2ILs9glDwE?=
 =?us-ascii?q?SaauS4s72R6ysw/6zqJtLvDI9S0AqZLjyN916vXJmhEp9Tx0CMed33uXT25unG?=
 =?us-ascii?q?MFXDs23KF5oUxgxVaPy6l4g/pEFdNN4/NFSBs1NZnZz+ZiEdD9RhrBfsuVSFah?=
 =?us-ascii?q?WtimAis+TtQrz98KYkZyAdOijh/Y0iquAr8VkaGLBZMu/qLd2XjxO9hyy3Lc2K?=
 =?us-ascii?q?Y9iFkmR9NFNXe6ia5n6wjTG4nJnl2EmKmwa6QTwjTB9GeZwmqIp0FXTghwXaLB?=
 =?us-ascii?q?XXAcY0vWqc/05kfDT7+oFLQmPRFNyc+EKqtWdNLpiU9KS+vkONTbe2ixgXu/BQ?=
 =?us-ascii?q?6UxrOQa4rnY3gS0z/DCEcaiQwT/WyJNQ4lBii/pWLTFzhuFVPpY0Px/uhysnK7?=
 =?us-ascii?q?Tkkozw6Ua01tzaa6+hkQhfaEUfMcwqoEuDs9qzVzBFu9w9PWC9+Hpwp9fKVdYc?=
 =?us-ascii?q?kx4Etd2WLerQx9Op2gL6ZthlMFdwR3vkXu1wh4C4lakMgqqm8qwxR2Ka6CzFxB?=
 =?us-ascii?q?cDaY14jqOrLLMmny4Ayva6nO117E1NaZ5KgO5+o4qln5pw6pC1ct/G9h09lW1H?=
 =?us-ascii?q?uc+I7HDA4TUZL3T0Y2+AJ2p7DcYikh+YzU0WdgPrWzsj/Hw9gpHvcqyg68f9dD?=
 =?us-ascii?q?N6OJDA/zE9AAC8eyMuArmlipYQgCPOBd76M0O8Kmd/2b2K+kJupgnTSmjXhZ74?=
 =?us-ascii?q?B5yE6D6y18SuvQ1ZYf3/6YxheHVyv7jFq5qMD3mJxLaisIHmWizijoHohRabNo?=
 =?us-ascii?q?fYYKEGuhP9e4xtFjiJHzQX5Y81ijCkgC2M+ofxqSclP80RdR1UQRvXyohy+4wy?=
 =?us-ascii?q?ZonDEuq6qVxDbOzPj6dBobJm5LQ3FvjFftIYSuj9EWRlOobxUvlBa+4Ub6xq5b?=
 =?us-ascii?q?pLlwLmXJQEdIeTT2IH9mUqeqqrWCZMtP4osysSpLSOS8fUyaSrnlrhsYySzjBW?=
 =?us-ascii?q?hexDM8dz2woZX2hR96iGGcLHZ1snXZf9p9xRPe5NzaWP5Q0SAKRCh+iTnLGFe8?=
 =?us-ascii?q?O8Ol8smTl5fGquq+TX6uVoVPcSn3yoONrCu66ndtARGlnfCzm9vnHBM+0S/60d?=
 =?us-ascii?q?lqSCrJoAz9Yonty6S1L+ZnclN0C1/77spwApt+nZcohJEMxXgagY2Y/Xkdnmfy?=
 =?us-ascii?q?K9lb2b/+Y2ALRT4E2NPV5Anl2Et+LnOG3Y75V3Odwtd/aNm+eG8ZxiU978VSAq?=
 =?us-ascii?q?eO8LNEhTd1oka/rQ/JZPh9nzQdxuE05H8Une4JoxYtwTuHAr8JA0ZYJyPsmg+M?=
 =?us-ascii?q?79C/qqVXeWmufaKx1Ep4gdCuErWCrhtAV3b+f5coBTVw4dlnMFLQzH3z7ZnpeM?=
 =?us-ascii?q?XXbdIWrBGVkg3Pj+5IKJIqjfoKhDFqOWb8vX0j1u46ggZi3ZC8vIibNWpt+Li1?=
 =?us-ascii?q?DQJfNj3wf8kT4C3ijb5CnsaK2ICiBo5uFS8MXJvsUPKkCjYSten8OgaKET08rG?=
 =?us-ascii?q?qbGLXFEQ+e7kdms2zAE5SxO36LI3kZyM1oRAOBK0xHnAAUQDI6k4Y7Fg+wwczu?=
 =?us-ascii?q?blx56ioN5lLiqRtM1+FoNwT5UmjFvwelcTM0SJmZLBpL4QBO/UbVMcqC7u1tGy?=
 =?us-ascii?q?FU5IGurAuIKmaDfQRHEXkJWlCYB1DkJrSv5d7A8/WBBuqjNfTOZ6+CqfdZV/eO?=
 =?us-ascii?q?ypKiyY9m/zeKNsWSMXhuFfw72kxfXX9nH8TVgSkASysSlyjVdc6UuA+8+jFrrs?=
 =?us-ascii?q?C46PnrWBzg5YqMC7tRMNVj4RO2gb2EN+6fmil5MytY1ogXyH/Mybgf2kMSii50?=
 =?us-ascii?q?ezmsF7QAqTDCTKbKlqBLCB4bbjt5NNFU4KIkwglNJcnbh8vv2b5llfE1EUlKVF?=
 =?us-ascii?q?z7lsGtZMwHOGW9NFLBBEaWO7WKPzzLw8frYayiTb1clvlbtxq1uTyDCU/sIiyD?=
 =?us-ascii?q?lyX1VxCoKexMkCCbPBlEtI6haBpiFWjjQ8zgahCgNN93jDs2waA7h3/QNG4cNy?=
 =?us-ascii?q?R8fF1JrrGK8SxYhfB/EXRb7nV5NemEhzqZ7+7AJ5cWq/RrBCF0l+Nc4HsiyrpV?=
 =?us-ascii?q?7DtLRPp6mCbJqt5uolemkvSAyzZ9URpOrCpLi5yPvUl4JarZ8ZxACj74+0ch5H?=
 =?us-ascii?q?udQz8Kpt1jB8en76xZ1NnDvKzpLzJF6djV4Y0XAM2Ce+ydN390ExfzHzvZRCQB?=
 =?us-ascii?q?TCWwOCmLhUNZkeqJ+1WPo5Q6o4Sqk50LHOwIHGcpH+8XXxw2VOcJJ416C3Z9ye?=
 =?us-ascii?q?aW?=
X-IronPort-Anti-Spam-Filtered: true
X-IronPort-Anti-Spam-Result: =?us-ascii?q?A0ADAABpvRFch0O0hNFjGQEBAQEBAQEBA?=
 =?us-ascii?q?QEBAQcBAQEBAQGBUwIBAQEBAQsBAYFUBYIRjRuLM4INFJc/ggcrAYc+IjYHDQE?=
 =?us-ascii?q?DAQEBAQEBAgETAQEBCA0JCCkvQgEOAYFkJAGCYQEBAQECAQECCRsLAUYGCQEBC?=
 =?us-ascii?q?g4KCSUDDAUpIBgZgjhLgXoIBad7M4o1jDwXgUA/hCOETYYPAokZIAExgUWEFX6?=
 =?us-ascii?q?QSQmRTAsYgVyIDTaHJyyZE4FNBIIDMxoIGxWDKIImF447IQEBgTYBARyGTIM4K?=
 =?us-ascii?q?4IdAwEB?=
X-IPAS-Result: =?us-ascii?q?A0ADAABpvRFch0O0hNFjGQEBAQEBAQEBAQEBAQcBAQEBAQG?=
 =?us-ascii?q?BUwIBAQEBAQsBAYFUBYIRjRuLM4INFJc/ggcrAYc+IjYHDQEDAQEBAQEBAgETA?=
 =?us-ascii?q?QEBCA0JCCkvQgEOAYFkJAGCYQEBAQECAQECCRsLAUYGCQEBCg4KCSUDDAUpIBg?=
 =?us-ascii?q?ZgjhLgXoIBad7M4o1jDwXgUA/hCOETYYPAokZIAExgUWEFX6QSQmRTAsYgVyID?=
 =?us-ascii?q?TaHJyyZE4FNBIIDMxoIGxWDKIImF447IQEBgTYBARyGTIM4K4IdAwEB?=
X-IronPort-AV: E=Sophos;i="5.56,347,1539673200"; 
   d="scan'208";a="44760139"
X-Amp-Result: UNSCANNABLE
X-Amp-File-Uploaded: False
Unscannable: 2
Received: from vger.kernel.org ([209.132.180.67])
  by mtab.intel.com with ESMTP; 12 Dec 2018 18:05:39 -0800
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
        id S1726500AbeLMCCf (ORCPT <rfc822;like.xu@linux.intel.com>
        + 23 others); Wed, 12 Dec 2018 21:02:35 -0500
Received: from mx1.redhat.com ([209.132.183.28]:47364 "EHLO mx1.redhat.com"
        rhost-flags-OK-OK-OK-OK) by vger.kernel.org with ESMTP
        id S1726372AbeLMCCf (ORCPT <rfc822;linux-kernel@vger.kernel.org>);
        Wed, 12 Dec 2018 21:02:35 -0500
Received: from smtp.corp.redhat.com (int-mx04.intmail.prod.int.phx2.redhat.com [10.5.11.14])
        (using TLSv1.2 with cipher AECDH-AES256-SHA (256/256 bits))
        (No client certificate requested)
        by mx1.redhat.com (Postfix) with ESMTPS id 43D3D308FB90;
        Thu, 13 Dec 2018 02:02:34 +0000 (UTC)
Received: from redhat.com (ovpn-124-14.rdu2.redhat.com [10.10.124.14])
        by smtp.corp.redhat.com (Postfix) with ESMTPS id 87C9C607B3;
        Thu, 13 Dec 2018 02:02:31 +0000 (UTC)
Date: Wed, 12 Dec 2018 21:02:29 -0500
From: Jerome Glisse <jglisse@redhat.com>
To: Dave Chinner <david@fromorbit.com>
Cc: Jan Kara <jack@suse.cz>, John Hubbard <jhubbard@nvidia.com>,
        Matthew Wilcox <willy@infradead.org>,
        Dan Williams <dan.j.williams@intel.com>,
        John Hubbard <john.hubbard@gmail.com>,
        Andrew Morton <akpm@linux-foundation.org>,
        Linux MM <linux-mm@kvack.org>, tom@talpey.com,
        Al Viro <viro@zeniv.linux.org.uk>, benve@cisco.com,
        Christoph Hellwig <hch@infradead.org>,
        Christopher Lameter <cl@linux.com>,
        "Dalessandro, Dennis" <dennis.dalessandro@intel.com>,
        Doug Ledford <dledford@redhat.com>,
        Jason Gunthorpe <jgg@ziepe.ca>,
        Michal Hocko <mhocko@kernel.org>, mike.marciniszyn@intel.com,
        rcampbell@nvidia.com,
        Linux Kernel Mailing List <linux-kernel@vger.kernel.org>,
        linux-fsdevel <linux-fsdevel@vger.kernel.org>
Subject: Re: [PATCH 1/2] mm: introduce put_user_page*(), placeholder versions
Message-ID: <20181213020229.GN5037@redhat.com>
References: <59ca5c4b-fd5b-1fc6-f891-c7986d91908e@nvidia.com>
 <7b4733be-13d3-c790-ff1b-ac51b505e9a6@nvidia.com>
 <20181207191620.GD3293@redhat.com>
 <3c4d46c0-aced-f96f-1bf3-725d02f11b60@nvidia.com>
 <20181208022445.GA7024@redhat.com>
 <20181210102846.GC29289@quack2.suse.cz>
 <20181212150319.GA3432@redhat.com>
 <20181212214641.GB29416@dastard>
 <20181212215931.GG5037@redhat.com>
 <20181213005119.GD29416@dastard>
MIME-Version: 1.0
Content-Type: text/plain; charset=iso-8859-1
Content-Disposition: inline
Content-Transfer-Encoding: 8bit
In-Reply-To: <20181213005119.GD29416@dastard>
User-Agent: Mutt/1.10.1 (2018-07-13)
X-Scanned-By: MIMEDefang 2.79 on 10.5.11.14
X-Greylist: Sender IP whitelisted, not delayed by milter-greylist-4.5.16 (mx1.redhat.com [10.5.110.43]); Thu, 13 Dec 2018 02:02:34 +0000 (UTC)
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: <linux-kernel.vger.kernel.org>
X-Mailing-List: linux-kernel@vger.kernel.org

On Thu, Dec 13, 2018 at 11:51:19AM +1100, Dave Chinner wrote:
> On Wed, Dec 12, 2018 at 04:59:31PM -0500, Jerome Glisse wrote:
> > On Thu, Dec 13, 2018 at 08:46:41AM +1100, Dave Chinner wrote:
> > > On Wed, Dec 12, 2018 at 10:03:20AM -0500, Jerome Glisse wrote:
> > > > On Mon, Dec 10, 2018 at 11:28:46AM +0100, Jan Kara wrote:
> > > > > On Fri 07-12-18 21:24:46, Jerome Glisse wrote:
> > > > > So this approach doesn't look like a win to me over using counter in struct
> > > > > page and I'd rather try looking into squeezing HMM public page usage of
> > > > > struct page so that we can fit that gup counter there as well. I know that
> > > > > it may be easier said than done...
> > > > 
> > > > So i want back to the drawing board and first i would like to ascertain
> > > > that we all agree on what the objectives are:
> > > > 
> > > >     [O1] Avoid write back from a page still being written by either a
> > > >          device or some direct I/O or any other existing user of GUP.
> 
> IOWs, you need to mark pages being written to by a GUP as
> PageWriteback, so all attempts to write the page will block on
> wait_on_page_writeback() before trying to write the dirty page.

No you don't and you can't for the simple reasons is that the GUP
of some device driver can last days, weeks, months, years ... so
it is not something you want to do. Here is what happens today:
    - user space submit directio read from a file and writing to
      virtual address and the problematic case is when that virtual
      address is actualy a mmap of a file itself
    - kernel do GUP on the virtual address, if the page has write
      permission in the CPU page table mapping then the page
      refcount is incremented and the page is return to directio
      kernel code that do memcpy

      It means that the page already went through page_mkwrite so
      all is fine from fs point of view.

      If page does not have write permission then a page fault is
      triggered and page_mkwrite will happen and prep the page
      accordingly

In the above scheme a page write back might happens after we looked
up the page from the CPU page table and before directio finish with
memcpy so that the page content during the write back might not be
stable. This is a small window for things to go bad and i do not
think we know if anybody ever experience a bug because of that.

For other GUP users the flow is the same except that device driver
that keep the page around and do continuous dma to it might last
days, weeks, months, years ... so for those the race window is big
enough for bad things to happen. Jan have report of such bugs.

So what i am proposing to fix the above is have page_mkclean return
a is_pin boolean if page is pin than the fs code use a bounce page
to do the write back giving a stable bounce page. More over fs will
need to keep around all buffer_head, blocks, ... ie whatever is
associated with that file offset so that any latter set_page_dirty
would not freak out and would not need to reallocate blocks or do
anything heavy weight.

We have a separate discussion on what to do about truncate and other
fs event that inherently invalidate portion of file so i do not
want to complexify present discussion with those but we also have
that in mind.

Do you see any fundamental issues with that ? It abides by all
existing fs standard AFAICT (you have a page_mkwrite and we ask
fs to keep the result of that around).


> > > >          This would avoid possible file system corruption.
> 
> This isn't a filesystem corruption vector. At worst, it could cause
> torn data writes due to updating the page while it is under IO. We
> have a name for this: "stable pages". This is designed to prevent
> updates to pages via mmap writes from causing corruption of things
> like MD RAID due to modification of the data during RAID parity
> calculations. Hence we have wait_for_stable_page() calls in all
> ->page_mkwrite implementations so that new mmap writes block until
> writeback IO is complete on the devices that require stable pages
> to prevent corruption.
> 
> IOWs, we already deal with this "delay new modification while
> writeback is in progress" problem in the mmap/filesystem world and
> have infrastructure to handle it. And the ->page_mkwrite code
> already deals with it.

Does the above answer that too ?

> 
> > > > 
> > > >     [O2] Avoid crash when set_page_dirty() is call on a page that is
> > > >          considered clean by core mm (buffer head have been remove and
> > > >          with some file system this turns into an ugly mess).
> > > 
> > > I think that's wrong. This isn't an "avoid a crash" case, this is a
> > > "prevent data and/or filesystem corruption" case. The primary goal
> > > we have here is removing our exposure to potential corruption, which
> > > has the secondary effect of avoiding the crash/panics that currently
> > > occur as a result of inconsistent page/filesystem state.
> > 
> > This is O1 avoid corruption is O1
> 
> It's "avoid a specific instance of data corruption", not a general
> mechanism for avoiding data/filesystem corruption.
> 
> Calling set_page_dirty() on a file backed page which has not been
> correctly prepared can cause data corruption, filesystem coruption
> and shutdowns, etc because we have dirty data over a region that is
> not correctly mapped. Yes, it can also cause a crash (because we
> really, really suck at validation and error handling in generic code
> paths), but there's so, so much more that can go wrong than crash
> the kernel when we do stupid shit like this.

I believe i answer in the above explaination.

> 
> > > i.e. The goal is to have ->page_mkwrite() called on the clean page
> > > /before/ the file-backed page is marked dirty, and hence we don't
> > > expose ourselves to potential corruption or crashes that are a
> > > result of inappropriately calling set_page_dirty() on clean
> > > file-backed pages.
> > 
> > Yes and this would be handle by put_user_page ie:
> 
> No, put_user_page() is too late - it's after the DMA has completed,
> but we have to ensure the file has backing store allocated and the
> pages are in the correct state /before/ the DMA is done.
> 
> Think ENOSPC - that has to be handled before we do the DMA, not
> after. Before the DMA it is a recoverable error, after the DMA it is
> data loss/corruption failure.

Yes agree and i hope that the above explaination properly explains
that it would become legal to do set_page_dirty in put_user_page
thanks to page_mkclean telling fs code not to recycle anything
after write back finish.


> > put_user_page(struct page *page, bool dirty)
> > {
> >     if (!PageAnon(page)) {
> >         if (dirty) {
> >             // Do the whole dance ie page_mkwrite and all before
> >             // calling set_page_dirty()
> >         }
> >         ...
> >     }
> >     ...
> > }
> 
> Essentially, doing this would require a whole new "dirty a page"
> infrastructure because it is in the IO path, not the page fault
> path.
> 
> And, for hardware that does it's own page faults for DMA, this whole
> post-DMA page setup is broken because the pages will have already
> gone through ->page_mkwrite() and be set up correctly already.

Does the above properly explain that you would not need a new
set_page_dirty ?

> 
> > > > For [O2] i believe we can handle that case in the put_user_page()
> > > > function to properly dirty the page without causing filesystem
> > > > freak out.
> > > 
> > > I'm pretty sure you can't call ->page_mkwrite() from
> > > put_user_page(), so I don't think this is workable at all.
> > 
> > Hu why ? i can not think of any reason whike you could not. User of
> 
> It's not a fault path, you can't safely lock pages, you can't take
> fault-path only locks in the IO path (mmap_sem inversion problems),
> etc.
> 
> /me has a nagging feeling this was all explained in a previous
> discussions of this patchset...

Did i explain properly my idea this time ? In the scheme i am proposing
it abides by all fs rules that i am aware of at least. I hope i did not
forget any.

Cheers,
Jérôme
