Return-Path: <linux-kernel-owner@vger.kernel.org>
Delivered-To: unknown
Received: from linux.intel.com (10.54.29.200:995) by likexu-workstation with
  POP3-SSL; 06 Dec 2018 09:00:11 -0000
X-Original-To: like.xu@linux.intel.com
Delivered-To: like.xu@linux.intel.com
Received: from fmsmga005.fm.intel.com (fmsmga005.fm.intel.com [10.253.24.32])
	(using TLSv1.2 with cipher ECDHE-RSA-AES256-GCM-SHA384 (256/256 bits))
	(No client certificate requested)
	by linux.intel.com (Postfix) with ESMTPS id 5A284580375;
	Wed,  5 Dec 2018 15:14:19 -0800 (PST)
Received: from fmsmga101.fm.intel.com ([10.1.193.65])
  by fmsmga005-1.fm.intel.com with ESMTP/TLS/DHE-RSA-AES256-GCM-SHA384; 05 Dec 2018 15:14:18 -0800
X-SG-BADATTACHMENTNOREPLY: True
IronPort-PHdr: =?us-ascii?q?9a23=3ArAnNeh9bPN6f9/9uRHKM819IXTAuvvDOBiVQ1KB9?=
 =?us-ascii?q?1e0WIJqq85mqBkHD//Il1AaPAd2Lraocw8Pt8InYEVQa5piAtH1QOLdtbDQizf?=
 =?us-ascii?q?ssogo7HcSeAlf6JvO5JwYzHcBFSUM3tyrjaRsdF8nxfUDdrWOv5jAOBBr/KRB1?=
 =?us-ascii?q?JuPoEYLOksi7ze+/94HQbglSmDaxfa55IQmrownWqsQYm5ZpJLwryhvOrHtIeu?=
 =?us-ascii?q?BWyn1tKFmOgRvy5dq+8YB6/ShItP0v68BPUaPhf6QlVrNYFygpM3o05MLwqxbO?=
 =?us-ascii?q?SxaE62YGXWUXlhpIBBXF7A3/U5zsvCb2qvZx1S+HNsDtU7s6RSqt4LtqSB/wiS?=
 =?us-ascii?q?cIKTg58H3MisdtiK5XuQ+tqwBjz4LRZoyeKfhwcb7Hfd4CSmVBUMReWSxPDI2/?=
 =?us-ascii?q?coUBEfYOPf1Ar4T/vFYOsQeyCBOwCO/z1jNFhHn71rA63eQ7FgHG2RQtEs4IsH?=
 =?us-ascii?q?vJrNT+KaEcUf2pzKnPyDXDbulW2Sz+6IjJbxsspvWMXa9sccrW0kQvFB3Kjk+W?=
 =?us-ascii?q?qYP7OzOZzOMNs3KU7+d5U++klm0pqxlprzSx2sshjpPFip8bx1za7yl13YU4Kc?=
 =?us-ascii?q?GiREN6Y9OoCIVcuz2eOodsQc4vQ3tktDgkxrEbo5K2fDQGxZI6zBDFcfOHaZKH?=
 =?us-ascii?q?4hf7WeaRPzh4gHVldaqhhxa970eg0PfwVsqq31ZQqCpKjN3MumoK1xzJ5ciLUv?=
 =?us-ascii?q?p9/kG/1jaTzw3f9P1ILEQumabGJZMt3KQ8mocQvEjfBCP7mUf7gLeTdko+++io?=
 =?us-ascii?q?7+rnYq/hpp+ZL4J0jgD+MqIzms2wGOg4MRYBX3Kd+eui0L3v5Er5QbtMjvIoiK?=
 =?us-ascii?q?nUq47aJcsFqa6jGQNV0Zgs6wy5Dzi41NQUh34HLEhKeB6flYjmJ0nOIOzkDfe4?=
 =?us-ascii?q?m1mslDZrx/PYMbH7DZTNM2POkLPgfbZ79k5dxxA/zdFZ55JIFL4BJOj/VVP2tN?=
 =?us-ascii?q?zdFhU5KRC7w/77CNVh0YMTQWKPDbWYMKPOq1CI4fgjI+mRZIAPvjb9JOMo5/rv?=
 =?us-ascii?q?jX8/hF8ccrOl3ZoRaHCkAPtmJ1+VbmbrgtcECW0KpBYxTPT2iF2eVj5ef3SyX6?=
 =?us-ascii?q?Ui6T0hC4KmCoHDRoaqgLGa2Ce7H5tWZn1JC1yWEHfocZmEVOkIaC6IPsBhlTkE?=
 =?us-ascii?q?X6C7S4A9zRGuqBP6y71/I+XO4S0YtZXj1Ntv6+3Jjx4y9yd5D8Cc02GLUmF1kX?=
 =?us-ascii?q?kERz4w3KBjv0N9zk2P3rR/g/xdDdZT/e9GUh8mNZ7AyOx3E9PyVRjHftuTTFam?=
 =?us-ascii?q?Q8+pATc+Tt8qx98OYkB9G8itjxzZ3iqqBaMVmKKPBJAu7q3c2H3xLd5ny3nazK?=
 =?us-ascii?q?khk0UmQsxXOGK7nKF/6RbcC5TJk0qDkaaqbroT3CjK+GeHzmqOuUVYXRV0UaXE?=
 =?us-ascii?q?W3Afe0TXoc745kPEU7+hF7AnPhFdxs6FL6tAcsfpgkleRPf/JNTeZHq8lHqqCh?=
 =?us-ascii?q?aW2LyAdorqdH8b3CXGFkcElRse/XKHNQg4GyegrHjSDD1oFVLzfUzs9fNyp2+8?=
 =?us-ascii?q?Tk8x1wuKdVFu16Kp+h4JgvyRU+8T3rMBuCcmtzV0HFa808jKC9aaoAphZqFcYd?=
 =?us-ascii?q?I74FdIzm/Zsw19Ppq9L6FtnFIecgJ3v1/w2BVzEIlPjc8qrHYyxgpoNa2YyE9B?=
 =?us-ascii?q?dy+f3Z3oILLXLnf9/R+xZK/WwF3Ry8uW9boV5/Q+qFXjux+pG1Em83Vm1dlVzn?=
 =?us-ascii?q?Sd6o/LDAoUTZL+TEI3+wJmqLHdZyk3/5nU2mF0Mamorj/C3MokBes4yhq6Y9hT?=
 =?us-ascii?q?KqKFFA/oHM0cCMijM+gqm1mvbhIZM+Fe7q80P8W6d/SY3K6nJvpvnDWjjW5f+o?=
 =?us-ascii?q?ByzlqM9zZgSu7Px5sF2fCY0RedWDfmkVihtdr7mYZaajEIH2qz0DTrC5RVZqJv?=
 =?us-ascii?q?Y4kLE2CuI8usy9V6hp7tXWNY9VG5C1MH3s+pZQSdb1jn0QJM0kQXpGStmTGkwD?=
 =?us-ascii?q?xsjzEpsq2f0TTOwuTjbhYGOnRHRHJ/jVfqOoW0i9EaXE61bwkmjhel5ED6x7RF?=
 =?us-ascii?q?q6R7NWXcXUBIfy3uJWF4TqSwrqaCY9JI6J4wsyVYSv68YVOZSr76uRcayDnsH2?=
 =?us-ascii?q?hdxDA6cTGlpJP5kgd+iGKcKnZzsXXYddtxxRfZ+NzTW/pR0iAaSyl/jDndHkK8?=
 =?us-ascii?q?MMWx/dWIi5fDtfizVmK7WZ1UayXrz4KAtC2g6G1uAB2/me2zm9L9HQg71y/7y8?=
 =?us-ascii?q?dlVSHSoBngZYnr0rywMfh7cUlwGF/89816F5l9koQqhZEcw3gahoiP8noBnmf+?=
 =?us-ascii?q?KtFb2aP4bHoQSj8H2d/V4A752EJ9KnKF3Z72VnKYwsF5fdm1fnsW2j4h78BNEK?=
 =?us-ascii?q?qU6b1EnShvrVaiowPef+N9nisDxvs083EVnfsJuAU2wyWZA7ASG1RYPCP2mxSJ?=
 =?us-ascii?q?6dC+sLtYZGK1fbes00p+mMirDKuerQFERHb5ZpAiEDds7sV4NVLAynzy5ZvieN?=
 =?us-ascii?q?nNdtITrRyUngzEj+hULpIxi/ULiTBmOWL7oX0q1eo7gQZy0pG9uYiNM39t876h?=
 =?us-ascii?q?Ah5EKj31YNse9Sr3gqZZmsaWwpqjHpF8GjgQWJvoTPSoEC8dtPj9NgaOFiE8pW?=
 =?us-ascii?q?mfGbbFAQCf70JmpWrVE5+3L3GXOGUZzdJ6SRmfPkNfhR4bXC4gkp4lDAyqx9Hh?=
 =?us-ascii?q?cERk5jAX/FH4sQBByuZpNxn5T2feqx2kajYySJiDMhVW6htO6FvSMcyb9uhzBT?=
 =?us-ascii?q?1X/oW9rAyRLWyWfwRJDWYUWkydGlDsJL+u6cPb8+ifAOq+IODDYbGPqexYSveJ?=
 =?us-ascii?q?yoij0opg/zaQKMqPOmNuAOE82kpGRXp5AdjWmy0TSywLkCLAd86bqwm9+i10rc?=
 =?us-ascii?q?C/8e7nWAH15YuIBLtdL89v+w2tgaqYM+6QhSB5KStX158WxH/IzqQf00AWiy10?=
 =?us-ascii?q?azatFrEAvzbXTK3Mgq9XEwIbayRrOcRS8qIzxRNNNtDbi9/v0r54j+U4C1NEVV?=
 =?us-ascii?q?znh8GoatYGI2C7NFPbGkmLMK6KKiHMw8Hyeam8U6FfjP1Itx2svjaWC1PjPjWG?=
 =?us-ascii?q?lzXzSx+jK/1DjCGFMxxYo4y9dhdtCW7+TNPpcBG7Mdl3jSEozr0wnH/FKWkcMT?=
 =?us-ascii?q?1keUNXsrKQ9T9Ygul4G2FZ7ntqN++EmyOY7+neMpkXsPtrDT5yl+JV+3k6z7pV?=
 =?us-ascii?q?7CdZRP16gifSr9huo024nemL0DZoTB1OqjMYzL6M6GRtPr+RzYVHQW7NtEYM4m?=
 =?us-ascii?q?KKTQ8WoMN9A/XgvqlRzp7Ek6elbH9G8tTJ7Y4VHcPUYJaDMXw8IV/gAjXUJBUK?=
 =?us-ascii?q?QCTtNmzFgUFZ1vaI+SvR5pw7rIX83YFVG+cTAFg0EO4KT18+TYQqPph6RHUnnK?=
 =?us-ascii?q?SdgcpO4mCx+l2ZYcxAopHBHsmZAeruJDuXlrpVL08TyrPnLIgeOJb4ymRuZx97?=
 =?us-ascii?q?loGMEE3VC5QFgiBgbQh8i0xX62RzSHZ7j0LoawCqpnQaD+WokxgtogdzJ+Un8X?=
 =?us-ascii?q?Hn5FJhYhLgqS0ymUwwn53FjCqLfTjqJ6e1XI1KQ37+uk4xGpD2WQB4aUu5h0V/?=
 =?us-ascii?q?NDbCSPRWlbQ2Jk5xjwqJkJ1DCLZ4ULFDZR4K3vKWL6EszEhbgiaq30lK4a3CE5?=
 =?us-ascii?q?Q0x1hiSoKls38Vg1ErV9UyP6GFYfMRllU=3D?=
X-IronPort-Anti-Spam-Filtered: true
X-IronPort-Anti-Spam-Result: =?us-ascii?q?A0AeAADxWghch0O0hNFkHAEBAQQBAQcEA?=
 =?us-ascii?q?QGBUQcBAQsBg2sng3mIGYwNUgaBNRRoiBYOjiwUgVgbGBMBh1MiNAkNAQMBAQE?=
 =?us-ascii?q?BAQECARMBAQEIDQkIKSMMgjYkAYJiAQIDAQIgHQEBNwEFCQEBCgsHBgICJgICA?=
 =?us-ascii?q?x4BBgwBBQEODgYBEgUDgxmBagMIDQWaYDyKHXCBL4J2AQEFgQUBhAENghQIgQu?=
 =?us-ascii?q?Jd4EcF3iBB4ERghRJNYJXgW+DP4JXiySFD493LgmNJHCDLhiBW4g7hxksiF2Fd?=
 =?us-ascii?q?olwDyGBJYINfQhsBoI1ghsJAxeIXoUIAVcfMgGBBAEBiAUqgiMBAQ?=
X-IPAS-Result: =?us-ascii?q?A0AeAADxWghch0O0hNFkHAEBAQQBAQcEAQGBUQcBAQsBg2s?=
 =?us-ascii?q?ng3mIGYwNUgaBNRRoiBYOjiwUgVgbGBMBh1MiNAkNAQMBAQEBAQECARMBAQEID?=
 =?us-ascii?q?QkIKSMMgjYkAYJiAQIDAQIgHQEBNwEFCQEBCgsHBgICJgICAx4BBgwBBQEODgY?=
 =?us-ascii?q?BEgUDgxmBagMIDQWaYDyKHXCBL4J2AQEFgQUBhAENghQIgQuJd4EcF3iBB4ERg?=
 =?us-ascii?q?hRJNYJXgW+DP4JXiySFD493LgmNJHCDLhiBW4g7hxksiF2FdolwDyGBJYINfQh?=
 =?us-ascii?q?sBoI1ghsJAxeIXoUIAVcfMgGBBAEBiAUqgiMBAQ?=
X-IronPort-AV: E=Sophos;i="5.56,320,1539673200"; 
   d="scan'208";a="65526438"
X-Amp-Result: SKIPPED(no attachment in message)
X-Amp-File-Uploaded: False
Received: from vger.kernel.org ([209.132.180.67])
  by mga01b.intel.com with ESMTP; 05 Dec 2018 15:14:17 -0800
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
        id S1728702AbeLEXON (ORCPT <rfc822;like.xu@linux.intel.com>
        + 23 others); Wed, 5 Dec 2018 18:14:13 -0500
Received: from mail.kernel.org ([198.145.29.99]:49130 "EHLO mail.kernel.org"
        rhost-flags-OK-OK-OK-OK) by vger.kernel.org with ESMTP
        id S1727989AbeLEXOM (ORCPT <rfc822;linux-kernel@vger.kernel.org>);
        Wed, 5 Dec 2018 18:14:12 -0500
Received: from mail-wr1-f50.google.com (mail-wr1-f50.google.com [209.85.221.50])
        (using TLSv1.2 with cipher ECDHE-RSA-AES128-GCM-SHA256 (128/128 bits))
        (No client certificate requested)
        by mail.kernel.org (Postfix) with ESMTPSA id E66422151B
        for <linux-kernel@vger.kernel.org>; Wed,  5 Dec 2018 23:14:10 +0000 (UTC)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/simple; d=kernel.org;
        s=default; t=1544051651;
        bh=BeKaZU96jxQ+QrWHo5ZSjr1NGXhFTgyhcbAruoEOk6I=;
        h=References:In-Reply-To:From:Date:Subject:To:Cc:From;
        b=cEBqxt3amhIpDt6cjCKG2awm06xVX2IaxVoVYIQQewmdDocs/6+ZEJRpho4S07yS+
         DzeO9g2QliZzuLmTbbzTvO0wYrEYCmmaDudD6zBeUG/Z0zUbaiLbLalD/ZqLZP7fga
         oT4MfwwgsKiyFxh96ehgvUc1/ky/kUdd795ATq/M=
Received: by mail-wr1-f50.google.com with SMTP id j2so21421793wrw.1
        for <linux-kernel@vger.kernel.org>; Wed, 05 Dec 2018 15:14:10 -0800 (PST)
X-Gm-Message-State: AA+aEWY9KGnyBLpjMj+yOhNeSTizOnPRNYttH/7g0gD4iTTB+K91MyPn
        o4GX4SB0AsnnLfn5rk8EH4spjHsopE17Mcc6BEk4Rw==
X-Google-Smtp-Source: AFSGD/V38YyjfMkHxRGEfqJ9P8L29p9d6M28FVrFWWyTumhxF54mAzVTivWFmTLcKWcUnxOGgxdCvJ7/PxoHjGFE964=
X-Received: by 2002:adf:e08c:: with SMTP id c12mr22013414wri.199.1544051649220;
 Wed, 05 Dec 2018 15:14:09 -0800 (PST)
MIME-Version: 1.0
References: <20181204121805.4621-1-igor.stoppa@huawei.com> <20181204121805.4621-3-igor.stoppa@huawei.com>
In-Reply-To: <20181204121805.4621-3-igor.stoppa@huawei.com>
From: Andy Lutomirski <luto@kernel.org>
Date: Wed, 5 Dec 2018 15:13:56 -0800
X-Gmail-Original-Message-ID: <CALCETrVvoui0vksdt0Y9rdGL5ipEn_FtSXVVUFdH03ZC93cy_A@mail.gmail.com>
Message-ID: <CALCETrVvoui0vksdt0Y9rdGL5ipEn_FtSXVVUFdH03ZC93cy_A@mail.gmail.com>
Subject: Re: [PATCH 2/6] __wr_after_init: write rare for static allocation
To: Igor Stoppa <igor.stoppa@gmail.com>,
        linux-arch <linux-arch@vger.kernel.org>,
        linux-s390 <linux-s390@vger.kernel.org>,
        Martin Schwidefsky <schwidefsky@de.ibm.com>,
        Heiko Carstens <heiko.carstens@de.ibm.com>,
        Benjamin Herrenschmidt <benh@kernel.crashing.org>
Cc: Kees Cook <keescook@chromium.org>,
        Matthew Wilcox <willy@infradead.org>,
        Igor Stoppa <igor.stoppa@huawei.com>,
        Nadav Amit <nadav.amit@gmail.com>,
        Peter Zijlstra <peterz@infradead.org>,
        Dave Hansen <dave.hansen@linux.intel.com>,
        linux-integrity <linux-integrity@vger.kernel.org>,
        Kernel Hardening <kernel-hardening@lists.openwall.com>,
        Linux-MM <linux-mm@kvack.org>,
        LKML <linux-kernel@vger.kernel.org>
Content-Type: text/plain; charset="UTF-8"
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: <linux-kernel.vger.kernel.org>
X-Mailing-List: linux-kernel@vger.kernel.org

I added some s390 and powerpc people.

On Tue, Dec 4, 2018 at 4:18 AM Igor Stoppa <igor.stoppa@gmail.com> wrote:
>
> Implementation of write rare for statically allocated data, located in a
> specific memory section through the use of the __write_rare label.
>
> The basic functions are:
> - wr_memset(): write rare counterpart of memset()
> - wr_memcpy(): write rare counterpart of memcpy()
> - wr_assign(): write rare counterpart of the assignment ('=') operator
> - wr_rcu_assign_pointer(): write rare counterpart of rcu_assign_pointer()
>
> The implementation is based on code from Andy Lutomirski and Nadav Amit
> for patching the text on x86 [here goes reference to commits, once merged]
>
> The modification of write protected data is done through an alternate
> mapping of the same pages, as writable.
> This mapping is local to each core and is active only for the duration
> of each write operation.
> Local interrupts are disabled, while the alternate mapping is active.
>
> In theory, it could introduce a non-predictable delay, in a preemptible
> system, however the amount of data to be altered is likely to be far
> smaller than a page.
>
> Signed-off-by: Igor Stoppa <igor.stoppa@huawei.com>
>
> CC: Andy Lutomirski <luto@amacapital.net>
> CC: Nadav Amit <nadav.amit@gmail.com>
> CC: Matthew Wilcox <willy@infradead.org>
> CC: Peter Zijlstra <peterz@infradead.org>
> CC: Kees Cook <keescook@chromium.org>
> CC: Dave Hansen <dave.hansen@linux.intel.com>
> CC: linux-integrity@vger.kernel.org
> CC: kernel-hardening@lists.openwall.com
> CC: linux-mm@kvack.org
> CC: linux-kernel@vger.kernel.org
> ---
>  include/linux/prmem.h | 133 ++++++++++++++++++++++++++++++++++++++++++
>  init/main.c           |   2 +
>  mm/Kconfig            |   4 ++
>  mm/Makefile           |   1 +
>  mm/prmem.c            | 124 +++++++++++++++++++++++++++++++++++++++
>  5 files changed, 264 insertions(+)
>  create mode 100644 include/linux/prmem.h
>  create mode 100644 mm/prmem.c
>
> diff --git a/include/linux/prmem.h b/include/linux/prmem.h
> new file mode 100644
> index 000000000000..b0131c1f5dc0
> --- /dev/null
> +++ b/include/linux/prmem.h
> @@ -0,0 +1,133 @@
> +/* SPDX-License-Identifier: GPL-2.0 */
> +/*
> + * prmem.h: Header for memory protection library
> + *
> + * (C) Copyright 2018 Huawei Technologies Co. Ltd.
> + * Author: Igor Stoppa <igor.stoppa@huawei.com>
> + *
> + * Support for:
> + * - statically allocated write rare data
> + */
> +
> +#ifndef _LINUX_PRMEM_H
> +#define _LINUX_PRMEM_H
> +
> +#include <linux/set_memory.h>
> +#include <linux/mm.h>
> +#include <linux/vmalloc.h>
> +#include <linux/string.h>
> +#include <linux/slab.h>
> +#include <linux/mutex.h>
> +#include <linux/compiler.h>
> +#include <linux/irqflags.h>
> +
> +/**
> + * memtst() - test n bytes of the source to match the c value
> + * @p: beginning of the memory to test
> + * @c: byte to compare against
> + * @len: amount of bytes to test
> + *
> + * Returns 0 on success, non-zero otherwise.
> + */
> +static inline int memtst(void *p, int c, __kernel_size_t len)
> +{
> +       __kernel_size_t i;
> +
> +       for (i = 0; i < len; i++) {
> +               u8 d =  *(i + (u8 *)p) - (u8)c;
> +
> +               if (unlikely(d))
> +                       return d;
> +       }
> +       return 0;
> +}
> +
> +
> +#ifndef CONFIG_PRMEM
> +
> +static inline void *wr_memset(void *p, int c, __kernel_size_t len)
> +{
> +       return memset(p, c, len);
> +}
> +
> +static inline void *wr_memcpy(void *p, const void *q, __kernel_size_t size)
> +{
> +       return memcpy(p, q, size);
> +}
> +
> +#define wr_assign(var, val)    ((var) = (val))
> +
> +#define wr_rcu_assign_pointer(p, v)    \
> +       rcu_assign_pointer(p, v)
> +
> +#else
> +
> +enum wr_op_type {
> +       WR_MEMCPY,
> +       WR_MEMSET,
> +       WR_RCU_ASSIGN_PTR,
> +       WR_OPS_NUMBER,
> +};
> +
> +void *__wr_op(unsigned long dst, unsigned long src, __kernel_size_t len,
> +             enum wr_op_type op);
> +
> +/**
> + * wr_memset() - sets n bytes of the destination to the c value
> + * @p: beginning of the memory to write to
> + * @c: byte to replicate
> + * @len: amount of bytes to copy
> + *
> + * Returns true on success, false otherwise.
> + */
> +static inline void *wr_memset(void *p, int c, __kernel_size_t len)
> +{
> +       return __wr_op((unsigned long)p, (unsigned long)c, len, WR_MEMSET);
> +}
> +
> +/**
> + * wr_memcpy() - copyes n bytes from source to destination
> + * @dst: beginning of the memory to write to
> + * @src: beginning of the memory to read from
> + * @n_bytes: amount of bytes to copy
> + *
> + * Returns pointer to the destination
> + */
> +static inline void *wr_memcpy(void *p, const void *q, __kernel_size_t size)
> +{
> +       return __wr_op((unsigned long)p, (unsigned long)q, size, WR_MEMCPY);
> +}
> +
> +/**
> + * wr_assign() - sets a write-rare variable to a specified value
> + * @var: the variable to set
> + * @val: the new value
> + *
> + * Returns: the variable
> + *
> + * Note: it might be possible to optimize this, to use wr_memset in some
> + * cases (maybe with NULL?).
> + */
> +
> +#define wr_assign(var, val) ({                 \
> +       typeof(var) tmp = (typeof(var))val;     \
> +                                               \
> +       wr_memcpy(&var, &tmp, sizeof(var));     \
> +       var;                                    \
> +})
> +
> +/**
> + * wr_rcu_assign_pointer() - initialize a pointer in rcu mode
> + * @p: the rcu pointer
> + * @v: the new value
> + *
> + * Returns the value assigned to the rcu pointer.
> + *
> + * It is provided as macro, to match rcu_assign_pointer()
> + */
> +#define wr_rcu_assign_pointer(p, v) ({                                 \
> +       __wr_op((unsigned long)&p, v, sizeof(p), WR_RCU_ASSIGN_PTR);    \
> +       p;                                                              \
> +})
> +#endif
> +#endif
> diff --git a/init/main.c b/init/main.c
> index a461150adfb1..a36f2e54f937 100644
> --- a/init/main.c
> +++ b/init/main.c
> @@ -498,6 +498,7 @@ void __init __weak thread_stack_cache_init(void)
>  void __init __weak mem_encrypt_init(void) { }
>
>  void __init __weak poking_init(void) { }
> +void __init __weak wr_poking_init(void) { }
>
>  bool initcall_debug;
>  core_param(initcall_debug, initcall_debug, bool, 0644);
> @@ -734,6 +735,7 @@ asmlinkage __visible void __init start_kernel(void)
>         delayacct_init();
>
>         poking_init();
> +       wr_poking_init();
>         check_bugs();
>
>         acpi_subsystem_init();
> diff --git a/mm/Kconfig b/mm/Kconfig
> index d85e39da47ae..9b09339c027f 100644
> --- a/mm/Kconfig
> +++ b/mm/Kconfig
> @@ -142,6 +142,10 @@ config ARCH_DISCARD_MEMBLOCK
>  config MEMORY_ISOLATION
>         bool
>
> +config PRMEM
> +       def_bool n
> +       depends on STRICT_KERNEL_RWX && X86_64
> +
>  #
>  # Only be set on architectures that have completely implemented memory hotplug
>  # feature. If you are not sure, don't touch it.
> diff --git a/mm/Makefile b/mm/Makefile
> index d210cc9d6f80..ef3867c16ce0 100644
> --- a/mm/Makefile
> +++ b/mm/Makefile
> @@ -58,6 +58,7 @@ obj-$(CONFIG_SPARSEMEM)       += sparse.o
>  obj-$(CONFIG_SPARSEMEM_VMEMMAP) += sparse-vmemmap.o
>  obj-$(CONFIG_SLOB) += slob.o
>  obj-$(CONFIG_MMU_NOTIFIER) += mmu_notifier.o
> +obj-$(CONFIG_PRMEM) += prmem.o
>  obj-$(CONFIG_KSM) += ksm.o
>  obj-$(CONFIG_PAGE_POISONING) += page_poison.o
>  obj-$(CONFIG_SLAB) += slab.o
> diff --git a/mm/prmem.c b/mm/prmem.c
> new file mode 100644
> index 000000000000..e8ab76701831
> --- /dev/null
> +++ b/mm/prmem.c
> @@ -0,0 +1,124 @@
> +// SPDX-License-Identifier: GPL-2.0
> +/*
> + * prmem.c: Memory Protection Library
> + *
> + * (C) Copyright 2017-2018 Huawei Technologies Co. Ltd.
> + * Author: Igor Stoppa <igor.stoppa@huawei.com>
> + */
> +
> +#include <linux/mm.h>
> +#include <linux/string.h>
> +#include <linux/compiler.h>
> +#include <linux/slab.h>
> +#include <linux/mmu_context.h>
> +#include <linux/rcupdate.h>
> +#include <linux/prmem.h>
> +
> +static __ro_after_init bool wr_ready;
> +static __ro_after_init struct mm_struct *wr_poking_mm;
> +static __ro_after_init unsigned long wr_poking_base;
> +
> +/*
> + * The following two variables are statically allocated by the linker
> + * script at the the boundaries of the memory region (rounded up to
> + * multiples of PAGE_SIZE) reserved for __wr_after_init.
> + */
> +extern long __start_wr_after_init;
> +extern long __end_wr_after_init;
> +
> +static inline bool is_wr_after_init(unsigned long ptr, __kernel_size_t size)
> +{
> +       unsigned long start = (unsigned long)&__start_wr_after_init;
> +       unsigned long end = (unsigned long)&__end_wr_after_init;
> +       unsigned long low = ptr;
> +       unsigned long high = ptr + size;
> +
> +       return likely(start <= low && low <= high && high <= end);
> +}
> +
> +
> +void *__wr_op(unsigned long dst, unsigned long src, __kernel_size_t len,
> +             enum wr_op_type op)
> +{

You might end up wanting something like:

#ifdef __arch_wr_op
return __arch_wr_op(...);
#endif

if an arch (s390? powerpc?) decides to have a totally different
implementation of this.

Hi s390 and powerpc people: it would be nice if this generic
implementation *worked* on your architectures and that it will allow
you to add some straightforward way to add a better arch-specific
implementation if you think that would be better.

--Andy

> +       temporary_mm_state_t prev;
> +       unsigned long flags;
> +       unsigned long offset;
> +       unsigned long wr_poking_addr;
> +
> +       /* Confirm that the writable mapping exists. */
> +       BUG_ON(!wr_ready);
> +
> +       if (WARN_ONCE(op >= WR_OPS_NUMBER, "Invalid WR operation.") ||
> +           WARN_ONCE(!is_wr_after_init(dst, len), "Invalid WR range."))
> +               return (void *)dst;
> +
> +       offset = dst - (unsigned long)&__start_wr_after_init;
> +       wr_poking_addr = wr_poking_base + offset;
> +       local_irq_save(flags);
> +       prev = use_temporary_mm(wr_poking_mm);
> +
> +       kasan_disable_current();
> +       if (op == WR_MEMCPY)
> +               memcpy((void *)wr_poking_addr, (void *)src, len);
> +       else if (op == WR_MEMSET)
> +               memset((u8 *)wr_poking_addr, (u8)src, len);
> +       else if (op == WR_RCU_ASSIGN_PTR)
> +               /* generic version of rcu_assign_pointer */
> +               smp_store_release((void **)wr_poking_addr,
> +                                 RCU_INITIALIZER((void **)src));
> +       kasan_enable_current();

Hmm.  I suspect this will explode quite badly on sane architectures
like s390.  (In my book, despite how weird s390 is, it has a vastly
nicer model of "user" memory than any other architecture I know
of...).  I think you should use copy_to_user(), etc, instead.  I'm not
entirely sure what the best smp_store_release() replacement is.
Making this change may also mean you can get rid of the
kasan_disable_current().

> +
> +       barrier(); /* XXX redundant? */

I think it's redundant.  If unuse_temporary_mm() allows earlier stores
to hit the wrong address space, then something is very very wrong, and
something is also very very wrong if the optimizer starts moving
stores across a function call that is most definitely a barrier.

> +
> +       unuse_temporary_mm(prev);
> +       /* XXX make the verification optional? */
> +       if (op == WR_MEMCPY)
> +               BUG_ON(memcmp((void *)dst, (void *)src, len));
> +       else if (op == WR_MEMSET)
> +               BUG_ON(memtst((void *)dst, (u8)src, len));
> +       else if (op == WR_RCU_ASSIGN_PTR)
> +               BUG_ON(*(unsigned long *)dst != src);

Hmm.  If you allowed cmpxchg or even plain xchg, then these bug_ons
would be thoroughly buggy, but maybe they're okay.  But they should,
at most, be WARN_ON_ONCE(), given that you can trigger them by writing
the same addresses from two threads at once, and this isn't even
entirely obviously bogus given the presence of smp_store_release().

> +       local_irq_restore(flags);
> +       return (void *)dst;
> +}
> +
> +struct mm_struct *copy_init_mm(void);
> +void __init wr_poking_init(void)
> +{
> +       unsigned long start = (unsigned long)&__start_wr_after_init;
> +       unsigned long end = (unsigned long)&__end_wr_after_init;
> +       unsigned long i;
> +       unsigned long wr_range;
> +
> +       wr_poking_mm = copy_init_mm();
> +       BUG_ON(!wr_poking_mm);
> +
> +       /* XXX What if it's too large to fit in the task unmapped mem? */
> +       wr_range = round_up(end - start, PAGE_SIZE);
> +
> +       /* Randomize the poking address base*/
> +       wr_poking_base = TASK_UNMAPPED_BASE +
> +               (kaslr_get_random_long("Write Rare Poking") & PAGE_MASK) %
> +               (TASK_SIZE - (TASK_UNMAPPED_BASE + wr_range));
> +
> +       /* Create alternate mapping for the entire wr_after_init range. */
> +       for (i = start; i < end; i += PAGE_SIZE) {
> +               struct page *page;
> +               spinlock_t *ptl;
> +               pte_t pte;
> +               pte_t *ptep;
> +               unsigned long wr_poking_addr;
> +
> +               BUG_ON(!(page = virt_to_page(i)));
> +               wr_poking_addr = i - start + wr_poking_base;
> +
> +               /* The lock is not needed, but avoids open-coding. */
> +               ptep = get_locked_pte(wr_poking_mm, wr_poking_addr, &ptl);
> +               VM_BUG_ON(!ptep);
> +
> +               pte = mk_pte(page, PAGE_KERNEL);
> +               set_pte_at(wr_poking_mm, wr_poking_addr, ptep, pte);
> +               spin_unlock(ptl);
> +       }
> +       wr_ready = true;
> +}
> --
> 2.19.1
>
