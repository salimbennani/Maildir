Return-Path: <linux-kernel-owner@vger.kernel.org>
Delivered-To: unknown
Received: from linux.intel.com (10.54.29.200:995) by likexu-workstation with
  POP3-SSL; 07 Dec 2018 16:18:01 -0000
X-Original-To: like.xu@linux.intel.com
Delivered-To: like.xu@linux.intel.com
Received: from orsmga006.jf.intel.com (orsmga006.jf.intel.com [10.7.209.51])
	(using TLSv1.2 with cipher ECDHE-RSA-AES256-GCM-SHA384 (256/256 bits))
	(No client certificate requested)
	by linux.intel.com (Postfix) with ESMTPS id 14F035804FD;
	Thu,  6 Dec 2018 21:42:07 -0800 (PST)
Received: from fmsmga105.fm.intel.com ([10.1.193.10])
  by orsmga006-1.jf.intel.com with ESMTP/TLS/DHE-RSA-AES256-GCM-SHA384; 06 Dec 2018 21:42:06 -0800
X-SG-BADATTACHMENTNOREPLY: True
IronPort-PHdr: =?us-ascii?q?9a23=3ACFs0whOsvgSniVIIotEl6mtUPXoX/o7sNwtQ0KIM?=
 =?us-ascii?q?zox0KPj+p8bcNUDSrc9gkEXOFd2Cra4c26yO6+jJYi8p2d65qncMcZhBBVcuqP?=
 =?us-ascii?q?49uEgeOvODElDxN/XwbiY3T4xoXV5h+GynYwAOQJ6tL1LdrWev4jEMBx7xKRR6?=
 =?us-ascii?q?JvjvGo7Vks+7y/2+94fcbglUhzexe69+IAmrpgjNq8cahpdvJLwswRXTuHtIfO?=
 =?us-ascii?q?pWxWJsJV2Nmhv3+9m98p1+/SlOovwt78FPX7n0cKQ+VrxYES8pM3sp683xtBnM?=
 =?us-ascii?q?VhWA630BWWgLiBVIAgzF7BbnXpfttybxq+Rw1DWGMcDwULs5Qiqp4bt1RxD0iS?=
 =?us-ascii?q?cHLz85/3/Risxsl6JQvRatqwViz4LIfI2ZMfxzdb7fc9wHX2pMRsZfWTJcDI2y?=
 =?us-ascii?q?bIUBCOgOPehDr4nlpVYDtgeyCRW2Ce/z0DJEmmP60Ksn2OohCwHG2wkgEsoMvn?=
 =?us-ascii?q?TJttr1MqgSWv23w6nJyzXDYO5d1DD96YjJdBAhruuAXbJtccXLz0kvGBjIjlSW?=
 =?us-ascii?q?qYz5ITyV0v4BvHSc7+plTO+ijXMspQJpojW32Msglo3EipgIxl3K6yl12ps5KN?=
 =?us-ascii?q?6kREJhYNOpEoNcuzyeOodoWM8vQ2FltDw6x7EYo5K2fysHxZI6zBDFcfOHaZKH?=
 =?us-ascii?q?4hf7WeaRPzh4gHVldaqhhxa970eg0PfwVsqq31ZQqCpKjN3MumoK1xzJ5ciLUv?=
 =?us-ascii?q?p9/kG/1jaTzw3f9P1ILEQumabGJZMt3KQ8mocQvEjfBCP7mUf7gLeTdko+++io?=
 =?us-ascii?q?7+rnYq/hpp+ZL4J0jgD+MqIzms2wGOg4MRYBX3Kd+eui0L3v5Er5QbtMjvIoiK?=
 =?us-ascii?q?nUq47aJcsFqa6jGQNV0Zgs6wy5Dzi41NQUh34HLEhKeB6flYjmJ0nOIOzkDfe4?=
 =?us-ascii?q?m1mslDZrx/PYMbH7DZTNM2POkLPgfbZ79k5dxxA/zdFZ55JIFL4BJOj/VVP2tN?=
 =?us-ascii?q?zdFhU5KRC7w/77CNVh0YMTQWKPDbWYMKPOq1CI4fgjI+mRZIAPvjb9JOMo5/rv?=
 =?us-ascii?q?jX8/hF8ccrOl3ZoRaHCkAPtmJ1+VbmbrgtcECW0KpBYxTPT2iF2eVj5ef3SyX6?=
 =?us-ascii?q?Ui6T0hC4KmCoHDRoaqgLGa2Ce7H5tWZn1JC1yWEHfocZmEVOkIaC6IPsBhlTkE?=
 =?us-ascii?q?X6C7S4A9zRGuqBP6y71/I+XO4S0YtZXj1Ntv6+3Jjx4y9yd5D8Cc02GLUmF1kX?=
 =?us-ascii?q?kERz4w3KBjv0N9zk2P3rR/g/xdDdZT/e9GUh8mNZ7AyOx3E9PyVRjHftuTTFam?=
 =?us-ascii?q?Q8+pATc+Tt8qx98OYkB9G8itjxzZ3iqqBaMVmKKPBJAu7q3c2H3xLd5ny3nazK?=
 =?us-ascii?q?khk0UmQsxXOGK7nKF/6RbcC5TJk0qDkaaqbroT3CjK+GeHzmqOuUVYXRV0UaXE?=
 =?us-ascii?q?W3Afe0TXoc745kPEU7+hF7AnPhFdxs6FL6tAcsfpgkleRPf/JNTeZHq8lHqqCh?=
 =?us-ascii?q?aW2LyAdorqdH8b3CXGFkcElRse/XKHNQg4GyegrHjSDD1oFVLzfUzs9fNyp2+8?=
 =?us-ascii?q?Tk8x1wuKdVFu16Kp+h4JgvyRU+8T3rMBuCcmtzV0HFa808jKC9aaoAphZqFcYd?=
 =?us-ascii?q?I74FdIzm/Zsw19Ppq9L6FtnFIecgJ3v1/w2BVzEIlPjc8qrHYyxgpoNa2YyE9B?=
 =?us-ascii?q?dy+f3Z3oILLXLnf9/R+xZK/WwF3Ry8uW9boV5/Q+qFXjux+pG1Em83Vm1dlVzn?=
 =?us-ascii?q?Sd6o/LDAoUTZL+TEI3+wJmqLHdZyk3/5nU2mF0Mamorj/C3MokBes4yhq6Y9hT?=
 =?us-ascii?q?KqKFFA/oHM0cCMijM+gqm1mvbhIZM+Fe7q80P8W6d/SY3K6nJvpvnDWjjW5f+o?=
 =?us-ascii?q?ByzlqM9zZgSu7Px5sF2fCY0RedWDfmkVihtdr7mYZaajEIH2qz0DTrC5RVZqJv?=
 =?us-ascii?q?Y4kLE2CuI8usy9V6hp7tXWNY9VG5C1MH3s+pZQSdb1jn0QJM0kQXpGStmTGkwD?=
 =?us-ascii?q?xsjzEpsq2f0TTOwuTjbhYGOnRHRHJ/jVfqOoW0i9EaXE61bwkmjhel5ED6x7RF?=
 =?us-ascii?q?q6R7NWXcXUBIfy3uJWF4TqSwrqaCY9JI6J4wsyVYSv68YVOZSr76uRcayDnsH2?=
 =?us-ascii?q?hdxDA6cTGlpJP5kgd+iGKcKnZzsXXYddtxxRfZ+NzTW/pR0iAaSyl/jDndHkK8?=
 =?us-ascii?q?MMWx/dWIi5fDtfizVmK7WZ1UayXrz4KAtC2g6G1uAB2/me2zm9L9HQg71y/7y8?=
 =?us-ascii?q?dlVSHSoBngZYnr0rywMfh7cUlwGF/89816F5l9koQqhZEcw3gahoiP8noBnmf+?=
 =?us-ascii?q?KtFb2aP4bHoQSj8H2d/V4A752EJ9KnKF3Z72VnKYwsF5fdm1fnsW2j4h78BNEK?=
 =?us-ascii?q?qU6b1EnShvrVaiowPef+N9nisDxvs083EVnfsJuAU2wyWZA7ASG1RYPCP2mxSJ?=
 =?us-ascii?q?6dC+sLtYZGK1fbes00p+mMirDKuerQFERHb5ZpAiEDds7sV4NVLAynzy5ZvieN?=
 =?us-ascii?q?nNdtITrRyUngzEj+hULpIxi/ULiTBmOWL7oX0q1eo7gQZy0pG9uYiNM39t876h?=
 =?us-ascii?q?Ah5EKj31YNse9Sr3gqZZmsaWwpqjHpF8GjgQWJvoTPSoEC8dtPj9NgaOFiE8pW?=
 =?us-ascii?q?mfGbbFAQCf70JmpWrVE5+3L3GXOGUZzdJ6SRmfPkNfhR4bXC4gkp4lDAyqx9Hh?=
 =?us-ascii?q?cERk5jAX/FH4sQBByuZpNxn5T2feqx2kajYySJiDMhVW6htO6FvSMcyb9uhzBT?=
 =?us-ascii?q?1X/oW9rAyRLWyWfwRJDWYUWkydGlDsJL+u6cPb8+ifAOq+IODDYbGPqexYSveJ?=
 =?us-ascii?q?yoij0opg/zaQKMqPOmNuAOE82kpGRXp5AdjWmy0TSywLkCLAd86bqwm9+i10rc?=
 =?us-ascii?q?C/8e7nWAH15YuIBLtdL89v+w2tgaqYM+6QhSB5KStX158WxH/IzqQf00AWiy10?=
 =?us-ascii?q?azatFrEAvzbXTK3Mgq9XEwIbayRrOcRS8qIzxRNNNtDbi9/v0r54j+U4C1NEVV?=
 =?us-ascii?q?znh8GoatYGI2C7NFPbGkmLMK6KKiHMw8Hyeam8U6FfjP1Itx2svjaWC1PjPjWG?=
 =?us-ascii?q?lzXzSx+jK/1DjCGFMxxYo4y9dhdtCW7+TNPpcBG7Mdl3jSEozr0wnH/FKWkcMT?=
 =?us-ascii?q?1keUNXsrKQ9T9Ygul4G2FZ7ntqN++EmyOY7+neMpkXsPtrDT5yl+JV+3k6z7pV?=
 =?us-ascii?q?7CdZRP16gifSr9huo024nemL0DZoTB1OqjMYzL6M6GxkNb/U6dFlXmzY+xRFuW?=
 =?us-ascii?q?yTExEio9pjF82qtadNzNTGiKP0LnFF6d2CruUGAM2BCN+ONnVpABvvF3aAHQoD?=
 =?us-ascii?q?QnirKGjZiGRclu2f8jueqZ1s+cuko4YHVrIODA99LfgdEEkwWYVaeJo=3D?=
X-IronPort-Anti-Spam-Filtered: true
X-IronPort-Anti-Spam-Result: =?us-ascii?q?A0ALAACoBwpch0O0hNFjHAEBAQQBAQcEA?=
 =?us-ascii?q?QGBUQcBAQsBg2snjBOOMZc7gSQDTxEYEwGHVyI0CQ0BAwEBAQEBAQIBEwEBAQg?=
 =?us-ascii?q?NCQgpL4I2JAGCYgMDAQIkUgYJAQEYOANUBhMFgxyCAgWmdjOKMIdwhC+CFoERg?=
 =?us-ascii?q?mSLCgKJLIF5hQ9RjwhVBwKRPwsYX32IPIcdAZkagUZsgSEzGiODPJBoMgEBMQG?=
 =?us-ascii?q?BBAEBij8BAQ?=
X-IPAS-Result: =?us-ascii?q?A0ALAACoBwpch0O0hNFjHAEBAQQBAQcEAQGBUQcBAQsBg2s?=
 =?us-ascii?q?njBOOMZc7gSQDTxEYEwGHVyI0CQ0BAwEBAQEBAQIBEwEBAQgNCQgpL4I2JAGCY?=
 =?us-ascii?q?gMDAQIkUgYJAQEYOANUBhMFgxyCAgWmdjOKMIdwhC+CFoERgmSLCgKJLIF5hQ9?=
 =?us-ascii?q?RjwhVBwKRPwsYX32IPIcdAZkagUZsgSEzGiODPJBoMgEBMQGBBAEBij8BAQ?=
X-IronPort-AV: E=Sophos;i="5.56,324,1539673200"; 
   d="scan'208";a="141159081"
X-Amp-Result: SKIPPED(no attachment in message)
X-Amp-File-Uploaded: False
Received: from vger.kernel.org ([209.132.180.67])
  by mtab.intel.com with ESMTP; 06 Dec 2018 21:42:04 -0800
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
        id S1726199AbeLGFmC (ORCPT <rfc822;like.xu@linux.intel.com>
        + 23 others); Fri, 7 Dec 2018 00:42:02 -0500
Received: from mga01.intel.com ([192.55.52.88]:55177 "EHLO mga01.intel.com"
        rhost-flags-OK-OK-OK-OK) by vger.kernel.org with ESMTP
        id S1726179AbeLGFl7 (ORCPT <rfc822;linux-kernel@vger.kernel.org>);
        Fri, 7 Dec 2018 00:41:59 -0500
X-Amp-Result: SKIPPED(no attachment in message)
X-Amp-File-Uploaded: False
Received: from fmsmga007.fm.intel.com ([10.253.24.52])
  by fmsmga101.fm.intel.com with ESMTP/TLS/DHE-RSA-AES256-GCM-SHA384; 06 Dec 2018 21:41:58 -0800
X-ExtLoop1: 1
X-IronPort-AV: E=Sophos;i="5.56,324,1539673200"; 
   d="scan'208";a="105567276"
Received: from yhuang-mobile.sh.intel.com ([10.239.196.133])
  by fmsmga007.fm.intel.com with ESMTP; 06 Dec 2018 21:41:56 -0800
From: Huang Ying <ying.huang@intel.com>
To: Andrew Morton <akpm@linux-foundation.org>
Cc: linux-mm@kvack.org, linux-kernel@vger.kernel.org,
        Huang Ying <ying.huang@intel.com>,
        "Kirill A. Shutemov" <kirill.shutemov@linux.intel.com>,
        Andrea Arcangeli <aarcange@redhat.com>,
        Michal Hocko <mhocko@kernel.org>,
        Johannes Weiner <hannes@cmpxchg.org>,
        Shaohua Li <shli@kernel.org>, Hugh Dickins <hughd@google.com>,
        Minchan Kim <minchan@kernel.org>,
        Rik van Riel <riel@redhat.com>,
        Dave Hansen <dave.hansen@linux.intel.com>,
        Naoya Horiguchi <n-horiguchi@ah.jp.nec.com>,
        Zi Yan <zi.yan@cs.rutgers.edu>,
        Daniel Jordan <daniel.m.jordan@oracle.com>
Subject: [PATCH -V8 11/21] swap: Add sysfs interface to configure THP swapin
Date: Fri,  7 Dec 2018 13:41:11 +0800
Message-Id: <20181207054122.27822-12-ying.huang@intel.com>
X-Mailer: git-send-email 2.18.1
In-Reply-To: <20181207054122.27822-1-ying.huang@intel.com>
References: <20181207054122.27822-1-ying.huang@intel.com>
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: <linux-kernel.vger.kernel.org>
X-Mailing-List: linux-kernel@vger.kernel.org

Swapin a THP as a whole isn't desirable in some situations.  For
example, for completely random access pattern, swapin a THP in one
piece will inflate the reading greatly.  So a sysfs interface:
/sys/kernel/mm/transparent_hugepage/swapin_enabled is added to
configure it.  Three options as follow are provided,

- always: THP swapin will be enabled always

- madvise: THP swapin will be enabled only for VMA with VM_HUGEPAGE
  flag set.

- never: THP swapin will be disabled always

The default configuration is: madvise.

During page fault, if a PMD swap mapping is found and THP swapin is
disabled, the huge swap cluster and the PMD swap mapping will be split
and fallback to normal page swapin.

Signed-off-by: "Huang, Ying" <ying.huang@intel.com>
Cc: "Kirill A. Shutemov" <kirill.shutemov@linux.intel.com>
Cc: Andrea Arcangeli <aarcange@redhat.com>
Cc: Michal Hocko <mhocko@kernel.org>
Cc: Johannes Weiner <hannes@cmpxchg.org>
Cc: Shaohua Li <shli@kernel.org>
Cc: Hugh Dickins <hughd@google.com>
Cc: Minchan Kim <minchan@kernel.org>
Cc: Rik van Riel <riel@redhat.com>
Cc: Dave Hansen <dave.hansen@linux.intel.com>
Cc: Naoya Horiguchi <n-horiguchi@ah.jp.nec.com>
Cc: Zi Yan <zi.yan@cs.rutgers.edu>
Cc: Daniel Jordan <daniel.m.jordan@oracle.com>
---
 Documentation/admin-guide/mm/transhuge.rst | 21 +++++
 include/linux/huge_mm.h                    | 31 +++++++
 mm/huge_memory.c                           | 94 +++++++++++++++++-----
 3 files changed, 127 insertions(+), 19 deletions(-)

diff --git a/Documentation/admin-guide/mm/transhuge.rst b/Documentation/admin-guide/mm/transhuge.rst
index 85e33f785fd7..23aefb17101c 100644
--- a/Documentation/admin-guide/mm/transhuge.rst
+++ b/Documentation/admin-guide/mm/transhuge.rst
@@ -160,6 +160,27 @@ Some userspace (such as a test program, or an optimized memory allocation
 
 	cat /sys/kernel/mm/transparent_hugepage/hpage_pmd_size
 
+Transparent hugepage may be swapout and swapin in one piece without
+splitting.  This will improve the utility of transparent hugepage but
+may inflate the read/write too.  So whether to enable swapin
+transparent hugepage in one piece can be configured as follow.
+
+	echo always >/sys/kernel/mm/transparent_hugepage/swapin_enabled
+	echo madvise >/sys/kernel/mm/transparent_hugepage/swapin_enabled
+	echo never >/sys/kernel/mm/transparent_hugepage/swapin_enabled
+
+always
+	Attempt to allocate a transparent huge page and read it from
+	swap space in one piece every time.
+
+never
+	Always split the swap space and PMD swap mapping and swapin
+	the fault normal page during swapin.
+
+madvise
+	Only swapin the transparent huge page in one piece for
+	MADV_HUGEPAGE madvise regions.
+
 khugepaged will be automatically started when
 transparent_hugepage/enabled is set to "always" or "madvise, and it'll
 be automatically shutdown if it's set to "never".
diff --git a/include/linux/huge_mm.h b/include/linux/huge_mm.h
index 909321c772b5..ea4999a4b6cd 100644
--- a/include/linux/huge_mm.h
+++ b/include/linux/huge_mm.h
@@ -63,6 +63,8 @@ enum transparent_hugepage_flag {
 #ifdef CONFIG_DEBUG_VM
 	TRANSPARENT_HUGEPAGE_DEBUG_COW_FLAG,
 #endif
+	TRANSPARENT_HUGEPAGE_SWAPIN_FLAG,
+	TRANSPARENT_HUGEPAGE_SWAPIN_REQ_MADV_FLAG,
 };
 
 struct kobject;
@@ -375,11 +377,40 @@ static inline gfp_t alloc_hugepage_direct_gfpmask(struct vm_area_struct *vma,
 
 #ifdef CONFIG_THP_SWAP
 extern int do_huge_pmd_swap_page(struct vm_fault *vmf, pmd_t orig_pmd);
+
+static inline bool transparent_hugepage_swapin_enabled(
+	struct vm_area_struct *vma)
+{
+	if (vma->vm_flags & VM_NOHUGEPAGE)
+		return false;
+
+	if (is_vma_temporary_stack(vma))
+		return false;
+
+	if (test_bit(MMF_DISABLE_THP, &vma->vm_mm->flags))
+		return false;
+
+	if (transparent_hugepage_flags &
+			(1 << TRANSPARENT_HUGEPAGE_SWAPIN_FLAG))
+		return true;
+
+	if (transparent_hugepage_flags &
+			(1 << TRANSPARENT_HUGEPAGE_SWAPIN_REQ_MADV_FLAG))
+		return !!(vma->vm_flags & VM_HUGEPAGE);
+
+	return false;
+}
 #else /* CONFIG_THP_SWAP */
 static inline int do_huge_pmd_swap_page(struct vm_fault *vmf, pmd_t orig_pmd)
 {
 	return 0;
 }
+
+static inline bool transparent_hugepage_swapin_enabled(
+	struct vm_area_struct *vma)
+{
+	return false;
+}
 #endif /* CONFIG_THP_SWAP */
 
 #endif /* _LINUX_HUGE_MM_H */
diff --git a/mm/huge_memory.c b/mm/huge_memory.c
index c674deb643d6..0ae7f824dbeb 100644
--- a/mm/huge_memory.c
+++ b/mm/huge_memory.c
@@ -58,7 +58,8 @@ unsigned long transparent_hugepage_flags __read_mostly =
 #endif
 	(1<<TRANSPARENT_HUGEPAGE_DEFRAG_REQ_MADV_FLAG)|
 	(1<<TRANSPARENT_HUGEPAGE_DEFRAG_KHUGEPAGED_FLAG)|
-	(1<<TRANSPARENT_HUGEPAGE_USE_ZERO_PAGE_FLAG);
+	(1<<TRANSPARENT_HUGEPAGE_USE_ZERO_PAGE_FLAG)|
+	(1<<TRANSPARENT_HUGEPAGE_SWAPIN_REQ_MADV_FLAG);
 
 static struct shrinker deferred_split_shrinker;
 
@@ -317,6 +318,53 @@ static struct kobj_attribute debug_cow_attr =
 	__ATTR(debug_cow, 0644, debug_cow_show, debug_cow_store);
 #endif /* CONFIG_DEBUG_VM */
 
+#ifdef CONFIG_THP_SWAP
+static ssize_t swapin_enabled_show(struct kobject *kobj,
+				   struct kobj_attribute *attr, char *buf)
+{
+	if (test_bit(TRANSPARENT_HUGEPAGE_SWAPIN_FLAG,
+		     &transparent_hugepage_flags))
+		return sprintf(buf, "[always] madvise never\n");
+	else if (test_bit(TRANSPARENT_HUGEPAGE_SWAPIN_REQ_MADV_FLAG,
+			  &transparent_hugepage_flags))
+		return sprintf(buf, "always [madvise] never\n");
+	else
+		return sprintf(buf, "always madvise [never]\n");
+}
+
+static ssize_t swapin_enabled_store(struct kobject *kobj,
+				    struct kobj_attribute *attr,
+				    const char *buf, size_t count)
+{
+	ssize_t ret = count;
+
+	if (!memcmp("always", buf,
+		    min(sizeof("always")-1, count))) {
+		clear_bit(TRANSPARENT_HUGEPAGE_SWAPIN_REQ_MADV_FLAG,
+			  &transparent_hugepage_flags);
+		set_bit(TRANSPARENT_HUGEPAGE_SWAPIN_FLAG,
+			&transparent_hugepage_flags);
+	} else if (!memcmp("madvise", buf,
+			   min(sizeof("madvise")-1, count))) {
+		clear_bit(TRANSPARENT_HUGEPAGE_SWAPIN_FLAG,
+			  &transparent_hugepage_flags);
+		set_bit(TRANSPARENT_HUGEPAGE_SWAPIN_REQ_MADV_FLAG,
+			&transparent_hugepage_flags);
+	} else if (!memcmp("never", buf,
+			   min(sizeof("never")-1, count))) {
+		clear_bit(TRANSPARENT_HUGEPAGE_SWAPIN_FLAG,
+			  &transparent_hugepage_flags);
+		clear_bit(TRANSPARENT_HUGEPAGE_SWAPIN_REQ_MADV_FLAG,
+			  &transparent_hugepage_flags);
+	} else
+		ret = -EINVAL;
+
+	return ret;
+}
+static struct kobj_attribute swapin_enabled_attr =
+	__ATTR(swapin_enabled, 0644, swapin_enabled_show, swapin_enabled_store);
+#endif /* CONFIG_THP_SWAP */
+
 static struct attribute *hugepage_attr[] = {
 	&enabled_attr.attr,
 	&defrag_attr.attr,
@@ -327,6 +375,9 @@ static struct attribute *hugepage_attr[] = {
 #endif
 #ifdef CONFIG_DEBUG_VM
 	&debug_cow_attr.attr,
+#endif
+#ifdef CONFIG_THP_SWAP
+	&swapin_enabled_attr.attr,
 #endif
 	NULL,
 };
@@ -1703,6 +1754,9 @@ int do_huge_pmd_swap_page(struct vm_fault *vmf, pmd_t orig_pmd)
 retry:
 	page = lookup_swap_cache(entry, NULL, vmf->address);
 	if (!page) {
+		if (!transparent_hugepage_swapin_enabled(vma))
+			goto split;
+
 		page = read_swap_cache_async(entry, GFP_HIGHUSER_MOVABLE, vma,
 					     haddr, false);
 		if (!page) {
@@ -1710,24 +1764,8 @@ int do_huge_pmd_swap_page(struct vm_fault *vmf, pmd_t orig_pmd)
 			 * Back out if somebody else faulted in this pmd
 			 * while we released the pmd lock.
 			 */
-			if (likely(pmd_same(*vmf->pmd, orig_pmd))) {
-				/*
-				 * Failed to allocate huge page, split huge swap
-				 * cluster, and fallback to swapin normal page
-				 */
-				ret = split_swap_cluster(entry, 0);
-				/* Somebody else swapin the swap entry, retry */
-				if (ret == -EEXIST) {
-					ret = 0;
-					goto retry;
-				/* swapoff occurs under us */
-				} else if (ret == -EINVAL)
-					ret = 0;
-				else {
-					count_vm_event(THP_SWPIN_FALLBACK);
-					goto fallback;
-				}
-			}
+			if (likely(pmd_same(*vmf->pmd, orig_pmd)))
+				goto split;
 			delayacct_clear_flag(DELAYACCT_PF_SWAPIN);
 			goto out;
 		}
@@ -1840,6 +1878,24 @@ int do_huge_pmd_swap_page(struct vm_fault *vmf, pmd_t orig_pmd)
 	if (page)
 		put_page(page);
 	return ret;
+split:
+	/*
+	 * Failed to allocate huge page, split huge swap cluster, and
+	 * fallback to swapin normal page
+	 */
+	ret = split_swap_cluster(entry, 0);
+	/* Somebody else swapin the swap entry, retry */
+	if (ret == -EEXIST) {
+		ret = 0;
+		goto retry;
+	}
+	/* swapoff occurs under us */
+	if (ret == -EINVAL) {
+		delayacct_clear_flag(DELAYACCT_PF_SWAPIN);
+		return 0;
+	}
+	count_vm_event(THP_SWPIN_FALLBACK);
+	goto fallback;
 }
 #endif
 
-- 
2.18.1

