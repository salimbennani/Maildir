Return-Path: <linux-kernel-owner@vger.kernel.org>
Delivered-To: unknown
Received: from linux.intel.com (10.54.29.200:995) by i7-8700 with POP3-SSL;
  14 Dec 2018 20:24:54 -0000
X-Original-To: like.xu@linux.intel.com
Delivered-To: like.xu@linux.intel.com
Received: from fmsmga004.fm.intel.com (fmsmga004.fm.intel.com [10.253.24.48])
	(using TLSv1.2 with cipher ECDHE-RSA-AES256-GCM-SHA384 (256/256 bits))
	(No client certificate requested)
	by linux.intel.com (Postfix) with ESMTPS id 68E0D5803DC;
	Thu, 13 Dec 2018 22:29:11 -0800 (PST)
Received: from fmsmga103.fm.intel.com ([10.1.193.90])
  by fmsmga004-1.fm.intel.com with ESMTP/TLS/DHE-RSA-AES256-GCM-SHA384; 13 Dec 2018 22:29:11 -0800
X-SG-BADATTACHMENTNOREPLY: True
IronPort-PHdr: =?us-ascii?q?9a23=3At5Cq2heziW7Xl6nASwHtzwZXlGMj4u6mDksu8pMi?=
 =?us-ascii?q?zoh2WeGdxc6+YRKN2/xhgRfzUJnB7Loc0qyK6/CmATRIyK3CmUhKSIZLWR4BhJ?=
 =?us-ascii?q?detC0bK+nBN3fGKuX3ZTcxBsVIWQwt1Xi6NU9IBJS2PAWK8TW94jEIBxrwKxd+?=
 =?us-ascii?q?KPjrFY7OlcS30P2594HObwlSizexfbB/IA+qoQnNq8IbnZZsJqEtxxXTv3BGYf?=
 =?us-ascii?q?5WxWRmJVKSmxbz+MK994N9/ipTpvws6ddOXb31cKokQ7NYCi8mM30u683wqRbD?=
 =?us-ascii?q?VwqP6WACXWgQjxFFHhLK7BD+Xpf2ryv6qu9w0zSUMMHqUbw5Xymp4rx1QxH0li?=
 =?us-ascii?q?gIKz858HnWisNuiqJbvAmhrAF7z4LNfY2ZKOZycqbbcNgHR2ROQ9xRWjRBDI2i?=
 =?us-ascii?q?coUBAekPM+FaoInzvFsOtRmzCBKwCO/z0DJEmmX70bEm3+knDArI3BYgH9ULsH?=
 =?us-ascii?q?nMrtv1Kb0dUea6zKLVzzrDbvVW2Tjg44XPchEhoPeMXb1qfcrR1EkgDQXFjlqL?=
 =?us-ascii?q?pIzkOTOVyvoCs2yB4+V8UuKvjncqpgdsqTas3schkpfFip4Rx1ze6Cl0zpg5Kc?=
 =?us-ascii?q?elREN4fdKoCppduiOCO4drTM4vTHtktDs0x7AJo5K3YSYHxZU9yxLCd/CLb46F?=
 =?us-ascii?q?6Q/5WumLOzd3nndldaq/hxms9UigzfXxVte70FlUtCpJiNrMuW4X1xzV9MeHTu?=
 =?us-ascii?q?Fx/kC72TaAzwzT6+dELl4olafDNZIt3ro9moAOvUnNACP6glj6gayKekk+++Wl?=
 =?us-ascii?q?6fzrYrD8qZ+dM490hBv+MqMrmsGnBeQ4Mw4OX3WU+Oil173s41f5QLNUgf0yi6?=
 =?us-ascii?q?XZt57bJcIFqa6jGAJVzIkj5AilDzu809QXg2MHLFRbdxKDlYTpPEvOIP/gAfel?=
 =?us-ascii?q?n1usiCtrx+zBPrD5BpXNL3vDn6n7cbdy9k5R0w4zzdFZ55JJBbANOvPzWknttN?=
 =?us-ascii?q?PGCh81KRC7w+HiCN9lzIMRRXqPArOFMKPVqVKI5vggI+iQZIAPvzbxMfgl5+P0?=
 =?us-ascii?q?gn8/ll8QZq2p3ZoRaHClEfVqOUSZYXzwgtgfFWcGpBYxTOvviFeaSz5ce26yX7?=
 =?us-ascii?q?4g5jE8EI+mD4DDSZ63jLyC2ye7GJtWZmddB1CIEHfocZiEWvgWZCKTJM9hjiIL?=
 =?us-ascii?q?Vby7R4A90hGusRfwy6B7IerM5i0YqZXj2cBv6O3IlREy8j90A96H026XTWF5hW?=
 =?us-ascii?q?cIRz4w3KBirk1x0FaD0a5kg/NGEdxf/e9GUgA/NZTE1ex1F8jyWh7dfteOUFum?=
 =?us-ascii?q?Qc+pATcrQtI1wt8BeUB9G9q5gxDH3iqqBaIVlrORCJw19KLcw2b+J8Jnx3na06?=
 =?us-ascii?q?khikEsQtFTOm2+mq5/6w/TCpbUnEqDiaala74Q3C7X+2eF1mqBokdYXAl0UaXG?=
 =?us-ascii?q?WHAfYlDbrdD45kPEUr+vBq4rMgpHyc6eNKRKbsflgklBRPfmIN7eeX6+m3+sBR?=
 =?us-ascii?q?aUwbOBdJfldH8D3CrDEkQEkxoc/XCdNQcgACesuGbeDD1oFVLybELg6+h+qHWn?=
 =?us-ascii?q?TkAqywGGdVFu172w+hQNn/yTV+sT3q4YuCcmszh0AFe939fRC9qcpwpgfL9QYc?=
 =?us-ascii?q?8n7FdAz2LZsw19PpqvL615gl4ecgJ3v17h1hltC4VAl9Qqo20uzAZoNa2Y11ZB?=
 =?us-ascii?q?fSuC3Z/sIr3XNnXy/Be3ZqHM3lHRztmX9bkP6fgisFrjoRymGVAk83Vk1NlVzW?=
 =?us-ascii?q?CR5pHLDAoUTJLwXVw79xl8p7HGfCY945nY2mFrMamxqjXCwc4mBPM5yha8eNdS?=
 =?us-ascii?q?KKOFFBLoH8IGHcSvKewqlEKvbhILJ+1S8K80P8W7d/qJwqKrPeBgnC64gmRD+o?=
 =?us-ascii?q?xyzkWM9y9kQO7Sw5kF2+2Y3heAVzrkllehs9z4lppeZT4PGWqz0y7kC5BLZq1z?=
 =?us-ascii?q?ZIoEFX2hI8mqydpgnZ7tXHhY+UWnB1MH3s+pZBWTY0b83Q1WyUQYv3inlTGkwD?=
 =?us-ascii?q?xzljEjtrCf0zDWw+T+aBoHPXZGRWljjVv2IYm4lcsaXFWubwUykBul5ED6x7VU?=
 =?us-ascii?q?pahlLmnTR1tIcDbyL214TqSwsb+CadZV6Jw0qSVXTPi8YVeCR77/uRQaySDjH2?=
 =?us-ascii?q?hZxDwhbDGloJb5nx97iGKbMnlzqmHUecVxxRfZ+dzdSuRd3jsARClklzbXAkKw?=
 =?us-ascii?q?MMWu/dWRj53DqPyxV3q9Vp1Pdinm1YOBuzG85WFwAx2/nvazl8bjEQg71y/7yt?=
 =?us-ascii?q?ZrWT/JrBb6fonkyaC6Pfh7cUlvAV/289B6FZ1mkossmJEQ3mAXhpaP8noGi2vz?=
 =?us-ascii?q?Mchb1rj4bHoCXjMLx9/V4A742ExsNH6JxoT5VmmDzctlfdW1fmQW2icl5cBQFK?=
 =?us-ascii?q?iU9KBEnTdyolegqALRYPt9kS0Hxfog9nEamP0JtxQ3ziqGHL8SB0ZYMDfolxSJ?=
 =?us-ascii?q?6dC+sapWaHyucbi2yEpxg9ShAKuerQFbXXbzYo0iEjNo7sVjLFLM12X+6p3jeN?=
 =?us-ascii?q?nVd94StwebkxHdj+hOM5Ixl+EHhS5mOWL7oH0kxPQ3jR1o3ZGmooeHL39h876+?=
 =?us-ascii?q?Ah5dLjf1fd8c+inxjaZCmcabx5ugEY9mGjUPQZvkV/aoEC8JuPTjNgaOFiA8q3?=
 =?us-ascii?q?iBFbreGw+f9Flpr3bVH5+3MHGXIWETzc9+SxmFOExfnAcUUS04npEjEwCl2tfh?=
 =?us-ascii?q?fF1l5jwL5V74txhMyv9uNxblSWfSvwOoajYySJiCIxta9ABC50HJMcOA6uJ/BT?=
 =?us-ascii?q?1X/pqkrAaVMGyUexxIDX0VWkyDH13iPr6u5cTZ8+iFHOW+KeHCYa6JqexYWPeF?=
 =?us-ascii?q?3pav0opg/zaROcSDJHhiD/sn2kVdWXB1AdjWmzIKSyYPjSLCc9abpAug+i1wts?=
 =?us-ascii?q?2/8OrkWAPs5YuMCrteK9Zv+wqxgaeMKeGQnjt5KS1D25MIxH/IzqUf3VEIhyFv?=
 =?us-ascii?q?cTmtDaoPtSrXQK3Mna9XCgYRazlvO8tQ86I8wg5NNNbBhdPozbF4lOA6CldfWV?=
 =?us-ascii?q?zlm8GkfsgKI2C7NFPaC0eHLrWGJTvXw87pZaOwU6FfjOJRtxeoozaUD1fjPiif?=
 =?us-ascii?q?lznuTx2vLeBMjCSBMBNCoo2ybhZtBnblTN/9bh27Mdl3jSA5wLEuh3PKM3IcPi?=
 =?us-ascii?q?Z4c09XsrKQ6iZYiO1lG2Nd9nplMfWEmyGB4ujYMJkWt/5rAiVyl+1C4XU6y6Fa?=
 =?us-ascii?q?7CdLRPFunCvSr9huo0ypk+WVyzpnVgZOpShPhI6RoUpiPqDZpdF8XiPt+h4X4H?=
 =?us-ascii?q?rYLhMQu9xjQonmuLhV4tzOkr/jbTlF7tTY9NcdAM6SL9iIZikPKx3sTR7JBQ0K?=
 =?us-ascii?q?BQ+qM26X011clv7U9mCcqJcSq57wlZ5IQbheAg9mXsgGA1hoSYRRaKx8WSkpxP?=
 =?us-ascii?q?vC1JYF?=
X-IronPort-Anti-Spam-Filtered: true
X-IronPort-Anti-Spam-Result: =?us-ascii?q?A0AAAAB1TRNch0O0hNFjGgEBAQEBAgEBA?=
 =?us-ascii?q?QEHAgEBAQGBUQUBAQEBCwGDayeMFYwRgiGXQYEkBU0RGBMBh0UiNAkNAQMBAQE?=
 =?us-ascii?q?BAQECARMBAQEIDQkIKS+CNiQBgmIDAwECJFIGCQEBGDgDVAYTBYMcggEFp3Azi?=
 =?us-ascii?q?i+HfYRBghaBEYJkiwoCiTeBfYUSUo8lVgcCkU4LGF9+iEaHJwGZUIFGbYEhMxo?=
 =?us-ascii?q?jgzyQaDIBATEBgQQBAYxlAQE?=
X-IPAS-Result: =?us-ascii?q?A0AAAAB1TRNch0O0hNFjGgEBAQEBAgEBAQEHAgEBAQGBUQU?=
 =?us-ascii?q?BAQEBCwGDayeMFYwRgiGXQYEkBU0RGBMBh0UiNAkNAQMBAQEBAQECARMBAQEID?=
 =?us-ascii?q?QkIKS+CNiQBgmIDAwECJFIGCQEBGDgDVAYTBYMcggEFp3Azii+HfYRBghaBEYJ?=
 =?us-ascii?q?kiwoCiTeBfYUSUo8lVgcCkU4LGF9+iEaHJwGZUIFGbYEhMxojgzyQaDIBATEBg?=
 =?us-ascii?q?QQBAYxlAQE?=
X-IronPort-AV: E=Sophos;i="5.56,351,1539673200"; 
   d="scan'208";a="55877561"
X-Amp-Result: SKIPPED(no attachment in message)
X-Amp-File-Uploaded: False
Received: from vger.kernel.org ([209.132.180.67])
  by mtab.intel.com with ESMTP; 13 Dec 2018 22:29:10 -0800
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
        id S1727239AbeLNG3I (ORCPT <rfc822;like.xu@linux.intel.com>
        + 23 others); Fri, 14 Dec 2018 01:29:08 -0500
Received: from mga07.intel.com ([134.134.136.100]:52278 "EHLO mga07.intel.com"
        rhost-flags-OK-OK-OK-OK) by vger.kernel.org with ESMTP
        id S1728530AbeLNG2P (ORCPT <rfc822;linux-kernel@vger.kernel.org>);
        Fri, 14 Dec 2018 01:28:15 -0500
X-Amp-Result: SKIPPED(no attachment in message)
X-Amp-File-Uploaded: False
Received: from fmsmga002.fm.intel.com ([10.253.24.26])
  by orsmga105.jf.intel.com with ESMTP/TLS/DHE-RSA-AES256-GCM-SHA384; 13 Dec 2018 22:28:15 -0800
X-ExtLoop1: 1
X-IronPort-AV: E=Sophos;i="5.56,351,1539673200"; 
   d="scan'208";a="125840988"
Received: from yhuang-mobile.sh.intel.com ([10.239.197.226])
  by fmsmga002.fm.intel.com with ESMTP; 13 Dec 2018 22:28:12 -0800
From: Huang Ying <ying.huang@intel.com>
To: Andrew Morton <akpm@linux-foundation.org>
Cc: linux-mm@kvack.org, linux-kernel@vger.kernel.org,
        Huang Ying <ying.huang@intel.com>,
        "Kirill A. Shutemov" <kirill.shutemov@linux.intel.com>,
        Andrea Arcangeli <aarcange@redhat.com>,
        Michal Hocko <mhocko@kernel.org>,
        Johannes Weiner <hannes@cmpxchg.org>,
        Shaohua Li <shli@kernel.org>, Hugh Dickins <hughd@google.com>,
        Minchan Kim <minchan@kernel.org>,
        Rik van Riel <riel@redhat.com>,
        Dave Hansen <dave.hansen@linux.intel.com>,
        Naoya Horiguchi <n-horiguchi@ah.jp.nec.com>,
        Zi Yan <zi.yan@cs.rutgers.edu>,
        Daniel Jordan <daniel.m.jordan@oracle.com>
Subject: [PATCH -V9 12/21] swap: Add sysfs interface to configure THP swapin
Date: Fri, 14 Dec 2018 14:27:45 +0800
Message-Id: <20181214062754.13723-13-ying.huang@intel.com>
X-Mailer: git-send-email 2.18.1
In-Reply-To: <20181214062754.13723-1-ying.huang@intel.com>
References: <20181214062754.13723-1-ying.huang@intel.com>
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: <linux-kernel.vger.kernel.org>
X-Mailing-List: linux-kernel@vger.kernel.org

Swapin a THP as a whole isn't desirable in some situations.  For
example, for completely random access pattern, swapin a THP in one
piece will inflate the reading greatly.  So a sysfs interface:
/sys/kernel/mm/transparent_hugepage/swapin_enabled is added to
configure it.  Three options as follow are provided,

- always: THP swapin will be enabled always

- madvise: THP swapin will be enabled only for VMA with VM_HUGEPAGE
  flag set.

- never: THP swapin will be disabled always

The default configuration is: madvise.

During page fault, if a PMD swap mapping is found and THP swapin is
disabled, the huge swap cluster and the PMD swap mapping will be split
and fallback to normal page swapin.

Signed-off-by: "Huang, Ying" <ying.huang@intel.com>
Cc: "Kirill A. Shutemov" <kirill.shutemov@linux.intel.com>
Cc: Andrea Arcangeli <aarcange@redhat.com>
Cc: Michal Hocko <mhocko@kernel.org>
Cc: Johannes Weiner <hannes@cmpxchg.org>
Cc: Shaohua Li <shli@kernel.org>
Cc: Hugh Dickins <hughd@google.com>
Cc: Minchan Kim <minchan@kernel.org>
Cc: Rik van Riel <riel@redhat.com>
Cc: Dave Hansen <dave.hansen@linux.intel.com>
Cc: Naoya Horiguchi <n-horiguchi@ah.jp.nec.com>
Cc: Zi Yan <zi.yan@cs.rutgers.edu>
Cc: Daniel Jordan <daniel.m.jordan@oracle.com>
---
 Documentation/admin-guide/mm/transhuge.rst | 21 +++++
 include/linux/huge_mm.h                    | 31 ++++++++
 mm/huge_memory.c                           | 93 +++++++++++++++++-----
 3 files changed, 126 insertions(+), 19 deletions(-)

diff --git a/Documentation/admin-guide/mm/transhuge.rst b/Documentation/admin-guide/mm/transhuge.rst
index 85e33f785fd7..23aefb17101c 100644
--- a/Documentation/admin-guide/mm/transhuge.rst
+++ b/Documentation/admin-guide/mm/transhuge.rst
@@ -160,6 +160,27 @@ Some userspace (such as a test program, or an optimized memory allocation
 
 	cat /sys/kernel/mm/transparent_hugepage/hpage_pmd_size
 
+Transparent hugepage may be swapout and swapin in one piece without
+splitting.  This will improve the utility of transparent hugepage but
+may inflate the read/write too.  So whether to enable swapin
+transparent hugepage in one piece can be configured as follow.
+
+	echo always >/sys/kernel/mm/transparent_hugepage/swapin_enabled
+	echo madvise >/sys/kernel/mm/transparent_hugepage/swapin_enabled
+	echo never >/sys/kernel/mm/transparent_hugepage/swapin_enabled
+
+always
+	Attempt to allocate a transparent huge page and read it from
+	swap space in one piece every time.
+
+never
+	Always split the swap space and PMD swap mapping and swapin
+	the fault normal page during swapin.
+
+madvise
+	Only swapin the transparent huge page in one piece for
+	MADV_HUGEPAGE madvise regions.
+
 khugepaged will be automatically started when
 transparent_hugepage/enabled is set to "always" or "madvise, and it'll
 be automatically shutdown if it's set to "never".
diff --git a/include/linux/huge_mm.h b/include/linux/huge_mm.h
index debe3760e894..06dbbcf6a6dd 100644
--- a/include/linux/huge_mm.h
+++ b/include/linux/huge_mm.h
@@ -63,6 +63,8 @@ enum transparent_hugepage_flag {
 #ifdef CONFIG_DEBUG_VM
 	TRANSPARENT_HUGEPAGE_DEBUG_COW_FLAG,
 #endif
+	TRANSPARENT_HUGEPAGE_SWAPIN_FLAG,
+	TRANSPARENT_HUGEPAGE_SWAPIN_REQ_MADV_FLAG,
 };
 
 struct kobject;
@@ -373,11 +375,40 @@ static inline gfp_t alloc_hugepage_direct_gfpmask(struct vm_area_struct *vma)
 
 #ifdef CONFIG_THP_SWAP
 extern int do_huge_pmd_swap_page(struct vm_fault *vmf, pmd_t orig_pmd);
+
+static inline bool transparent_hugepage_swapin_enabled(
+	struct vm_area_struct *vma)
+{
+	if (vma->vm_flags & VM_NOHUGEPAGE)
+		return false;
+
+	if (is_vma_temporary_stack(vma))
+		return false;
+
+	if (test_bit(MMF_DISABLE_THP, &vma->vm_mm->flags))
+		return false;
+
+	if (transparent_hugepage_flags &
+			(1 << TRANSPARENT_HUGEPAGE_SWAPIN_FLAG))
+		return true;
+
+	if (transparent_hugepage_flags &
+			(1 << TRANSPARENT_HUGEPAGE_SWAPIN_REQ_MADV_FLAG))
+		return !!(vma->vm_flags & VM_HUGEPAGE);
+
+	return false;
+}
 #else /* CONFIG_THP_SWAP */
 static inline int do_huge_pmd_swap_page(struct vm_fault *vmf, pmd_t orig_pmd)
 {
 	return 0;
 }
+
+static inline bool transparent_hugepage_swapin_enabled(
+	struct vm_area_struct *vma)
+{
+	return false;
+}
 #endif /* CONFIG_THP_SWAP */
 
 #endif /* _LINUX_HUGE_MM_H */
diff --git a/mm/huge_memory.c b/mm/huge_memory.c
index e1e95e6c86e3..8e8952938c25 100644
--- a/mm/huge_memory.c
+++ b/mm/huge_memory.c
@@ -57,7 +57,8 @@ unsigned long transparent_hugepage_flags __read_mostly =
 #endif
 	(1<<TRANSPARENT_HUGEPAGE_DEFRAG_REQ_MADV_FLAG)|
 	(1<<TRANSPARENT_HUGEPAGE_DEFRAG_KHUGEPAGED_FLAG)|
-	(1<<TRANSPARENT_HUGEPAGE_USE_ZERO_PAGE_FLAG);
+	(1<<TRANSPARENT_HUGEPAGE_USE_ZERO_PAGE_FLAG)|
+	(1<<TRANSPARENT_HUGEPAGE_SWAPIN_REQ_MADV_FLAG);
 
 static struct shrinker deferred_split_shrinker;
 
@@ -316,6 +317,53 @@ static struct kobj_attribute debug_cow_attr =
 	__ATTR(debug_cow, 0644, debug_cow_show, debug_cow_store);
 #endif /* CONFIG_DEBUG_VM */
 
+#ifdef CONFIG_THP_SWAP
+static ssize_t swapin_enabled_show(struct kobject *kobj,
+				   struct kobj_attribute *attr, char *buf)
+{
+	if (test_bit(TRANSPARENT_HUGEPAGE_SWAPIN_FLAG,
+		     &transparent_hugepage_flags))
+		return sprintf(buf, "[always] madvise never\n");
+	else if (test_bit(TRANSPARENT_HUGEPAGE_SWAPIN_REQ_MADV_FLAG,
+			  &transparent_hugepage_flags))
+		return sprintf(buf, "always [madvise] never\n");
+	else
+		return sprintf(buf, "always madvise [never]\n");
+}
+
+static ssize_t swapin_enabled_store(struct kobject *kobj,
+				    struct kobj_attribute *attr,
+				    const char *buf, size_t count)
+{
+	ssize_t ret = count;
+
+	if (!memcmp("always", buf,
+		    min(sizeof("always")-1, count))) {
+		clear_bit(TRANSPARENT_HUGEPAGE_SWAPIN_REQ_MADV_FLAG,
+			  &transparent_hugepage_flags);
+		set_bit(TRANSPARENT_HUGEPAGE_SWAPIN_FLAG,
+			&transparent_hugepage_flags);
+	} else if (!memcmp("madvise", buf,
+			   min(sizeof("madvise")-1, count))) {
+		clear_bit(TRANSPARENT_HUGEPAGE_SWAPIN_FLAG,
+			  &transparent_hugepage_flags);
+		set_bit(TRANSPARENT_HUGEPAGE_SWAPIN_REQ_MADV_FLAG,
+			&transparent_hugepage_flags);
+	} else if (!memcmp("never", buf,
+			   min(sizeof("never")-1, count))) {
+		clear_bit(TRANSPARENT_HUGEPAGE_SWAPIN_FLAG,
+			  &transparent_hugepage_flags);
+		clear_bit(TRANSPARENT_HUGEPAGE_SWAPIN_REQ_MADV_FLAG,
+			  &transparent_hugepage_flags);
+	} else
+		ret = -EINVAL;
+
+	return ret;
+}
+static struct kobj_attribute swapin_enabled_attr =
+	__ATTR(swapin_enabled, 0644, swapin_enabled_show, swapin_enabled_store);
+#endif /* CONFIG_THP_SWAP */
+
 static struct attribute *hugepage_attr[] = {
 	&enabled_attr.attr,
 	&defrag_attr.attr,
@@ -326,6 +374,9 @@ static struct attribute *hugepage_attr[] = {
 #endif
 #ifdef CONFIG_DEBUG_VM
 	&debug_cow_attr.attr,
+#endif
+#ifdef CONFIG_THP_SWAP
+	&swapin_enabled_attr.attr,
 #endif
 	NULL,
 };
@@ -1688,6 +1739,9 @@ int do_huge_pmd_swap_page(struct vm_fault *vmf, pmd_t orig_pmd)
 retry:
 	page = lookup_swap_cache(entry, NULL, vmf->address);
 	if (!page) {
+		if (!transparent_hugepage_swapin_enabled(vma))
+			goto split;
+
 		page = read_swap_cache_async(entry, GFP_HIGHUSER_MOVABLE, vma,
 					     haddr, false);
 		if (!page) {
@@ -1695,24 +1749,8 @@ int do_huge_pmd_swap_page(struct vm_fault *vmf, pmd_t orig_pmd)
 			 * Back out if somebody else faulted in this pmd
 			 * while we released the pmd lock.
 			 */
-			if (likely(pmd_same(*vmf->pmd, orig_pmd))) {
-				/*
-				 * Failed to allocate huge page, split huge swap
-				 * cluster, and fallback to swapin normal page
-				 */
-				ret = split_swap_cluster(entry, 0);
-				/* Somebody else swapin the swap entry, retry */
-				if (ret == -EEXIST) {
-					ret = 0;
-					goto retry;
-				/* swapoff occurs under us */
-				} else if (ret == -EINVAL)
-					ret = 0;
-				else {
-					count_vm_event(THP_SWPIN_FALLBACK);
-					goto fallback;
-				}
-			}
+			if (likely(pmd_same(*vmf->pmd, orig_pmd)))
+				goto split;
 			delayacct_clear_flag(DELAYACCT_PF_SWAPIN);
 			goto out;
 		}
@@ -1816,6 +1854,23 @@ int do_huge_pmd_swap_page(struct vm_fault *vmf, pmd_t orig_pmd)
 out_release:
 	put_page(page);
 	return ret;
+split:
+	/*
+	 * Failed to allocate huge page, split huge swap cluster, and
+	 * fallback to swapin normal page
+	 */
+	ret = split_swap_cluster(entry, 0);
+	/* Somebody else swapin the swap entry, retry */
+	if (ret == -EEXIST) {
+		ret = 0;
+		goto retry;
+	}
+	/* swapoff occurs under us */
+	if (ret == -EINVAL) {
+		delayacct_clear_flag(DELAYACCT_PF_SWAPIN);
+		return 0;
+	}
+	count_vm_event(THP_SWPIN_FALLBACK);
 fallback:
 	delayacct_clear_flag(DELAYACCT_PF_SWAPIN);
 	if (!split_huge_swap_pmd(vmf->vma, vmf->pmd, vmf->address, orig_pmd))
-- 
2.18.1

