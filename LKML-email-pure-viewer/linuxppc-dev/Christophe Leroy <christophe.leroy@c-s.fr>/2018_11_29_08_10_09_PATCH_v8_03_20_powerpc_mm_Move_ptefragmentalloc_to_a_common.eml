Return-Path: <linux-kernel-owner@vger.kernel.org>
Delivered-To: unknown
Received: from linux.intel.com (10.54.29.200:995) by likexu-workstation with
  POP3-SSL; 29 Nov 2018 18:18:12 -0000
X-Original-To: like.xu@linux.intel.com
Delivered-To: like.xu@linux.intel.com
Received: from orsmga004.jf.intel.com (orsmga004.jf.intel.com [10.7.209.38])
	(using TLSv1.2 with cipher ECDHE-RSA-AES256-GCM-SHA384 (256/256 bits))
	(No client certificate requested)
	by linux.intel.com (Postfix) with ESMTPS id 85BBF5802E4;
	Thu, 29 Nov 2018 00:12:36 -0800 (PST)
Received: from fmsmga105.fm.intel.com ([10.1.193.10])
  by orsmga004-1.jf.intel.com with ESMTP/TLS/DHE-RSA-AES256-GCM-SHA384; 29 Nov 2018 00:12:26 -0800
X-SG-BADATTACHMENTNOREPLY: True
IronPort-PHdr: =?us-ascii?q?9a23=3Aaq2oJxQoT/WTeRRJ3vp8IlA1ANpsv+yvbD5Q0YIu?=
 =?us-ascii?q?jvd0So/mwa64YRGAt8tkgFKBZ4jH8fUM07OQ7/iwHzRYqb+681k6OKRWUBEEjc?=
 =?us-ascii?q?hE1ycBO+WiTXPBEfjxciYhF95DXlI2t1uyMExSBdqsLwaK+i764jEdAAjwOhRo?=
 =?us-ascii?q?LerpBIHSk9631+ev8JHPfglEnjWwba9xIRmssQndqtQdjJd/JKo21hbHuGZDdf?=
 =?us-ascii?q?5MxWNvK1KTnhL86dm18ZV+7SleuO8v+tBZX6nicKs2UbJXDDI9M2Ao/8LrrgXM?=
 =?us-ascii?q?TRGO5nQHTGoblAdDDhXf4xH7WpfxtTb6tvZ41SKHM8D6Uaw4VDK/5KpwVhTmlD?=
 =?us-ascii?q?kIOCI48GHPi8x/kqRboA66pxdix4LYeZyZOOZicq/Ye94RWGhPUdtLVyFZAY2z?=
 =?us-ascii?q?bYUPAeocM+hGoYf9vEMOoBmlCAWwGO/i0CNEimPq0aEm1ekqDAHI3BYnH9ILqH?=
 =?us-ascii?q?nZstX1NL0TUeCu0KnIyi3Db/NI1jzg7obHbAohofaMXLltdsfe1UkvFxnEjlWL?=
 =?us-ascii?q?tYzlOCuV1uQTvGSB6+pvS/ivi2knqgxqvjej39wshpPHhoIP013J8zhyzoUtJd?=
 =?us-ascii?q?CgVkJ3fdqpHIFNuyyUKYd6WN4uTmJ0tCogy7ALu4a3cSwExZg92hLSaeaLf5aG?=
 =?us-ascii?q?7x/iTuqcLyt0iXR4c7ylnRmy61KvyujkW8m0zllKqi1Fn8HStnACyRPT8NKLSv?=
 =?us-ascii?q?hj8Ue73zaAyQTT5vtDIUAumqrXM58hwrgumZoPqUnPADP6lUHsgKOLeEgo5PKk?=
 =?us-ascii?q?5/nkb7n6vJORNo15hhn7Mqs0m8y/Beo4MhIJX2ie4em80Lzj/UvkQLRFl/E2kb?=
 =?us-ascii?q?fWsIrcJcsFoq61GghV04gl6xmhFTery8oYnXYZI1JfYh6HjJbmO0vIIP/mCfez?=
 =?us-ascii?q?mVOskC1kx/zeJL3uHo3NLmTfkLfmZbt9709cyAktwtxF6JNUF6oMIPbyWk/3qd?=
 =?us-ascii?q?zZAQU1Mw2yw+b7Ftp90pkSVn6IAq+cKKnSq0OH5vozI+mQY48YoDb9JOIk5/7y?=
 =?us-ascii?q?l3A5nkURfam03ZQNbnC4Ee9rI0GYYXrqn9cAHn0Gvgs4TOz2llKCVSRfaGq1X6?=
 =?us-ascii?q?I5/js7Ep6pDZ/fRoCxh7yMxCW7HppIaWxcCVCMFnHod4ODW/oXbCKSI8lhkiEL?=
 =?us-ascii?q?VLS7So8h0w2uuxH+y7Z9MuXU/SgYv4r51Ndp/+3TiQ0y9TtsAsuHyGGNT2Z0nm?=
 =?us-ascii?q?ASSz8sxq9/o1dwylOC0ah+nvxZGsZf5/JPUgcmK5Hcy/Z2BMz1WgLEZt2JUkqp?=
 =?us-ascii?q?Qs26ATEtSdI829wObFx7G9m4ihDD3jClA7kal7GQAJw086Tc32X+JspnynbG0r?=
 =?us-ascii?q?UhgEciQsdVKWKmgat//RDJB4HVi0WZi7qqdaME0SHQ7miD03SBsFtYUAFqV6XF?=
 =?us-ascii?q?Rm4QZk3RodT95UPCSruuBK8jMgtAz86CN6RLZsfojVVAWPfsJtDeb3itlGe3AB?=
 =?us-ascii?q?aC3qmMY5bye2UBwCXdD1AJnB0J8naYKwcyHCehrHjYDDx1C13vZVjh8e1/qHO9?=
 =?us-ascii?q?U081wBuGb0xn17qp5BEVgeaQRO8U3rIBoC0hsSl7HE6h39LKDNqNvxZhfKRZYd?=
 =?us-ascii?q?M6/FdH1WLYuxZhPpC6KKBinFoecwVxv0PhzBh3DoRAkc43rHIl1gZyKKSY0E9f?=
 =?us-ascii?q?eDOcx5z/JrrXKmzq9hC1d6HWwk3e0MqR+qoX8vs4r0vsvQ63GUsi6XloyMRV3G?=
 =?us-ascii?q?aG6ZXMDwoSVozxX10z9xh7obHafyY865nV1X1qLam7rDvC18g1C+sizxaqZ81f?=
 =?us-ascii?q?P7+cFA/uD80aANCjKew3m1Szch0IJuFT9K4uMMOgePuLw6qrPOdmnDK7gmVL+o?=
 =?us-ascii?q?F90kSQ9yViTu7ExYoKw/ad3gGfTTfzkE+hstzrmYBDfTwSBGu/xjT+C45Le6Jy?=
 =?us-ascii?q?epwHCWGwLM2tx9VynoLiVGRc9FG+GVwGwsipeRyJYlz53A1Q01kXoHO9lSu5yT?=
 =?us-ascii?q?x0jy8mrq6F0CPSxOTicQINOnRXS2l6kVfsPY+0gsgaXUipdQQolAGp5V3nx6hd?=
 =?us-ascii?q?v6l/K2jTQUFVfyn5NW1iU62wtqacbM5L8p8nrSJXUOGka1CAVrH9uwca0z/kH2?=
 =?us-ascii?q?ZGxjA0bSuqupb6nxx9km6dN2x8rHnaecFxwxfQ+trcSOVV3joHQil4lDbWCkK9?=
 =?us-ascii?q?P9mv4dWbiZPDvvqiWGKmU51ZaTPrwp+YtCun+W1qBgWynvCpld3gCwQ60y7719?=
 =?us-ascii?q?9xWCXMrRb8ZJTr1qugPeJmeEloGEHz685gFo5ilYswgYka2WIGiZWN4XoHjWDz?=
 =?us-ascii?q?PM1Y2a3kbXoBXz4Lw8PP7wjj101uNXaJx4P/VnWAzcptfdi6YmUK2i0j68BGEr?=
 =?us-ascii?q?ub7LtBnSFtuFq3sRrRYeRhnjca0fYu7X8ag+ITtwY3wCSSHKsSHVVGMiz2jBuH?=
 =?us-ascii?q?8cq+rKpMaWarcLiw0ld+nN+7ALGDpAFcRGj2epM4ESBs6cV/NUrG0Gfv5YH8ZN?=
 =?us-ascii?q?nQcdUTuwWIkxfHiuhZMpMwmeAMhSp6ImL9pnwlxvU/jRxv25G6oYeGJ39s/KK/?=
 =?us-ascii?q?Hh5XKDn1a9kP9THqiKZUhtyW0Jy3HpV9BjULW4PlQumyHzIVsfTnKhyCEDkhqn?=
 =?us-ascii?q?qAHbrfHAmf6Fpprn7VEpCrMW2XK2cdzdl4WBadI0lfihgOXDomhp45ChyqxMv5?=
 =?us-ascii?q?fUd7/D8R40D3qgBWxuJ0LRX/UXrfpAS1ajcyUpefNwFb7gVD50fTLMyf4fh/Hy?=
 =?us-ascii?q?Be/p29sgONLnaXaBhPDWEMQkaEHUzsPqGy5dnc9OiVHuq/L/zTYbWXtOxRTfGI?=
 =?us-ascii?q?yYi00oth+TaMOd6CPn1jD/09x0pCUmp1G8XfmzUTVSMXkzjBYNKcpBe54id3tN?=
 =?us-ascii?q?yw8Oz3WALz4ouCE7tSPstu+xC1gqeDNvSchCVjKTZf2ZMD22XIyKUE3FMJjyFu?=
 =?us-ascii?q?dj+tEakPtCLXTaLQnLNXAAAfay9pKMRI6Kc81BFXOcHHktP1yqJ4jvktBlhfSF?=
 =?us-ascii?q?zugdupatIKIm2nMFPHBV2GNLCHJT3N3sH2brmwSbxWjOVIqRKwvSyXHFPkPjSG?=
 =?us-ascii?q?jzPpTQygMflQjCGHOxxToJ29chdoCWT5UN3qcAG0MN9pgj0w2rA0gnLKNWgBMT?=
 =?us-ascii?q?lzaU9Nr7uQ7T9GjfV7AWBO8n1lLeyckSaD8+bYMooWsedsAilsl+NV+nI6y75U?=
 =?us-ascii?q?7CFCXPN0mSvSocRoo1GpieSPzjtnUBxTqjdEno6LvENiObnH+ZlEQ3rL4BUN7W?=
 =?us-ascii?q?DDQygN8vFoDN/mvqFWgvjCjrj+LixJ89fV8ddUU8LZLsKvM3c7NxftXjXOBRAF?=
 =?us-ascii?q?TDikc2bFiBoZ2Mmb63ndi5ExqZX2gpMVAutDXUExC+gyEU1gFtVEJ414CHdstL?=
 =?us-ascii?q?+QjMcF4TKTqB3cXsBTuNiTU+qfKfjrLDuDiLBCIRoEh7rle9c9LIr+jmdicFhh?=
 =?us-ascii?q?gIPSG0eYed1XpTwpOgQ0ukRW7H9mTmB130//bRKF6zoIU/CuyE1lwjBiaPggoW?=
 =?us-ascii?q?+/q2w8IUDH8W5pyBE8?=
X-IronPort-Anti-Spam-Filtered: true
X-IronPort-Anti-Spam-Result: =?us-ascii?q?A0AWAAAnn/9bh0O0hNFkHgEGBwaBUQkLA?=
 =?us-ascii?q?YNrJ4xwiymBaDmSN4R3gXYpEwGHcSI0CQ0BAwEBAQEBAQIBEwEBAQgNCQgpL4I?=
 =?us-ascii?q?2JAGCYgMDAQIkUgYJAQEYOAMpKwYBEgWDHIICBAGmejOFQYRsjBaBVz+BETONO?=
 =?us-ascii?q?wKJKZZ2BwKBDIERBI8pkRosiEuQeSCCDU0ngziCJxeOHT8BATEBgQQBAY0yAQE?=
X-IPAS-Result: =?us-ascii?q?A0AWAAAnn/9bh0O0hNFkHgEGBwaBUQkLAYNrJ4xwiymBaDm?=
 =?us-ascii?q?SN4R3gXYpEwGHcSI0CQ0BAwEBAQEBAQIBEwEBAQgNCQgpL4I2JAGCYgMDAQIkU?=
 =?us-ascii?q?gYJAQEYOAMpKwYBEgWDHIICBAGmejOFQYRsjBaBVz+BETONOwKJKZZ2BwKBDIE?=
 =?us-ascii?q?RBI8pkRosiEuQeSCCDU0ngziCJxeOHT8BATEBgQQBAY0yAQE?=
X-IronPort-AV: E=Sophos;i="5.56,293,1539673200"; 
   d="scan'208";a="140051031"
X-Amp-Result: SKIPPED(no attachment in message)
X-Amp-File-Uploaded: False
Received: from vger.kernel.org ([209.132.180.67])
  by mtab.intel.com with ESMTP; 29 Nov 2018 00:12:17 -0800
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
        id S1728113AbeK2TOn (ORCPT <rfc822;like.xu@linux.intel.com>
        + 23 others); Thu, 29 Nov 2018 14:14:43 -0500
Received: from pegase1.c-s.fr ([93.17.236.30]:32047 "EHLO pegase1.c-s.fr"
        rhost-flags-OK-OK-OK-OK) by vger.kernel.org with ESMTP
        id S1726789AbeK2TOm (ORCPT <rfc822;linux-kernel@vger.kernel.org>);
        Thu, 29 Nov 2018 14:14:42 -0500
Received: from localhost (mailhub1-int [192.168.12.234])
        by localhost (Postfix) with ESMTP id 4359Dd5FQhz9vGm1;
        Thu, 29 Nov 2018 09:10:09 +0100 (CET)
X-Virus-Scanned: Debian amavisd-new at c-s.fr
Received: from pegase1.c-s.fr ([192.168.12.234])
        by localhost (pegase1.c-s.fr [192.168.12.234]) (amavisd-new, port 10024)
        with ESMTP id TZc51XkKmpfs; Thu, 29 Nov 2018 09:10:09 +0100 (CET)
Received: from messagerie.si.c-s.fr (messagerie.si.c-s.fr [192.168.25.192])
        by pegase1.c-s.fr (Postfix) with ESMTP id 4359Dd4gtCz9vGlV;
        Thu, 29 Nov 2018 09:10:09 +0100 (CET)
Received: from localhost (localhost [127.0.0.1])
        by messagerie.si.c-s.fr (Postfix) with ESMTP id 5E2B08B892;
        Thu, 29 Nov 2018 09:10:10 +0100 (CET)
X-Virus-Scanned: amavisd-new at c-s.fr
Received: from messagerie.si.c-s.fr ([127.0.0.1])
        by localhost (messagerie.si.c-s.fr [127.0.0.1]) (amavisd-new, port 10023)
        with ESMTP id 4Wg3a0gYScNr; Thu, 29 Nov 2018 09:10:10 +0100 (CET)
Received: from po14163vm.idsi0.si.c-s.fr (unknown [192.168.232.3])
        by messagerie.si.c-s.fr (Postfix) with ESMTP id 00D598B762;
        Thu, 29 Nov 2018 09:10:09 +0100 (CET)
Received: by po14163vm.idsi0.si.c-s.fr (Postfix, from userid 0)
        id C833669B13; Thu, 29 Nov 2018 08:10:09 +0000 (UTC)
Message-Id: <a0eb810bd261679fbddbef5578f50c64d8373038.1543478200.git.christophe.leroy@c-s.fr>
In-Reply-To: <cover.1543478199.git.christophe.leroy@c-s.fr>
References: <cover.1543478199.git.christophe.leroy@c-s.fr>
From: Christophe Leroy <christophe.leroy@c-s.fr>
Subject: [PATCH v8 03/20] powerpc/mm: Move pte_fragment_alloc() to a common
 location
To: Benjamin Herrenschmidt <benh@kernel.crashing.org>,
        Paul Mackerras <paulus@samba.org>,
        Michael Ellerman <mpe@ellerman.id.au>
Cc: linux-kernel@vger.kernel.org, linuxppc-dev@lists.ozlabs.org
Date: Thu, 29 Nov 2018 08:10:09 +0000 (UTC)
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: <linux-kernel.vger.kernel.org>
X-Mailing-List: linux-kernel@vger.kernel.org

In preparation of next patch which generalises the use of
pte_fragment_alloc() for all, this patch moves the related functions
in a place that is common to all subarches.

The 8xx will need that for supporting 16k pages, as in that mode
page tables still have a size of 4k.

Since pte_fragment with only once fragment is not different
from what is done in the general case, we can easily migrate all
subarchs to pte fragments.

Reviewed-by: Aneesh Kumar K.V <aneesh.kumar@linux.ibm.com>
Signed-off-by: Christophe Leroy <christophe.leroy@c-s.fr>
---
 arch/powerpc/include/asm/book3s/64/pgalloc.h |   1 +
 arch/powerpc/mm/Makefile                     |   4 +-
 arch/powerpc/mm/mmu_context_book3s64.c       |  15 ----
 arch/powerpc/mm/pgtable-book3s64.c           |  85 --------------------
 arch/powerpc/mm/pgtable-frag.c               | 116 +++++++++++++++++++++++++++
 5 files changed, 120 insertions(+), 101 deletions(-)
 create mode 100644 arch/powerpc/mm/pgtable-frag.c

diff --git a/arch/powerpc/include/asm/book3s/64/pgalloc.h b/arch/powerpc/include/asm/book3s/64/pgalloc.h
index 391ed2c3b697..f949dd90af9b 100644
--- a/arch/powerpc/include/asm/book3s/64/pgalloc.h
+++ b/arch/powerpc/include/asm/book3s/64/pgalloc.h
@@ -50,6 +50,7 @@ extern void pgtable_free_tlb(struct mmu_gather *tlb, void *table, int shift);
 #ifdef CONFIG_SMP
 extern void __tlb_remove_table(void *_table);
 #endif
+void pte_frag_destroy(void *pte_frag);
 
 static inline pgd_t *radix__pgd_alloc(struct mm_struct *mm)
 {
diff --git a/arch/powerpc/mm/Makefile b/arch/powerpc/mm/Makefile
index ca96e7be4d0e..3cbb1acf0745 100644
--- a/arch/powerpc/mm/Makefile
+++ b/arch/powerpc/mm/Makefile
@@ -15,7 +15,9 @@ obj-$(CONFIG_PPC_MMU_NOHASH)	+= mmu_context_nohash.o tlb_nohash.o \
 obj-$(CONFIG_PPC_BOOK3E)	+= tlb_low_$(BITS)e.o
 hash64-$(CONFIG_PPC_NATIVE)	:= hash_native_64.o
 obj-$(CONFIG_PPC_BOOK3E_64)   += pgtable-book3e.o
-obj-$(CONFIG_PPC_BOOK3S_64)	+= pgtable-hash64.o hash_utils_64.o slb.o $(hash64-y) mmu_context_book3s64.o pgtable-book3s64.o
+obj-$(CONFIG_PPC_BOOK3S_64)	+= pgtable-hash64.o hash_utils_64.o slb.o \
+				   $(hash64-y) mmu_context_book3s64.o \
+				   pgtable-book3s64.o pgtable-frag.o
 obj-$(CONFIG_PPC_RADIX_MMU)	+= pgtable-radix.o tlb-radix.o
 obj-$(CONFIG_PPC_STD_MMU_32)	+= ppc_mmu_32.o hash_low_32.o mmu_context_hash32.o
 obj-$(CONFIG_PPC_STD_MMU)	+= tlb_hash$(BITS).o
diff --git a/arch/powerpc/mm/mmu_context_book3s64.c b/arch/powerpc/mm/mmu_context_book3s64.c
index 510f103d7813..f720c5cc0b5e 100644
--- a/arch/powerpc/mm/mmu_context_book3s64.c
+++ b/arch/powerpc/mm/mmu_context_book3s64.c
@@ -164,21 +164,6 @@ static void destroy_contexts(mm_context_t *ctx)
 	}
 }
 
-static void pte_frag_destroy(void *pte_frag)
-{
-	int count;
-	struct page *page;
-
-	page = virt_to_page(pte_frag);
-	/* drop all the pending references */
-	count = ((unsigned long)pte_frag & ~PAGE_MASK) >> PTE_FRAG_SIZE_SHIFT;
-	/* We allow PTE_FRAG_NR fragments from a PTE page */
-	if (atomic_sub_and_test(PTE_FRAG_NR - count, &page->pt_frag_refcount)) {
-		pgtable_page_dtor(page);
-		__free_page(page);
-	}
-}
-
 static void pmd_frag_destroy(void *pmd_frag)
 {
 	int count;
diff --git a/arch/powerpc/mm/pgtable-book3s64.c b/arch/powerpc/mm/pgtable-book3s64.c
index 9f93c9f985c5..0c0fd173208a 100644
--- a/arch/powerpc/mm/pgtable-book3s64.c
+++ b/arch/powerpc/mm/pgtable-book3s64.c
@@ -322,91 +322,6 @@ void pmd_fragment_free(unsigned long *pmd)
 	}
 }
 
-static pte_t *get_pte_from_cache(struct mm_struct *mm)
-{
-	void *pte_frag, *ret;
-
-	spin_lock(&mm->page_table_lock);
-	ret = mm->context.pte_frag;
-	if (ret) {
-		pte_frag = ret + PTE_FRAG_SIZE;
-		/*
-		 * If we have taken up all the fragments mark PTE page NULL
-		 */
-		if (((unsigned long)pte_frag & ~PAGE_MASK) == 0)
-			pte_frag = NULL;
-		mm->context.pte_frag = pte_frag;
-	}
-	spin_unlock(&mm->page_table_lock);
-	return (pte_t *)ret;
-}
-
-static pte_t *__alloc_for_ptecache(struct mm_struct *mm, int kernel)
-{
-	void *ret = NULL;
-	struct page *page;
-
-	if (!kernel) {
-		page = alloc_page(PGALLOC_GFP | __GFP_ACCOUNT);
-		if (!page)
-			return NULL;
-		if (!pgtable_page_ctor(page)) {
-			__free_page(page);
-			return NULL;
-		}
-	} else {
-		page = alloc_page(PGALLOC_GFP);
-		if (!page)
-			return NULL;
-	}
-
-	atomic_set(&page->pt_frag_refcount, 1);
-
-	ret = page_address(page);
-	/*
-	 * if we support only one fragment just return the
-	 * allocated page.
-	 */
-	if (PTE_FRAG_NR == 1)
-		return ret;
-	spin_lock(&mm->page_table_lock);
-	/*
-	 * If we find pgtable_page set, we return
-	 * the allocated page with single fragement
-	 * count.
-	 */
-	if (likely(!mm->context.pte_frag)) {
-		atomic_set(&page->pt_frag_refcount, PTE_FRAG_NR);
-		mm->context.pte_frag = ret + PTE_FRAG_SIZE;
-	}
-	spin_unlock(&mm->page_table_lock);
-
-	return (pte_t *)ret;
-}
-
-pte_t *pte_fragment_alloc(struct mm_struct *mm, unsigned long vmaddr, int kernel)
-{
-	pte_t *pte;
-
-	pte = get_pte_from_cache(mm);
-	if (pte)
-		return pte;
-
-	return __alloc_for_ptecache(mm, kernel);
-}
-
-void pte_fragment_free(unsigned long *table, int kernel)
-{
-	struct page *page = virt_to_page(table);
-
-	BUG_ON(atomic_read(&page->pt_frag_refcount) <= 0);
-	if (atomic_dec_and_test(&page->pt_frag_refcount)) {
-		if (!kernel)
-			pgtable_page_dtor(page);
-		__free_page(page);
-	}
-}
-
 static inline void pgtable_free(void *table, int index)
 {
 	switch (index) {
diff --git a/arch/powerpc/mm/pgtable-frag.c b/arch/powerpc/mm/pgtable-frag.c
new file mode 100644
index 000000000000..d61e7c2a9a79
--- /dev/null
+++ b/arch/powerpc/mm/pgtable-frag.c
@@ -0,0 +1,116 @@
+// SPDX-License-Identifier: GPL-2.0
+
+/*
+ *  Handling Page Tables through page fragments
+ *
+ */
+
+#include <linux/kernel.h>
+#include <linux/gfp.h>
+#include <linux/mm.h>
+#include <linux/percpu.h>
+#include <linux/hardirq.h>
+#include <linux/hugetlb.h>
+#include <asm/pgalloc.h>
+#include <asm/tlbflush.h>
+#include <asm/tlb.h>
+
+void pte_frag_destroy(void *pte_frag)
+{
+	int count;
+	struct page *page;
+
+	page = virt_to_page(pte_frag);
+	/* drop all the pending references */
+	count = ((unsigned long)pte_frag & ~PAGE_MASK) >> PTE_FRAG_SIZE_SHIFT;
+	/* We allow PTE_FRAG_NR fragments from a PTE page */
+	if (atomic_sub_and_test(PTE_FRAG_NR - count, &page->pt_frag_refcount)) {
+		pgtable_page_dtor(page);
+		__free_page(page);
+	}
+}
+
+static pte_t *get_pte_from_cache(struct mm_struct *mm)
+{
+	void *pte_frag, *ret;
+
+	spin_lock(&mm->page_table_lock);
+	ret = mm->context.pte_frag;
+	if (ret) {
+		pte_frag = ret + PTE_FRAG_SIZE;
+		/*
+		 * If we have taken up all the fragments mark PTE page NULL
+		 */
+		if (((unsigned long)pte_frag & ~PAGE_MASK) == 0)
+			pte_frag = NULL;
+		mm->context.pte_frag = pte_frag;
+	}
+	spin_unlock(&mm->page_table_lock);
+	return (pte_t *)ret;
+}
+
+static pte_t *__alloc_for_ptecache(struct mm_struct *mm, int kernel)
+{
+	void *ret = NULL;
+	struct page *page;
+
+	if (!kernel) {
+		page = alloc_page(PGALLOC_GFP | __GFP_ACCOUNT);
+		if (!page)
+			return NULL;
+		if (!pgtable_page_ctor(page)) {
+			__free_page(page);
+			return NULL;
+		}
+	} else {
+		page = alloc_page(PGALLOC_GFP);
+		if (!page)
+			return NULL;
+	}
+
+	atomic_set(&page->pt_frag_refcount, 1);
+
+	ret = page_address(page);
+	/*
+	 * if we support only one fragment just return the
+	 * allocated page.
+	 */
+	if (PTE_FRAG_NR == 1)
+		return ret;
+	spin_lock(&mm->page_table_lock);
+	/*
+	 * If we find pgtable_page set, we return
+	 * the allocated page with single fragement
+	 * count.
+	 */
+	if (likely(!mm->context.pte_frag)) {
+		atomic_set(&page->pt_frag_refcount, PTE_FRAG_NR);
+		mm->context.pte_frag = ret + PTE_FRAG_SIZE;
+	}
+	spin_unlock(&mm->page_table_lock);
+
+	return (pte_t *)ret;
+}
+
+pte_t *pte_fragment_alloc(struct mm_struct *mm, unsigned long vmaddr, int kernel)
+{
+	pte_t *pte;
+
+	pte = get_pte_from_cache(mm);
+	if (pte)
+		return pte;
+
+	return __alloc_for_ptecache(mm, kernel);
+}
+
+void pte_fragment_free(unsigned long *table, int kernel)
+{
+	struct page *page = virt_to_page(table);
+
+	BUG_ON(atomic_read(&page->pt_frag_refcount) <= 0);
+	if (atomic_dec_and_test(&page->pt_frag_refcount)) {
+		if (!kernel)
+			pgtable_page_dtor(page);
+		__free_page(page);
+	}
+}
-- 
2.13.3

