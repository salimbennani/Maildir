Return-Path: <linux-kernel-owner@vger.kernel.org>
Delivered-To: unknown
Received: from linux.intel.com (10.54.29.200:995) by i7-8700 with POP3-SSL;
  24 Dec 2018 16:18:32 -0000
X-Original-To: like.xu@linux.intel.com
Delivered-To: like.xu@linux.intel.com
Received: from orsmga005.jf.intel.com (orsmga005.jf.intel.com [10.7.209.41])
	(using TLSv1.2 with cipher ECDHE-RSA-AES256-GCM-SHA384 (256/256 bits))
	(No client certificate requested)
	by linux.intel.com (Postfix) with ESMTPS id 0C8DE58049E;
	Sun, 23 Dec 2018 23:56:30 -0800 (PST)
Received: from orsmga106.jf.intel.com ([10.7.208.65])
  by orsmga005-1.jf.intel.com with ESMTP; 23 Dec 2018 23:56:29 -0800
X-SG-BADATTACHMENTNOREPLY: True
IronPort-PHdr: =?us-ascii?q?9a23=3AvG1hEBD1knbp6OEtgnPwUyQJP3N1i/DPJgcQr6Af?=
 =?us-ascii?q?oPdwSP74o8qwAkXT6L1XgUPTWs2DsrQY07qQ6/iocFdDyK7JiGoFfp1IWk1Nou?=
 =?us-ascii?q?QttCtkPvS4D1bmJuXhdS0wEZcKflZk+3amLRodQ56mNBXdrXKo8DEdBAj0OxZr?=
 =?us-ascii?q?KeTpAI7SiNm82/yv95HJbAhEmDmwbaluIBmqsA7cqtQYjYx+J6gr1xDHuGFIe+?=
 =?us-ascii?q?NYxWNpIVKcgRPx7dqu8ZBg7ipdpesv+9ZPXqvmcas4S6dYDCk9PGAu+MLrrxjD?=
 =?us-ascii?q?QhCR6XYaT24bjwBHAwnB7BH9Q5fxri73vfdz1SWGIcH7S60/VDK/5KlpVRDokj?=
 =?us-ascii?q?8KOSMn/mHZisJ+j6xVrxyuqBN934Hab5qVNOJ8c67GYdMXRnBMUtpNWyFPAI6x?=
 =?us-ascii?q?aZYEAeobPeZfqonwv18AogGlBQmrAuPk1z9HiWXw3a01zu8sFgPG0xY7H9IJvn?=
 =?us-ascii?q?XbttP1NKgJXOCv0qbH0DXDYOlK2Tvn9IfIdRUhrOiKULltcsTR0VEiGx3ZgliU?=
 =?us-ascii?q?s4DpIj2Y2voXv2SG7OdsSfijhm8lpg1pvDSj2sMhhpPUio8b1FzI7zh1zYU7KN?=
 =?us-ascii?q?GiVkJ2YtipG4ZKuS6ALYt5WMYiTnlouCkkzr0Gvoa2fDYFyJs53R7Tcf+HfJaS?=
 =?us-ascii?q?4hLlSumRJS10hHV/eLKwnxqy8E6gxfPgVsSszlpGsi5InsPRun0DyRDf8NWLR/?=
 =?us-ascii?q?hh8ku72DuC1Rjf6uReLkA1karbJYQhwrk1lpcLtUTDHyn2mFj5jaOPdUUr5PKo?=
 =?us-ascii?q?6+L5bbXiv5OcMIF1igfgPaQ0gcG/H+s4PRYUX2SB+uSzyqfj/UvnT7VOlPE2lb?=
 =?us-ascii?q?PZsJ/CKcQBuqG5GxNV0pok6xunCzem0dcYkmcdIFNKZRKKlIzpO1DIIPDlAvaz?=
 =?us-ascii?q?mVWskDF3x//YOr3tGInCLn/GkL35Z7Zy91ZcyBYvzdBY/59UCqsOIPPvWkDrs9?=
 =?us-ascii?q?zUFB85MxGuzObhB9VwzYceWWOJAq+EP6Leq16I5uQzI+aSYI8ZoiryK/8g5/T2?=
 =?us-ascii?q?l382hUcdfbW13ZsQcH23BO9mI0WeYXrvmNsBC30FvgglQezuiV2CVyNTZnmoU6?=
 =?us-ascii?q?I94DE7FJypDYPZSo+xh7yB2T+xHodKaWBeFlCMDXDoep2HW/gWbiKeOMthkj0e?=
 =?us-ascii?q?WrinRI8szhWutA78y7p6IevY4CwYtZT/1Ndr4+3fjw099TtxD86FyWGCU3l0nn?=
 =?us-ascii?q?8URz8xxK1wvFZyykmd3qRig/xXD9pT5+hXXQc8MpLcy+96C9X2Wg/aeteJSVCm?=
 =?us-ascii?q?QsipAD0rT9IxxcMObFh5G9m4kh/D2C+qCacPl7OXHJw07r7c33/pKslg0XnGyr?=
 =?us-ascii?q?cug0MmQsRVM22mnbBw9w7ICo7NkkWZkbuqdKsG0C7M8meD0XSBvEVCXAFsVqXF?=
 =?us-ascii?q?WGgVZlHKotTh+kPCU7iuBKw7MgtAzM6CLbdKat3pjFlcWPfvItPeY3i1m2exAx?=
 =?us-ascii?q?aIyaiBbI7re2UbwSXcB1IIkwEV/XaaKwc+Aj2trH7ZDDxrDVjveV/j8fFiqHOn?=
 =?us-ascii?q?SU851xuFb0l/2Lu65BEUheaQROgO3r0ZoighrTZ0HFGj39/ND9qApgxhfLhTYN?=
 =?us-ascii?q?8n4VdH037ZuBJ5PpC6M69igVseeRxtv0zyzxV3FplAkc8yoXIq0Qp+M76X3ElA?=
 =?us-ascii?q?djOYx5/wPLLXJ3L2/BCuba7Wx17f3MyX+qcJ9PQ3tVHjsBu1GUol9nVty8NV3G?=
 =?us-ascii?q?eE5pXWEAoSVor8Ulw29xdmvb7aeDQy54TO2X1qL6a0qD7C18s1C+Q/zhavYslQ?=
 =?us-ascii?q?MLmDFA/0CMAaA8muKOo3m1mmdB4EPeZS9LIqMMOibfeJxKmrPON4ljK8kWtH+J?=
 =?us-ascii?q?x90l6L9ydkSu/I3owJwvGC0gucSjf8ikysssT2mYBCeDETEXCzySniBI5NeKJy?=
 =?us-ascii?q?eZwHBnupI82y3t9+nYLiW2ZE9F6/AFMLwM2pdgCIb1z+3g1Q0l4boWe9liu7zD?=
 =?us-ascii?q?x0kjcpobSZ3CHVx+TidRwHOnNERWV4jFfsJ5S0gM4eXESycwcpkx6l717gx6dH?=
 =?us-ascii?q?vKR/M3XTQUBQcin2NW5iVbG8triDY85J854otSRXUOKhYVGVULL9oh0a0z/9EG?=
 =?us-ascii?q?ta3jw0azaqupDhlRxglG2dNGpzrGbeecxoxhfQ/t3cSeRR3jobXiZ4jzbXC0O4?=
 =?us-ascii?q?P9mo+9WUipjCvvq/V2KnSp1cby3rwZmcuyu84G1gGQe/kOyrmt37DQg61jf219?=
 =?us-ascii?q?xrVSXLthnweIfq2LqhMeJ7YEZoHkTz5NRgGoFxiYYwgJAQ2X4HhpSa53YHkGHz?=
 =?us-ascii?q?MclF1qL6dnYCWTkLw9vN6gj/xEJjNm6Jx57+VniF3sthYNy6bnkX2y0n6cBKFb?=
 =?us-ascii?q?yU7KdFnSZuplq4rATRYeVynzsHyPsu7mIajP8NuAY30iqdBbUSF1FCPSPwjxSI?=
 =?us-ascii?q?88y+rKJPaWm0a7ew005+nc27ALGGvwFRQ3L5epYkHS9t4cRzKlPM0Hvv6o76fN?=
 =?us-ascii?q?ncd84cthqRkx3YlehaNIoxluYWhSpgIW/9v2cqy+slghx1x526oJKLK2Zw/KK6?=
 =?us-ascii?q?Hx5YMCf6Z9gI9zHpjKZemNuW3o+1EpVgHDULQIXnTfayHD0OsvTnMh6EECcgpX?=
 =?us-ascii?q?eDBbrfAQif5V9mrnLIDpCrLmyXK2Mfzdl4XxmdI0pfgA8PUTU+n545EB2qxcP7?=
 =?us-ascii?q?fEd44DAR+kD3qh9Wxu10MBn/V3/VpB20ZTcsVJifMB1W4xlC50jLMMye7eFzHy?=
 =?us-ascii?q?BC8p2itgyNLWObaBpSDWEUQUyJHFTjPrio5dnd/OmUHOu+L/3SYbqQrexSTeuH?=
 =?us-ascii?q?xZWq0oF+5TaDKt2PPmV+D/08wkdMR215FN/DmzoRSy0bjSbNb8+AqRe4+y13qN?=
 =?us-ascii?q?2/8fvxVALu44uPF6VdMdF19x+qhqeDMvaahDxlJjZAypMM2XjIxaAD3F4TjiFi?=
 =?us-ascii?q?bSWiHa4cui7NUq3QnLRaDxoaayN1KctJ4Lgw3ghLOc7HlNz10qR0geIyC1dATV?=
 =?us-ascii?q?bhgN2mZdQWI2GhM1PKHEaKO66AJT3OwsH3Z7uzSLxQjOpOsR2wti2WE0viPjSF?=
 =?us-ascii?q?ijnoWAqjMeBKjCGHIhNevJuxfQpqCWjmH5rabUjxFd58jTQ7xfUPwDv2Lm8GMj?=
 =?us-ascii?q?l6OQsZq6aMxTlVjvV2BypK6X8zfseenCPMzeDDLZBejvJtDWwgletB52szzbR9?=
 =?us-ascii?q?9ixIRPVp3iDVq4g98BmdjuCTx28/A1J1oTFRidfTsA=3D=3D?=
X-IronPort-Anti-Spam-Filtered: true
X-IronPort-Anti-Spam-Result: =?us-ascii?q?A0ADAAAIkCBch0O0hNFbCBkBAQEBAQEBA?=
 =?us-ascii?q?QEBAQEHAQEBAQEBgVIDAQEBAQELAYNrFBODfoh4jHotFJdPgXMVGBMBgUuFZyI?=
 =?us-ascii?q?1CA0BAwEBAQEBAQIBEwEBAQoLCQgpL4I6IoJuAQEBAQIBAQIgBAsBBTQKAwYJA?=
 =?us-ascii?q?QEIAhgCAiYCAgNUBgoDBgIBAQGDHYF6CAWLcZtdfDOFQIRegQuLNBeBQD+BESe?=
 =?us-ascii?q?BbX6EOyGDLYJXApBihUaLIwmRYwYYiXsRh1qaKYFIAYILMxoIGxWDJ4InFxKOG?=
 =?us-ascii?q?DIBATGBBQEBHItdDRcHgiABAQ?=
X-IPAS-Result: =?us-ascii?q?A0ADAAAIkCBch0O0hNFbCBkBAQEBAQEBAQEBAQEHAQEBAQE?=
 =?us-ascii?q?BgVIDAQEBAQELAYNrFBODfoh4jHotFJdPgXMVGBMBgUuFZyI1CA0BAwEBAQEBA?=
 =?us-ascii?q?QIBEwEBAQoLCQgpL4I6IoJuAQEBAQIBAQIgBAsBBTQKAwYJAQEIAhgCAiYCAgN?=
 =?us-ascii?q?UBgoDBgIBAQGDHYF6CAWLcZtdfDOFQIRegQuLNBeBQD+BESeBbX6EOyGDLYJXA?=
 =?us-ascii?q?pBihUaLIwmRYwYYiXsRh1qaKYFIAYILMxoIGxWDJ4InFxKOGDIBATGBBQEBHIt?=
 =?us-ascii?q?dDRcHgiABAQ?=
X-IronPort-AV: E=Sophos;i="5.56,391,1539673200"; 
   d="scan'208";a="45205193"
X-Amp-Result: SKIPPED(no attachment in message)
X-Amp-File-Uploaded: False
Received: from vger.kernel.org ([209.132.180.67])
  by mtab.intel.com with ESMTP; 23 Dec 2018 23:56:28 -0800
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
        id S1726807AbeLXHxZ (ORCPT <rfc822;like.xu@linux.intel.com>
        + 22 others); Mon, 24 Dec 2018 02:53:25 -0500
Received: from mx1.redhat.com ([209.132.183.28]:50434 "EHLO mx1.redhat.com"
        rhost-flags-OK-OK-OK-OK) by vger.kernel.org with ESMTP
        id S1726733AbeLXHxZ (ORCPT <rfc822;linux-kernel@vger.kernel.org>);
        Mon, 24 Dec 2018 02:53:25 -0500
Received: from smtp.corp.redhat.com (int-mx07.intmail.prod.int.phx2.redhat.com [10.5.11.22])
        (using TLSv1.2 with cipher AECDH-AES256-SHA (256/256 bits))
        (No client certificate requested)
        by mx1.redhat.com (Postfix) with ESMTPS id F0E6F88304;
        Mon, 24 Dec 2018 07:53:24 +0000 (UTC)
Received: from [10.72.12.206] (ovpn-12-206.pek2.redhat.com [10.72.12.206])
        by smtp.corp.redhat.com (Postfix) with ESMTPS id B84291001942;
        Mon, 24 Dec 2018 07:53:20 +0000 (UTC)
Subject: Re: [PATCH net-next 3/3] vhost: access vq metadata through kernel
 virtual address
To: "Michael S. Tsirkin" <mst@redhat.com>
Cc: kvm@vger.kernel.org, virtualization@lists.linux-foundation.org,
        netdev@vger.kernel.org, linux-kernel@vger.kernel.org
References: <20181213101022.12475-1-jasowang@redhat.com>
 <20181213101022.12475-4-jasowang@redhat.com>
 <20181213102713-mutt-send-email-mst@kernel.org>
 <d70c5ac1-c805-cefd-ace1-643a2e271ba0@redhat.com>
 <20181214073332-mutt-send-email-mst@kernel.org>
From: Jason Wang <jasowang@redhat.com>
Message-ID: <2ea274df-a79a-250f-648f-12927529d78a@redhat.com>
Date: Mon, 24 Dec 2018 15:53:16 +0800
User-Agent: Mozilla/5.0 (X11; Linux x86_64; rv:60.0) Gecko/20100101
 Thunderbird/60.2.1
MIME-Version: 1.0
In-Reply-To: <20181214073332-mutt-send-email-mst@kernel.org>
Content-Type: text/plain; charset=utf-8; format=flowed
Content-Transfer-Encoding: 8bit
Content-Language: en-US
X-Scanned-By: MIMEDefang 2.84 on 10.5.11.22
X-Greylist: Sender IP whitelisted, not delayed by milter-greylist-4.5.16 (mx1.redhat.com [10.5.110.28]); Mon, 24 Dec 2018 07:53:25 +0000 (UTC)
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: <linux-kernel.vger.kernel.org>
X-Mailing-List: linux-kernel@vger.kernel.org


On 2018/12/14 下午8:36, Michael S. Tsirkin wrote:
> On Fri, Dec 14, 2018 at 11:57:35AM +0800, Jason Wang wrote:
>> On 2018/12/13 下午11:44, Michael S. Tsirkin wrote:
>>> On Thu, Dec 13, 2018 at 06:10:22PM +0800, Jason Wang wrote:
>>>> It was noticed that the copy_user() friends that was used to access
>>>> virtqueue metdata tends to be very expensive for dataplane
>>>> implementation like vhost since it involves lots of software check,
>>>> speculation barrier, hardware feature toggling (e.g SMAP). The
>>>> extra cost will be more obvious when transferring small packets.
>>>>
>>>> This patch tries to eliminate those overhead by pin vq metadata pages
>>>> and access them through vmap(). During SET_VRING_ADDR, we will setup
>>>> those mappings and memory accessors are modified to use pointers to
>>>> access the metadata directly.
>>>>
>>>> Note, this was only done when device IOTLB is not enabled. We could
>>>> use similar method to optimize it in the future.
>>>>
>>>> Tests shows about ~24% improvement on TX PPS when using virtio-user +
>>>> vhost_net + xdp1 on TAP (CONFIG_HARDENED_USERCOPY is not enabled):
>>>>
>>>> Before: ~5.0Mpps
>>>> After:  ~6.1Mpps
>>>>
>>>> Signed-off-by: Jason Wang<jasowang@redhat.com>
>>>> ---
>>>>    drivers/vhost/vhost.c | 178 ++++++++++++++++++++++++++++++++++++++++++
>>>>    drivers/vhost/vhost.h |  11 +++
>>>>    2 files changed, 189 insertions(+)
>>>>
>>>> diff --git a/drivers/vhost/vhost.c b/drivers/vhost/vhost.c
>>>> index bafe39d2e637..1bd24203afb6 100644
>>>> --- a/drivers/vhost/vhost.c
>>>> +++ b/drivers/vhost/vhost.c
>>>> @@ -443,6 +443,9 @@ void vhost_dev_init(struct vhost_dev *dev,
>>>>    		vq->indirect = NULL;
>>>>    		vq->heads = NULL;
>>>>    		vq->dev = dev;
>>>> +		memset(&vq->avail_ring, 0, sizeof(vq->avail_ring));
>>>> +		memset(&vq->used_ring, 0, sizeof(vq->used_ring));
>>>> +		memset(&vq->desc_ring, 0, sizeof(vq->desc_ring));
>>>>    		mutex_init(&vq->mutex);
>>>>    		vhost_vq_reset(dev, vq);
>>>>    		if (vq->handle_kick)
>>>> @@ -614,6 +617,102 @@ static void vhost_clear_msg(struct vhost_dev *dev)
>>>>    	spin_unlock(&dev->iotlb_lock);
>>>>    }
>>>> +static int vhost_init_vmap(struct vhost_vmap *map, unsigned long uaddr,
>>>> +			   size_t size, int write)
>>>> +{
>>>> +	struct page **pages;
>>>> +	int npages = DIV_ROUND_UP(size, PAGE_SIZE);
>>>> +	int npinned;
>>>> +	void *vaddr;
>>>> +
>>>> +	pages = kmalloc_array(npages, sizeof(struct page *), GFP_KERNEL);
>>>> +	if (!pages)
>>>> +		return -ENOMEM;
>>>> +
>>>> +	npinned = get_user_pages_fast(uaddr, npages, write, pages);
>>>> +	if (npinned != npages)
>>>> +		goto err;
>>>> +
>>> As I said I have doubts about the whole approach, but this
>>> implementation in particular isn't a good idea
>>> as it keeps the page around forever.


The pages wil be released during set features.


>>> So no THP, no NUMA rebalancing,


For THP, we will probably miss 2 or 4 pages, but does this really matter 
consider the gain we have? For NUMA rebalancing, I'm even not quite sure 
if it can helps for the case of IPC (vhost). It looks to me the worst 
case it may cause page to be thrash between nodes if vhost and userspace 
are running in two nodes.


>>
>> This is the price of all GUP users not only vhost itself.
> Yes. GUP is just not a great interface for vhost to use.


Zerocopy codes (enabled by defualt) use them for years.


>
>> What's more
>> important, the goal is not to be left too much behind for other backends
>> like DPDK or AF_XDP (all of which are using GUP).
>
> So these guys assume userspace knows what it's doing.
> We can't assume that.


What kind of assumption do you they have?


>
>>> userspace-controlled
>>> amount of memory locked up and not accounted for.
>>
>> It's pretty easy to add this since the slow path was still kept. If we
>> exceeds the limitation, we can switch back to slow path.
>>
>>> Don't get me wrong it's a great patch in an ideal world.
>>> But then in an ideal world no barriers smap etc are necessary at all.
>>
>> Again, this is only for metadata accessing not the data which has been used
>> for years for real use cases.
>>
>> For SMAP, it makes senses for the address that kernel can not forcast. But
>> it's not the case for the vhost metadata since we know the address will be
>> accessed very frequently. For speculation barrier, it helps nothing for the
>> data path of vhost which is a kthread.
> I don't see how a kthread makes any difference. We do have a validation
> step which makes some difference.


The problem is not kthread but the address of userspace address. The 
addresses of vq metadata tends to be consistent for a while, and vhost 
knows they will be frequently. SMAP doesn't help too much in this case.

Thanks.


>
>> Packet or AF_XDP benefit from
>> accessing metadata directly, we should do it as well.
>>
>> Thanks
