Return-Path: <linux-kernel-owner@vger.kernel.org>
Delivered-To: unknown
Received: from linux.intel.com (10.54.29.200:995) by likexu-workstation with
  POP3-SSL; 06 Dec 2018 09:00:54 -0000
X-Original-To: like.xu@linux.intel.com
Delivered-To: like.xu@linux.intel.com
Received: from fmsmga007.fm.intel.com (fmsmga007.fm.intel.com [10.253.24.52])
	(using TLSv1.2 with cipher ECDHE-RSA-AES256-GCM-SHA384 (256/256 bits))
	(No client certificate requested)
	by linux.intel.com (Postfix) with ESMTPS id 0745A5804C1;
	Wed,  5 Dec 2018 15:50:52 -0800 (PST)
Received: from fmsmga105.fm.intel.com ([10.1.193.10])
  by fmsmga007-1.fm.intel.com with ESMTP/TLS/DHE-RSA-AES256-GCM-SHA384; 05 Dec 2018 15:50:51 -0800
X-SG-BADATTACHMENTNOREPLY: True
IronPort-PHdr: =?us-ascii?q?9a23=3AFK+t1BIGwIQq2rltw9mcpTZWNBhigK39O0sv0rFi?=
 =?us-ascii?q?tYgULvj9rarrMEGX3/hxlliBBdydt6oUzbKO+4nbGkU4qa6bt34DdJEeHzQksu?=
 =?us-ascii?q?4x2zIaPcieFEfgJ+TrZSFpVO5LVVti4m3peRMNQJW2aFLduGC94iAPERvjKwV1?=
 =?us-ascii?q?Ov71GonPhMiryuy+4ZLebxlLiTanfb9+MAi9oBnMuMURnYZsMLs6xAHTontPde?=
 =?us-ascii?q?RWxGdoKkyWkh3h+Mq+/4Nt/jpJtf45+MFOTav1f6IjTbxFFzsmKHw65NfqtRbY?=
 =?us-ascii?q?UwSC4GYXX3gMnRpJBwjF6wz6Xov0vyDnuOdxxDWWMMvrRr0vRz+s87lkRwPpiC?=
 =?us-ascii?q?cfNj427mfXitBrjKlGpB6tvgFzz5LIbI2QMvd1Y6HTcs4ARWdZXcheWSJPDIOi?=
 =?us-ascii?q?YYUSAeoOMvpXr5Llp1YMtha+GRWgCe3zxjNUnHL736s32PkhHwHc2wwgGsoDvm?=
 =?us-ascii?q?nIrNrrKqcdT+a1x7TUwzXEdPNWxSny55XUchs8pvyMR7VwcdHNyUYxCgzFkk6d?=
 =?us-ascii?q?qYPiPzOSy+sNtmmb7/F6WeKokW4npBh8rz6yzckvkonEnpwZxkzA+Clj3Yo4K8?=
 =?us-ascii?q?O0RFRmbdOnDJdcrSCXOoluTs4jQmxkojg2x7IctZO7fSUG0pYqyh3ZZveaaYaH?=
 =?us-ascii?q?+AjjW/yUITpghHJqZra/hxGq/Ei+xe3zSNO03ExJriVbiNnMsG4C1xjJ5siAUP?=
 =?us-ascii?q?t98V+t2TeJ1w/N9uFJOV44mbbfJpI737I9mIQfvV7eEiL1hEn6lq6be0c89uit?=
 =?us-ascii?q?8evnY7HmppGGN49zjwHzKqAums25AeQlPQkCRmub9vqm1L3l40L5RKxGjvo4k6?=
 =?us-ascii?q?nfrp/aP98WprC2AwBLyIYv8RW/ACm80NQeg3YHKEhJeBWdj4jmI13OOuz3De+j?=
 =?us-ascii?q?g1Swlzdm3/TGPrziAprTNHTCn6rhcK15605dzgoz0N9e64hVCrEHPPL8REvxuM?=
 =?us-ascii?q?bEAR8+Ngy+2/znB8ll1oMCRWKPBbeUMKPIvl+J+uIgOe6MaJUVuDbgMfcl4fHu?=
 =?us-ascii?q?gGQ9mV8ce6mpwJQWZGq5HvRgP0WWf37sjs0dHmcNuwo0VPbqh0GaUT5Pe3ayWL?=
 =?us-ascii?q?ox5jM8CI24F4vDRYetgLqH3Ce8BZBWYmFGClaREXbnbYmEWvEMaD6MLc9liDAL?=
 =?us-ascii?q?Sb+hS4o53xG0qAD606ZnLvbT+iAAr53jz9h15+rQlR0o7zx7Fcad3nqJT2F1mG?=
 =?us-ascii?q?MIWjA30Lp+oUx71leMz6x4j+ZEGtxU4vNDSh06OoLEz+xmF9DyXRrMftSTR1ag?=
 =?us-ascii?q?WNmmBTAxQcg3w98BeEt9H9Sijhbe3yulGbMVlrqLBIAq/aLYxXT+O8F9y3Pe3q?=
 =?us-ascii?q?k7k1YmWtdPNXGhhqNn6gfcHZDJnFuDm6aqb6sc2jXN+3mFzWaJuEFYUwtwUaHe?=
 =?us-ascii?q?UHAbZ0vWq8n550zYQ7+vD7QnLhVOycqYJqRWbd3piE1MRO3/N9TGf2Kxh2CwCA?=
 =?us-ascii?q?6VybyWcorlZX8R3CXHB0gCiAAc43CGOBM6BiegpWLeETNvGUjuY0Pq7elxtne7?=
 =?us-ascii?q?QlUowAGNak1rz6C19QINhfyAV/MT2aoJuDsgqzVxG1a9w9LWCtqaqwp9ZqlcZs?=
 =?us-ascii?q?k94FNG1WLfuAxwJZigL6Fkhl4DfAV7pULu1xNrCopelcgmtm8lzA13KaiAylNO?=
 =?us-ascii?q?ayuY3YzsOr3QMmT95hSvZLDZ217A0Nea4LwA6OklpFr5ugGpFU0i82t83tlR0n?=
 =?us-ascii?q?uc4IjKDQUIXZLwVEY36wZ1p7XAbiYh4IPU0GVmMbOovT/ax9IpGOwlxw6gftdC?=
 =?us-ascii?q?Kq+LCBX+EswaB8e0LuwqlEOkbhYFPOBU6a41MNmqd/qA2K63IulgmCiqgnhA4I?=
 =?us-ascii?q?B4ykiM7TZzSvbU35YZxPGVxhGHVzbgg1i7qMD4hIdEaSsUHmWh0yjkBZddabFo?=
 =?us-ascii?q?coYPFGihPde3xtJ4h5P2X35Y9VijB04J2cOzeBqSaUD90hNU1UgNvXOnni64xS?=
 =?us-ascii?q?Rukz41tqqfwDDOw+P6eRsHO25HXmljgU33IYipidAXR0yobwkvlBu46kf23alb?=
 =?us-ascii?q?pKJjL2bNRUdEZTT5L2ZnUqGorLqNf9ZP6I80sSVQSOm8Y0qVSqT+oxsZ1CPvBX?=
 =?us-ascii?q?Beyyo4dzGpu5X5mQJ1iGSGIXZ3rXrZf9xwxBjF6NzdQ/5RwiQJRC1ihTbLAVi8?=
 =?us-ascii?q?OsGj/c+ImJfbruC+S2WhW4VTcCbxyoOMrim75WxsARCkm/Czm9vnERU10CPh1t?=
 =?us-ascii?q?lqUznIowj4YoXxy6u6NudndFFyBFDg88p6Bp1+kowoiZETw3cah4+Z/XoakWjp?=
 =?us-ascii?q?N9Vb1rnzbH4MRT4N3t7U7xLp2ExlLnKV2Y35Um+RzddmZ9m/emkWwD4y79hWCK?=
 =?us-ascii?q?eI67xJhS51olu7rQ3Le/R8kCkSyeAy6HEEmeEGoxQizj+SAr0JGUlYPCrslwmH?=
 =?us-ascii?q?7tykraVXYnqvfqa01EZkgd+hC7SCqBlGWHnlYpciATNw7sJnPVLQ133z75voed?=
 =?us-ascii?q?jKYtIVqx2UiAzAj+lOJZI1l/oKgzdnOG3nsX0kze47kQJh3ZWgsIebLGVt+bqz?=
 =?us-ascii?q?AgREOT3te8MT5jbtgL5FkcmM2ICvGohhFi8PXJv1Vv+oFDMStfL6NweBCjE8q3?=
 =?us-ascii?q?GbGabBEg+b8ktps3XPE5WzPXGNOHYZ1cliRAWaJEFHggAbRjA6kYAiFgyw2Mzt?=
 =?us-ascii?q?akR55i0S5l7lrBtD0PloOgL7Umfeogeodzg1RIKeLBpQ8gFN+UPVPdaC4eJ0Gi?=
 =?us-ascii?q?FS5oehoxCVKmyHewRICnkEW0yDB1D+J7mu+MPP8+6CCuqlKPvOZ7qOpPdaV/eJ?=
 =?us-ascii?q?w5Kvz4Rn8yyNNsWJInltEfk71lBfUnB+HsTTgy8PRDAPlyLRc86bow+x+i1poc?=
 =?us-ascii?q?C+8/TrWwPv6ZGMC7tINtVv9A65gb2eN+6Lnyt5LTdY1pURxX7H0rQf3VgSiz1w?=
 =?us-ascii?q?eDmpC7gPqSnNTKfIkK9NExEbcz9zNNdP768kxAZNJNXUisnr2b94lPI1D1ZFWE?=
 =?us-ascii?q?flmsGoY8wKPm68OEnGBEaNKLSJOznLz9vrbqO7TL1alP9UuAGouTaHD0/jOSyO?=
 =?us-ascii?q?lyXoVxCqK+1DkDuXMwBeuI6jdBZgEmzjTNPgah2mP957lzw2wbsohnzUMW4QKy?=
 =?us-ascii?q?Rzc0RIrreI9yNXnu1/G3Bd7npiNeSFmzyW7+/dKpYXt/tkGiV1l+JA73Q8xLtY?=
 =?us-ascii?q?9yVERP1zmCvPod9iuVCmku+TyjV5VBpCsCpEhIWOvRYqBaKM8phGRGaB/x8X62?=
 =?us-ascii?q?iUIwoFqsEjCdD1va1UjN/Vm/HdMjBHpunI8NURAYDuL9mbPXY9eU7zHyXIAQcZ?=
 =?us-ascii?q?ZTGsMm3ahlcbl+udoC7G5qMmo4ThzcJdAoRQU0Y4Q7ZDUhxo?=
X-IronPort-Anti-Spam-Filtered: true
X-IronPort-Anti-Spam-Result: =?us-ascii?q?A0ANAABqYwhch0O0hNFkHAEBAQQBAQcEA?=
 =?us-ascii?q?QGBUQcBAQsBg2sng3mIGV+LLoINFGiIFo46FIFbGBgTAYdTIjQJDQEDAQEBAQE?=
 =?us-ascii?q?BAgETAQEBCA0JCCkvgjYkAYJiAwMBAiAEUgYJAQEfBQIFEw4CAgMMEhsKERkFg?=
 =?us-ascii?q?xyBagMVBaYTfAwnhUGCRA2CHIELhymDaheBf4ERgl0HgwWBb4M/gjUiAokzgW+?=
 =?us-ascii?q?FD493LgmOFIMjI4FbiDuHGYoMhHOJf4FGbIEhMxoIKAiDJ4InFxKOKSIygQUBA?=
 =?us-ascii?q?YpSAQE?=
X-IPAS-Result: =?us-ascii?q?A0ANAABqYwhch0O0hNFkHAEBAQQBAQcEAQGBUQcBAQsBg2s?=
 =?us-ascii?q?ng3mIGV+LLoINFGiIFo46FIFbGBgTAYdTIjQJDQEDAQEBAQEBAgETAQEBCA0JC?=
 =?us-ascii?q?CkvgjYkAYJiAwMBAiAEUgYJAQEfBQIFEw4CAgMMEhsKERkFgxyBagMVBaYTfAw?=
 =?us-ascii?q?nhUGCRA2CHIELhymDaheBf4ERgl0HgwWBb4M/gjUiAokzgW+FD493LgmOFIMjI?=
 =?us-ascii?q?4FbiDuHGYoMhHOJf4FGbIEhMxoIKAiDJ4InFxKOKSIygQUBAYpSAQE?=
X-IronPort-AV: E=Sophos;i="5.56,320,1539673200"; 
   d="scan'208";a="140962752"
X-Amp-Result: SKIPPED(no attachment in message)
X-Amp-File-Uploaded: False
Received: from vger.kernel.org ([209.132.180.67])
  by mtab.intel.com with ESMTP; 05 Dec 2018 15:50:50 -0800
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
        id S1729064AbeLEXu2 (ORCPT <rfc822;like.xu@linux.intel.com>
        + 23 others); Wed, 5 Dec 2018 18:50:28 -0500
Received: from mail.kernel.org ([198.145.29.99]:58320 "EHLO mail.kernel.org"
        rhost-flags-OK-OK-OK-OK) by vger.kernel.org with ESMTP
        id S1728731AbeLEXsb (ORCPT <rfc822;linux-kernel@vger.kernel.org>);
        Wed, 5 Dec 2018 18:48:31 -0500
Received: from gandalf.local.home (cpe-66-24-56-78.stny.res.rr.com [66.24.56.78])
        (using TLSv1.2 with cipher ECDHE-RSA-AES256-GCM-SHA384 (256/256 bits))
        (No client certificate requested)
        by mail.kernel.org (Postfix) with ESMTPSA id EA5B321527;
        Wed,  5 Dec 2018 23:48:29 +0000 (UTC)
Received: from rostedt by gandalf.local.home with local (Exim 4.91)
        (envelope-from <rostedt@goodmis.org>)
        id 1gUgu4-00007B-Vv; Wed, 05 Dec 2018 18:48:28 -0500
Message-Id: <20181205234828.889332707@goodmis.org>
User-Agent: quilt/0.65
Date: Wed, 05 Dec 2018 18:47:52 -0500
From: Steven Rostedt <rostedt@goodmis.org>
To: linux-kernel@vger.kernel.org
Cc: Ingo Molnar <mingo@kernel.org>,
        Andrew Morton <akpm@linux-foundation.org>,
        Namhyung Kim <namhyung@kernel.org>,
        Masami Hiramatsu <mhiramat@kernel.org>,
        Tom Zanussi <zanussi@kernel.org>,
        Ravi Bangoria <ravi.bangoria@linux.vnet.ibm.com>,
        "Joel Fernandes (Google)" <joel@joelfernandes.org>
Subject: [for-next][PATCH 03/30] fgraph: Create a fgraph.c file to store function graph infrastructure
References: <20181205234749.372720574@goodmis.org>
MIME-Version: 1.0
Content-Type: text/plain; charset=UTF-8
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: <linux-kernel.vger.kernel.org>
X-Mailing-List: linux-kernel@vger.kernel.org

From: "Steven Rostedt (VMware)" <rostedt@goodmis.org>

As the function graph infrastructure can be used by thing other than
tracing, moving the code to its own file out of the trace_functions_graph.c
code makes more sense.

The fgraph.c file will only contain the infrastructure required to hook into
functions and their return code.

Reviewed-by: Joel Fernandes (Google) <joel@joelfernandes.org>
Signed-off-by: Steven Rostedt (VMware) <rostedt@goodmis.org>
---
 kernel/trace/Makefile                |   1 +
 kernel/trace/fgraph.c                | 232 +++++++++++++++++++++++++++
 kernel/trace/trace_functions_graph.c | 220 -------------------------
 3 files changed, 233 insertions(+), 220 deletions(-)
 create mode 100644 kernel/trace/fgraph.c

diff --git a/kernel/trace/Makefile b/kernel/trace/Makefile
index f81dadbc7c4a..c7ade7965464 100644
--- a/kernel/trace/Makefile
+++ b/kernel/trace/Makefile
@@ -57,6 +57,7 @@ obj-$(CONFIG_MMIOTRACE) += trace_mmiotrace.o
 obj-$(CONFIG_FUNCTION_GRAPH_TRACER) += trace_functions_graph.o
 obj-$(CONFIG_TRACE_BRANCH_PROFILING) += trace_branch.o
 obj-$(CONFIG_BLK_DEV_IO_TRACE) += blktrace.o
+obj-$(CONFIG_FUNCTION_GRAPH_TRACER) += fgraph.o
 ifeq ($(CONFIG_BLOCK),y)
 obj-$(CONFIG_EVENT_TRACING) += blktrace.o
 endif
diff --git a/kernel/trace/fgraph.c b/kernel/trace/fgraph.c
new file mode 100644
index 000000000000..5ad9c0e88b80
--- /dev/null
+++ b/kernel/trace/fgraph.c
@@ -0,0 +1,232 @@
+// SPDX-License-Identifier: GPL-2.0
+/*
+ * Infrastructure to took into function calls and returns.
+ * Copyright (c) 2008-2009 Frederic Weisbecker <fweisbec@gmail.com>
+ * Mostly borrowed from function tracer which
+ * is Copyright (c) Steven Rostedt <srostedt@redhat.com>
+ *
+ * Highly modified by Steven Rostedt (VMware).
+ */
+#include <linux/ftrace.h>
+
+#include "trace.h"
+
+static bool kill_ftrace_graph;
+
+/**
+ * ftrace_graph_is_dead - returns true if ftrace_graph_stop() was called
+ *
+ * ftrace_graph_stop() is called when a severe error is detected in
+ * the function graph tracing. This function is called by the critical
+ * paths of function graph to keep those paths from doing any more harm.
+ */
+bool ftrace_graph_is_dead(void)
+{
+	return kill_ftrace_graph;
+}
+
+/**
+ * ftrace_graph_stop - set to permanently disable function graph tracincg
+ *
+ * In case of an error int function graph tracing, this is called
+ * to try to keep function graph tracing from causing any more harm.
+ * Usually this is pretty severe and this is called to try to at least
+ * get a warning out to the user.
+ */
+void ftrace_graph_stop(void)
+{
+	kill_ftrace_graph = true;
+}
+
+/* Add a function return address to the trace stack on thread info.*/
+static int
+ftrace_push_return_trace(unsigned long ret, unsigned long func,
+			 unsigned long frame_pointer, unsigned long *retp)
+{
+	unsigned long long calltime;
+	int index;
+
+	if (unlikely(ftrace_graph_is_dead()))
+		return -EBUSY;
+
+	if (!current->ret_stack)
+		return -EBUSY;
+
+	/*
+	 * We must make sure the ret_stack is tested before we read
+	 * anything else.
+	 */
+	smp_rmb();
+
+	/* The return trace stack is full */
+	if (current->curr_ret_stack == FTRACE_RETFUNC_DEPTH - 1) {
+		atomic_inc(&current->trace_overrun);
+		return -EBUSY;
+	}
+
+	/*
+	 * The curr_ret_stack is an index to ftrace return stack of
+	 * current task.  Its value should be in [0, FTRACE_RETFUNC_
+	 * DEPTH) when the function graph tracer is used.  To support
+	 * filtering out specific functions, it makes the index
+	 * negative by subtracting huge value (FTRACE_NOTRACE_DEPTH)
+	 * so when it sees a negative index the ftrace will ignore
+	 * the record.  And the index gets recovered when returning
+	 * from the filtered function by adding the FTRACE_NOTRACE_
+	 * DEPTH and then it'll continue to record functions normally.
+	 *
+	 * The curr_ret_stack is initialized to -1 and get increased
+	 * in this function.  So it can be less than -1 only if it was
+	 * filtered out via ftrace_graph_notrace_addr() which can be
+	 * set from set_graph_notrace file in tracefs by user.
+	 */
+	if (current->curr_ret_stack < -1)
+		return -EBUSY;
+
+	calltime = trace_clock_local();
+
+	index = ++current->curr_ret_stack;
+	if (ftrace_graph_notrace_addr(func))
+		current->curr_ret_stack -= FTRACE_NOTRACE_DEPTH;
+	barrier();
+	current->ret_stack[index].ret = ret;
+	current->ret_stack[index].func = func;
+	current->ret_stack[index].calltime = calltime;
+#ifdef HAVE_FUNCTION_GRAPH_FP_TEST
+	current->ret_stack[index].fp = frame_pointer;
+#endif
+#ifdef HAVE_FUNCTION_GRAPH_RET_ADDR_PTR
+	current->ret_stack[index].retp = retp;
+#endif
+	return 0;
+}
+
+int function_graph_enter(unsigned long ret, unsigned long func,
+			 unsigned long frame_pointer, unsigned long *retp)
+{
+	struct ftrace_graph_ent trace;
+
+	trace.func = func;
+	trace.depth = ++current->curr_ret_depth;
+
+	if (ftrace_push_return_trace(ret, func, frame_pointer, retp))
+		goto out;
+
+	/* Only trace if the calling function expects to */
+	if (!ftrace_graph_entry(&trace))
+		goto out_ret;
+
+	return 0;
+ out_ret:
+	current->curr_ret_stack--;
+ out:
+	current->curr_ret_depth--;
+	return -EBUSY;
+}
+
+/* Retrieve a function return address to the trace stack on thread info.*/
+static void
+ftrace_pop_return_trace(struct ftrace_graph_ret *trace, unsigned long *ret,
+			unsigned long frame_pointer)
+{
+	int index;
+
+	index = current->curr_ret_stack;
+
+	/*
+	 * A negative index here means that it's just returned from a
+	 * notrace'd function.  Recover index to get an original
+	 * return address.  See ftrace_push_return_trace().
+	 *
+	 * TODO: Need to check whether the stack gets corrupted.
+	 */
+	if (index < 0)
+		index += FTRACE_NOTRACE_DEPTH;
+
+	if (unlikely(index < 0 || index >= FTRACE_RETFUNC_DEPTH)) {
+		ftrace_graph_stop();
+		WARN_ON(1);
+		/* Might as well panic, otherwise we have no where to go */
+		*ret = (unsigned long)panic;
+		return;
+	}
+
+#ifdef HAVE_FUNCTION_GRAPH_FP_TEST
+	/*
+	 * The arch may choose to record the frame pointer used
+	 * and check it here to make sure that it is what we expect it
+	 * to be. If gcc does not set the place holder of the return
+	 * address in the frame pointer, and does a copy instead, then
+	 * the function graph trace will fail. This test detects this
+	 * case.
+	 *
+	 * Currently, x86_32 with optimize for size (-Os) makes the latest
+	 * gcc do the above.
+	 *
+	 * Note, -mfentry does not use frame pointers, and this test
+	 *  is not needed if CC_USING_FENTRY is set.
+	 */
+	if (unlikely(current->ret_stack[index].fp != frame_pointer)) {
+		ftrace_graph_stop();
+		WARN(1, "Bad frame pointer: expected %lx, received %lx\n"
+		     "  from func %ps return to %lx\n",
+		     current->ret_stack[index].fp,
+		     frame_pointer,
+		     (void *)current->ret_stack[index].func,
+		     current->ret_stack[index].ret);
+		*ret = (unsigned long)panic;
+		return;
+	}
+#endif
+
+	*ret = current->ret_stack[index].ret;
+	trace->func = current->ret_stack[index].func;
+	trace->calltime = current->ret_stack[index].calltime;
+	trace->overrun = atomic_read(&current->trace_overrun);
+	trace->depth = current->curr_ret_depth--;
+	/*
+	 * We still want to trace interrupts coming in if
+	 * max_depth is set to 1. Make sure the decrement is
+	 * seen before ftrace_graph_return.
+	 */
+	barrier();
+}
+
+/*
+ * Send the trace to the ring-buffer.
+ * @return the original return address.
+ */
+unsigned long ftrace_return_to_handler(unsigned long frame_pointer)
+{
+	struct ftrace_graph_ret trace;
+	unsigned long ret;
+
+	ftrace_pop_return_trace(&trace, &ret, frame_pointer);
+	trace.rettime = trace_clock_local();
+	ftrace_graph_return(&trace);
+	/*
+	 * The ftrace_graph_return() may still access the current
+	 * ret_stack structure, we need to make sure the update of
+	 * curr_ret_stack is after that.
+	 */
+	barrier();
+	current->curr_ret_stack--;
+	/*
+	 * The curr_ret_stack can be less than -1 only if it was
+	 * filtered out and it's about to return from the function.
+	 * Recover the index and continue to trace normal functions.
+	 */
+	if (current->curr_ret_stack < -1) {
+		current->curr_ret_stack += FTRACE_NOTRACE_DEPTH;
+		return ret;
+	}
+
+	if (unlikely(!ret)) {
+		ftrace_graph_stop();
+		WARN_ON(1);
+		/* Might as well panic. What else to do? */
+		ret = (unsigned long)panic;
+	}
+
+	return ret;
+}
diff --git a/kernel/trace/trace_functions_graph.c b/kernel/trace/trace_functions_graph.c
index 0d235e44d08e..b846d82c2f95 100644
--- a/kernel/trace/trace_functions_graph.c
+++ b/kernel/trace/trace_functions_graph.c
@@ -16,33 +16,6 @@
 #include "trace.h"
 #include "trace_output.h"
 
-static bool kill_ftrace_graph;
-
-/**
- * ftrace_graph_is_dead - returns true if ftrace_graph_stop() was called
- *
- * ftrace_graph_stop() is called when a severe error is detected in
- * the function graph tracing. This function is called by the critical
- * paths of function graph to keep those paths from doing any more harm.
- */
-bool ftrace_graph_is_dead(void)
-{
-	return kill_ftrace_graph;
-}
-
-/**
- * ftrace_graph_stop - set to permanently disable function graph tracincg
- *
- * In case of an error int function graph tracing, this is called
- * to try to keep function graph tracing from causing any more harm.
- * Usually this is pretty severe and this is called to try to at least
- * get a warning out to the user.
- */
-void ftrace_graph_stop(void)
-{
-	kill_ftrace_graph = true;
-}
-
 /* When set, irq functions will be ignored */
 static int ftrace_graph_skip_irqs;
 
@@ -117,199 +90,6 @@ static void
 print_graph_duration(struct trace_array *tr, unsigned long long duration,
 		     struct trace_seq *s, u32 flags);
 
-/* Add a function return address to the trace stack on thread info.*/
-static int
-ftrace_push_return_trace(unsigned long ret, unsigned long func,
-			 unsigned long frame_pointer, unsigned long *retp)
-{
-	unsigned long long calltime;
-	int index;
-
-	if (unlikely(ftrace_graph_is_dead()))
-		return -EBUSY;
-
-	if (!current->ret_stack)
-		return -EBUSY;
-
-	/*
-	 * We must make sure the ret_stack is tested before we read
-	 * anything else.
-	 */
-	smp_rmb();
-
-	/* The return trace stack is full */
-	if (current->curr_ret_stack == FTRACE_RETFUNC_DEPTH - 1) {
-		atomic_inc(&current->trace_overrun);
-		return -EBUSY;
-	}
-
-	/*
-	 * The curr_ret_stack is an index to ftrace return stack of
-	 * current task.  Its value should be in [0, FTRACE_RETFUNC_
-	 * DEPTH) when the function graph tracer is used.  To support
-	 * filtering out specific functions, it makes the index
-	 * negative by subtracting huge value (FTRACE_NOTRACE_DEPTH)
-	 * so when it sees a negative index the ftrace will ignore
-	 * the record.  And the index gets recovered when returning
-	 * from the filtered function by adding the FTRACE_NOTRACE_
-	 * DEPTH and then it'll continue to record functions normally.
-	 *
-	 * The curr_ret_stack is initialized to -1 and get increased
-	 * in this function.  So it can be less than -1 only if it was
-	 * filtered out via ftrace_graph_notrace_addr() which can be
-	 * set from set_graph_notrace file in tracefs by user.
-	 */
-	if (current->curr_ret_stack < -1)
-		return -EBUSY;
-
-	calltime = trace_clock_local();
-
-	index = ++current->curr_ret_stack;
-	if (ftrace_graph_notrace_addr(func))
-		current->curr_ret_stack -= FTRACE_NOTRACE_DEPTH;
-	barrier();
-	current->ret_stack[index].ret = ret;
-	current->ret_stack[index].func = func;
-	current->ret_stack[index].calltime = calltime;
-#ifdef HAVE_FUNCTION_GRAPH_FP_TEST
-	current->ret_stack[index].fp = frame_pointer;
-#endif
-#ifdef HAVE_FUNCTION_GRAPH_RET_ADDR_PTR
-	current->ret_stack[index].retp = retp;
-#endif
-	return 0;
-}
-
-int function_graph_enter(unsigned long ret, unsigned long func,
-			 unsigned long frame_pointer, unsigned long *retp)
-{
-	struct ftrace_graph_ent trace;
-
-	trace.func = func;
-	trace.depth = ++current->curr_ret_depth;
-
-	if (ftrace_push_return_trace(ret, func, frame_pointer, retp))
-		goto out;
-
-	/* Only trace if the calling function expects to */
-	if (!ftrace_graph_entry(&trace))
-		goto out_ret;
-
-	return 0;
- out_ret:
-	current->curr_ret_stack--;
- out:
-	current->curr_ret_depth--;
-	return -EBUSY;
-}
-
-/* Retrieve a function return address to the trace stack on thread info.*/
-static void
-ftrace_pop_return_trace(struct ftrace_graph_ret *trace, unsigned long *ret,
-			unsigned long frame_pointer)
-{
-	int index;
-
-	index = current->curr_ret_stack;
-
-	/*
-	 * A negative index here means that it's just returned from a
-	 * notrace'd function.  Recover index to get an original
-	 * return address.  See ftrace_push_return_trace().
-	 *
-	 * TODO: Need to check whether the stack gets corrupted.
-	 */
-	if (index < 0)
-		index += FTRACE_NOTRACE_DEPTH;
-
-	if (unlikely(index < 0 || index >= FTRACE_RETFUNC_DEPTH)) {
-		ftrace_graph_stop();
-		WARN_ON(1);
-		/* Might as well panic, otherwise we have no where to go */
-		*ret = (unsigned long)panic;
-		return;
-	}
-
-#ifdef HAVE_FUNCTION_GRAPH_FP_TEST
-	/*
-	 * The arch may choose to record the frame pointer used
-	 * and check it here to make sure that it is what we expect it
-	 * to be. If gcc does not set the place holder of the return
-	 * address in the frame pointer, and does a copy instead, then
-	 * the function graph trace will fail. This test detects this
-	 * case.
-	 *
-	 * Currently, x86_32 with optimize for size (-Os) makes the latest
-	 * gcc do the above.
-	 *
-	 * Note, -mfentry does not use frame pointers, and this test
-	 *  is not needed if CC_USING_FENTRY is set.
-	 */
-	if (unlikely(current->ret_stack[index].fp != frame_pointer)) {
-		ftrace_graph_stop();
-		WARN(1, "Bad frame pointer: expected %lx, received %lx\n"
-		     "  from func %ps return to %lx\n",
-		     current->ret_stack[index].fp,
-		     frame_pointer,
-		     (void *)current->ret_stack[index].func,
-		     current->ret_stack[index].ret);
-		*ret = (unsigned long)panic;
-		return;
-	}
-#endif
-
-	*ret = current->ret_stack[index].ret;
-	trace->func = current->ret_stack[index].func;
-	trace->calltime = current->ret_stack[index].calltime;
-	trace->overrun = atomic_read(&current->trace_overrun);
-	trace->depth = current->curr_ret_depth--;
-	/*
-	 * We still want to trace interrupts coming in if
-	 * max_depth is set to 1. Make sure the decrement is
-	 * seen before ftrace_graph_return.
-	 */
-	barrier();
-}
-
-/*
- * Send the trace to the ring-buffer.
- * @return the original return address.
- */
-unsigned long ftrace_return_to_handler(unsigned long frame_pointer)
-{
-	struct ftrace_graph_ret trace;
-	unsigned long ret;
-
-	ftrace_pop_return_trace(&trace, &ret, frame_pointer);
-	trace.rettime = trace_clock_local();
-	ftrace_graph_return(&trace);
-	/*
-	 * The ftrace_graph_return() may still access the current
-	 * ret_stack structure, we need to make sure the update of
-	 * curr_ret_stack is after that.
-	 */
-	barrier();
-	current->curr_ret_stack--;
-	/*
-	 * The curr_ret_stack can be less than -1 only if it was
-	 * filtered out and it's about to return from the function.
-	 * Recover the index and continue to trace normal functions.
-	 */
-	if (current->curr_ret_stack < -1) {
-		current->curr_ret_stack += FTRACE_NOTRACE_DEPTH;
-		return ret;
-	}
-
-	if (unlikely(!ret)) {
-		ftrace_graph_stop();
-		WARN_ON(1);
-		/* Might as well panic. What else to do? */
-		ret = (unsigned long)panic;
-	}
-
-	return ret;
-}
-
 /**
  * ftrace_graph_ret_addr - convert a potentially modified stack return address
  *			   to its original value
-- 
2.19.1


