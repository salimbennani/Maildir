Return-Path: <linux-kernel-owner@vger.kernel.org>
Delivered-To: unknown
Received: from linux.intel.com (10.54.29.200:995) by likexu-workstation with
  POP3-SSL; 07 Dec 2018 08:54:30 -0000
X-Original-To: like.xu@linux.intel.com
Delivered-To: like.xu@linux.intel.com
Received: from fmsmga004.fm.intel.com (fmsmga004.fm.intel.com [10.253.24.48])
	(using TLSv1.2 with cipher ECDHE-RSA-AES256-GCM-SHA384 (256/256 bits))
	(No client certificate requested)
	by linux.intel.com (Postfix) with ESMTPS id 0CE305804F9;
	Thu,  6 Dec 2018 14:00:30 -0800 (PST)
Received: from fmsmga104.fm.intel.com ([10.1.193.100])
  by fmsmga004-1.fm.intel.com with ESMTP/TLS/DHE-RSA-AES256-GCM-SHA384; 06 Dec 2018 14:00:29 -0800
X-SG-BADATTACHMENTNOREPLY: True
IronPort-PHdr: =?us-ascii?q?9a23=3ADKwRtxwwD/SqleDXCy+O+j09IxM/srCxBDY+r6Qd?=
 =?us-ascii?q?0ewWLPad9pjvdHbS+e9qxAeQG9mDu7Qc06L/iOPJYSQ4+5GPsXQPItRndiQuro?=
 =?us-ascii?q?EopTEmG9OPEkbhLfTnPGQQFcVGU0J5rTngaRAGUMnxaEfPrXKs8DUcBgvwNRZv?=
 =?us-ascii?q?JuTyB4Xek9m72/q99pHPYAhEniaxba9vJxiqsAvdsdUbj5F/Iagr0BvJpXVIe+?=
 =?us-ascii?q?VSxWx2IF+Yggjx6MSt8pN96ipco/0u+dJOXqX8ZKQ4UKdXDC86PGAv5c3krgfM?=
 =?us-ascii?q?QA2S7XYBSGoWkx5IAw/Y7BHmW5r6ryX3uvZh1CScIMb7Vq4/Vyi84Kh3SR/okC?=
 =?us-ascii?q?YHOCA/8GHLkcx7kaZXrAu8qxBj34LYZYeYP+d8cKzAZ9MXXWRPUMZPWSJcAIyy?=
 =?us-ascii?q?bIUPAOQOMulEtIn9v1kDoACiBQWwHu7j1iNEi2Xo0aA8zu8vERvG3AslH98Wvn?=
 =?us-ascii?q?rbtsv1NKYPXuuo0KfIzCvMb/VK2Tf/9ofIaQ0qrPaWXbJxb8XRz1UvFwHbgVWL?=
 =?us-ascii?q?soHlMDSV1uMCs2if8eVsT/6gi2kiqwxopDWk28kiio7Mho0Py1DE8z10wIMrKt?=
 =?us-ascii?q?29T057e96lHIFMuC2DLod6W9ktT3ltuCkkz70GoZm7fCwLyJs7xx/TceCIf5GR?=
 =?us-ascii?q?7h76TumdOSx4hHJgeL2hgha+61SvxvTlWsWtyllHqDdOnNrUtn0VyRDf9syKRu?=
 =?us-ascii?q?Fg8kqvxzqDzR3f5+JYLUwulKfWKYYtzqAxm5YNrUjOGzL6lUXqg6KTa0kp+O2l?=
 =?us-ascii?q?5urib7jovJCRN4p5hh/wP6s0mMGyBOQ1PRYAUmSF/Omx273u8En6TbhMk/Y4iL?=
 =?us-ascii?q?PWsIrAKsQevqO5AxFa0oIk6xunETem38oXnWMdIFJGZh2HlY7pNE/KIPziCve/?=
 =?us-ascii?q?mVusnC9qx/DAILLhHo3AImbfnLrlZ7px9kBRxBQpwdxC5J9YFqsNLfPxV0Ppsd?=
 =?us-ascii?q?zXFB45Mwi6w+b9D9V905sTWWaOAq+fLaPTvkaE5uExLOmWYo8apjL9J+Ei5//g?=
 =?us-ascii?q?i382h0UdcLK33ZsYdn+4BO5qI0aHbnr2hNcOD2MKshA5TOzwh12OSSRTaGqqX6?=
 =?us-ascii?q?Ig+jE7D5qrDYPCRoCunrONxii6HoBNa2BCC1CMF2rodoqeV/cNbiKSPtFukjge?=
 =?us-ascii?q?Wbe9TI8h0AmktBXmxLp/MurU5ioYuIrj1Ndv5u3TiQs99TtuA8SdzmGCVWd0nm?=
 =?us-ascii?q?wTSj8y3aB/p1F9y1iZ3ah5hfxYCcJc5/dTXggmMp7cyvRwC8ruVQLZYteJVFGm?=
 =?us-ascii?q?T82kATE2UN092dwOY0F7G9WkiRDOxC6qA74Tl7yWC5046KPc337tJ8ljz3bKzr?=
 =?us-ascii?q?Uuj14jQsFXL22pmrZ/9xTPB47Oi0iWjb2qdaQb3C7O7muD13CBvENDXQ50UKXF?=
 =?us-ascii?q?W20fZ0TModT44EPCU6GhCbA9PgRdzs6CL7NAasf1glVeWPfjJNPebnqym2iqAx?=
 =?us-ascii?q?aE3LeMbIvwdGUb0yXQE0wEkwEV/XabOgkyHCaho2TCDDNwEVLjeV/j8e57qHmj?=
 =?us-ascii?q?VE870xmKb1F917qy4hMamOaTS+0N0b4euCcusTN0HE2j0NLQDNaAowlhfKBYYd?=
 =?us-ascii?q?4m5FdH1GTZtxFyP5C6LqBigEIefBpzv0/0yxp3DYBAm9AwrHw21ApyNb6Y0FRZ?=
 =?us-ascii?q?ejyFx5/wJKPYJnPy/B+1ba7WwU/R0NCN96cL6fQ4rUjjvQ6zGkoj9XVnz8da03?=
 =?us-ascii?q?+G6prWCwoSVIr7Ulwr+Bhiu7Hafi496pvI1X1tNKm0tSPC29IpBec/1hasZdBf?=
 =?us-ascii?q?MLmAFA/zFc0aCNOjKOgrm1ivcxIFM/pe9K8yP8O6afSG3LSnM/pnnDKjlW5H+p?=
 =?us-ascii?q?xy0lqQ9ypgTe7Fx4wKw/WG0QqISTj9jE2tvdvqmY9Zfz4SGGm/yS/6BINKYq1y?=
 =?us-ascii?q?fIALCXqhIsGtx9V+gYLtVGBc9FK5G1wG38qpcwKIb1PhxQ1QyVgXoXu/lCq40j?=
 =?us-ascii?q?x4iS0morCe3SzO2evichUHN3VPRGlji1fsPIe1g8obXEiucwgmih+l6VzmyKhc?=
 =?us-ascii?q?oaR1N3PTTltQfyjqM2FiVbO9tqCDY8FT8pwoqzhYUOOmbVCcVLH9uRoa3zr/EG?=
 =?us-ascii?q?REwDA0ai+luo/+nxx8k2+dKHdzrHzEecB/3xvf5drcReJP0ToCXiV3lT7XBl2k?=
 =?us-ascii?q?Ndmz4dqUj4vDsvy5V2+5VpxTcDPnzIOauCug+G1qBwayn/Symt3hDAg73jX319?=
 =?us-ascii?q?hsVSXUshn8ZpPn2Li9MeJiZkNoHkPz69JmGoFilYs9nJMQ1mIAhpWW/noHln3/?=
 =?us-ascii?q?Mc5B1qL9b3oNRDgLzMDT4AX+3E1jL3SJx5/2V3mHw8thYcW6bX0S2i4n889KD6?=
 =?us-ascii?q?KU5qRenSRpulq4sR7RYf9lkzYd0/Qu72QWg+MIuAor1SidBrESHU9FPS3jjRiI?=
 =?us-ascii?q?7ta+rLlJa2ara7S/yE1+ndW5BrGYvg5cQGr5eoslHSJo7cVwKlPM3Gfz6oH5Yt?=
 =?us-ascii?q?bQa90TuwaQkxfBiehVNZ0wmuALhSphJWLyo3klx/Qnghxp2JGwpJKHJHl1/KKl?=
 =?us-ascii?q?Hh5YMSX4Z8YS+jHul6lShMiX0J60HpV9BDoLRoDnQuyyEDIdrvnnMweOEDshqn?=
 =?us-ascii?q?aUA7bfHAmf6Ft4oHLLCZykK3aXJHwBx9V4WBadPFBfgBwTXDgigp45EQWqyNbg?=
 =?us-ascii?q?cUhj4DAR+0X4qgBNyu9zMxn/U2HfpBqnazsuSZifKgZW4R9G50vPLcOe6edzFT?=
 =?us-ascii?q?lC/pK9tAyNNnCbZwNQAG4SQEOEAFTjPqS06dnE7uiVHe6+L/rIYbWTpu1STfaI?=
 =?us-ascii?q?xZSz0oR4+zaALNmAPn5nD/cjwEpMQWh5G9jFmzUIUyEXlTjCb8uFqxen4CF3st?=
 =?us-ascii?q?qz8Pf2WALs+IuPDaFdMc509hCygKeDMfOQhSljJTZZ0JMM2WHHyLwF0FEOjCFu?=
 =?us-ascii?q?ciGnEa4cui7VUKLQhqhXAgYbaiN0KctI9r880RNLOcLBkdP10bh4jvEuBldBVF?=
 =?us-ascii?q?zhnNypZMMQL2G8MlPHGFiENLCcKTLXxMH3ZLu2SadMg+VMqx2wpTGbHlfjPjud?=
 =?us-ascii?q?ljnpVBOvMeBWgCGYJhxev469fQh3CWj+V9LrcRm7MN5xjT0rzrw4nHLKNWgAMT?=
 =?us-ascii?q?did0NBtKGf7SRdgv9nAWxO8mJlLfWYmyae9+TXMIsWvuBxAitql+NW+nA6y7pO?=
 =?us-ascii?q?4SFARfx1njbSr9F0r1GnlOmP1iRoUB5UpjlXg4KLuF1oOb/F+ZlYRXbE4BUN4H?=
 =?us-ascii?q?2MCxQLottpEMHgt7pMxdjPiq3zLixP89bV/csaGsjVJ9iLMHsnMRr1BjHUCBEJ?=
 =?us-ascii?q?QiKsNWHan0Zdiu2d9mWJrpgmrZjhgJoPRaVdVFwwF/MaDFxqHd0CIJhtWDMknq?=
 =?us-ascii?q?WWjMoJ5Xq4sRnQS99WvpHBVvKOH/rvLCyVgqVDZxsNkvvEKtE3N4vmwARebUNk?=
 =?us-ascii?q?lYDGAAKEQddXvCRlYhQcpERL7Wg7QGou3U7sdgKq5jkUD/HizTAsjQ4rTe0z9T?=
 =?us-ascii?q?uk2VY6IEbIqTB4xFMwlNP5gz2KWDH2K6i0UMddDC+i5Bt5CY/yXwsgNV76pkdj?=
 =?us-ascii?q?LjqRAusJ17Y=3D?=
X-IronPort-Anti-Spam-Filtered: true
X-IronPort-Anti-Spam-Result: =?us-ascii?q?A0APAQComwlch0O0hNFjHAEBAQQBAQcEA?=
 =?us-ascii?q?QGBZYExKoIRJ5gigWg5kkGGHQNPDwEBGBMBh1ciOBIBAwEBAQEBAQIBEwEBAQg?=
 =?us-ascii?q?NCQgpIwyCNiQBgmIDAwECJBMGAQE3AQUJAQFQAzEBBQEcBhMFgxyCAgEEmns8i?=
 =?us-ascii?q?h2BbDOCdgEBBYcmCBKKcYEcF4F/gREzhX0ChzyJN4Z+kCwJhTiFA4cLGIlih1Q?=
 =?us-ascii?q?smDkGAgkHDyGBPFWBIU0jFYMnghsMFxJtAQmCQYp0HzKBBQEBIYoZAQE?=
X-IPAS-Result: =?us-ascii?q?A0APAQComwlch0O0hNFjHAEBAQQBAQcEAQGBZYExKoIRJ5g?=
 =?us-ascii?q?igWg5kkGGHQNPDwEBGBMBh1ciOBIBAwEBAQEBAQIBEwEBAQgNCQgpIwyCNiQBg?=
 =?us-ascii?q?mIDAwECJBMGAQE3AQUJAQFQAzEBBQEcBhMFgxyCAgEEmns8ih2BbDOCdgEBBYc?=
 =?us-ascii?q?mCBKKcYEcF4F/gREzhX0ChzyJN4Z+kCwJhTiFA4cLGIlih1QsmDkGAgkHDyGBP?=
 =?us-ascii?q?FWBIU0jFYMnghsMFxJtAQmCQYp0HzKBBQEBIYoZAQE?=
X-IronPort-AV: E=Sophos;i="5.56,323,1539673200"; 
   d="scan'208";a="54176577"
X-Amp-Result: SKIPPED(no attachment in message)
X-Amp-File-Uploaded: False
Received: from vger.kernel.org ([209.132.180.67])
  by mtab.intel.com with ESMTP; 06 Dec 2018 14:00:28 -0800
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
        id S1726234AbeLFWAY (ORCPT <rfc822;like.xu@linux.intel.com>
        + 23 others); Thu, 6 Dec 2018 17:00:24 -0500
Received: from mail-pg1-f196.google.com ([209.85.215.196]:32886 "EHLO
        mail-pg1-f196.google.com" rhost-flags-OK-OK-OK-OK) by vger.kernel.org
        with ESMTP id S1725965AbeLFWAY (ORCPT
        <rfc822;linux-kernel@vger.kernel.org>);
        Thu, 6 Dec 2018 17:00:24 -0500
Received: by mail-pg1-f196.google.com with SMTP id z11so749769pgu.0
        for <linux-kernel@vger.kernel.org>; Thu, 06 Dec 2018 14:00:22 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=google.com; s=20161025;
        h=date:from:to:cc:subject:in-reply-to:message-id:references
         :user-agent:mime-version;
        bh=i4WHwLL8nrvBGhlnmQBClzLxgWS8npDJmDeSthaOXuM=;
        b=pWmkbCrFbsrKoKRgg0z3r/jwHC+uR2TrHaiiQVcD//VHjZTgVv+xu2bXu5O24Hksed
         Tr6rSK4tlHzjwUMTKv5bVkGPGKuAhNFoz3Pb7ZpsY4CrzJ/NCNotMqLEB/qgfeOnCpRw
         lF00o0HZp484GWAL27rgzrWFZMsD4yzr+NQJ5S3g24JJJhlWQHWbL0ODLjwlilQpmNRv
         qGuIYXnK79evLEaT2o9oIrwn1ZyJ/ZHSiBTrrEYd4oGkaF+dtBOQG3iNrl0Q8G5Fkag0
         M3slbQYT+AT+MRKiTp5ZpHhr37G8KQKkCh1q4hZWSY/meH5AnZvmryoUaU5a9DnupAeS
         GRgQ==
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20161025;
        h=x-gm-message-state:date:from:to:cc:subject:in-reply-to:message-id
         :references:user-agent:mime-version;
        bh=i4WHwLL8nrvBGhlnmQBClzLxgWS8npDJmDeSthaOXuM=;
        b=Ad+Q5pgrZu1VLa/irXobtJTD8osTTqdC0K7q4H/VdcLFjAvj3g+pGJyefkDCl5g7T4
         fzJhlLIKpCuz6aGZJEfkteZOuHH7W6xvVcSF/7oqRnJ3wkEmaCmaUrvK3NWijf/BrgX2
         s8qqQSKeXe6zLPhs9vgW/Nw542YfsHCY/Qgmu4kihxjt4r13qupxwM5v1OFAYRfusmuS
         4/3g+C2VF8S03eW6cw3ucGSFvDocxj5ytJMq11TKaaf8LVEL3QDsK1dEdgjL6gQ4ghL3
         5ybXbKcFFsmQSADucPnZueHBWAioHQuzcmPlou+snLr72lk4g4tIeyLX1oshoQ/Dc8uO
         E3VA==
X-Gm-Message-State: AA+aEWbxlhC/XVy+KXwY3Kz3DaCRBWP6RX9OGXYtBOfOWXeS/eWLXZnN
        CUp+mfTzX92XrPnKab0eiqeW5w==
X-Google-Smtp-Source: AFSGD/XcqGiA5CtiiGGGY3YqNxr5e06tjqM/K3vJ+ibWwpwlWEa1UVlPjrnRZJl6/qhFargrtVRYWg==
X-Received: by 2002:a63:f1f:: with SMTP id e31mr25297768pgl.274.1544133622308;
        Thu, 06 Dec 2018 14:00:22 -0800 (PST)
Received: from [2620:15c:17:3:3a5:23a7:5e32:4598] ([2620:15c:17:3:3a5:23a7:5e32:4598])
        by smtp.gmail.com with ESMTPSA id d11sm1321251pgi.25.2018.12.06.14.00.20
        (version=TLS1_2 cipher=ECDHE-RSA-CHACHA20-POLY1305 bits=256/256);
        Thu, 06 Dec 2018 14:00:21 -0800 (PST)
Date: Thu, 6 Dec 2018 14:00:20 -0800 (PST)
From: David Rientjes <rientjes@google.com>
X-X-Sender: rientjes@chino.kir.corp.google.com
To: Linus Torvalds <torvalds@linux-foundation.org>
cc: Andrea Arcangeli <aarcange@redhat.com>,
        mgorman@techsingularity.net, Vlastimil Babka <vbabka@suse.cz>,
        mhocko@kernel.org, ying.huang@intel.com, s.priebe@profihost.ag,
        Linux List Kernel Mailing <linux-kernel@vger.kernel.org>,
        alex.williamson@redhat.com, lkp@01.org, kirill@shutemov.name,
        Andrew Morton <akpm@linux-foundation.org>,
        zi.yan@cs.rutgers.edu
Subject: [patch for-4.20] Revert "mm, thp: consolidate THP gfp handling into
 alloc_hugepage_direct_gfpmask"
In-Reply-To: <alpine.DEB.2.21.1812061341130.144733@chino.kir.corp.google.com>
Message-ID: <alpine.DEB.2.21.1812061343240.144733@chino.kir.corp.google.com>
References: <alpine.DEB.2.21.1812051445390.35948@chino.kir.corp.google.com> <alpine.DEB.2.21.1812061341130.144733@chino.kir.corp.google.com>
User-Agent: Alpine 2.21 (DEB 202 2017-01-01)
MIME-Version: 1.0
Content-Type: text/plain; charset=US-ASCII
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: <linux-kernel.vger.kernel.org>
X-Mailing-List: linux-kernel@vger.kernel.org

This reverts commit 89c83fb539f95491be80cdd5158e6f0ce329e317.

There are a couple of issues with 89c83fb539f9 independent of its partial 
revert in 2f0799a0ffc0 ("mm, thp: restore node-local hugepage 
allocations"):

Firstly, the interaction between alloc_hugepage_direct_gfpmask() and 
alloc_pages_vma() is racy wrt __GFP_THISNODE and MPOL_BIND.  
alloc_hugepage_direct_gfpmask() makes sure not to set __GFP_THISNODE for 
an MPOL_BIND policy but the policy used in alloc_pages_vma() may not be 
the same for shared vma policies, triggering the WARN_ON_ONCE() in 
policy_node().

Secondly, prior to 89c83fb539f9, alloc_pages_vma() implemented a somewhat 
different policy for hugepage allocations, which were allocated through 
alloc_hugepage_vma().  For hugepage allocations, if the allocating 
process's node is in the set of allowed nodes, allocate with 
__GFP_THISNODE for that node (for MPOL_PREFERRED, use that node with 
__GFP_THISNODE instead).  This was changed for shmem_alloc_hugepage() to 
allow fallback to other nodes in 89c83fb539f9 as it did for new_page() in 
mm/mempolicy.c which is functionally different behavior and removes the 
requirement to only allocate hugepages locally.

The latter should have been reverted as part of 2f0799a0ffc0 as well.

Fully revert 89c83fb539f9 so that hugepage allocation policy is fully 
restored and there is no race between alloc_hugepage_direct_gfpmask() and 
alloc_pages_vma().

Fixes: 89c83fb539f9 ("mm, thp: consolidate THP gfp handling into alloc_hugepage_direct_gfpmask")
Fixes: 2f0799a0ffc0 ("mm, thp: restore node-local hugepage allocations")
Signed-off-by: David Rientjes <rientjes@google.com>
---
 include/linux/gfp.h | 12 ++++++++----
 mm/huge_memory.c    | 27 +++++++++++++--------------
 mm/mempolicy.c      | 32 +++++++++++++++++++++++++++++---
 mm/shmem.c          |  2 +-
 4 files changed, 51 insertions(+), 22 deletions(-)

diff --git a/include/linux/gfp.h b/include/linux/gfp.h
--- a/include/linux/gfp.h
+++ b/include/linux/gfp.h
@@ -510,18 +510,22 @@ alloc_pages(gfp_t gfp_mask, unsigned int order)
 }
 extern struct page *alloc_pages_vma(gfp_t gfp_mask, int order,
 			struct vm_area_struct *vma, unsigned long addr,
-			int node);
+			int node, bool hugepage);
+#define alloc_hugepage_vma(gfp_mask, vma, addr, order) \
+	alloc_pages_vma(gfp_mask, order, vma, addr, numa_node_id(), true)
 #else
 #define alloc_pages(gfp_mask, order) \
 		alloc_pages_node(numa_node_id(), gfp_mask, order)
-#define alloc_pages_vma(gfp_mask, order, vma, addr, node)\
+#define alloc_pages_vma(gfp_mask, order, vma, addr, node, false)\
+	alloc_pages(gfp_mask, order)
+#define alloc_hugepage_vma(gfp_mask, vma, addr, order) \
 	alloc_pages(gfp_mask, order)
 #endif
 #define alloc_page(gfp_mask) alloc_pages(gfp_mask, 0)
 #define alloc_page_vma(gfp_mask, vma, addr)			\
-	alloc_pages_vma(gfp_mask, 0, vma, addr, numa_node_id())
+	alloc_pages_vma(gfp_mask, 0, vma, addr, numa_node_id(), false)
 #define alloc_page_vma_node(gfp_mask, vma, addr, node)		\
-	alloc_pages_vma(gfp_mask, 0, vma, addr, node)
+	alloc_pages_vma(gfp_mask, 0, vma, addr, node, false)
 
 extern unsigned long __get_free_pages(gfp_t gfp_mask, unsigned int order);
 extern unsigned long get_zeroed_page(gfp_t gfp_mask);
diff --git a/mm/huge_memory.c b/mm/huge_memory.c
--- a/mm/huge_memory.c
+++ b/mm/huge_memory.c
@@ -629,30 +629,30 @@ static vm_fault_t __do_huge_pmd_anonymous_page(struct vm_fault *vmf,
  *	    available
  * never: never stall for any thp allocation
  */
-static inline gfp_t alloc_hugepage_direct_gfpmask(struct vm_area_struct *vma, unsigned long addr)
+static inline gfp_t alloc_hugepage_direct_gfpmask(struct vm_area_struct *vma)
 {
 	const bool vma_madvised = !!(vma->vm_flags & VM_HUGEPAGE);
-	const gfp_t gfp_mask = GFP_TRANSHUGE_LIGHT | __GFP_THISNODE;
 
 	/* Always do synchronous compaction */
 	if (test_bit(TRANSPARENT_HUGEPAGE_DEFRAG_DIRECT_FLAG, &transparent_hugepage_flags))
-		return GFP_TRANSHUGE | __GFP_THISNODE |
-		       (vma_madvised ? 0 : __GFP_NORETRY);
+		return GFP_TRANSHUGE | (vma_madvised ? 0 : __GFP_NORETRY);
 
 	/* Kick kcompactd and fail quickly */
 	if (test_bit(TRANSPARENT_HUGEPAGE_DEFRAG_KSWAPD_FLAG, &transparent_hugepage_flags))
-		return gfp_mask | __GFP_KSWAPD_RECLAIM;
+		return GFP_TRANSHUGE_LIGHT | __GFP_KSWAPD_RECLAIM;
 
 	/* Synchronous compaction if madvised, otherwise kick kcompactd */
 	if (test_bit(TRANSPARENT_HUGEPAGE_DEFRAG_KSWAPD_OR_MADV_FLAG, &transparent_hugepage_flags))
-		return gfp_mask | (vma_madvised ? __GFP_DIRECT_RECLAIM :
-						  __GFP_KSWAPD_RECLAIM);
+		return GFP_TRANSHUGE_LIGHT |
+			(vma_madvised ? __GFP_DIRECT_RECLAIM :
+					__GFP_KSWAPD_RECLAIM);
 
 	/* Only do synchronous compaction if madvised */
 	if (test_bit(TRANSPARENT_HUGEPAGE_DEFRAG_REQ_MADV_FLAG, &transparent_hugepage_flags))
-		return gfp_mask | (vma_madvised ? __GFP_DIRECT_RECLAIM : 0);
+		return GFP_TRANSHUGE_LIGHT |
+		       (vma_madvised ? __GFP_DIRECT_RECLAIM : 0);
 
-	return gfp_mask;
+	return GFP_TRANSHUGE_LIGHT;
 }
 
 /* Caller must hold page table lock. */
@@ -724,8 +724,8 @@ vm_fault_t do_huge_pmd_anonymous_page(struct vm_fault *vmf)
 			pte_free(vma->vm_mm, pgtable);
 		return ret;
 	}
-	gfp = alloc_hugepage_direct_gfpmask(vma, haddr);
-	page = alloc_pages_vma(gfp, HPAGE_PMD_ORDER, vma, haddr, numa_node_id());
+	gfp = alloc_hugepage_direct_gfpmask(vma);
+	page = alloc_hugepage_vma(gfp, vma, haddr, HPAGE_PMD_ORDER);
 	if (unlikely(!page)) {
 		count_vm_event(THP_FAULT_FALLBACK);
 		return VM_FAULT_FALLBACK;
@@ -1295,9 +1295,8 @@ vm_fault_t do_huge_pmd_wp_page(struct vm_fault *vmf, pmd_t orig_pmd)
 alloc:
 	if (transparent_hugepage_enabled(vma) &&
 	    !transparent_hugepage_debug_cow()) {
-		huge_gfp = alloc_hugepage_direct_gfpmask(vma, haddr);
-		new_page = alloc_pages_vma(huge_gfp, HPAGE_PMD_ORDER, vma,
-				haddr, numa_node_id());
+		huge_gfp = alloc_hugepage_direct_gfpmask(vma);
+		new_page = alloc_hugepage_vma(huge_gfp, vma, haddr, HPAGE_PMD_ORDER);
 	} else
 		new_page = NULL;
 
diff --git a/mm/mempolicy.c b/mm/mempolicy.c
--- a/mm/mempolicy.c
+++ b/mm/mempolicy.c
@@ -1116,8 +1116,8 @@ static struct page *new_page(struct page *page, unsigned long start)
 	} else if (PageTransHuge(page)) {
 		struct page *thp;
 
-		thp = alloc_pages_vma(GFP_TRANSHUGE, HPAGE_PMD_ORDER, vma,
-				address, numa_node_id());
+		thp = alloc_hugepage_vma(GFP_TRANSHUGE, vma, address,
+					 HPAGE_PMD_ORDER);
 		if (!thp)
 			return NULL;
 		prep_transhuge_page(thp);
@@ -2011,6 +2011,7 @@ static struct page *alloc_page_interleave(gfp_t gfp, unsigned order,
  * 	@vma:  Pointer to VMA or NULL if not available.
  *	@addr: Virtual Address of the allocation. Must be inside the VMA.
  *	@node: Which node to prefer for allocation (modulo policy).
+ *	@hugepage: for hugepages try only the preferred node if possible
  *
  * 	This function allocates a page from the kernel page pool and applies
  *	a NUMA policy associated with the VMA or the current process.
@@ -2021,7 +2022,7 @@ static struct page *alloc_page_interleave(gfp_t gfp, unsigned order,
  */
 struct page *
 alloc_pages_vma(gfp_t gfp, int order, struct vm_area_struct *vma,
-		unsigned long addr, int node)
+		unsigned long addr, int node, bool hugepage)
 {
 	struct mempolicy *pol;
 	struct page *page;
@@ -2039,6 +2040,31 @@ alloc_pages_vma(gfp_t gfp, int order, struct vm_area_struct *vma,
 		goto out;
 	}
 
+	if (unlikely(IS_ENABLED(CONFIG_TRANSPARENT_HUGEPAGE) && hugepage)) {
+		int hpage_node = node;
+
+		/*
+		 * For hugepage allocation and non-interleave policy which
+		 * allows the current node (or other explicitly preferred
+		 * node) we only try to allocate from the current/preferred
+		 * node and don't fall back to other nodes, as the cost of
+		 * remote accesses would likely offset THP benefits.
+		 *
+		 * If the policy is interleave, or does not allow the current
+		 * node in its nodemask, we allocate the standard way.
+		 */
+		if (pol->mode == MPOL_PREFERRED && !(pol->flags & MPOL_F_LOCAL))
+			hpage_node = pol->v.preferred_node;
+
+		nmask = policy_nodemask(gfp, pol);
+		if (!nmask || node_isset(hpage_node, *nmask)) {
+			mpol_cond_put(pol);
+			page = __alloc_pages_node(hpage_node,
+						gfp | __GFP_THISNODE, order);
+			goto out;
+		}
+	}
+
 	nmask = policy_nodemask(gfp, pol);
 	preferred_nid = policy_node(gfp, pol, node);
 	page = __alloc_pages_nodemask(gfp, order, preferred_nid, nmask);
diff --git a/mm/shmem.c b/mm/shmem.c
--- a/mm/shmem.c
+++ b/mm/shmem.c
@@ -1439,7 +1439,7 @@ static struct page *shmem_alloc_hugepage(gfp_t gfp,
 
 	shmem_pseudo_vma_init(&pvma, info, hindex);
 	page = alloc_pages_vma(gfp | __GFP_COMP | __GFP_NORETRY | __GFP_NOWARN,
-			HPAGE_PMD_ORDER, &pvma, 0, numa_node_id());
+			HPAGE_PMD_ORDER, &pvma, 0, numa_node_id(), true);
 	shmem_pseudo_vma_destroy(&pvma);
 	if (page)
 		prep_transhuge_page(page);
