Return-Path: <virtualization-bounces@lists.linux-foundation.org>
Delivered-To: unknown
Received: from linux.intel.com (10.54.29.200:995) by likexu-workstation with
  POP3-SSL; 30 Nov 2018 08:43:25 -0000
X-Original-To: like.xu@linux.intel.com
Delivered-To: like.xu@linux.intel.com
Received: from orsmga002.jf.intel.com (orsmga002.jf.intel.com [10.7.209.21])
	(using TLSv1.2 with cipher ECDHE-RSA-AES256-GCM-SHA384 (256/256 bits))
	(No client certificate requested)
	by linux.intel.com (Postfix) with ESMTPS id 92EE85802E4
	for <like.xu@linux.intel.com>; Thu, 29 Nov 2018 06:20:11 -0800 (PST)
Received: from fmsmga101.fm.intel.com ([10.1.193.65])
  by orsmga002-1.jf.intel.com with ESMTP/TLS/DHE-RSA-AES256-GCM-SHA384; 29 Nov 2018 06:20:11 -0800
IronPort-PHdr: =?us-ascii?q?9a23=3A9sjZexdib34t75h+R1hQWS34lGMj4u6mDksu8pMi?=
 =?us-ascii?q?zoh2WeGdxcWyYB7h7PlgxGXEQZ/co6odzbaO4+a4ASQp2tWoiDg6aptCVhsI24?=
 =?us-ascii?q?09vjcLJ4q7M3D9N+PgdCcgHc5PBxdP9nC/NlVJSo6lPwWB6nK94iQPFRrhKAF7?=
 =?us-ascii?q?Ovr6GpLIj8Swyuu+54Dfbx9HiTahYr5+Ngm6oRnMvcQKnIVuLbo8xAHUqXVSYe?=
 =?us-ascii?q?RWwm1oJVOXnxni48q74YBu/SdNtf8/7sBMSar1cbg2QrxeFzQmLns65Nb3uhnZ?=
 =?us-ascii?q?TAuA/WUTX2MLmRdVGQfF7RX6XpDssivms+d2xSeXMdHqQb0yRD+v6bpgRh31hy?=
 =?us-ascii?q?cdLzM3/mHZhNJtgqxYrhKuqB5wzIDMYIyXNvRzcb7RcN0GSWVdRcZeSTdMAoag?=
 =?us-ascii?q?Y4YVFecNIfxVoov7qlATrRW+Hw6sBOb3xzFVmn/5w6M63P4nEQrb3gIvBdAOsH?=
 =?us-ascii?q?LTrNrpNaYSUP2+wa7TzTXfcfxW1y3y6I7Ich87uvyMR6x/ftfRyUY1CwPJlEmf?=
 =?us-ascii?q?qYvgPz6M0OkGrmuV7/J4WO6yhGMrtxt9riayyssxkIXFm4MYx1Te+Slk3oo5Pc?=
 =?us-ascii?q?O0RFJ/bNK+DZdduT+WO5FrTs4hTWxkojg2x74AtJWmZiYF0o4nyATaa/Gfc4iH?=
 =?us-ascii?q?/BbjVOGJLDd9nn1leba/iwy28UihzO38S8a10FhNripYlNnDq2oC1wDS6siATP?=
 =?us-ascii?q?tx5ECh2SyA1wzL6+FEJ147lbbDJpI8zbM8ioAfvVreEiPrgkn6ka6be0E+9uS1?=
 =?us-ascii?q?9ejrerDmqYWdN49whAH+KKMumsmnDOQmMwgORXSb+fmm273n/E34Qa9FjuE3kq?=
 =?us-ascii?q?netpDWPN8UpqmkAw9Tzoks9Q2/Aiyi0NQZhnkHMElFdAiDj4joPVHOPf/5Ae6x?=
 =?us-ascii?q?g1SrjTdrwe3JMaf9ApXMKXjDlq3tfbFn605T0AYz18xQ54pICrEdJ/L+QkvxtN?=
 =?us-ascii?q?3bDhAnKQC1zPvnBc551oMfX2KPH6CYPLnTsV+O+uIgPe2MaJUJtzb6Lvh2r8Po?=
 =?us-ascii?q?lmIzzF8BYbGyj9xQbHGjAu8gJ0SffGrihcoHHW4Wvw04CuvwhxqHWD9XYn+0GK?=
 =?us-ascii?q?Uk+jA8DpnhE4bZWp2khL2T1Tu6GZsFW2ZdF1rZFH7pc5mDCekNcj6PK8tggDUY?=
 =?us-ascii?q?VL+nDpUszAyjrxPSz7t8MvGS/iweqIKm2t9o4eHaiRA183pzFcvKyHyHTWx/gj?=
 =?us-ascii?q?YVQSQr1rt0u013xwS/1v16gvVeGs1S+P5PGlM4NJfawP17FN30cgLcd8iESRCt?=
 =?us-ascii?q?RdDwUh8rSddk+MMDbU97U/WrjBbE1DirS+sOi7GFDZo0+4rG0nTxLto7wHHDgv?=
 =?us-ascii?q?pyx2I6S9dCYDX1zpV08BLeUtbE?=
X-IronPort-Anti-Spam-Filtered: true
X-IronPort-Anti-Spam-Result: =?us-ascii?q?A0ACAACK9P9bhwyp04xkGQEBAQEBAQEBA?=
 =?us-ascii?q?QEBAQcBAQEBAQGBUgMBAQEBAQsBgVWBFIEpg3mId4spgg2BIZYjFIFeAQ8FGAs?=
 =?us-ascii?q?Jg3pBA4M2IjUIDQEDAQEBAQEBAgETAQEBCgsJCCkjDII2BQIDGAmCXAECAwEBA?=
 =?us-ascii?q?SAEHwoeCwMDAQIGAQEIAhgJGQQEAgIDAQsFEwE1EwUPgw0BggEFCoo1m1B8M4o?=
 =?us-ascii?q?eCgWCbYkpF4FAP4MlfoMeAQSBKwESAYMjMYImAokHhmOPZA9GCYIhhF2CcTyCa?=
 =?us-ascii?q?4QRI4lWAodEjViKdoFHAYEacU0jFTuCbIInF4hehT8/AQExgSOKYEeBdwEB?=
X-IPAS-Result: =?us-ascii?q?A0ACAACK9P9bhwyp04xkGQEBAQEBAQEBAQEBAQcBAQEBAQG?=
 =?us-ascii?q?BUgMBAQEBAQsBgVWBFIEpg3mId4spgg2BIZYjFIFeAQ8FGAsJg3pBA4M2IjUID?=
 =?us-ascii?q?QEDAQEBAQEBAgETAQEBCgsJCCkjDII2BQIDGAmCXAECAwEBASAEHwoeCwMDAQI?=
 =?us-ascii?q?GAQEIAhgJGQQEAgIDAQsFEwE1EwUPgw0BggEFCoo1m1B8M4oeCgWCbYkpF4FAP?=
 =?us-ascii?q?4MlfoMeAQSBKwESAYMjMYImAokHhmOPZA9GCYIhhF2CcTyCa4QRI4lWAodEjVi?=
 =?us-ascii?q?KdoFHAYEacU0jFTuCbIInF4hehT8/AQExgSOKYEeBdwEB?=
X-IronPort-AV: E=Sophos;i="5.56,294,1539673200"; 
   d="asc'?scan'208";a="64558214"
X-Amp-Result: UNKNOWN
X-Amp-Original-Verdict: FILE UNKNOWN
X-Amp-File-Uploaded: False
Received: from mail.linuxfoundation.org ([140.211.169.12])
  by mga01b.intel.com with ESMTP/TLS/DHE-RSA-AES256-GCM-SHA384; 29 Nov 2018 06:20:10 -0800
Received: from mail.linux-foundation.org (localhost [127.0.0.1])
	by mail.linuxfoundation.org (Postfix) with ESMTP id 3F49CAE1;
	Thu, 29 Nov 2018 14:19:38 +0000 (UTC)
X-Original-To: virtualization@lists.linux-foundation.org
Delivered-To: virtualization@mail.linuxfoundation.org
Received: from smtp1.linuxfoundation.org (smtp1.linux-foundation.org
	[172.17.192.35])
	by mail.linuxfoundation.org (Postfix) with ESMTPS id 2386189F
	for <virtualization@lists.linux-foundation.org>;
	Thu, 29 Nov 2018 14:19:36 +0000 (UTC)
X-Greylist: domain auto-whitelisted by SQLgrey-1.7.6
Received: from mx1.redhat.com (mx1.redhat.com [209.132.183.28])
	by smtp1.linuxfoundation.org (Postfix) with ESMTPS id 8ED69771
	for <virtualization@lists.linux-foundation.org>;
	Thu, 29 Nov 2018 14:19:35 +0000 (UTC)
Received: from smtp.corp.redhat.com (int-mx02.intmail.prod.int.phx2.redhat.com
	[10.5.11.12])
	(using TLSv1.2 with cipher AECDH-AES256-SHA (256/256 bits))
	(No client certificate requested)
	by mx1.redhat.com (Postfix) with ESMTPS id 0712C394D4D;
	Thu, 29 Nov 2018 14:19:35 +0000 (UTC)
Received: from localhost (ovpn-117-196.ams2.redhat.com [10.36.117.196])
	by smtp.corp.redhat.com (Postfix) with ESMTP id 344237012D;
	Thu, 29 Nov 2018 14:19:29 +0000 (UTC)
Date: Thu, 29 Nov 2018 14:19:28 +0000
From: Stefan Hajnoczi <stefanha@redhat.com>
To: jiangyiwen <jiangyiwen@huawei.com>
Subject: Re: [PATCH 0/5] VSOCK: support mergeable rx buffer in vhost-vsock
Message-ID: <20181129141928.GC17554@stefanha-x1.localdomain>
References: <5BDFF49C.3040603@huawei.com>
	<b9d535f8-ddc3-a4bc-21c9-ca21e808f0d1@redhat.com>
	<5BE0F9C9.2080003@huawei.com>
	<b4ce06c8-1c4b-724f-52e8-cb8d7b23fd27@redhat.com>
	<5BE107B5.2050900@huawei.com>
	<229559d5-1787-09b1-6c26-57b535f20006@redhat.com>
	<5BE12C72.6000204@huawei.com>
MIME-Version: 1.0
In-Reply-To: <5BE12C72.6000204@huawei.com>
User-Agent: Mutt/1.10.1 (2018-07-13)
X-Scanned-By: MIMEDefang 2.79 on 10.5.11.12
X-Greylist: Sender IP whitelisted, not delayed by milter-greylist-4.5.16
	(mx1.redhat.com [10.5.110.38]);
	Thu, 29 Nov 2018 14:19:35 +0000 (UTC)
X-Spam-Status: No, score=-6.9 required=5.0 tests=BAYES_00,RCVD_IN_DNSWL_HI
	autolearn=ham version=3.3.1
X-Spam-Checker-Version: SpamAssassin 3.3.1 (2010-03-16) on
	smtp1.linux-foundation.org
Cc: netdev@vger.kernel.org, kvm@vger.kernel.org,
	virtualization@lists.linux-foundation.org
X-BeenThere: virtualization@lists.linux-foundation.org
X-Mailman-Version: 2.1.12
Precedence: list
List-Id: Linux virtualization <virtualization.lists.linux-foundation.org>
List-Unsubscribe: <https://lists.linuxfoundation.org/mailman/options/virtualization>,
	<mailto:virtualization-request@lists.linux-foundation.org?subject=unsubscribe>
List-Archive: <http://lists.linuxfoundation.org/pipermail/virtualization/>
List-Post: <mailto:virtualization@lists.linux-foundation.org>
List-Help: <mailto:virtualization-request@lists.linux-foundation.org?subject=help>
List-Subscribe: <https://lists.linuxfoundation.org/mailman/listinfo/virtualization>,
	<mailto:virtualization-request@lists.linux-foundation.org?subject=subscribe>
Content-Type: multipart/mixed; boundary="===============2625636413438673550=="
Sender: virtualization-bounces@lists.linux-foundation.org
Errors-To: virtualization-bounces@lists.linux-foundation.org


--===============2625636413438673550==
Content-Type: multipart/signed; micalg=pgp-sha1;
	protocol="application/pgp-signature"; boundary="kfjH4zxOES6UT95V"
Content-Disposition: inline


--kfjH4zxOES6UT95V
Content-Type: text/plain; charset=utf-8
Content-Disposition: inline
Content-Transfer-Encoding: quoted-printable

On Tue, Nov 06, 2018 at 01:53:54PM +0800, jiangyiwen wrote:
> On 2018/11/6 11:32, Jason Wang wrote:
> >=20
> > On 2018/11/6 =E4=B8=8A=E5=8D=8811:17, jiangyiwen wrote:
> >> On 2018/11/6 10:41, Jason Wang wrote:
> >>> On 2018/11/6 =E4=B8=8A=E5=8D=8810:17, jiangyiwen wrote:
> >>>> On 2018/11/5 17:21, Jason Wang wrote:
> >>>>> On 2018/11/5 =E4=B8=8B=E5=8D=883:43, jiangyiwen wrote:
> >>>>>> Now vsock only support send/receive small packet, it can't achieve
> >>>>>> high performance. As previous discussed with Jason Wang, I revisit=
 the
> >>>>>> idea of vhost-net about mergeable rx buffer and implement the merg=
eable
> >>>>>> rx buffer in vhost-vsock, it can allow big packet to be scattered =
in
> >>>>>> into different buffers and improve performance obviously.
> >>>>>>
> >>>>>> I write a tool to test the vhost-vsock performance, mainly send big
> >>>>>> packet(64K) included guest->Host and Host->Guest. The result as
> >>>>>> follows:
> >>>>>>
> >>>>>> Before performance:
> >>>>>>                  Single socket            Multiple sockets(Max Ban=
dwidth)
> >>>>>> Guest->Host   ~400MB/s                 ~480MB/s
> >>>>>> Host->Guest   ~1450MB/s                ~1600MB/s
> >>>>>>
> >>>>>> After performance:
> >>>>>>                  Single socket            Multiple sockets(Max Ban=
dwidth)
> >>>>>> Guest->Host   ~1700MB/s                ~2900MB/s
> >>>>>> Host->Guest   ~1700MB/s                ~2900MB/s
> >>>>>>
> >>>>>>    From the test results, the performance is improved obviously, a=
nd guest
> >>>>>> memory will not be wasted.
> >>>>> Hi:
> >>>>>
> >>>>> Thanks for the patches and the numbers are really impressive.
> >>>>>
> >>>>> But instead of duplicating codes between sock and net. I was consid=
ering to use virtio-net as a transport of vsock. Then we may have all exist=
ed features likes batching, mergeable rx buffers and multiqueue. Want to co=
nsider this idea? Thoughts?
> >>>>>
> >>>>>
> >>>> Hi Jason,
> >>>>
> >>>> I am not very familiar with virtio-net, so I am afraid I can't give =
too
> >>>> much effective advice. Then I have several problems:
> >>>>
> >>>> 1. If use virtio-net as a transport, guest should see a virtio-net
> >>>> device instead of virtio-vsock device, right? Is vsock only as a
> >>>> transport between socket and net_device? User should still use
> >>>> AF_VSOCK type to create socket, right?
> >>>
> >>> Well, there're many choices. What you need is just to keep the socket=
 API and hide the implementation. For example, you can keep the vosck devic=
e in guest and switch to use vhost-net in host. We probably need a new feat=
ure bit or header to let vhost know we are passing vsock packet. And vhost-=
net could forward the packet to vsock core on host.
> >>>
> >>>
> >>>> 2. I want to know if this idea has already started, and how is
> >>>> the current progress?
> >>>
> >>> Not yet started.  Just want to listen from the community. If this sou=
nds good, do you have interest in implementing this?
> >>>
> >>>
> >>>> 3. And what is stefan's idea?
> >>>
> >>> Talk with Stefan a little on this during KVM Forum. I think he tends =
to agree on this idea. Anyway, let's wait for his reply.
> >>>
> >>>
> >>> Thanks
> >>>
> >>>
> >> Hi Jason,
> >>
> >> Thanks your reply, what you want is try to avoid duplicate code, and s=
till
> >> use the existed features with virtio-net.
> >=20
> >=20
> > Yes, technically we can use virtio-net driver is guest as well but we c=
ould do it step by step.
> >=20
> >=20
> >> Yes, if this sounds good and most people can recognize this idea, I am=
 very
> >> happy to implement this.
> >=20
> >=20
> > Cool, thanks.
> >=20
> >=20
> >>
> >> In addition, I hope you can review these patches before the new idea is
> >> implemented, after all the performance can be improved. :-)
> >=20
> >=20
> > Ok.
> >=20
> >=20
> > So the patch actually did three things:
> >=20
> > - mergeable buffer implementation
> >=20
> > - increase the default rx buffer size
> >=20
> > - add used and signal guest in a batch
> >=20
> > It would be helpful if you can measure the performance improvement inde=
pendently. This can give reviewer a better understanding on how much did ea=
ch part help.
> >=20
> > Thanks
> >=20
> >=20
>=20
> Great, I will test the performance independently in the later version.

I'm catching up on email so maybe you've already discussed this, but a
key design point in virtio-vsock is reliable in-order delivery.  When
using virtio-net code it's important to keep those properties so that
AF_VSOCK SOCK_STREAM sockets work as expected.  Packets must not be
reordered or dropped.

In addition, there's the virtio-vsock flow control scheme that allows
multiple sockets to share a ring without starvation or denial-of-service
problems.  The guest knows how much socket buffer space is available on
the host (and vice versa).  A well-behaved guest only sends up to the
available buffer space so that the host can copy the data into the
socket buffer and free up ring space for other sockets.  This scheme is
how virtio-vsock achieves guaranteed delivery while avoiding starvation
or denial-of-service.

So you'll need to use some kind of framing (protocol) that preserves
these properties on top of virtio-net.  This framing could be based on
virtio-vsock's packet headers.

Stefan

--kfjH4zxOES6UT95V
Content-Type: application/pgp-signature; name="signature.asc"

-----BEGIN PGP SIGNATURE-----

iQEcBAEBAgAGBQJb//VvAAoJEJykq7OBq3PIXVMIALRFVOEPu8o5ufxAnxdqbYIy
ZKy6L7Zoqt60JL0uMuGdoI2hm2vaZD3waoafCmv69Rj0iuwTAPa8gpdj3OLR+bDq
7ckNaNfmGx8daS41B4UZQ0PEhhz93JlzOyWyLDDvZPxlW1xX2E4G9zfFV8fF7ywi
X9XcKW845j3Xu26Buy+J5yVRyj/ycb7YTpt8rHgmZ2PxBTQSxVTAXrRUHIr+WZaS
2DqsvWn5c4oaXZLUsQn/Q4lzO1Fz8CpL0Gu9pUd8W6gcPO01SBK33u4sm5vKAjYM
eZ0O470xjDpjYkLGKeR73Xtrh7OuatXma++qqlVWaXRXph6e4c002TEuWzHvV98=
=0hK5
-----END PGP SIGNATURE-----

--kfjH4zxOES6UT95V--

--===============2625636413438673550==
Content-Type: text/plain; charset="us-ascii"
MIME-Version: 1.0
Content-Transfer-Encoding: 7bit
Content-Disposition: inline

_______________________________________________
Virtualization mailing list
Virtualization@lists.linux-foundation.org
https://lists.linuxfoundation.org/mailman/listinfo/virtualization
--===============2625636413438673550==--
