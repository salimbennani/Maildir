Return-Path: <linux-kernel-owner@vger.kernel.org>
Delivered-To: unknown
Received: from linux.intel.com (10.54.29.200:995) by likexu-workstation with
  POP3-SSL; 29 Nov 2018 08:40:27 -0000
X-Original-To: like.xu@linux.intel.com
Delivered-To: like.xu@linux.intel.com
Received: from orsmga003.jf.intel.com (orsmga003.jf.intel.com [10.7.209.27])
	(using TLSv1.2 with cipher ECDHE-RSA-AES256-GCM-SHA384 (256/256 bits))
	(No client certificate requested)
	by linux.intel.com (Postfix) with ESMTPS id E8F55580322;
	Wed, 28 Nov 2018 11:38:26 -0800 (PST)
Received: from orsmga106.jf.intel.com ([10.7.208.65])
  by orsmga003-1.jf.intel.com with ESMTP; 28 Nov 2018 11:38:26 -0800
X-SG-BADATTACHMENTNOREPLY: True
IronPort-PHdr: =?us-ascii?q?9a23=3A4WSu+x0A2zwq7u50smDT+DRfVm0co7zxezQtwd8Z?=
 =?us-ascii?q?segTI/jxwZ3uMQTl6Ol3ixeRBMOHs6IC07KempujcFRI2YyGvnEGfc4EfD4+ou?=
 =?us-ascii?q?JSoTYdBtWYA1bwNv/gYn9yNs1DUFh44yPzahANS47xaFLIv3K98yMZFAnhOgpp?=
 =?us-ascii?q?POT1HZPZg9iq2+yo9JDffwZFiCChbb9uMR67sRjfus4KjIV4N60/0AHJonxGe+?=
 =?us-ascii?q?RXwWNnO1eelAvi68mz4ZBu7T1et+ou+MBcX6r6eb84TaFDAzQ9L281/szrugLd?=
 =?us-ascii?q?QgaJ+3ART38ZkhtMAwjC8RH6QpL8uTb0u+ZhxCWXO9D9QLYpUjqg8qhrUgflhi?=
 =?us-ascii?q?kFODA6/27XhMt+gr9brhy/uxN/2JbUbYOOOfpiYq/QZ88WSHBdUstTUSFKH4Oy?=
 =?us-ascii?q?b5EID+oEJetVspP9qEUIrRSjHwasAv7kxD1Jhn/50q060uIhERrb1wEnBN0Oqm?=
 =?us-ascii?q?rbrNPoO6gIV+C1zKjIzTrMb/NX3zf985PFch8mofGLUrJwddTexVMzGAPCi1Wd?=
 =?us-ascii?q?sIroNC6b2OQKtmiU9etgVeS3hm4orAFxpTevxsMyhYnSgYIV10rE+jlnz4ovOd?=
 =?us-ascii?q?K4T0t7bcarEJtRqyGaN5Z2Tdg4T250vyY6z6UKuZuhcygQ1JQnxhjfa/KAc4mG?=
 =?us-ascii?q?5hLsSvyRLS1ki3JifbKygQu5/0u4yuDkSMW4zFJHojBYntTCqHwBzQHf58ubRv?=
 =?us-ascii?q?dn/0qs2y6D2x7P5uxAO0w5lqrWJ4Q8zrMxl5cfq0bOEyDwlU7rlqGZbF8k9fKt?=
 =?us-ascii?q?6+n/YrXpuJucN4hshwHgPaQhhNa/Df47MgcQRWib//qz1Ln58U3+WrVKgeU6kq?=
 =?us-ascii?q?jfsJ/EOcQWvrC1DxNR34o59hqyASmq3M4FkXQEMF5JYhOKgorxN1HLOv/4DPO/?=
 =?us-ascii?q?g1q2kDdswvDLJrnhApTLLnjen7btZLV95FBGyAo1099f44tYCrYPIfL1REDxrs?=
 =?us-ascii?q?fVDgE2MwOq2ebrEtZ92Z0EWWKJHKCZNLnesViS5uIgO+WMfpMauC7hK/g54P7j?=
 =?us-ascii?q?lXs5mV4efaa3x5cWZ224E+9iI0WYZ3rsn9gAHX0Lvgo4UOzlllmCXSRPaHa1Wq?=
 =?us-ascii?q?I2/is7B56+DYffWoCth6SM3CehEZ1XemBJEFeMHW3od4WZQfgMbi2SL9RlkjwF?=
 =?us-ascii?q?U7ihVoAg2QuvtA/817poMO7U9jcEupLk0dh///fTmg0q9TxoE8Sd1HmAT2Nznm?=
 =?us-ascii?q?wWXTM236d/oUp7yleEyqV4h/1YFdpO5/JGSAs6NJjcz/BkBND2QA7OYtCJSFO+?=
 =?us-ascii?q?SNW8HT4xVs4xw8MJY0tlAdqilRDD3y2pA7MPjbyEHp40/7nY33jwIcZ91nnH2L?=
 =?us-ascii?q?Mgj1kgXstAK2mmirRj+AjUAo7Di1+ZmLqydaQAwC7N83+OzWmUs0FeSgJwVaTF?=
 =?us-ascii?q?UmoZZkvZttn54kLCT7mzCbUoKAdByMiCKrdUZd3tl1lJWPDjONHGaWKrh2iwHQ?=
 =?us-ascii?q?qIxq+LbIfyZmoSxjvdB1YenwAT53mGMxM+CTmno27ZCDxuFlfvY0f3/Ol6qXO7?=
 =?us-ascii?q?SFI0zg6QY01g0bq15gAahfiGR/wP2bIEvT8rqy9oE1alw9LWF92AqhJ8c6pGf9?=
 =?us-ascii?q?My/k1L1WLDuAx7JZyvMaZii0UacwR2uUPuyhp2Bp9BkcgssHMl0g5yJbiE31NG?=
 =?us-ascii?q?cjOSxYrwNaHPKmnu4BCvbLbb2k3f0NaT/acP9PQ4qlX5sAG1DEYi9G9n091U03?=
 =?us-ascii?q?ua6ZXHFw4SUZP3UkYq+Bl2vbDaYi8h54zK0X1gK7W7sjjH29gxHusq1g6gf8tD?=
 =?us-ascii?q?MKODDAL9CckaCNahKeM0m1mldAkLPP1P+6EuOcOmdPyG2LCwMeZknTKmi3lH4Y?=
 =?us-ascii?q?9n3kKN8Sp8VvDH35Ifz/6E2QuHUi/2jE29vcDvhYBEeTYSE3K/yCj5HoJeerd+?=
 =?us-ascii?q?fIcLCWi0Jc23yc5zh5rsW35e6V6iCEkK2M6veRqOcVP92Rdc2lgQoXyigSG41S?=
 =?us-ascii?q?B7kyk1rqqD2yzD2/7idBsbNWFRXmltkFDsLZKyj98ERkiobhElmwe/6kb+2qdU?=
 =?us-ascii?q?ur5/L27VQUpTeyj2LmdiUra/t7aYYs5P7o8ovjtTUOimfV+aTbv9qQMA0yz/B2?=
 =?us-ascii?q?te2Cw7dzayt5T5nhx2kmKcIGxorHrEf8F93hPf5N3aRf5M0TsKXih4iT/LBlei?=
 =?us-ascii?q?O9ml58mbl5DGsuqmTWKuSoVTcTX3zYOHrCa753dlAQe8n/Cwnd3rCxM63jX419?=
 =?us-ascii?q?lpVCXIqgjzYo/w2qS+MOJneFRoBVDm58p7HIF+jpU/hJUK1XcGgZWV+GINkX3v?=
 =?us-ascii?q?PtVDxaL+cH0NSCYLwtHP5wjpwk9jLnOPx4/iUnWdw81hZ8S1Y28M2yI96dxKB7?=
 =?us-ascii?q?mQ7LBegSR1pV+4pxrLYfdhhjcd1ecu6HkCjuEKogUtzz+RArAPHUZCOyzsmA+F?=
 =?us-ascii?q?79S/rKVReWaufqK81Et4ndC9Er6CphtQV2r+epcnBSVw9NlwMErQ0H3v7YHpYN?=
 =?us-ascii?q?zQbdMQthKOiRvBgfZaKIktlvUUnypoInzyvWcqy+MgiRxu3Je6vJWIKml3/aK5?=
 =?us-ascii?q?BAJYOSPxZ88J5j7tiqNelN6M34+zBpVhBikLXJzwQPK0FzISsO7rNgeUHz06t3?=
 =?us-ascii?q?ebAqHfHQ6E5UdirnLPFY2rNn6NKHkYy9ViWAeSJEhFjA8IWzU6m4YzFhq2y8z5?=
 =?us-ascii?q?bEd5+jcR60bjpRRWzeJoMwT/Xn3bpAe1cTo0TJmfLBxL7gBN/UvVMMqe7v5tEC?=
 =?us-ascii?q?Fc5JGusAuNKmmDbQRSEW4JQlCEB0zkPrS259nP6e2YCfSlL/fUfbWCs+9eV+qL?=
 =?us-ascii?q?xZKy1Itp5S2MO96LPnljCf07x0VCUWp4G8TfhzUAVSgXmzjRYM6coRe24jd3od?=
 =?us-ascii?q?yn8PT3RALv4pOCCrtVMdVy4hC2nL2MN+iKiCZiLjZY0JwMyGTMyLge2l4Sli5v?=
 =?us-ascii?q?eyOsEbQGqS7CUqbQlrVLAB4cbiN5LNFI4L4k3glRJc7bjcv41r5mgf40CFdFVl?=
 =?us-ascii?q?3hltuqZcwQJGG9O03IBFyWNLSdPjDLx8D3YaWhSbxflulUthuwuSqFHE/nJDiM?=
 =?us-ascii?q?iz7pVxW3O+FWkC6bJABeuJ26cht1E2fjUcnpagelP953lzE2xbw0i2jONW4dNz?=
 =?us-ascii?q?h8bkxMoqeR7SNenvVwBWhB4mB5IumDniaT9/PYJYoOsft3HiR0kPpX4Gg7y7tQ?=
 =?us-ascii?q?9i1LWOZ5lzfSrtFwpVGrie2PyjthUBpTpTdHnoOLvUN+OarH8plMQ2rL/BUI7W?=
 =?us-ascii?q?+IERQFu8NlCsHzu6BX0tXOlLj8KDFH89LV+8sTH8nVKMKdP3onPhrkAzrUDAoD?=
 =?us-ascii?q?TT62OmDTnU1dkPeO9nKLqpg2sITjmJ0LSuwTaFtgGekXBUdlNNgDJopnUDQ5l7?=
 =?us-ascii?q?KSkM8P4zy5thaVDMZXs4vMUfWRKfroLzmdgP9PYB5MibbzIp4UOKX41lZkZ108?=
 =?us-ascii?q?m57FXwLLXc1EogViYxUyrUEL92JxHUMp3EewQBmg5nMaE7aUnxE5iw1lKbAn7j?=
 =?us-ascii?q?rq714xJlvFqyo2i2E+ntLqhT3Xezn0evTjFbpKAjb54hBieqjwRBx4OFW/?=
X-IronPort-Anti-Spam-Filtered: true
X-IronPort-Anti-Spam-Result: =?us-ascii?q?A0AeAABT7f5bh0O0hNFjHgEGBwaBUQkLA?=
 =?us-ascii?q?YFagQ9LNyeDeZQggiGIfIUsiQaBJANQKA0GAYQ8AoMwIjQJDQEDAQEBAQEBAgE?=
 =?us-ascii?q?TAQEBCA0JCCkjDII2IoJlAwMBAhcJBBkBATcBBQkBARwIAiYCAgMeEwEFAQ4OB?=
 =?us-ascii?q?xIFgxwBgWkDFQUKm1c8ih1wfDOCdgEBBYEwAYETgkQNghQIEnmGYIQrF4FAP4E?=
 =?us-ascii?q?RhWlHAgEBgTkKgyCCNSKJIQYEhXt3UI5bJy4JgiCDEoFLgnE8gx49gyELGIFaI?=
 =?us-ascii?q?yqHZ4cHiHaEXoELiVowgSVsgSEzGiNQgmwJCYIJCQMXfwECgkiFZYUPHjOBBQE?=
 =?us-ascii?q?BixeCTAEB?=
X-IPAS-Result: =?us-ascii?q?A0AeAABT7f5bh0O0hNFjHgEGBwaBUQkLAYFagQ9LNyeDeZQ?=
 =?us-ascii?q?ggiGIfIUsiQaBJANQKA0GAYQ8AoMwIjQJDQEDAQEBAQEBAgETAQEBCA0JCCkjD?=
 =?us-ascii?q?II2IoJlAwMBAhcJBBkBATcBBQkBARwIAiYCAgMeEwEFAQ4OBxIFgxwBgWkDFQU?=
 =?us-ascii?q?Km1c8ih1wfDOCdgEBBYEwAYETgkQNghQIEnmGYIQrF4FAP4ERhWlHAgEBgTkKg?=
 =?us-ascii?q?yCCNSKJIQYEhXt3UI5bJy4JgiCDEoFLgnE8gx49gyELGIFaIyqHZ4cHiHaEXoE?=
 =?us-ascii?q?LiVowgSVsgSEzGiNQgmwJCYIJCQMXfwECgkiFZYUPHjOBBQEBixeCTAEB?=
X-IronPort-AV: E=Sophos;i="5.56,291,1539673200"; 
   d="scan'208";a="41963189"
X-Amp-Result: SKIPPED(no attachment in message)
X-Amp-File-Uploaded: False
Received: from vger.kernel.org ([209.132.180.67])
  by mtab.intel.com with ESMTP; 28 Nov 2018 11:38:24 -0800
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
        id S1729510AbeK2GlE (ORCPT <rfc822;like.xu@linux.intel.com>
        + 23 others); Thu, 29 Nov 2018 01:41:04 -0500
Received: from mail-io1-f74.google.com ([209.85.166.74]:55734 "EHLO
        mail-io1-f74.google.com" rhost-flags-OK-OK-OK-OK) by vger.kernel.org
        with ESMTP id S1729433AbeK2GlD (ORCPT
        <rfc822;linux-kernel@vger.kernel.org>);
        Thu, 29 Nov 2018 01:41:03 -0500
Received: by mail-io1-f74.google.com with SMTP id m5so11100483iok.22
        for <linux-kernel@vger.kernel.org>; Wed, 28 Nov 2018 11:38:18 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=google.com; s=20161025;
        h=date:in-reply-to:message-id:mime-version:references:subject:from:to
         :cc;
        bh=d6uvqmmiqPZQcRsjwqxUb50lbmxr9QOMc7S4OZk1tZs=;
        b=g5L6XKb2n1pLBlD2qCqIPfv56xWm4u4y4ZStuJiuGj3tQVWRMRW+qP/nQIus+XTVbl
         w5pLR6jMjQtTpfR+opfQWhObaVWO1CqOeAq1ZGJt26PMSzb6xtYs8AhFxUfKpox1bXq4
         uvi+dXel4QYseU+tdHpr9/VVLwKA9BwzODv73YNdtgaiWG+/lgMg1zjizfbDp8KA+Qqv
         cOKQlBEo/uazNvsSqv83WOvkwiik7lzzO15LCFgPKLlcr2Iq9jHsCUbhkFNovZNoA59l
         Zx6D1wOtAAE+PP/MeaxZJEGtQU8WiX7ajH6bxA1Sqqkac1M3RGPSTxOrUmZllNB2C3tU
         CKbw==
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20161025;
        h=x-gm-message-state:date:in-reply-to:message-id:mime-version
         :references:subject:from:to:cc;
        bh=d6uvqmmiqPZQcRsjwqxUb50lbmxr9QOMc7S4OZk1tZs=;
        b=Wh6eyYofDYcr+Bj6dSHMnyMPDHsqGwZsjNIK1xEhtKtAAznCIADUfa3MvYze19CH5Y
         c63f10C8ajtlWlvM11SswPh7HAz6KKiNh0lW87pyEdl/u2cK6Xoz5tt6DuMu2N8Uzau+
         0Iqdjeo96Lu9AGojMtG9sJME31f5s3zYWBHWLpvfXZy6k/2kDFAIydl0T82XVn+JHYD+
         4JE3sUWlO2DUzt5Tl7n9O/DuuxBeTUGXu1beaX4AYH8vHeqcaqHc8nfCEEjAC7F0Knpq
         sohmSiwLQ456NVbLrawf4f/1S5WazJDT0RaloFUO3rbkwisRShtCafbTBUMERazbf337
         Sr2A==
X-Gm-Message-State: AA+aEWYA0lFwKQ8TFUh7vZ42kcydQR6dLELOX1nRS3m3wpwt1n9ln9d5
        82zQg2aow4gBYo5ZueLBSUgJZu4a1k5Fhguv5iPiwg==
X-Google-Smtp-Source: AFSGD/U8nIbmFCXwrlRT53SqZChqPAonPAuTb8EOMXvm52RWLK/kOpOgeaRUF7MvLS2H/4Bc7b7XJi4+0a/o1Z7aNuJSmg==
X-Received: by 2002:a24:2793:: with SMTP id g141-v6mr3305750ita.39.1543433898077;
 Wed, 28 Nov 2018 11:38:18 -0800 (PST)
Date: Wed, 28 Nov 2018 11:36:31 -0800
In-Reply-To: <20181128193636.254378-1-brendanhiggins@google.com>
Message-Id: <20181128193636.254378-15-brendanhiggins@google.com>
Mime-Version: 1.0
References: <20181128193636.254378-1-brendanhiggins@google.com>
X-Mailer: git-send-email 2.20.0.rc0.387.gc7a69e6b6c-goog
Subject: [RFC v3 14/19] Documentation: kunit: add documentation for KUnit
From: Brendan Higgins <brendanhiggins@google.com>
To: gregkh@linuxfoundation.org, keescook@google.com, mcgrof@kernel.org,
        shuah@kernel.org
Cc: joel@jms.id.au, mpe@ellerman.id.au, joe@perches.com, brakmo@fb.com,
        rostedt@goodmis.org, Tim.Bird@sony.com, khilman@baylibre.com,
        julia.lawall@lip6.fr, linux-kselftest@vger.kernel.org,
        kunit-dev@googlegroups.com, linux-kernel@vger.kernel.org,
        jdike@addtoit.com, richard@nod.at, linux-um@lists.infradead.org,
        daniel@ffwll.ch, dri-devel@lists.freedesktop.org, robh@kernel.org,
        dan.j.williams@intel.com, linux-nvdimm@lists.01.org,
        kieran.bingham@ideasonboard.com, frowand.list@gmail.com,
        knut.omang@oracle.com, Brendan Higgins <brendanhiggins@google.com>,
        Felix Guo <felixguoxiuping@gmail.com>
Content-Type: text/plain; charset="UTF-8"
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: <linux-kernel.vger.kernel.org>
X-Mailing-List: linux-kernel@vger.kernel.org

Add documentation for KUnit, the Linux kernel unit testing framework.
- Add intro and usage guide for KUnit
- Add API reference

Signed-off-by: Felix Guo <felixguoxiuping@gmail.com>
Signed-off-by: Brendan Higgins <brendanhiggins@google.com>
---
 Documentation/index.rst           |   1 +
 Documentation/kunit/api/index.rst |  16 ++
 Documentation/kunit/api/test.rst  |  15 +
 Documentation/kunit/faq.rst       |  46 +++
 Documentation/kunit/index.rst     |  80 ++++++
 Documentation/kunit/start.rst     | 180 ++++++++++++
 Documentation/kunit/usage.rst     | 447 ++++++++++++++++++++++++++++++
 7 files changed, 785 insertions(+)
 create mode 100644 Documentation/kunit/api/index.rst
 create mode 100644 Documentation/kunit/api/test.rst
 create mode 100644 Documentation/kunit/faq.rst
 create mode 100644 Documentation/kunit/index.rst
 create mode 100644 Documentation/kunit/start.rst
 create mode 100644 Documentation/kunit/usage.rst

diff --git a/Documentation/index.rst b/Documentation/index.rst
index 5db7e87c7cb1d..275ef4db79f61 100644
--- a/Documentation/index.rst
+++ b/Documentation/index.rst
@@ -68,6 +68,7 @@ merged much easier.
    kernel-hacking/index
    trace/index
    maintainer/index
+   kunit/index
 
 Kernel API documentation
 ------------------------
diff --git a/Documentation/kunit/api/index.rst b/Documentation/kunit/api/index.rst
new file mode 100644
index 0000000000000..c31c530088153
--- /dev/null
+++ b/Documentation/kunit/api/index.rst
@@ -0,0 +1,16 @@
+.. SPDX-License-Identifier: GPL-2.0
+
+=============
+API Reference
+=============
+.. toctree::
+
+	test
+
+This section documents the KUnit kernel testing API. It is divided into 3
+sections:
+
+================================= ==============================================
+:doc:`test`                       documents all of the standard testing API
+                                  excluding mocking or mocking related features.
+================================= ==============================================
diff --git a/Documentation/kunit/api/test.rst b/Documentation/kunit/api/test.rst
new file mode 100644
index 0000000000000..7c926014f047c
--- /dev/null
+++ b/Documentation/kunit/api/test.rst
@@ -0,0 +1,15 @@
+.. SPDX-License-Identifier: GPL-2.0
+
+========
+Test API
+========
+
+This file documents all of the standard testing API excluding mocking or mocking
+related features.
+
+.. kernel-doc:: include/kunit/test.h
+   :internal:
+
+.. kernel-doc:: include/kunit/kunit-stream.h
+   :internal:
+
diff --git a/Documentation/kunit/faq.rst b/Documentation/kunit/faq.rst
new file mode 100644
index 0000000000000..cb8e4fb2257a0
--- /dev/null
+++ b/Documentation/kunit/faq.rst
@@ -0,0 +1,46 @@
+.. SPDX-License-Identifier: GPL-2.0
+
+=========================================
+Frequently Asked Questions
+=========================================
+
+How is this different from Autotest, kselftest, etc?
+====================================================
+KUnit is a unit testing framework. Autotest, kselftest (and some others) are
+not.
+
+A `unit test <https://martinfowler.com/bliki/UnitTest.html>`_ is supposed to
+test a single unit of code in isolation, hence the name. A unit test should be
+the finest granularity of testing and as such should allow all possible code
+paths to be tested in the code under test; this is only possible if the code
+under test is very small and does not have any external dependencies outside of
+the test's control like hardware.
+
+There are no testing frameworks currently available for the kernel that do not
+require installing the kernel on a test machine or in a VM and all require
+tests to be written in userspace and run on the kernel under test; this is true
+for Autotest, kselftest, and some others, disqualifying any of them from being
+considered unit testing frameworks.
+
+What is the difference between a unit test and these other kinds of tests?
+==========================================================================
+Most existing tests for the Linux kernel would be categorized as an integration
+test, or an end-to-end test.
+
+- A unit test is supposed to test a single unit of code in isolation, hence the
+  name. A unit test should be the finest granularity of testing and as such
+  should allow all possible code paths to be tested in the code under test; this
+  is only possible if the code under test is very small and does not have any
+  external dependencies outside of the test's control like hardware.
+- An integration test tests the interaction between a minimal set of components,
+  usually just two or three. For example, someone might write an integration
+  test to test the interaction between a driver and a piece of hardware, or to
+  test the interaction between the userspace libraries the kernel provides and
+  the kernel itself; however, one of these tests would probably not test the
+  entire kernel along with hardware interactions and interactions with the
+  userspace.
+- An end-to-end test usually tests the entire system from the perspective of the
+  code under test. For example, someone might write an end-to-end test for the
+  kernel by installing a production configuration of the kernel on production
+  hardware with a production userspace and then trying to exercise some behavior
+  that depends on interactions between the hardware, the kernel, and userspace.
diff --git a/Documentation/kunit/index.rst b/Documentation/kunit/index.rst
new file mode 100644
index 0000000000000..c6710211b647f
--- /dev/null
+++ b/Documentation/kunit/index.rst
@@ -0,0 +1,80 @@
+.. SPDX-License-Identifier: GPL-2.0
+
+=========================================
+KUnit - Unit Testing for the Linux Kernel
+=========================================
+
+.. toctree::
+	:maxdepth: 2
+
+	start
+	usage
+	api/index
+	faq
+
+What is KUnit?
+==============
+
+KUnit is a lightweight unit testing and mocking framework for the Linux kernel.
+These tests are able to be run locally on a developer's workstation without a VM
+or special hardware.
+
+KUnit is heavily inspired by JUnit, Python's unittest.mock, and
+Googletest/Googlemock for C++. KUnit provides facilities for defining unit test
+cases, grouping related test cases into test suites, providing common
+infrastructure for running tests, and much more.
+
+Get started now: :doc:`start`
+
+Why KUnit?
+==========
+
+A unit test is supposed to test a single unit of code in isolation, hence the
+name. A unit test should be the finest granularity of testing and as such should
+allow all possible code paths to be tested in the code under test; this is only
+possible if the code under test is very small and does not have any external
+dependencies outside of the test's control like hardware.
+
+Outside of KUnit, there are no testing frameworks currently
+available for the kernel that do not require installing the kernel on a test
+machine or in a VM and all require tests to be written in userspace running on
+the kernel; this is true for Autotest, and kselftest, disqualifying
+any of them from being considered unit testing frameworks.
+
+KUnit addresses the problem of being able to run tests without needing a virtual
+machine or actual hardware with User Mode Linux. User Mode Linux is a Linux
+architecture, like ARM or x86; however, unlike other architectures it compiles
+to a standalone program that can be run like any other program directly inside
+of a host operating system; to be clear, it does not require any virtualization
+support; it is just a regular program.
+
+KUnit is fast. Excluding build time, from invocation to completion KUnit can run
+several dozen tests in only 10 to 20 seconds; this might not sound like a big
+deal to some people, but having such fast and easy to run tests fundamentally
+changes the way you go about testing and even writing code in the first place.
+Linus himself said in his `git talk at Google
+<https://gist.github.com/lorn/1272686/revisions#diff-53c65572127855f1b003db4064a94573R874>`_:
+
+	"... a lot of people seem to think that performance is about doing the
+	same thing, just doing it faster, and that is not true. That is not what
+	performance is all about. If you can do something really fast, really
+	well, people will start using it differently."
+
+In this context Linus was talking about branching and merging,
+but this point also applies to testing. If your tests are slow, unreliable, are
+difficult to write, and require a special setup or special hardware to run,
+then you wait a lot longer to write tests, and you wait a lot longer to run
+tests; this means that tests are likely to break, unlikely to test a lot of
+things, and are unlikely to be rerun once they pass. If your tests are really
+fast, you run them all the time, every time you make a change, and every time
+someone sends you some code. Why trust that someone ran all their tests
+correctly on every change when you can just run them yourself in less time than
+it takes to read his / her test log?
+
+How do I use it?
+===================
+
+*   :doc:`start` - for new users of KUnit
+*   :doc:`usage` - for a more detailed explanation of KUnit features
+*   :doc:`api/index` - for the list of KUnit APIs used for testing
+
diff --git a/Documentation/kunit/start.rst b/Documentation/kunit/start.rst
new file mode 100644
index 0000000000000..5cdba5091905e
--- /dev/null
+++ b/Documentation/kunit/start.rst
@@ -0,0 +1,180 @@
+.. SPDX-License-Identifier: GPL-2.0
+
+===============
+Getting Started
+===============
+
+Installing dependencies
+=======================
+KUnit has the same dependencies as the Linux kernel. As long as you can build
+the kernel, you can run KUnit.
+
+KUnit Wrapper
+=============
+Included with KUnit is a simple Python wrapper that helps format the output to
+easily use and read KUnit output. It handles building and running the kernel, as
+well as formatting the output.
+
+The wrapper can be run with:
+
+.. code-block:: bash
+
+   ./tools/testing/kunit/kunit.py
+
+Creating a kunitconfig
+======================
+The Python script is a thin wrapper around Kbuild as such, it needs to be
+configured with a ``kunitconfig`` file. This file essentially contains the
+regular Kernel config, with the specific test targets as well.
+
+.. code-block:: bash
+
+	git clone -b master https://kunit.googlesource.com/kunitconfig $PATH_TO_KUNITCONFIG_REPO
+	cd $PATH_TO_LINUX_REPO
+	ln -s $PATH_TO_KUNIT_CONFIG_REPO/kunitconfig kunitconfig
+
+You may want to add kunitconfig to your local gitignore.
+
+Verifying KUnit Works
+-------------------------
+
+To make sure that everything is set up correctly, simply invoke the Python
+wrapper from your kernel repo:
+
+.. code-block:: bash
+
+	./tools/testing/kunit/kunit.py
+
+.. note::
+   You may want to run ``make mrproper`` first.
+
+If everything worked correctly, you should see the following:
+
+.. code-block:: bash
+
+	Generating .config ...
+	Building KUnit Kernel ...
+	Starting KUnit Kernel ...
+
+followed by a list of tests that are run. All of them should be passing.
+
+.. note::
+   Because it is building a lot of sources for the first time, the ``Building
+   kunit kernel`` step may take a while.
+
+Writing your first test
+==========================
+
+In your kernel repo let's add some code that we can test. Create a file
+``drivers/misc/example.h`` with the contents:
+
+.. code-block:: c
+
+	int misc_example_add(int left, int right);
+
+create a file ``drivers/misc/example.c``:
+
+.. code-block:: c
+
+	#include <linux/errno.h>
+
+	#include "example.h"
+
+	int misc_example_add(int left, int right)
+	{
+		return left + right;
+	}
+
+Now add the following lines to ``drivers/misc/Kconfig``:
+
+.. code-block:: kconfig
+
+	config MISC_EXAMPLE
+		bool "My example"
+
+and the following lines to ``drivers/misc/Makefile``:
+
+.. code-block:: make
+
+	obj-$(CONFIG_MISC_EXAMPLE) += example.o
+
+Now we are ready to write the test. The test will be in
+``drivers/misc/example-test.c``:
+
+.. code-block:: c
+
+	#include <kunit/test.h>
+	#include "example.h"
+
+	/* Define the test cases. */
+
+	static void misc_example_add_test_basic(struct kunit *test)
+	{
+		KUNIT_EXPECT_EQ(test, 1, misc_example_add(1, 0));
+		KUNIT_EXPECT_EQ(test, 2, misc_example_add(1, 1));
+		KUNIT_EXPECT_EQ(test, 0, misc_example_add(-1, 1));
+		KUNIT_EXPECT_EQ(test, INT_MAX, misc_example_add(0, INT_MAX));
+		KUNIT_EXPECT_EQ(test, -1, misc_example_add(INT_MAX, INT_MIN));
+	}
+
+	static void misc_example_test_failure(struct kunit *test)
+	{
+		KUNIT_FAIL(test, "This test never passes.");
+	}
+
+	static struct kunit_case misc_example_test_cases[] = {
+		KUNIT_CASE(misc_example_add_test_basic),
+		KUNIT_CASE(misc_example_test_failure),
+		{},
+	};
+
+	static struct kunit_module misc_example_test_module = {
+		.name = "misc-example",
+		.test_cases = misc_example_test_cases,
+	};
+	module_test(misc_example_test_module);
+
+Now add the following to ``drivers/misc/Kconfig``:
+
+.. code-block:: kconfig
+
+	config MISC_EXAMPLE_TEST
+		bool "Test for my example"
+		depends on MISC_EXAMPLE && KUNIT
+
+and the following to ``drivers/misc/Makefile``:
+
+.. code-block:: make
+
+	obj-$(CONFIG_MISC_EXAMPLE_TEST) += example-test.o
+
+Now add it to your ``kunitconfig``:
+
+.. code-block:: none
+
+	CONFIG_MISC_EXAMPLE=y
+	CONFIG_MISC_EXAMPLE_TEST=y
+
+Now you can run the test:
+
+.. code-block:: bash
+
+	./tools/testing/kunit/kunit.py
+
+You should see the following failure:
+
+.. code-block:: none
+
+	...
+	[16:08:57] [PASSED] misc-example:misc_example_add_test_basic
+	[16:08:57] [FAILED] misc-example:misc_example_test_failure
+	[16:08:57] EXPECTATION FAILED at drivers/misc/example-test.c:17
+	[16:08:57] 	This test never passes.
+	...
+
+Congrats! You just wrote your first KUnit test!
+
+Next Steps
+=============
+*   Check out the :doc:`usage` page for a more
+    in-depth explanation of KUnit.
diff --git a/Documentation/kunit/usage.rst b/Documentation/kunit/usage.rst
new file mode 100644
index 0000000000000..96ef7f9a1add4
--- /dev/null
+++ b/Documentation/kunit/usage.rst
@@ -0,0 +1,447 @@
+.. SPDX-License-Identifier: GPL-2.0
+
+=============
+Using KUnit
+=============
+
+The purpose of this document is to describe what KUnit is, how it works, how it
+is intended to be used, and all the concepts and terminology that are needed to
+understand it. This guide assumes a working knowledge of the Linux kernel and
+some basic knowledge of testing.
+
+For a high level introduction to KUnit, including setting up KUnit for your
+project, see :doc:`start`.
+
+Organization of this document
+=================================
+
+This document is organized into two main sections: Testing and Isolating
+Behavior. The first covers what a unit test is and how to use KUnit to write
+them. The second covers how to use KUnit to isolate code and make it possible
+to unit test code that was otherwise un-unit-testable.
+
+Testing
+==========
+
+What is KUnit?
+------------------
+
+"K" is short for "kernel" so "KUnit" is the "(Linux) Kernel Unit Testing
+Framework." KUnit is intended first and foremost for writing unit tests; it is
+general enough that it can be used to write integration tests; however, this is
+a secondary goal. KUnit has no ambition of being the only testing framework for
+the kernel; for example, it does not intend to be an end-to-end testing
+framework.
+
+What is Unit Testing?
+-------------------------
+
+A `unit test <https://martinfowler.com/bliki/UnitTest.html>`_ is a test that
+tests code at the smallest possible scope, a *unit* of code. In the C
+programming language that's a function.
+
+Unit tests should be written for all the publicly exposed functions in a
+compilation unit; so that is all the functions that are exported in either a
+*class* (defined below) or all functions which are **not** static.
+
+Writing Tests
+-------------
+
+Test Cases
+~~~~~~~~~~
+
+The fundamental unit in KUnit is the test case. A test case is a function with
+the signature ``void (*)(struct kunit *test)``. It calls a function to be tested
+and then sets *expectations* for what should happen. For example:
+
+.. code-block:: c
+
+	void example_test_success(struct kunit *test)
+	{
+	}
+
+	void example_test_failure(struct kunit *test)
+	{
+		KUNIT_FAIL(test, "This test never passes.");
+	}
+
+In the above example ``example_test_success`` always passes because it does
+nothing; no expectations are set, so all expectations pass. On the other hand
+``example_test_failure`` always fails because it calls ``KUNIT_FAIL``, which is
+a special expectation that logs a message and causes the test case to fail.
+
+Expectations
+~~~~~~~~~~~~
+An *expectation* is a way to specify that you expect a piece of code to do
+something in a test. An expectation is called like a function. A test is made
+by setting expectations about the behavior of a piece of code under test; when
+one or more of the expectations fail, the test case fails and information about
+the failure is logged. For example:
+
+.. code-block:: c
+
+	void add_test_basic(struct kunit *test)
+	{
+		KUNIT_EXPECT_EQ(test, 1, add(1, 0));
+		KUNIT_EXPECT_EQ(test, 2, add(1, 1));
+	}
+
+In the above example ``add_test_basic`` makes a number of assertions about the
+behavior of a function called ``add``; the first parameter is always of type
+``struct kunit *``, which contains information about the current test context;
+the second parameter, in this case, is what the value is expected to be; the
+last value is what the value actually is. If ``add`` passes all of these
+expectations, the test case, ``add_test_basic`` will pass; if any one of these
+expectations fail, the test case will fail.
+
+It is important to understand that a test case *fails* when any expectation is
+violated; however, the test will continue running, potentially trying other
+expectations until the test case ends or is otherwise terminated. This is as
+opposed to *assertions* which are discussed later.
+
+To learn about more expectations supported by KUnit, see :doc:`api/test`.
+
+.. note::
+   A single test case should be pretty short, pretty easy to understand,
+   focused on a single behavior.
+
+For example, if we wanted to properly test the add function above, we would
+create additional tests cases which would each test a different property that an
+add function should have like this:
+
+.. code-block:: c
+
+	void add_test_basic(struct kunit *test)
+	{
+		KUNIT_EXPECT_EQ(test, 1, add(1, 0));
+		KUNIT_EXPECT_EQ(test, 2, add(1, 1));
+	}
+
+	void add_test_negative(struct kunit *test)
+	{
+		KUNIT_EXPECT_EQ(test, 0, add(-1, 1));
+	}
+
+	void add_test_max(struct kunit *test)
+	{
+		KUNIT_EXPECT_EQ(test, INT_MAX, add(0, INT_MAX));
+		KUNIT_EXPECT_EQ(test, -1, add(INT_MAX, INT_MIN));
+	}
+
+	void add_test_overflow(struct kunit *test)
+	{
+		KUNIT_EXPECT_EQ(test, INT_MIN, add(INT_MAX, 1));
+	}
+
+Notice how it is immediately obvious what all the properties that we are testing
+for are.
+
+Assertions
+~~~~~~~~~~
+
+KUnit also has the concept of an *assertion*. An assertion is just like an
+expectation except the assertion immediately terminates the test case if it is
+not satisfied.
+
+For example:
+
+.. code-block:: c
+
+	static void mock_test_do_expect_default_return(struct kunit *test)
+	{
+		struct mock_test_context *ctx = test->priv;
+		struct mock *mock = ctx->mock;
+		int param0 = 5, param1 = -5;
+		const char *two_param_types[] = {"int", "int"};
+		const void *two_params[] = {&param0, &param1};
+		const void *ret;
+
+		ret = mock->do_expect(mock,
+				      "test_printk", test_printk,
+				      two_param_types, two_params,
+				      ARRAY_SIZE(two_params));
+		KUNIT_ASSERT_NOT_ERR_OR_NULL(test, ret);
+		KUNIT_EXPECT_EQ(test, -4, *((int *) ret));
+	}
+
+In this example, the method under test should return a pointer to a value, so
+if the pointer returned by the method is null or an errno, we don't want to
+bother continuing the test since the following expectation could crash the test
+case. `ASSERT_NOT_ERR_OR_NULL(...)` allows us to bail out of the test case if
+the appropriate conditions have not been satisfied to complete the test.
+
+Modules / Test Suites
+~~~~~~~~~~~~~~~~~~~~~
+
+Now obviously one unit test isn't very helpful; the power comes from having
+many test cases covering all of your behaviors. Consequently it is common to
+have many *similar* tests; in order to reduce duplication in these closely
+related tests most unit testing frameworks provide the concept of a *test
+suite*, in KUnit we call it a *test module*; all it is is just a collection of
+test cases for a unit of code with a set up function that gets invoked before
+every test cases and then a tear down function that gets invoked after every
+test case completes.
+
+Example:
+
+.. code-block:: c
+
+	static struct kunit_case example_test_cases[] = {
+		KUNIT_CASE(example_test_foo),
+		KUNIT_CASE(example_test_bar),
+		KUNIT_CASE(example_test_baz),
+		{},
+	};
+
+	static struct kunit_module example_test_module[] = {
+		.name = "example",
+		.init = example_test_init,
+		.exit = example_test_exit,
+		.test_cases = example_test_cases,
+	};
+	module_test(example_test_module);
+
+In the above example the test suite, ``example_test_module``, would run the test
+cases ``example_test_foo``, ``example_test_bar``, and ``example_test_baz``, each
+would have ``example_test_init`` called immediately before it and would have
+``example_test_exit`` called immediately after it.
+``module_test(example_test_module)`` registers the test suite with the KUnit
+test framework.
+
+.. note::
+   A test case will only be run if it is associated with a test suite.
+
+For a more information on these types of things see the :doc:`api/test`.
+
+Isolating Behavior
+==================
+
+The most important aspect of unit testing that other forms of testing do not
+provide is the ability to limit the amount of code under test to a single unit.
+In practice, this is only possible by being able to control what code gets run
+when the unit under test calls a function and this is usually accomplished
+through some sort of indirection where a function is exposed as part of an API
+such that the definition of that function can be changed without affecting the
+rest of the code base. In the kernel this primarily comes from two constructs,
+classes, structs that contain function pointers that are provided by the
+implementer, and architecture specific functions which have definitions selected
+at compile time.
+
+Classes
+-------
+
+Classes are not a construct that is built into the C programming language;
+however, it is an easily derived concept. Accordingly, pretty much every project
+that does not use a standardized object oriented library (like GNOME's GObject)
+has their own slightly different way of doing object oriented programming; the
+Linux kernel is no exception.
+
+The central concept in kernel object oriented programming is the class. In the
+kernel, a *class* is a struct that contains function pointers. This creates a
+contract between *implementers* and *users* since it forces them to use the
+same function signature without having to call the function directly. In order
+for it to truly be a class, the function pointers must specify that a pointer
+to the class, known as a *class handle*, be one of the parameters; this makes
+it possible for the member functions (also known as *methods*) to have access
+to member variables (more commonly known as *fields*) allowing the same
+implementation to have multiple *instances*.
+
+Typically a class can be *overridden* by *child classes* by embedding the
+*parent class* in the child class. Then when a method provided by the child
+class is called, the child implementation knows that the pointer passed to it is
+of a parent contained within the child; because of this, the child can compute
+the pointer to itself because the pointer to the parent is always a fixed offset
+from the pointer to the child; this offset is the offset of the parent contained
+in the child struct. For example:
+
+.. code-block:: c
+
+	struct shape {
+		int (*area)(struct shape *this);
+	};
+
+	struct rectangle {
+		struct shape parent;
+		int length;
+		int width;
+	};
+
+	int rectangle_area(struct shape *this)
+	{
+		struct rectangle *self = container_of(this, struct shape, parent);
+
+		return self->length * self->width;
+	};
+
+	void rectangle_new(struct rectangle *self, int length, int width)
+	{
+		self->parent.area = rectangle_area;
+		self->length = length;
+		self->width = width;
+	}
+
+In this example (as in most kernel code) the operation of computing the pointer
+to the child from the pointer to the parent is done by ``container_of``.
+
+Faking Classes
+~~~~~~~~~~~~~~
+
+In order to unit test a piece of code that calls a method in a class, the
+behavior of the method must be controllable, otherwise the test ceases to be a
+unit test and becomes an integration test.
+
+A fake just provides an implementation of a piece of code that is different than
+what runs in a production instance, but behaves identically from the standpoint
+of the callers; this is usually done to replace a dependency that is hard to
+deal with, or is slow.
+
+A good example for this might be implementing a fake EEPROM that just stores the
+"contents" in an internal buffer. For example, let's assume we have a class that
+represents an EEPROM:
+
+.. code-block:: c
+
+	struct eeprom {
+		ssize_t (*read)(struct eeprom *this, size_t offset, char *buffer, size_t count);
+		ssize_t (*write)(struct eeprom *this, size_t offset, const char *buffer, size_t count);
+	};
+
+And we want to test some code that buffers writes to the EEPROM:
+
+.. code-block:: c
+
+	struct eeprom_buffer {
+		ssize_t (*write)(struct eeprom_buffer *this, const char *buffer, size_t count);
+		int flush(struct eeprom_buffer *this);
+		size_t flush_count; /* Flushes when buffer exceeds flush_count. */
+	};
+
+	struct eeprom_buffer *new_eeprom_buffer(struct eeprom *eeprom);
+	void destroy_eeprom_buffer(struct eeprom *eeprom);
+
+We can easily test this code by *faking out* the underlying EEPROM:
+
+.. code-block:: c
+
+	struct fake_eeprom {
+		struct eeprom parent;
+		char contents[FAKE_EEPROM_CONTENTS_SIZE];
+	};
+
+	ssize_t fake_eeprom_read(struct eeprom *parent, size_t offset, char *buffer, size_t count)
+	{
+		struct fake_eeprom *this = container_of(parent, struct fake_eeprom, parent);
+
+		count = min(count, FAKE_EEPROM_CONTENTS_SIZE - offset);
+		memcpy(buffer, this->contents + offset, count);
+
+		return count;
+	}
+
+	ssize_t fake_eeprom_write(struct eeprom *this, size_t offset, const char *buffer, size_t count)
+	{
+		struct fake_eeprom *this = container_of(parent, struct fake_eeprom, parent);
+
+		count = min(count, FAKE_EEPROM_CONTENTS_SIZE - offset);
+		memcpy(this->contents + offset, buffer, count);
+
+		return count;
+	}
+
+	void fake_eeprom_init(struct fake_eeprom *this)
+	{
+		this->parent.read = fake_eeprom_read;
+		this->parent.write = fake_eeprom_write;
+		memset(this->contents, 0, FAKE_EEPROM_CONTENTS_SIZE);
+	}
+
+We can now use it to test ``struct eeprom_buffer``:
+
+.. code-block:: c
+
+	struct eeprom_buffer_test {
+		struct fake_eeprom *fake_eeprom;
+		struct eeprom_buffer *eeprom_buffer;
+	};
+
+	static void eeprom_buffer_test_does_not_write_until_flush(struct kunit *test)
+	{
+		struct eeprom_buffer_test *ctx = test->priv;
+		struct eeprom_buffer *eeprom_buffer = ctx->eeprom_buffer;
+		struct fake_eeprom *fake_eeprom = ctx->fake_eeprom;
+		char buffer[] = {0xff};
+
+		eeprom_buffer->flush_count = SIZE_MAX;
+
+		eeprom_buffer->write(eeprom_buffer, buffer, 1);
+		KUNIT_EXPECT_EQ(test, fake_eeprom->contents[0], 0);
+
+		eeprom_buffer->write(eeprom_buffer, buffer, 1);
+		KUNIT_EXPECT_EQ(test, fake_eeprom->contents[1], 0);
+
+		eeprom_buffer->flush(eeprom_buffer);
+		KUNIT_EXPECT_EQ(test, fake_eeprom->contents[0], 0xff);
+		KUNIT_EXPECT_EQ(test, fake_eeprom->contents[1], 0xff);
+	}
+
+	static void eeprom_buffer_test_flushes_after_flush_count_met(struct kunit *test)
+	{
+		struct eeprom_buffer_test *ctx = test->priv;
+		struct eeprom_buffer *eeprom_buffer = ctx->eeprom_buffer;
+		struct fake_eeprom *fake_eeprom = ctx->fake_eeprom;
+		char buffer[] = {0xff};
+
+		eeprom_buffer->flush_count = 2;
+
+		eeprom_buffer->write(eeprom_buffer, buffer, 1);
+		KUNIT_EXPECT_EQ(test, fake_eeprom->contents[0], 0);
+
+		eeprom_buffer->write(eeprom_buffer, buffer, 1);
+		KUNIT_EXPECT_EQ(test, fake_eeprom->contents[0], 0xff);
+		KUNIT_EXPECT_EQ(test, fake_eeprom->contents[1], 0xff);
+	}
+
+	static void eeprom_buffer_test_flushes_increments_of_flush_count(struct kunit *test)
+	{
+		struct eeprom_buffer_test *ctx = test->priv;
+		struct eeprom_buffer *eeprom_buffer = ctx->eeprom_buffer;
+		struct fake_eeprom *fake_eeprom = ctx->fake_eeprom;
+		char buffer[] = {0xff, 0xff};
+
+		eeprom_buffer->flush_count = 2;
+
+		eeprom_buffer->write(eeprom_buffer, buffer, 1);
+		KUNIT_EXPECT_EQ(test, fake_eeprom->contents[0], 0);
+
+		eeprom_buffer->write(eeprom_buffer, buffer, 2);
+		KUNIT_EXPECT_EQ(test, fake_eeprom->contents[0], 0xff);
+		KUNIT_EXPECT_EQ(test, fake_eeprom->contents[1], 0xff);
+		/* Should have only flushed the first two bytes. */
+		KUNIT_EXPECT_EQ(test, fake_eeprom->contents[2], 0);
+	}
+
+	static int eeprom_buffer_test_init(struct kunit *test)
+	{
+		struct eeprom_buffer_test *ctx;
+
+		ctx = kunit_kzalloc(test, sizeof(*ctx), GFP_KERNEL);
+		ASSERT_NOT_ERR_OR_NULL(test, ctx);
+
+		ctx->fake_eeprom = kunit_kzalloc(test, sizeof(*ctx->fake_eeprom), GFP_KERNEL);
+		ASSERT_NOT_ERR_OR_NULL(test, ctx->fake_eeprom);
+
+		ctx->eeprom_buffer = new_eeprom_buffer(&ctx->fake_eeprom->parent);
+		ASSERT_NOT_ERR_OR_NULL(test, ctx->eeprom_buffer);
+
+		test->priv = ctx;
+
+		return 0;
+	}
+
+	static void eeprom_buffer_test_exit(struct kunit *test)
+	{
+		struct eeprom_buffer_test *ctx = test->priv;
+
+		destroy_eeprom_buffer(ctx->eeprom_buffer);
+	}
+
-- 
2.20.0.rc0.387.gc7a69e6b6c-goog

