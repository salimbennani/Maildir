Return-Path: <linux-kernel-owner@vger.kernel.org>
Delivered-To: unknown
Received: from linux.intel.com (10.54.29.200:995) by likexu-workstation with
  POP3-SSL; 02 Dec 2018 19:22:58 -0000
X-Original-To: like.xu@linux.intel.com
Delivered-To: like.xu@linux.intel.com
Received: from orsmga003.jf.intel.com (orsmga003.jf.intel.com [10.7.209.27])
	(using TLSv1.2 with cipher ECDHE-RSA-AES256-GCM-SHA384 (256/256 bits))
	(No client certificate requested)
	by linux.intel.com (Postfix) with ESMTPS id 8FEC8580213;
	Fri, 30 Nov 2018 12:46:10 -0800 (PST)
Received: from orsmga103.jf.intel.com ([10.7.208.35])
  by orsmga003-1.jf.intel.com with ESMTP/TLS/DHE-RSA-AES256-GCM-SHA384; 30 Nov 2018 12:46:10 -0800
X-SG-BADATTACHMENTNOREPLY: True
IronPort-PHdr: =?us-ascii?q?9a23=3AlfXRlxW7Mx52QE5vlR2hkDz7fWDV8LGtZVwlr6E/?=
 =?us-ascii?q?grcLSJyIuqrYZhGAv6dThVPEFb/W9+hDw7KP9fy4CSpYud6oizMrSNR0TRgLiM?=
 =?us-ascii?q?EbzUQLIfWuLgnFFsPsdDEwB89YVVVorDmROElRH9viNRWJ+iXhpTEdFQ/iOgVr?=
 =?us-ascii?q?O+/7BpDdj9it1+C15pbffxhEiCCybL9uLxi6txndutULioZ+N6g9zQfErGFVcO?=
 =?us-ascii?q?pM32NoIlyTnxf45siu+ZNo7jpdtfE8+cNeSKv2Z6s3Q6BWAzQgKGA1+dbktQLf?=
 =?us-ascii?q?QguV53sTSXsZnxxVCAXY9h76X5Pxsizntuph3SSRIMP7QawoVTmk8qxmUwHjhj?=
 =?us-ascii?q?sZODEl8WHXks1wg7xdoBK9vBx03orYbJiIOPZiYq/ReNUXTndDUMlMTSxMGoOy?=
 =?us-ascii?q?YZUSAeQPPuhWqIbyqVQVrRumBwShH//jxzxSi3Pqx6A2z/gtHAfb1wIgBdIOt3?=
 =?us-ascii?q?HUoc3pOacITO++0bTFzTTdYPNN2Tfy9pXIcg4/rvGIQLl9dtDeyVMyGA/flVqQ?=
 =?us-ascii?q?qJLqPyiV1usTrmib8fRvVea0hm4jqgFxpCKgxt0rioXTgYIV0F/E+Dx/zY0oK9?=
 =?us-ascii?q?O4T0t7bsSlEJtWryyVK4t2Tdk+TGFooik207sGtoC8fCgM0Zgo2xnfa+aZfISS?=
 =?us-ascii?q?+RLsT+CcKip7inJ9YL+zmQq+/Ey6xuHhWMS4zkxGojdGn9XQrHwA1h7e5tCZRv?=
 =?us-ascii?q?Rn4kutxDOC2BzI5e1ZPE85kLfXJ4M/zrM1l5cTv1jPEjPzlUrrj6KbckUp9+22?=
 =?us-ascii?q?5Oj7bLjquJqROo1vhQ3iLqgjn8+yDOUkPQcTWWWQ5P6y26f5/ULjRbVHlv02nb?=
 =?us-ascii?q?fdsJDdPckbuKG5DBFP0oo56BawES2m0NIGknkDNl5FfwiHj4fxN1HPJvD3E+u/?=
 =?us-ascii?q?jkyynDt3w/3KJKDtD5vTInTZjbvsfqpx51RdxQcx1dxf4ohbCrAFIPL9QE/xs9?=
 =?us-ascii?q?nYAwc9Mwy1xebnFdp82podWW2RGK+ZNr3dsVuR6uIoLeiMYpEauCzmJvg76P7h?=
 =?us-ascii?q?k2U5lUUefaa3x5sXbm63HvB8L0Wee3rsjc8NEX0WsQomUOzqlFqCXCZXZ3azXK?=
 =?us-ascii?q?Iz+Cs3CY27DYrYQoCtgbqB3Dq0H5FMZ2BGDEyMHmnsd4meR/gMbyeSKNd7kjMY?=
 =?us-ascii?q?TbihV5Mh1Ra2uQ/60bVnL/bU9TcftZ751Nh1+vfclRc99TFvC8Sd0meNT3x7n2?=
 =?us-ascii?q?8SRj822rx/rlJ5yluZzad4hPlYH8RJ5/xVSgc6KYLcz+tiBtDwXQLOYM2FSFWh?=
 =?us-ascii?q?QtWgBzExSck8w9sPY0Z7BtWjgQrP3yusA78JibOLAIY4/b7b33j0P8x90WrJ1L?=
 =?us-ascii?q?E9j1k6RctCLXephrV/9wjUBI7FiV+ZmLyodakH2C7N9WGDzXeBvU1CUQ5wV7nF?=
 =?us-ascii?q?Um4bZkfMsdv54UbCRae0Cbs7KgtB1dKCKqxSZ93ql1pGQu3vONDfY22rnWewCg?=
 =?us-ascii?q?2FxreNbIrsZmUc0z/RCEkCkwAP43mGMRIyCTumo2LbFDZuD07gY1vw8elir3O2?=
 =?us-ascii?q?VlI7wBuUb0J/zba1+gQahfqHS/wN2LIIvyMhqzZxHFa5xN/WD9uApwx8fKRTe9?=
 =?us-ascii?q?894VFH1X7HuAx5JJCvM6dihlsGeQRto0zuzwl3CplHkcUysXwl1hRyJryC3FNB?=
 =?us-ascii?q?bTyY24vwNaPRKmTp+BCvaqjW2kzR0dqM+6cP7ug4pEvnvA2zCkUi9HBn2cFP03?=
 =?us-ascii?q?SA/pXKEBYSUZXpX0Yr9hh6orbaYjU954LUz3FsLbO4sjjY29ItBeslzBmgcsxb?=
 =?us-ascii?q?MKOFEg/yDsIbC9KvKOwsh1imcBYEMPpO+64zOsOsb+GG17KzPOZ8gDKminxK75?=
 =?us-ascii?q?p50k2S+CtzVO7J04wezPGFwwSITTH8jFSmssDpgo1EYTASHmyiySnrHoJRZ6ty?=
 =?us-ascii?q?fZoVBmeqOcG42tJ+h5v1UX5C6FGjH08G2NOueReKb139wBdc2lgNrX2mmSu31T?=
 =?us-ascii?q?p0kz4yo6qb3SzOxfnidRUdNm5KQmlikUnjIYyug98GW0ioahAjlAG56kbi26hb?=
 =?us-ascii?q?uKN/InHJQUdJYyf5NXtiXba3traYZc5A9okosSROXOuge1+aTqPyrAUA0yPkGW?=
 =?us-ascii?q?tT3zQ7dzCsupXkkB12kmOdLHBvrHXHfcF83wvQ5NvZRfRJxDoJWDF4iSXLBli7?=
 =?us-ascii?q?J9So/dSUm43Ds+ykTGKhS5tTfDLvzYOBsiu7+GJrDQe+n/C1ht3oDww63TXn2N?=
 =?us-ascii?q?ltUCXCtAz8bZXz16SmLeJneVFlBF3m5MpgGYF+kYwwiIsL2XcAhZWV/nsHkWHt?=
 =?us-ascii?q?PtVdwq/+aHsNRTgWw9/a+gTl2UtjLm6XyIL9THmS3sxhZ9yiaGMMxi0999xKCL?=
 =?us-ascii?q?uT7LFcnSp6uF24oRjTYfh8mDcQ0v8u6H8cg+EUtwsh1CSdArYOHUZGOSzgjQiH?=
 =?us-ascii?q?79e7rK9PfmagbaCw1FZindCmFLyCoRtTWHfjdpciAC9/9MN/MF3X3X3364Hkfs?=
 =?us-ascii?q?TQbN0Juh2VlRfAk/ZaKJYrmvUWgipnPHr3vWc5xO4jkRxuwZa6sZCCK2Vs/6K2?=
 =?us-ascii?q?GARUNzPraMMI5jHik7xekd2I0IC1EZVsATELXJruTfK1HzMer/XnNwCSEDIirn?=
 =?us-ascii?q?eXA6bQHQia6E1+tXLAD4irN22LJHke1dhiWB6dJElFjAEVRjo6mIM5FhuxxMzg?=
 =?us-ascii?q?a0p54jER5ljlqhpD0O5oNh//UnvBqwescDs7VJ+fLB9O5AFY+0jVKdCe7v50Hy?=
 =?us-ascii?q?xA5ZKutguNKmiGZwhSCWEJR1eJB1TiPrmo+NnB/PKUBuu4L/vSf7qOrfZSWOuP?=
 =?us-ascii?q?xZKqyoFm5SqDNt2TPnl+CP02wkhDUmp8G8vHgDUDUTAXmzjOb86Gpxe85yt3od?=
 =?us-ascii?q?qk8PnwXALv5I2PC6ZdMNl1+hC2h7uDOPCUhCpjNTlY0ZYMz2fSyLcDxF4Slz1u?=
 =?us-ascii?q?dz61HLUAsi7NUbvQmrJNAB4dcS9zL8xI76Qz3gRWPc7bi9X11qN3j/IvCldFU0?=
 =?us-ascii?q?Dhld+tZcAQP269M1bHDl6RNLuaPT3L3933YaSkRL1QkupUth6wuTWaE0P5PTSD?=
 =?us-ascii?q?jT7pVx+xPuFWkSGbJwdTuIW8chZrFGjiQ8jqahy9MN9rkzI2xac4iW/NNW4ZKT?=
 =?us-ascii?q?J8aV9CrqWM7SNEhfVyA3ZO7md+IumehSmY7/PUKpIXsfZwBiR0luRa4Gk1yrdP?=
 =?us-ascii?q?7SFEQuB1lzXWrtJ0v16mleyPwCJ9UBVSsjZLmJ6LvUJ6NKXF95lAXGzI8w4X4W?=
 =?us-ascii?q?qMCxQFud1lB8bru6BRzNjPia3yJC1D89LS4csTGczUJNibP3omNBrjACTUAxcd?=
 =?us-ascii?q?TT63KWHfgFRQkfGI+X2Tq5g6q57sl4IPS79bTlM1EPwaB19hHNwDJpd3Qzwlna?=
 =?us-ascii?q?SajM4O+Xqxsh3RSN9GsZDAU/LBScnofTKYi6RUIhAS0KvkKqwNOYDhnU9vcF93?=
 =?us-ascii?q?mMLNAUWDc8pKp3hIdAN8ikRA63hzU3M+3wqxYxmhpnUSGOW0kwMohw9WZeUr/S?=
 =?us-ascii?q?3rpVAtKQyZ92MLjEAtlIC90niqeznrIfL1BNkOBg=3D=3D?=
X-IronPort-Anti-Spam-Filtered: true
X-IronPort-Anti-Spam-Result: =?us-ascii?q?A0AUAAAjoQFch0O0hNFjHAEBAQQBAQcEA?=
 =?us-ascii?q?QGBUgYBAQsBgTCCOyeaPGiWTIF2DwEBGBMBh3YiNQgNAQMBAQEBAQECARMBAQE?=
 =?us-ascii?q?IDQkIKSMMgjYkAYJpAi8BDQEBKg0BBQkCUAMxAQUBAjMFgxyCAgEEm0A8ih2CH?=
 =?us-ascii?q?4J2AQEFhycIEodagihEJoEcgVc/gRGCXYUChg+JK5cMBwKCHgSPCgsYgVuHfod?=
 =?us-ascii?q?GgnmHBY44AgQCBAUCBQ8hgScDggh9gy+CGwkDF4hehUA/MoEEAQEBII0gAQE?=
X-IPAS-Result: =?us-ascii?q?A0AUAAAjoQFch0O0hNFjHAEBAQQBAQcEAQGBUgYBAQsBgTC?=
 =?us-ascii?q?COyeaPGiWTIF2DwEBGBMBh3YiNQgNAQMBAQEBAQECARMBAQEIDQkIKSMMgjYkA?=
 =?us-ascii?q?YJpAi8BDQEBKg0BBQkCUAMxAQUBAjMFgxyCAgEEm0A8ih2CH4J2AQEFhycIEod?=
 =?us-ascii?q?agihEJoEcgVc/gRGCXYUChg+JK5cMBwKCHgSPCgsYgVuHfodGgnmHBY44AgQCB?=
 =?us-ascii?q?AUCBQ8hgScDggh9gy+CGwkDF4hehUA/MoEEAQEBII0gAQE?=
X-IronPort-AV: E=Sophos;i="5.56,299,1539673200"; 
   d="scan'208";a="54455766"
X-Amp-Result: SKIPPED(no attachment in message)
X-Amp-File-Uploaded: False
Received: from vger.kernel.org ([209.132.180.67])
  by mtab.intel.com with ESMTP; 30 Nov 2018 12:46:08 -0800
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
        id S1726554AbeLAH4g (ORCPT <rfc822;like.xu@linux.intel.com>
        + 23 others); Sat, 1 Dec 2018 02:56:36 -0500
Received: from mail-wr1-f65.google.com ([209.85.221.65]:34795 "EHLO
        mail-wr1-f65.google.com" rhost-flags-OK-OK-OK-OK) by vger.kernel.org
        with ESMTP id S1725867AbeLAH4g (ORCPT
        <rfc822;linux-kernel@vger.kernel.org>);
        Sat, 1 Dec 2018 02:56:36 -0500
Received: by mail-wr1-f65.google.com with SMTP id j2so6520840wrw.1
        for <linux-kernel@vger.kernel.org>; Fri, 30 Nov 2018 12:46:03 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=linaro.org; s=google;
        h=from:to:cc:subject:date:message-id:mime-version
         :content-transfer-encoding;
        bh=N23ecysPLPuVwmWPBcYm2Kn7j5y448PatwAcTMxhNL8=;
        b=hHEqAsC+FCyhjQYwQS3NvtNtmh91/JZLVR5VRaYy2KAGJ+2dNDME2+DA0nfQnH6XsZ
         EtbPnY7ZiFr9TjPIsHdawd02KSKen9/WY3wzp0vwlq/G/HZU9o1tR1yzTuT7tdjXvDpn
         lr1k2D0gO72XxnKhsGqSLDjp8i+8le7003ENs=
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20161025;
        h=x-gm-message-state:from:to:cc:subject:date:message-id:mime-version
         :content-transfer-encoding;
        bh=N23ecysPLPuVwmWPBcYm2Kn7j5y448PatwAcTMxhNL8=;
        b=tl00qr3ZvFXmAOd6Xdz2lDVm/iNfePHgOmT90B7ehkeB3pjOqkRujtfXOceCz0HxcQ
         wZ1mEhEij9X5IlR2o2k3DrUMJ7IWJ5dqUWvlALGFU95ubFaXOgr9mQ0RiwWivyLWSht+
         xgQwcXTYCGQzbmevepIwOrspNvPjYtF/eI1jrzN2F+Rt6kT0TUTfZiwuJsO/o9H8EbKn
         OfIiah9RPDkaosE/+iH5Bxtzja2QpQb+Tp+css6eO2+4zvo3zlSYd3vL5I5SN1yXLWbh
         QfzIree/tO1fP7R4ILNxAuh/PXv/FiiwiV+qsAvvZVDSWzdmmif7OeQANm+R1WENrigJ
         JqQQ==
X-Gm-Message-State: AA+aEWZH01DCOBVTXatNsCXI7wynG0eiv4ROOiMonWoMwwAtybVFg5Iq
        6V2bU4oJLyKhVX2Nuq+ywcoN0A==
X-Google-Smtp-Source: AFSGD/Vzt7NhQPkGvGtax5OCWiQyZcAQ49EhWaLCbOXmpGvAHOz27xUifXE1axo7FRKlgtjAM2z4nw==
X-Received: by 2002:adf:9521:: with SMTP id 30mr5811622wrs.192.1543610320670;
        Fri, 30 Nov 2018 12:38:40 -0800 (PST)
Received: from harold.home ([2a01:cb1d:112:6f00:d895:e032:7b00:86cd])
        by smtp.gmail.com with ESMTPSA id r76-v6sm137643wmb.21.2018.11.30.12.38.39
        (version=TLS1_2 cipher=ECDHE-RSA-AES128-GCM-SHA256 bits=128/128);
        Fri, 30 Nov 2018 12:38:39 -0800 (PST)
From: Ard Biesheuvel <ard.biesheuvel@linaro.org>
To: linux-crypto@vger.kernel.org
Cc: linux-kernel@vger.kernel.org, linux-arm-kernel@lists.infradead.org,
        herbert@gondor.apana.org.au,
        Ard Biesheuvel <ard.biesheuvel@linaro.org>,
        Eric Biggers <ebiggers@kernel.org>,
        Martin Willi <martin@strongswan.org>
Subject: [RFC/RFT PATCH] crypto: arm64/chacha - optimize for arbitrary length inputs
Date: Fri, 30 Nov 2018 21:38:11 +0100
Message-Id: <20181130203811.30269-1-ard.biesheuvel@linaro.org>
X-Mailer: git-send-email 2.19.1
MIME-Version: 1.0
Content-Transfer-Encoding: 8bit
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: <linux-kernel.vger.kernel.org>
X-Mailing-List: linux-kernel@vger.kernel.org

Update the 4-way NEON ChaCha routine so it can handle input of any
length >64 bytes in its entirety, rather than having to call into
the 1-way routine and/or do memcpy()s via temp buffers to handle the
tail of a ChaCha invocation that is not a multiple of 256 bytes.

On inputs that are a multiple of 256 bytes (and thus in tcrypt
benchmarks), performance drops by around 1% on Cortex-A57, while
performance for inputs drawn randomly from the range [64, 1024+64)
increases by around 30% (using ChaCha20). On Cortex-A72, performance
gains are similar. On Cortex-A53, performance improves but only by 5%.

Cc: Eric Biggers <ebiggers@kernel.org>
Cc: Martin Willi <martin@strongswan.org>
Signed-off-by: Ard Biesheuvel <ard.biesheuvel@linaro.org>
---
Test program after the patch. 

 arch/arm64/crypto/chacha-neon-core.S | 185 ++++++++++++++++++--
 arch/arm64/crypto/chacha-neon-glue.c |  36 ++--
 2 files changed, 188 insertions(+), 33 deletions(-)

diff --git a/arch/arm64/crypto/chacha-neon-core.S b/arch/arm64/crypto/chacha-neon-core.S
index 75b4e06cee79..45ffc51cb437 100644
--- a/arch/arm64/crypto/chacha-neon-core.S
+++ b/arch/arm64/crypto/chacha-neon-core.S
@@ -19,6 +19,7 @@
  */
 
 #include <linux/linkage.h>
+#include <asm/cache.h>
 
 	.text
 	.align		6
@@ -164,6 +165,7 @@ ENTRY(chacha_4block_xor_neon)
 	// x1: 4 data blocks output, o
 	// x2: 4 data blocks input, i
 	// w3: nrounds
+	// x4: byte count
 
 	//
 	// This function encrypts four consecutive ChaCha blocks by loading
@@ -177,11 +179,11 @@ ENTRY(chacha_4block_xor_neon)
 	ld1		{v30.4s-v31.4s}, [x9]
 
 	// x0..15[0-3] = s0..3[0..3]
-	mov		x4, x0
-	ld4r		{ v0.4s- v3.4s}, [x4], #16
-	ld4r		{ v4.4s- v7.4s}, [x4], #16
-	ld4r		{ v8.4s-v11.4s}, [x4], #16
-	ld4r		{v12.4s-v15.4s}, [x4]
+	mov		x8, x0
+	ld4r		{ v0.4s- v3.4s}, [x8], #16
+	ld4r		{ v4.4s- v7.4s}, [x8], #16
+	ld4r		{ v8.4s-v11.4s}, [x8], #16
+	ld4r		{v12.4s-v15.4s}, [x8]
 
 	// x12 += counter values 0-3
 	add		v12.4s, v12.4s, v30.4s
@@ -425,24 +427,47 @@ ENTRY(chacha_4block_xor_neon)
 	zip1		v30.4s, v14.4s, v15.4s
 	zip2		v31.4s, v14.4s, v15.4s
 
+	mov		x3, #64
+	subs		x5, x4, #64
+	add		x6, x5, x2
+	csel		x3, x3, xzr, ge
+	csel		x2, x2, x6, ge
+
 	// interleave 64-bit words in state n, n+2
 	zip1		v0.2d, v16.2d, v18.2d
 	zip2		v4.2d, v16.2d, v18.2d
 	zip1		v8.2d, v17.2d, v19.2d
 	zip2		v12.2d, v17.2d, v19.2d
-	ld1		{v16.16b-v19.16b}, [x2], #64
+	ld1		{v16.16b-v19.16b}, [x2], x3
+
+	subs		x6, x4, #128
+	ccmp		x3, xzr, #4, lt
+	add		x7, x6, x2
+	csel		x3, x3, xzr, eq
+	csel		x2, x2, x7, eq
 
 	zip1		v1.2d, v20.2d, v22.2d
 	zip2		v5.2d, v20.2d, v22.2d
 	zip1		v9.2d, v21.2d, v23.2d
 	zip2		v13.2d, v21.2d, v23.2d
-	ld1		{v20.16b-v23.16b}, [x2], #64
+	ld1		{v20.16b-v23.16b}, [x2], x3
+
+	subs		x7, x4, #192
+	ccmp		x3, xzr, #4, lt
+	add		x8, x7, x2
+	csel		x3, x3, xzr, eq
+	csel		x2, x2, x8, eq
 
 	zip1		v2.2d, v24.2d, v26.2d
 	zip2		v6.2d, v24.2d, v26.2d
 	zip1		v10.2d, v25.2d, v27.2d
 	zip2		v14.2d, v25.2d, v27.2d
-	ld1		{v24.16b-v27.16b}, [x2], #64
+	ld1		{v24.16b-v27.16b}, [x2], x3
+
+	subs		x8, x4, #256
+	ccmp		x3, xzr, #4, lt
+	add		x9, x8, x2
+	csel		x2, x2, x9, eq
 
 	zip1		v3.2d, v28.2d, v30.2d
 	zip2		v7.2d, v28.2d, v30.2d
@@ -451,29 +476,167 @@ ENTRY(chacha_4block_xor_neon)
 	ld1		{v28.16b-v31.16b}, [x2]
 
 	// xor with corresponding input, write to output
+	tbnz		x5, #63, 0f
 	eor		v16.16b, v16.16b, v0.16b
 	eor		v17.16b, v17.16b, v1.16b
 	eor		v18.16b, v18.16b, v2.16b
 	eor		v19.16b, v19.16b, v3.16b
+	st1		{v16.16b-v19.16b}, [x1], #64
+
+	tbnz		x6, #63, 1f
 	eor		v20.16b, v20.16b, v4.16b
 	eor		v21.16b, v21.16b, v5.16b
-	st1		{v16.16b-v19.16b}, [x1], #64
 	eor		v22.16b, v22.16b, v6.16b
 	eor		v23.16b, v23.16b, v7.16b
+	st1		{v20.16b-v23.16b}, [x1], #64
+
+	tbnz		x7, #63, 2f
 	eor		v24.16b, v24.16b, v8.16b
 	eor		v25.16b, v25.16b, v9.16b
-	st1		{v20.16b-v23.16b}, [x1], #64
 	eor		v26.16b, v26.16b, v10.16b
 	eor		v27.16b, v27.16b, v11.16b
-	eor		v28.16b, v28.16b, v12.16b
 	st1		{v24.16b-v27.16b}, [x1], #64
+
+	tbnz		x8, #63, 3f
+	eor		v28.16b, v28.16b, v12.16b
 	eor		v29.16b, v29.16b, v13.16b
 	eor		v30.16b, v30.16b, v14.16b
 	eor		v31.16b, v31.16b, v15.16b
 	st1		{v28.16b-v31.16b}, [x1]
 
 	ret
+
+	// fewer than 64 bytes of in/output
+0:	adr		x12, .Lpermute
+	add		x12, x12, x5
+	sub		x2, x1, #64
+	add		x1, x1, x5
+	add		x13, x12, #64
+	ld1		{v8.16b}, [x12]
+	ld1		{v9.16b}, [x13]
+	movi		v10.16b, #16
+
+	ld1		{v16.16b-v19.16b}, [x2]
+	tbl		v4.16b, {v0.16b-v3.16b}, v8.16b
+	tbx		v20.16b, {v16.16b-v19.16b}, v9.16b
+	add		v8.16b, v8.16b, v10.16b
+	add		v9.16b, v9.16b, v10.16b
+	tbl		v5.16b, {v0.16b-v3.16b}, v8.16b
+	tbx		v21.16b, {v16.16b-v19.16b}, v9.16b
+	add		v8.16b, v8.16b, v10.16b
+	add		v9.16b, v9.16b, v10.16b
+	tbl		v6.16b, {v0.16b-v3.16b}, v8.16b
+	tbx		v22.16b, {v16.16b-v19.16b}, v9.16b
+	add		v8.16b, v8.16b, v10.16b
+	add		v9.16b, v9.16b, v10.16b
+	tbl		v7.16b, {v0.16b-v3.16b}, v8.16b
+	tbx		v23.16b, {v16.16b-v19.16b}, v9.16b
+
+	eor		v20.16b, v20.16b, v4.16b
+	eor		v21.16b, v21.16b, v5.16b
+	eor		v22.16b, v22.16b, v6.16b
+	eor		v23.16b, v23.16b, v7.16b
+	st1		{v20.16b-v23.16b}, [x1]
+	ret
+
+	// fewer than 128 bytes of in/output
+1:	adr		x12, .Lpermute
+	add		x12, x12, x6
+	add		x1, x1, x6
+	add		x13, x12, #64
+	ld1		{v8.16b}, [x12]
+	ld1		{v9.16b}, [x13]
+	movi		v10.16b, #16
+	tbl		v0.16b, {v4.16b-v7.16b}, v8.16b
+	tbx		v20.16b, {v16.16b-v19.16b}, v9.16b
+	add		v8.16b, v8.16b, v10.16b
+	add		v9.16b, v9.16b, v10.16b
+	tbl		v1.16b, {v4.16b-v7.16b}, v8.16b
+	tbx		v21.16b, {v16.16b-v19.16b}, v9.16b
+	add		v8.16b, v8.16b, v10.16b
+	add		v9.16b, v9.16b, v10.16b
+	tbl		v2.16b, {v4.16b-v7.16b}, v8.16b
+	tbx		v22.16b, {v16.16b-v19.16b}, v9.16b
+	add		v8.16b, v8.16b, v10.16b
+	add		v9.16b, v9.16b, v10.16b
+	tbl		v3.16b, {v4.16b-v7.16b}, v8.16b
+	tbx		v23.16b, {v16.16b-v19.16b}, v9.16b
+
+	eor		v20.16b, v20.16b, v0.16b
+	eor		v21.16b, v21.16b, v1.16b
+	eor		v22.16b, v22.16b, v2.16b
+	eor		v23.16b, v23.16b, v3.16b
+	st1		{v20.16b-v23.16b}, [x1]
+	ret
+
+	// fewer than 192 bytes of in/output
+2:	adr		x12, .Lpermute
+	add		x12, x12, x7
+	add		x1, x1, x7
+	add		x13, x12, #64
+	ld1		{v4.16b}, [x12]
+	ld1		{v5.16b}, [x13]
+	movi		v6.16b, #16
+	tbl		v0.16b, {v8.16b-v11.16b}, v4.16b
+	tbx		v24.16b, {v20.16b-v23.16b}, v5.16b
+	add		v4.16b, v4.16b, v6.16b
+	add		v5.16b, v5.16b, v6.16b
+	tbl		v1.16b, {v8.16b-v11.16b}, v4.16b
+	tbx		v25.16b, {v20.16b-v23.16b}, v5.16b
+	add		v4.16b, v4.16b, v6.16b
+	add		v5.16b, v5.16b, v6.16b
+	tbl		v2.16b, {v8.16b-v11.16b}, v4.16b
+	tbx		v26.16b, {v20.16b-v23.16b}, v5.16b
+	add		v4.16b, v4.16b, v6.16b
+	add		v5.16b, v5.16b, v6.16b
+	tbl		v3.16b, {v8.16b-v11.16b}, v4.16b
+	tbx		v27.16b, {v20.16b-v23.16b}, v5.16b
+
+	eor		v24.16b, v24.16b, v0.16b
+	eor		v25.16b, v25.16b, v1.16b
+	eor		v26.16b, v26.16b, v2.16b
+	eor		v27.16b, v27.16b, v3.16b
+	st1		{v24.16b-v27.16b}, [x1]
+	ret
+
+	// fewer than 256 bytes of in/output
+3:	adr		x12, .Lpermute
+	add		x12, x12, x8
+	add		x1, x1, x8
+	add		x13, x12, #64
+	ld1		{v4.16b}, [x12]
+	ld1		{v5.16b}, [x13]
+	movi		v6.16b, #16
+	tbl		v0.16b, {v12.16b-v15.16b}, v4.16b
+	tbx		v28.16b, {v24.16b-v27.16b}, v5.16b
+	add		v4.16b, v4.16b, v6.16b
+	add		v5.16b, v5.16b, v6.16b
+	tbl		v1.16b, {v12.16b-v15.16b}, v4.16b
+	tbx		v29.16b, {v24.16b-v27.16b}, v5.16b
+	add		v4.16b, v4.16b, v6.16b
+	add		v5.16b, v5.16b, v6.16b
+	tbl		v2.16b, {v12.16b-v15.16b}, v4.16b
+	tbx		v30.16b, {v24.16b-v27.16b}, v5.16b
+	add		v4.16b, v4.16b, v6.16b
+	add		v5.16b, v5.16b, v6.16b
+	tbl		v3.16b, {v12.16b-v15.16b}, v4.16b
+	tbx		v31.16b, {v24.16b-v27.16b}, v5.16b
+
+	eor		v28.16b, v28.16b, v0.16b
+	eor		v29.16b, v29.16b, v1.16b
+	eor		v30.16b, v30.16b, v2.16b
+	eor		v31.16b, v31.16b, v3.16b
+	st1		{v28.16b-v31.16b}, [x1]
+	ret
 ENDPROC(chacha_4block_xor_neon)
 
 CTRINC:	.word		0, 1, 2, 3
 ROT8:	.word		0x02010003, 0x06050407, 0x0a09080b, 0x0e0d0c0f
+
+	.align		L1_CACHE_SHIFT
+	.set		.Lpermute, . + 64
+	.set		.Li, 0
+	.rept		192
+	.byte		(.Li - 64)
+	.set		.Li, .Li + 1
+	.endr
diff --git a/arch/arm64/crypto/chacha-neon-glue.c b/arch/arm64/crypto/chacha-neon-glue.c
index 346eb85498a1..458d9b36cf9d 100644
--- a/arch/arm64/crypto/chacha-neon-glue.c
+++ b/arch/arm64/crypto/chacha-neon-glue.c
@@ -32,41 +32,33 @@
 asmlinkage void chacha_block_xor_neon(u32 *state, u8 *dst, const u8 *src,
 				      int nrounds);
 asmlinkage void chacha_4block_xor_neon(u32 *state, u8 *dst, const u8 *src,
-				       int nrounds);
+				       int nrounds, int bytes);
 asmlinkage void hchacha_block_neon(const u32 *state, u32 *out, int nrounds);
 
 static void chacha_doneon(u32 *state, u8 *dst, const u8 *src,
-			  unsigned int bytes, int nrounds)
+			  int bytes, int nrounds)
 {
 	u8 buf[CHACHA_BLOCK_SIZE];
 
-	while (bytes >= CHACHA_BLOCK_SIZE * 4) {
+	if (bytes < CHACHA_BLOCK_SIZE) {
+		memcpy(buf, src, bytes);
 		kernel_neon_begin();
-		chacha_4block_xor_neon(state, dst, src, nrounds);
+		chacha_block_xor_neon(state, buf, buf, nrounds);
+		kernel_neon_end();
+		memcpy(dst, buf, bytes);
+		return;
+	}
+
+	while (bytes > 0) {
+		kernel_neon_begin();
+		chacha_4block_xor_neon(state, dst, src, nrounds,
+				       min(bytes, CHACHA_BLOCK_SIZE * 4));
 		kernel_neon_end();
 		bytes -= CHACHA_BLOCK_SIZE * 4;
 		src += CHACHA_BLOCK_SIZE * 4;
 		dst += CHACHA_BLOCK_SIZE * 4;
 		state[12] += 4;
 	}
-
-	if (!bytes)
-		return;
-
-	kernel_neon_begin();
-	while (bytes >= CHACHA_BLOCK_SIZE) {
-		chacha_block_xor_neon(state, dst, src, nrounds);
-		bytes -= CHACHA_BLOCK_SIZE;
-		src += CHACHA_BLOCK_SIZE;
-		dst += CHACHA_BLOCK_SIZE;
-		state[12]++;
-	}
-	if (bytes) {
-		memcpy(buf, src, bytes);
-		chacha_block_xor_neon(state, buf, buf, nrounds);
-		memcpy(dst, buf, bytes);
-	}
-	kernel_neon_end();
 }
 
 static int chacha_neon_stream_xor(struct skcipher_request *req,
-- 
2.19.1


#include <stdlib.h>
#include <string.h>

extern void chacha_4block_xor_neon(unsigned int *state, unsigned char *dst,
				   unsigned char *src, int rounds, int bytes);

extern void chacha_block_xor_neon(unsigned int *state, unsigned char *dst,
				  unsigned char *src, int rounds);

int main(void)
{
	static char buf[1024];
	unsigned int state[64];

	srand(20181130);

	for (int i = 0; i < 10 * 1000 * 1000; i++) {
		int l = 64 + rand() % (1024 - 64);

#ifdef NEW
		while (l > 0) {
			chacha_4block_xor_neon(state, buf, buf, 20,
					       l > 256 ? 256 : l);
			l -= 256;
		}
#else
		while (l >= 256) {
			chacha_4block_xor_neon(state, buf, buf, 20, 256);
			l -= 256;
		}
		while (l >= 64) {
			chacha_block_xor_neon(state, buf, buf, 20);
			l -= 64;
		}
		if (l > 0) {
			unsigned char tmp[64];

			memcpy(tmp, buf, l);
			chacha_block_xor_neon(state, tmp, tmp, 20);
			memcpy(buf, tmp, l);
		}
#endif
	}

	return 0;
}
