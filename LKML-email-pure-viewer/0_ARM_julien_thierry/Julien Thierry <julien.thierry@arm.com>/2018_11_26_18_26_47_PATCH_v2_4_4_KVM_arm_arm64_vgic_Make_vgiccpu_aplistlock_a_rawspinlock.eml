Return-Path: <linux-kernel-owner@vger.kernel.org>
Delivered-To: unknown
Received: from linux.intel.com (10.54.29.200:995) by likexu-workstation with
  POP3-SSL; 27 Nov 2018 08:39:27 -0000
X-Original-To: like.xu@linux.intel.com
Delivered-To: like.xu@linux.intel.com
Received: from orsmga002.jf.intel.com (orsmga002.jf.intel.com [10.7.209.21])
	(using TLSv1.2 with cipher ECDHE-RSA-AES256-GCM-SHA384 (256/256 bits))
	(No client certificate requested)
	by linux.intel.com (Postfix) with ESMTPS id 94EBC5802E4;
	Mon, 26 Nov 2018 10:27:12 -0800 (PST)
Received: from fmsmga102.fm.intel.com ([10.1.193.69])
  by orsmga002-1.jf.intel.com with ESMTP/TLS/DHE-RSA-AES256-GCM-SHA384; 26 Nov 2018 10:27:11 -0800
X-SG-BADATTACHMENTNOREPLY: True
IronPort-PHdr: =?us-ascii?q?9a23=3ArXiyShaFVnj1qxWsWhiXron/LSx+4OfEezUN459i?=
 =?us-ascii?q?sYplN5qZpciybR7h7PlgxGXEQZ/co6odzbaO4+a4ASQp2tWoiDg6aptCVhsI24?=
 =?us-ascii?q?09vjcLJ4q7M3D9N+PgdCcgHc5PBxdP9nC/NlVJSo6lPwWB6nK94iQPFRrhKAF7?=
 =?us-ascii?q?Ovr6GpLIj8Swyuu+54Dfbx9HiTahYr5+Ngm6oRnMvcQKnIVuLbo8xAHUqXVSYe?=
 =?us-ascii?q?RWwm1oJVOXnxni48q74YBu/SdNtf8/7sBMSar1cbg2QrxeFzQmLns65Nb3uhnZ?=
 =?us-ascii?q?TAuA/WUTX2MLmRdVGQfF7RX6XpDssivms+d2xSeXMdHqQb0yRD+v9LlgRgP2hy?=
 =?us-ascii?q?gbNj456GDXhdJ2jKJHuxKquhhzz5fJbI2JKPZye6XQds4YS2VcRMZcTyxPDJ2h?=
 =?us-ascii?q?YYUBDOQPOuRXr4fmp1sWrxazHhWgCP/1xzNUnHL6wbE23uI8Gg/GxgwgGNcOvW?=
 =?us-ascii?q?zQotXoMKcSUP66zK/Vxjvdb/NW2Cny6JLSchEhvPqBWrBwcdfVyUkuCQzFiE+c?=
 =?us-ascii?q?qZDlPzOUyOsNqXKb7up7WO21kW4nrht9rSSoxscpk4TEgJ8exFPc9Shh3oo5Od?=
 =?us-ascii?q?m1RFRmbdOqDpdcrTyWOohqTs84Qmxluj42xqMbtZO5ZiQG1ZsqywLFZ/Cab4SE?=
 =?us-ascii?q?/wjvWeSNLTp+mXlrYqiwhwyo/kil0uD8Vte70FJNriddjNnMuW4C1wbJ5siEVP?=
 =?us-ascii?q?R95EGh1iiL1wzJ7eFEO080mbLaK54n3LEwioIevVrfEiLygkn6kaGbels+9uS1?=
 =?us-ascii?q?6Onrfq/qq56eOoNsjwHxKKUumsixAeQiNQgOWnCW+eC91L3l4E34T6xGjv4ona?=
 =?us-ascii?q?nDtpDVO8Abqre+Aw5b1IYs9Qy/Aiy40NQXg3YHNkhJeBGZgIjzPVHBPvT4Ae24?=
 =?us-ascii?q?g1S2nzdn3+rGMaH5ApXRMnjDl6/sfbJ8605f1gU/199e549PB7EFIfLzXFLxtd?=
 =?us-ascii?q?PCAh84NQy03/joCNFn2owCXmKPB7eTMLnOvl+Q+uIvP+6MaZcVuDnnKvgl++Th?=
 =?us-ascii?q?jXgjlV8dYKmmx50XaH+jE/RiIkWZZ2fsg9gbHWcLuAo+UPLliFmYXTFPYHayWr?=
 =?us-ascii?q?o25isnB4K+EYfDWoetjaSD3Ce8AJJafGNGCleKEXfucIWJQPMMaCOUIs98nT0I?=
 =?us-ascii?q?T7mhS4k91R6wsA/20aZoLu3R+icAr5LsyMB15/HPlRE17TF7Fd+d02GKT2F3hG?=
 =?us-ascii?q?8IXSU53KJkrEx5y1eD17V4gvNCGdxS4fNJThk1NZrGw+NmDNDyXxrLfs2VR1a+?=
 =?us-ascii?q?XtWmHTYxQ8oyw9AUZUZxAdGijhHZ0CqsDL8YjLiLBJ0y8qLB0Hn9Pcd9y3Da1K?=
 =?us-ascii?q?Y/i1kqWNdANWqjhqRn7QjcG5bJk1mFl6atbakTwTTC9HmdwmaUvEFXSghwUb7b?=
 =?us-ascii?q?UnAZYUfWqdf55kbGT7K1DbQnMw1BydONK6dQa93pi0lGS+nnONjEf22xnGKwDw?=
 =?us-ascii?q?6SxryQdIrqZ3kd3CLFBUcZiQ8T42iJORI+Bii7pWLeFyJhFVT0bkPo8Ol+rm67?=
 =?us-ascii?q?T0AuwwGLaU1hy6S6+hoPifOATPMT26oOuD09pDVsAFa9w9XWBsKcpwpgeaVcZs?=
 =?us-ascii?q?894FdH1G7DqwxxJJugL7pmhl4fdQR3sFjj1xF2CoVGjMgro2kmzAt0KaKEzlxB?=
 =?us-ascii?q?cymU0oz3Or3SMmPy5gyga7bK2lHC19ab4r0A6PAmpFTsog6oFlAu/G5609ZIyX?=
 =?us-ascii?q?Sc4JbKDA0MUZ/qVkY39h56p6zVYyUn5oPU02FsPrewsjPYx90pA+4lwA66f9hD?=
 =?us-ascii?q?KKOECBPyE8oCCsmuNewmgUSmYggFPeBS7qE0OcymeuCC2K6qOuZggT2ngX5G4I?=
 =?us-ascii?q?B7zkKD6S58RvTU0JYCxvGSxhGHWCvkjFe9rsD3nphJZSsTHmWj0yfkHpNeZqpo?=
 =?us-ascii?q?cYYNF2iuOcy3ysxiiJH3X35X6UCsB0kB2M+vYheSa1393QtN1UUYu3CnmC24zy?=
 =?us-ascii?q?BqnDEttKaQwCvOw+H6fhodJmFLXHVijUvrIYWsj9EaXVKkbggzmBu++Eb6wbNW?=
 =?us-ascii?q?pKB+L2nVXEdJcDL6L2BkUqusqLWCZ9RD548vsSVSSO68e0yVSqbhoxsG1CPuB2?=
 =?us-ascii?q?leyyohdzGpuZX5mAZ2iHmHI3Zwr3rZeMdwygnZ5NHHQf5R3zwGRDR3iDXNB1i8?=
 =?us-ascii?q?OcWp8suQl5vZru++UGehXIVJcSb31YOAqDe75WpyDBy/hf+zncfrEQo70S/9zN?=
 =?us-ascii?q?RqUSTIrBDhYojkzai6MORnflV2C1/48cZ1BoZ+ko4ojpEKxXcanomV/WYAkWrr?=
 =?us-ascii?q?MtVUw6P+YGANRT4W2dHV5gfl1VZnLnKIwYL5S3qcztFgZ9m8fmMZxCY949pWB6?=
 =?us-ascii?q?eT6bxOhTF1rUagrQLNffh9mS8Qyf4v6H4Zme4FogQswTuGArAOA0ZYJzfjmAqS?=
 =?us-ascii?q?79Cxt6hXYGevcb6t1Etxh9yhDbeCoh1CV3b9YJstAShw7sBnOlLWzHLz8p3keM?=
 =?us-ascii?q?XXbd8Lqh2UlBLAg/JUKZ0rkPoKmDFnOXn8vXA+z+47jBpu3Yy1vYSdKmVt+r65?=
 =?us-ascii?q?DQBcNjHve8wT/TTth75EnsmKx4CvAolhGjITUZTzV/2oFzYSten9OwaKDT0xsX?=
 =?us-ascii?q?ObGbvZHQ+C50ZqtXPPE5a3N36JIHkV18ltRB6YJEZHmgAbQC06noIlFgCt3MHh?=
 =?us-ascii?q?cl125jUP6V7jsBdM1vhkNxriUmfcuQeobC07SIOEIRpS7wFC4VrVMMOE4uJyGS?=
 =?us-ascii?q?FY4oOurAiXJmOHYARICHkDWlaYCFD7Irmu+d7A/vCYB+q5MvvOeKiOpvZYV/uS?=
 =?us-ascii?q?3pKv1Y1m/zmXO8WLP3liCeA720VZUXB4HcTZhysASygNmy3RaM6boQ+2+jdroc?=
 =?us-ascii?q?Cn7PTrRAXv6JOPC7RMMNVv+BO2gaaZO+6TniZ5LjlY2Y0WxX/V07gSx1oSiyBo?=
 =?us-ascii?q?dzmwHrUMry/NTKTMmqBJCx4XcT98NMxN76gkxAlCJdbbis/p1r5/lvM6EUpFWk?=
 =?us-ascii?q?f7ms63Zc0GOWW9NFLcCUaPNbSGIyDLws7tbaO9T71QkPtbtxmqtTmHFE/jOyyJ?=
 =?us-ascii?q?lyP1WBC3LeFMkCabMQRCuIG8dxZhE3TsQMj6ZR27LtB3iyY7wbk1hnPMKG4dPi?=
 =?us-ascii?q?Jwc0JLrr2M8yxYhu9zFHBG7npgNeOEgTqW7/HEKpYKtvtmGiR1mPhc4HQ/yrtV?=
 =?us-ascii?q?6jlLRf11mCTIqN5urEqrku2OyjphTRpPpSxHhIONvUV+J6rZ8oNMVmrD/BIIvi?=
 =?us-ascii?q?2sDEEOpt14GpjstrpWx9zniq3+MnFB/sjS8M9aANLbbIqELn8oKx/BHD/PEBBD?=
 =?us-ascii?q?RiXtPmbbmklXkfjU+3GI/bYgrZ25uocKS7JdHGA1F/4AEFUtSN4fJJZ6WHU4kb?=
 =?us-ascii?q?+WltQZzXOkqV/aQ8AM7cOPbe6bHfi6cGXRtrJDfRZdhOqgdYk=3D?=
X-IronPort-Anti-Spam-Filtered: true
X-IronPort-Anti-Spam-Result: =?us-ascii?q?A0ATAAB/Ovxbh0O0hNFjDg8BAQUBBwUBg?=
 =?us-ascii?q?VEIAQsBg2snjBFfiySCIZcogXMsEwGIYyI0CQ0BAwEBAQEBAQIBEwEBAQgNCQg?=
 =?us-ascii?q?pL4I2JAGCYgMDAQIkUgYJAQFQA1QHEgWDHIICBAGnIjOKJYdehCuBVz+BEY1rA?=
 =?us-ascii?q?okjll8HAoIcBIgJhwgWkQgsmUqCDTMaI1CCbIInF41iOj8BATGBBQEBi3sBAQ?=
X-IPAS-Result: =?us-ascii?q?A0ATAAB/Ovxbh0O0hNFjDg8BAQUBBwUBgVEIAQsBg2snjBF?=
 =?us-ascii?q?fiySCIZcogXMsEwGIYyI0CQ0BAwEBAQEBAQIBEwEBAQgNCQgpL4I2JAGCYgMDA?=
 =?us-ascii?q?QIkUgYJAQFQA1QHEgWDHIICBAGnIjOKJYdehCuBVz+BEY1rAokjll8HAoIcBIg?=
 =?us-ascii?q?JhwgWkQgsmUqCDTMaI1CCbIInF41iOj8BATGBBQEBi3sBAQ?=
X-IronPort-AV: E=Sophos;i="5.56,283,1539673200"; 
   d="scan'208";a="54369108"
X-Amp-Result: SKIPPED(no attachment in message)
X-Amp-File-Uploaded: False
Received: from vger.kernel.org ([209.132.180.67])
  by mtab.intel.com with ESMTP; 26 Nov 2018 10:27:09 -0800
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
        id S1727001AbeK0FWB (ORCPT <rfc822;like.xu@linux.intel.com>
        + 23 others); Tue, 27 Nov 2018 00:22:01 -0500
Received: from foss.arm.com ([217.140.101.70]:44634 "EHLO foss.arm.com"
        rhost-flags-OK-OK-OK-OK) by vger.kernel.org with ESMTP
        id S1725199AbeK0FWA (ORCPT <rfc822;linux-kernel@vger.kernel.org>);
        Tue, 27 Nov 2018 00:22:00 -0500
Received: from usa-sjc-imap-foss1.foss.arm.com (unknown [10.72.51.249])
        by usa-sjc-mx-foss1.foss.arm.com (Postfix) with ESMTP id B61F51C00;
        Mon, 26 Nov 2018 10:27:02 -0800 (PST)
Received: from e112298-lin.cambridge.arm.com (usa-sjc-imap-foss1.foss.arm.com [10.72.51.249])
        by usa-sjc-imap-foss1.foss.arm.com (Postfix) with ESMTPA id E77173F5AF;
        Mon, 26 Nov 2018 10:27:00 -0800 (PST)
From: Julien Thierry <julien.thierry@arm.com>
To: linux-kernel@vger.kernel.org, kvmarm@lists.cs.columbia.edu
Cc: marc.zyngier@arm.com, Christoffer.Dall@arm.com,
        linux-arm-kernel@lists.infradead.org,
        linux-rt-users@vger.kernel.org, tglx@linutronix.de,
        rostedt@goodmis.org, bigeasy@linutronix.de,
        Julien Thierry <julien.thierry@arm.com>,
        Christoffer Dall <christoffer.dall@arm.com>
Subject: [PATCH v2 4/4] KVM: arm/arm64: vgic: Make vgic_cpu->ap_list_lock a raw_spinlock
Date: Mon, 26 Nov 2018 18:26:47 +0000
Message-Id: <1543256807-9768-5-git-send-email-julien.thierry@arm.com>
X-Mailer: git-send-email 1.9.1
In-Reply-To: <1543256807-9768-1-git-send-email-julien.thierry@arm.com>
References: <1543256807-9768-1-git-send-email-julien.thierry@arm.com>
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: <linux-kernel.vger.kernel.org>
X-Mailing-List: linux-kernel@vger.kernel.org

vgic_cpu->ap_list_lock must always be taken with interrupts disabled as
it is used in interrupt context.

For configurations such as PREEMPT_RT_FULL, this means that it should
be a raw_spinlock since RT spinlocks are interruptible.

Signed-off-by: Julien Thierry <julien.thierry@arm.com>
Cc: Christoffer Dall <christoffer.dall@arm.com>
Cc: Marc Zyngier <marc.zyngier@arm.com>
---
 include/kvm/arm_vgic.h        |  2 +-
 virt/kvm/arm/vgic/vgic-init.c |  2 +-
 virt/kvm/arm/vgic/vgic.c      | 43 ++++++++++++++++++++++---------------------
 3 files changed, 24 insertions(+), 23 deletions(-)

diff --git a/include/kvm/arm_vgic.h b/include/kvm/arm_vgic.h
index 32954e1..c36c86f 100644
--- a/include/kvm/arm_vgic.h
+++ b/include/kvm/arm_vgic.h
@@ -307,7 +307,7 @@ struct vgic_cpu {
 	unsigned int used_lrs;
 	struct vgic_irq private_irqs[VGIC_NR_PRIVATE_IRQS];
 
-	spinlock_t ap_list_lock;	/* Protects the ap_list */
+	raw_spinlock_t ap_list_lock;	/* Protects the ap_list */
 
 	/*
 	 * List of IRQs that this VCPU should consider because they are either
diff --git a/virt/kvm/arm/vgic/vgic-init.c b/virt/kvm/arm/vgic/vgic-init.c
index 330c1ad..dfbfcb1 100644
--- a/virt/kvm/arm/vgic/vgic-init.c
+++ b/virt/kvm/arm/vgic/vgic-init.c
@@ -206,7 +206,7 @@ int kvm_vgic_vcpu_init(struct kvm_vcpu *vcpu)
 	vgic_cpu->sgi_iodev.base_addr = VGIC_ADDR_UNDEF;
 
 	INIT_LIST_HEAD(&vgic_cpu->ap_list_head);
-	spin_lock_init(&vgic_cpu->ap_list_lock);
+	raw_spin_lock_init(&vgic_cpu->ap_list_lock);
 
 	/*
 	 * Enable and configure all SGIs to be edge-triggered and
diff --git a/virt/kvm/arm/vgic/vgic.c b/virt/kvm/arm/vgic/vgic.c
index 01bd18c..736ae59 100644
--- a/virt/kvm/arm/vgic/vgic.c
+++ b/virt/kvm/arm/vgic/vgic.c
@@ -54,11 +54,11 @@ struct vgic_global kvm_vgic_global_state __ro_after_init = {
  * When taking more than one ap_list_lock at the same time, always take the
  * lowest numbered VCPU's ap_list_lock first, so:
  *   vcpuX->vcpu_id < vcpuY->vcpu_id:
- *     spin_lock(vcpuX->arch.vgic_cpu.ap_list_lock);
- *     spin_lock(vcpuY->arch.vgic_cpu.ap_list_lock);
+ *     raw_spin_lock(vcpuX->arch.vgic_cpu.ap_list_lock);
+ *     raw_spin_lock(vcpuY->arch.vgic_cpu.ap_list_lock);
  *
  * Since the VGIC must support injecting virtual interrupts from ISRs, we have
- * to use the spin_lock_irqsave/spin_unlock_irqrestore versions of outer
+ * to use the raw_spin_lock_irqsave/raw_spin_unlock_irqrestore versions of outer
  * spinlocks for any lock that may be taken while injecting an interrupt.
  */
 
@@ -273,7 +273,7 @@ static void vgic_sort_ap_list(struct kvm_vcpu *vcpu)
 {
 	struct vgic_cpu *vgic_cpu = &vcpu->arch.vgic_cpu;
 
-	DEBUG_SPINLOCK_BUG_ON(!spin_is_locked(&vgic_cpu->ap_list_lock));
+	DEBUG_SPINLOCK_BUG_ON(!raw_spin_is_locked(&vgic_cpu->ap_list_lock));
 
 	list_sort(NULL, &vgic_cpu->ap_list_head, vgic_irq_cmp);
 }
@@ -351,7 +351,7 @@ bool vgic_queue_irq_unlock(struct kvm *kvm, struct vgic_irq *irq,
 
 	/* someone can do stuff here, which we re-check below */
 
-	spin_lock_irqsave(&vcpu->arch.vgic_cpu.ap_list_lock, flags);
+	raw_spin_lock_irqsave(&vcpu->arch.vgic_cpu.ap_list_lock, flags);
 	raw_spin_lock(&irq->irq_lock);
 
 	/*
@@ -368,7 +368,8 @@ bool vgic_queue_irq_unlock(struct kvm *kvm, struct vgic_irq *irq,
 
 	if (unlikely(irq->vcpu || vcpu != vgic_target_oracle(irq))) {
 		raw_spin_unlock(&irq->irq_lock);
-		spin_unlock_irqrestore(&vcpu->arch.vgic_cpu.ap_list_lock, flags);
+		raw_spin_unlock_irqrestore(&vcpu->arch.vgic_cpu.ap_list_lock,
+					   flags);
 
 		raw_spin_lock_irqsave(&irq->irq_lock, flags);
 		goto retry;
@@ -383,7 +384,7 @@ bool vgic_queue_irq_unlock(struct kvm *kvm, struct vgic_irq *irq,
 	irq->vcpu = vcpu;
 
 	raw_spin_unlock(&irq->irq_lock);
-	spin_unlock_irqrestore(&vcpu->arch.vgic_cpu.ap_list_lock, flags);
+	raw_spin_unlock_irqrestore(&vcpu->arch.vgic_cpu.ap_list_lock, flags);
 
 	kvm_make_request(KVM_REQ_IRQ_PENDING, vcpu);
 	kvm_vcpu_kick(vcpu);
@@ -597,7 +598,7 @@ static void vgic_prune_ap_list(struct kvm_vcpu *vcpu)
 	DEBUG_SPINLOCK_BUG_ON(!irqs_disabled());
 
 retry:
-	spin_lock(&vgic_cpu->ap_list_lock);
+	raw_spin_lock(&vgic_cpu->ap_list_lock);
 
 	list_for_each_entry_safe(irq, tmp, &vgic_cpu->ap_list_head, ap_list) {
 		struct kvm_vcpu *target_vcpu, *vcpuA, *vcpuB;
@@ -638,7 +639,7 @@ static void vgic_prune_ap_list(struct kvm_vcpu *vcpu)
 		/* This interrupt looks like it has to be migrated. */
 
 		raw_spin_unlock(&irq->irq_lock);
-		spin_unlock(&vgic_cpu->ap_list_lock);
+		raw_spin_unlock(&vgic_cpu->ap_list_lock);
 
 		/*
 		 * Ensure locking order by always locking the smallest
@@ -652,9 +653,9 @@ static void vgic_prune_ap_list(struct kvm_vcpu *vcpu)
 			vcpuB = vcpu;
 		}
 
-		spin_lock(&vcpuA->arch.vgic_cpu.ap_list_lock);
-		spin_lock_nested(&vcpuB->arch.vgic_cpu.ap_list_lock,
-				 SINGLE_DEPTH_NESTING);
+		raw_spin_lock(&vcpuA->arch.vgic_cpu.ap_list_lock);
+		raw_spin_lock_nested(&vcpuB->arch.vgic_cpu.ap_list_lock,
+				      SINGLE_DEPTH_NESTING);
 		raw_spin_lock(&irq->irq_lock);
 
 		/*
@@ -676,8 +677,8 @@ static void vgic_prune_ap_list(struct kvm_vcpu *vcpu)
 		}
 
 		raw_spin_unlock(&irq->irq_lock);
-		spin_unlock(&vcpuB->arch.vgic_cpu.ap_list_lock);
-		spin_unlock(&vcpuA->arch.vgic_cpu.ap_list_lock);
+		raw_spin_unlock(&vcpuB->arch.vgic_cpu.ap_list_lock);
+		raw_spin_unlock(&vcpuA->arch.vgic_cpu.ap_list_lock);
 
 		if (target_vcpu_needs_kick) {
 			kvm_make_request(KVM_REQ_IRQ_PENDING, target_vcpu);
@@ -687,7 +688,7 @@ static void vgic_prune_ap_list(struct kvm_vcpu *vcpu)
 		goto retry;
 	}
 
-	spin_unlock(&vgic_cpu->ap_list_lock);
+	raw_spin_unlock(&vgic_cpu->ap_list_lock);
 }
 
 static inline void vgic_fold_lr_state(struct kvm_vcpu *vcpu)
@@ -736,7 +737,7 @@ static int compute_ap_list_depth(struct kvm_vcpu *vcpu,
 
 	*multi_sgi = false;
 
-	DEBUG_SPINLOCK_BUG_ON(!spin_is_locked(&vgic_cpu->ap_list_lock));
+	DEBUG_SPINLOCK_BUG_ON(!raw_spin_is_locked(&vgic_cpu->ap_list_lock));
 
 	list_for_each_entry(irq, &vgic_cpu->ap_list_head, ap_list) {
 		int w;
@@ -761,7 +762,7 @@ static void vgic_flush_lr_state(struct kvm_vcpu *vcpu)
 	bool multi_sgi;
 	u8 prio = 0xff;
 
-	DEBUG_SPINLOCK_BUG_ON(!spin_is_locked(&vgic_cpu->ap_list_lock));
+	DEBUG_SPINLOCK_BUG_ON(!raw_spin_is_locked(&vgic_cpu->ap_list_lock));
 
 	count = compute_ap_list_depth(vcpu, &multi_sgi);
 	if (count > kvm_vgic_global_state.nr_lr || multi_sgi)
@@ -872,9 +873,9 @@ void kvm_vgic_flush_hwstate(struct kvm_vcpu *vcpu)
 
 	DEBUG_SPINLOCK_BUG_ON(!irqs_disabled());
 
-	spin_lock(&vcpu->arch.vgic_cpu.ap_list_lock);
+	raw_spin_lock(&vcpu->arch.vgic_cpu.ap_list_lock);
 	vgic_flush_lr_state(vcpu);
-	spin_unlock(&vcpu->arch.vgic_cpu.ap_list_lock);
+	raw_spin_unlock(&vcpu->arch.vgic_cpu.ap_list_lock);
 
 	if (can_access_vgic_from_kernel())
 		vgic_restore_state(vcpu);
@@ -915,7 +916,7 @@ int kvm_vgic_vcpu_pending_irq(struct kvm_vcpu *vcpu)
 	if (vcpu->arch.vgic_cpu.vgic_v3.its_vpe.pending_last)
 		return true;
 
-	spin_lock_irqsave(&vgic_cpu->ap_list_lock, flags);
+	raw_spin_lock_irqsave(&vgic_cpu->ap_list_lock, flags);
 
 	list_for_each_entry(irq, &vgic_cpu->ap_list_head, ap_list) {
 		raw_spin_lock(&irq->irq_lock);
@@ -926,7 +927,7 @@ int kvm_vgic_vcpu_pending_irq(struct kvm_vcpu *vcpu)
 			break;
 	}
 
-	spin_unlock_irqrestore(&vgic_cpu->ap_list_lock, flags);
+	raw_spin_unlock_irqrestore(&vgic_cpu->ap_list_lock, flags);
 
 	return pending;
 }
-- 
1.9.1

