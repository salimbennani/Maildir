Return-Path: <linux-kernel-owner@vger.kernel.org>
Delivered-To: unknown
Received: from linux.intel.com (10.54.29.200:995) by likexu-workstation with
  POP3-SSL; 05 Dec 2018 08:45:20 -0000
X-Original-To: like.xu@linux.intel.com
Delivered-To: like.xu@linux.intel.com
Received: from orsmga005.jf.intel.com (orsmga005.jf.intel.com [10.7.209.41])
	(using TLSv1.2 with cipher ECDHE-RSA-AES256-GCM-SHA384 (256/256 bits))
	(No client certificate requested)
	by linux.intel.com (Postfix) with ESMTPS id AAAD0580375;
	Tue,  4 Dec 2018 14:43:09 -0800 (PST)
Received: from orsmga102-1.jf.intel.com (HELO mga09.intel.com) ([10.7.208.27])
  by orsmga005-1.jf.intel.com with ESMTP; 04 Dec 2018 14:43:09 -0800
X-SG-BADATTACHMENTNOREPLY: True
IronPort-PHdr: =?us-ascii?q?9a23=3AfkIoWhd9VC3IbWJBNVsSKLQQlGMj4u6mDksu8pMi?=
 =?us-ascii?q?zoh2WeGdxc68YRWN2/xhgRfzUJnB7Loc0qyK6/CmATRIyK3CmUhKSIZLWR4BhJ?=
 =?us-ascii?q?detC0bK+nBN3fGKuX3ZTcxBsVIWQwt1Xi6NU9IBJS2PAWK8TW94jEIBxrwKxd+?=
 =?us-ascii?q?KPjrFY7OlcS30P2594HObwlSizexfbB/IA+qoQnNq8IbnZZsJqEtxxXTv3BGYf?=
 =?us-ascii?q?5WxWRmJVKSmxbz+MK994N9/ipTpvws6ddOXb31cKokQ7NYCi8mM30u683wqRbD?=
 =?us-ascii?q?VwqP6WACXWgQjxFFHhLK7BD+Xpf2ryv6qu9w0zSUMMHqUbw5Xymp4qF2QxHqlS?=
 =?us-ascii?q?gHLSY0/m/XhMJzlqJVvg+vqRtwzIDbfI6aKeF+frvfcN4BWWpMXdxcWzBbD4+g?=
 =?us-ascii?q?bYYCCfcKM+ZCr4n6olsDtRWyBRWtBOP30zNHnXj23bEn2OQvFgHGxhErEcgUv3?=
 =?us-ascii?q?TJqNX+KagcXfqox6fP0TrNau1Z2TH76IfWchEtr+yHULVsccrQ0UkgDATFjkmL?=
 =?us-ascii?q?pI3kPzKVyuMNs3KB4+V8UuKvjncqpgdsqTahwccsj5PGhoMTyl3c9iV23pw1Jd?=
 =?us-ascii?q?umR05/e9KkF4FQty6cOoBrQc0iW3lltDgmxrACo5K3YSYHxIo9yxLCaPGLb5KE?=
 =?us-ascii?q?7xPhWeqJPDt1gHFodKiiixu880Ws0PPwWtWq3FpQsyZInNjBu3YQ3BLJ8MeHUO?=
 =?us-ascii?q?Fy/kK51DaPyQ/T7uZELFgqlarUNZEh2KQ8lpkNvkTZGC/5hkH2gLWRdkU+9eik?=
 =?us-ascii?q?8+XnYrP4qZ+AL4J4lB3yP6A0lsCiD+k0LBICU3WY9OigzrHu/E/0TK1PjvIsk6?=
 =?us-ascii?q?nZtJ7aJd4cpq68GwJV1ocj6xCiDzapydgYnmcILEhDeB2Zi4jlIlbOIf7+Dfih?=
 =?us-ascii?q?mVShiylrx//YMb37GJnNLWbMkK3nfblj705Q0g0zzcpQ555MELEOPOrzWlPttN?=
 =?us-ascii?q?zfFhI5Nw20w+X5B9ln2YIeRHmCAquYMKPUrF+J6fgjI+iKZI8Jpjn9L+Ip6OLp?=
 =?us-ascii?q?jX88gVUdZ7Wm3YMLaHCkGfRrO0WZbmDtgtcdC2gKuRAyTOz3iFKYVz5TaG2/X6?=
 =?us-ascii?q?Y95jE9FYKnAp3PRoGrgLydwii7GodaaXxBClCJCX3obZmLW+8QaCKOJc9sij4E?=
 =?us-ascii?q?Vb+/RIM71hGuswn6y7xgLufP/i0YtJTj1MV65uHJlBEy8yB0ANqZ022XU250mW?=
 =?us-ascii?q?YITScs3K9juUx91kuD0a9gjvNCDtxT5/RJUgQgOZ7G1eN6Ccv/WgbAftePVVan?=
 =?us-ascii?q?Tc+qATA3TtIt3dAOZ1xxFMmljhDGxyCqGaMal6SXBJwo9aLRx3vxKNx7y3rc0K?=
 =?us-ascii?q?khjkMpQs1ANWC9gq5/9g7TB5PGkkmDlqaqc7gc0zDJ9GuZ0WWOu0RYWhZqUarZ?=
 =?us-ascii?q?RXAfelfWrdPh60zfVbCuF6ooPhFBycGYLKtKccPmjVNBSPfnO9TeZmaxlny0BR?=
 =?us-ascii?q?aJwLOMcYXrd38c3CXbFEgLjQQT8WyaOgg5Ayeru3jeAyB2FVLzf0Ps9vFzp26h?=
 =?us-ascii?q?QU8q0Q6GdU1h2KCz+h4Om/OcTege3rYFuCcntjV1E0yx39PQC9qcuQVheL9Qbs?=
 =?us-ascii?q?864FdCzWjZrRByPoS8L6B+gV4Taxh3v0Lr1xVwFoVAkcgroGk2zAZoLqKYyldB?=
 =?us-ascii?q?dzKe3ZD/IbDXLmjy/Baya6/ZwF3e0dCW+rsR5/Q8sVnsoAapFk86+XV9z9ZVy2?=
 =?us-ascii?q?ec5onNDAcKS53xVlg49hdkqLDaeCUy/J7U2mB2PqmysT/C3MwpCfAhyhaheddf?=
 =?us-ascii?q?LayFGBXzE80cG8ihNugql0K1YRIDOeBY7LQ0MN++d/uaxK6rO/5tnTK7jWhd/I?=
 =?us-ascii?q?9xyEON9ypmRe7O0JYI2PWY3gqBVzfhg1atqMH3mYZYZT4MGmqz0zTrBIlUZqdq?=
 =?us-ascii?q?Z4YEFX+uI9GrxtV5n5PtQX9Y+0K5CFMcxcCpfgCeb1rj0g1K1EQbuGColjG8zz?=
 =?us-ascii?q?NpjT4ptK2f3CrVzuTmdRoHPHNLRWZ4gVftJ4i0k84VXEyyYwc1kxul4F7wx7JH?=
 =?us-ascii?q?q6RnM2nTXUBIcjD2LmFjSKextqCOY9VS6JMuqihXVOW8YVaHSr/yuRca0iXjH3?=
 =?us-ascii?q?dAyzA/bT2lppL5nxligmKHMHlztGbZed13xRrH5tzTX+RR3jkFRCl/kzXXHUKz?=
 =?us-ascii?q?P9qq/dWVkZfMrOa+WnmlVp1Sdynr0IyBuDG65W1sHR2wgfSzlsf7Hgg91C/xz8?=
 =?us-ascii?q?NqWjnQrBbgfonr0Ly3MOJ9cUlvHlP86ct6Godln4s0hZEQ32Uah5qP8XoGl2fz?=
 =?us-ascii?q?LctU2abkYHURQj4Lxsbf4BL51017MnKJ24X5W22ewsR7Ztm2eGMW2j8n4MBMB6?=
 =?us-ascii?q?eZ97hEnSpzolqlogPde/l9njEByfQw7H4Wmf0GuA0ozi+FGLAdAVFYPTDwlxSP?=
 =?us-ascii?q?992+qaRXZGW1frSq2ktxg8uhDK2crQFGQ3n2ZI0iHSBr48V7MVLM1mDz647+dN?=
 =?us-ascii?q?nRa9ITqgObkxPag+dJL5Ixk+IAhTB7NmLloX0l1+k7gARy3ZG9uYiLMWRs87i/?=
 =?us-ascii?q?Ah5FLT31fMIT9yrpjaZfmMaWwo+uEo9gGjUNQJvnU/aoHCgOuvTgMgaECCc8pW?=
 =?us-ascii?q?uDGbrDAQ+f719roGnVHJCsM3GXOWMVzdF/RBSGIExfgQYUXCg1n5IjFwCqwtDh?=
 =?us-ascii?q?f1l95jwL+lH4rR5MwPpyNxbjSmffuBuoajAsRZidNhVW6x9N51zPPcyC9O5zHD?=
 =?us-ascii?q?xY/p68rAyLMGObfB9FDWUIWkyCGlDiMaOi5djG8+iEGOW+K+HCbqmJqexbT/2I?=
 =?us-ascii?q?346g0pN6/zaQMcWCJnljD/om2kpaQHB2AcLZly8USywQkSLNYNWWpBO9+i1xs8?=
 =?us-ascii?q?C+/+7nWAPp5YuTFbRSNc9j9AyxgaeGL+SQnjp2KS5E1pMQwn/F0Lgf00ATiyFt?=
 =?us-ascii?q?dDmtEK4MtS3XTKLXla9YEQQbaz5oNMZT66I83w9NOdPUi9/v1754iOI1BElBVV?=
 =?us-ascii?q?D7hs6pYskKKXmnNFzbHEaLKKiGJTrTzs7tfKOzUqdQg/tUthGqvTabElTuPjCC?=
 =?us-ascii?q?lznvShCuPvtAjCCdPBxCpo69dgxhBnTkTNLjche7KsN4jSUqwb0ogXPHLXIcMT?=
 =?us-ascii?q?l5c09XsrKc9z9XgvVhFGxH9XdlKeiEmyCE7+jXMJoWsP1rAjhqmOJe+ng117xV?=
 =?us-ascii?q?7CRcTvxvhCTStsJuo02hkuSXyjtoShxOqjNKhIKNpUpjOKXZ+YNGWXbL5x8N6W?=
 =?us-ascii?q?SQCxIXp9pqENHvuqZQysTRm6L3MjtN79XU/c5PT/TTfcaGNmcxdAboAHvfCw4A?=
 =?us-ascii?q?TCKwHX/QilYbk/yI8HCR6J8gpcvWlYIKW4NcAVk0EPwdIkdoBtoPJNFwRDxg2b?=
 =?us-ascii?q?6DheYa9Ga5tl/aQ8Ae9ozIUuK6BfTpNSqDir9Fd10EzPewKIUVOYrTwUFualBm?=
 =?us-ascii?q?2o/NHg6YR9dWviBtcic7p0JB9XllCGop1AatbgKr/W9WFvOumBMyohVxbP5r9z?=
 =?us-ascii?q?r25VozYF3Qq294iEAsndDughiVcTjsPOGxV4QQAC3x5GYrNZauCRp0dUi4mlAs?=
 =?us-ascii?q?OjDeD4pYkr8oWCYjrQT/tJ1JFO8WBflYYQcawu2/deQ01k4aoSKikxwUrdDZAI?=
 =?us-ascii?q?dvwVN5OaWnqGhNjlpu?=
X-IronPort-Anti-Spam-Filtered: true
X-IronPort-Anti-Spam-Result: =?us-ascii?q?A0AaAAB+AQdch0O0hNFkHQEBBQEHBQGBU?=
 =?us-ascii?q?QgBCwGBWoEPgQIng3mIGV+LLgGCIZI8hHkUDIFWDwEBGAsIAYdMIjQJDQEDAQE?=
 =?us-ascii?q?BAQEBAgETAQEBCA0JCCkjDII2IoJsAiAEBQYBRgYJAiQCJgICA20FA4JOSwGCA?=
 =?us-ascii?q?QUKpTx8Mx6EDwGBA4R9BRN4ixMRBoF/gRGHfIMbglcCiTGGfpAaBwIChwGKVoF?=
 =?us-ascii?q?biDaHFSyNQopiAgQCBAUCFIFGgg1wFTuBNA4LAQyBEoImAReIXoVgHgEyCnsBA?=
 =?us-ascii?q?YphAQE?=
X-IPAS-Result: =?us-ascii?q?A0AaAAB+AQdch0O0hNFkHQEBBQEHBQGBUQgBCwGBWoEPgQI?=
 =?us-ascii?q?ng3mIGV+LLgGCIZI8hHkUDIFWDwEBGAsIAYdMIjQJDQEDAQEBAQEBAgETAQEBC?=
 =?us-ascii?q?A0JCCkjDII2IoJsAiAEBQYBRgYJAiQCJgICA20FA4JOSwGCAQUKpTx8Mx6EDwG?=
 =?us-ascii?q?BA4R9BRN4ixMRBoF/gRGHfIMbglcCiTGGfpAaBwIChwGKVoFbiDaHFSyNQopiA?=
 =?us-ascii?q?gQCBAUCFIFGgg1wFTuBNA4LAQyBEoImAReIXoVgHgEyCnsBAYphAQE?=
X-IronPort-AV: E=Sophos;i="5.56,315,1539673200"; 
   d="scan'208";a="56106453"
X-Amp-Result: UNSCANNABLE
X-Amp-File-Uploaded: False
Unscannable: 2
Received: from vger.kernel.org ([209.132.180.67])
  by mtab.intel.com with ESMTP; 04 Dec 2018 14:42:07 -0800
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
        id S1726410AbeLDWmF (ORCPT <rfc822;like.xu@linux.intel.com>
        + 23 others); Tue, 4 Dec 2018 17:42:05 -0500
Received: from terminus.zytor.com ([198.137.202.136]:47077 "EHLO
        terminus.zytor.com" rhost-flags-OK-OK-OK-OK) by vger.kernel.org
        with ESMTP id S1725899AbeLDWmC (ORCPT
        <rfc822;linux-kernel@vger.kernel.org>);
        Tue, 4 Dec 2018 17:42:02 -0500
Received: from terminus.zytor.com (localhost [127.0.0.1])
        by terminus.zytor.com (8.15.2/8.15.2) with ESMTPS id wB4MfpOm1037516
        (version=TLSv1.2 cipher=ECDHE-RSA-AES256-GCM-SHA384 bits=256 verify=NO);
        Tue, 4 Dec 2018 14:41:51 -0800
Received: (from tipbot@localhost)
        by terminus.zytor.com (8.15.2/8.15.2/Submit) id wB4MfpCb1037513;
        Tue, 4 Dec 2018 14:41:51 -0800
Date: Tue, 4 Dec 2018 14:41:51 -0800
X-Authentication-Warning: terminus.zytor.com: tipbot set sender to tipbot@zytor.com using -f
From: "tip-bot for Paul E. McKenney" <tipbot@zytor.com>
Message-ID: <tip-7440172974e85b1828bdd84ac6b23b5bcad9c5eb@git.kernel.org>
Cc: rostedt@goodmis.org, paulmck@linux.ibm.com,
        linux-kernel@vger.kernel.org, mingo@redhat.com, hpa@zytor.com,
        tglx@linutronix.de, mingo@kernel.org
Reply-To: mingo@kernel.org, hpa@zytor.com, tglx@linutronix.de,
          mingo@redhat.com, rostedt@goodmis.org,
          linux-kernel@vger.kernel.org, paulmck@linux.ibm.com
To: linux-tip-commits@vger.kernel.org
Subject: [tip:core/rcu] tracing: Replace synchronize_sched() and
 call_rcu_sched()
Git-Commit-ID: 7440172974e85b1828bdd84ac6b23b5bcad9c5eb
X-Mailer: tip-git-log-daemon
Robot-ID: <tip-bot.git.kernel.org>
Robot-Unsubscribe: Contact <mailto:hpa@kernel.org> to get blacklisted from
 these emails
MIME-Version: 1.0
Content-Transfer-Encoding: 8bit
Content-Type: text/plain; charset=UTF-8
Content-Disposition: inline
X-Spam-Status: No, score=-0.0 required=5.0 tests=ALL_TRUSTED,BAYES_00,
        DATE_IN_FUTURE_96_Q autolearn=no autolearn_force=no version=3.4.2
X-Spam-Checker-Version: SpamAssassin 3.4.2 (2018-09-13) on terminus.zytor.com
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: <linux-kernel.vger.kernel.org>
X-Mailing-List: linux-kernel@vger.kernel.org

Commit-ID:  7440172974e85b1828bdd84ac6b23b5bcad9c5eb
Gitweb:     https://git.kernel.org/tip/7440172974e85b1828bdd84ac6b23b5bcad9c5eb
Author:     Paul E. McKenney <paulmck@linux.ibm.com>
AuthorDate: Tue, 6 Nov 2018 18:44:52 -0800
Committer:  Paul E. McKenney <paulmck@linux.ibm.com>
CommitDate: Tue, 27 Nov 2018 09:21:41 -0800

tracing: Replace synchronize_sched() and call_rcu_sched()

Now that synchronize_rcu() waits for preempt-disable regions of code
as well as RCU read-side critical sections, synchronize_sched() can
be replaced by synchronize_rcu().  Similarly, call_rcu_sched() can be
replaced by call_rcu().  This commit therefore makes these changes.

Signed-off-by: Paul E. McKenney <paulmck@linux.ibm.com>
Cc: Ingo Molnar <mingo@redhat.com>
Cc: <linux-kernel@vger.kernel.org>
Acked-by: Steven Rostedt (VMware) <rostedt@goodmis.org>
---
 include/linux/tracepoint.h         |  2 +-
 kernel/trace/ftrace.c              | 24 ++++++++++++------------
 kernel/trace/ring_buffer.c         | 12 ++++++------
 kernel/trace/trace.c               | 10 +++++-----
 kernel/trace/trace_events_filter.c |  4 ++--
 kernel/trace/trace_kprobe.c        |  2 +-
 kernel/tracepoint.c                |  4 ++--
 7 files changed, 29 insertions(+), 29 deletions(-)

diff --git a/include/linux/tracepoint.h b/include/linux/tracepoint.h
index 538ba1a58f5b..432080b59c26 100644
--- a/include/linux/tracepoint.h
+++ b/include/linux/tracepoint.h
@@ -82,7 +82,7 @@ int unregister_tracepoint_module_notifier(struct notifier_block *nb)
 static inline void tracepoint_synchronize_unregister(void)
 {
 	synchronize_srcu(&tracepoint_srcu);
-	synchronize_sched();
+	synchronize_rcu();
 }
 #else
 static inline void tracepoint_synchronize_unregister(void)
diff --git a/kernel/trace/ftrace.c b/kernel/trace/ftrace.c
index f536f601bd46..5b4f73e4fd56 100644
--- a/kernel/trace/ftrace.c
+++ b/kernel/trace/ftrace.c
@@ -173,7 +173,7 @@ static void ftrace_sync(struct work_struct *work)
 {
 	/*
 	 * This function is just a stub to implement a hard force
-	 * of synchronize_sched(). This requires synchronizing
+	 * of synchronize_rcu(). This requires synchronizing
 	 * tasks even in userspace and idle.
 	 *
 	 * Yes, function tracing is rude.
@@ -934,7 +934,7 @@ ftrace_profile_write(struct file *filp, const char __user *ubuf,
 			ftrace_profile_enabled = 0;
 			/*
 			 * unregister_ftrace_profiler calls stop_machine
-			 * so this acts like an synchronize_sched.
+			 * so this acts like an synchronize_rcu.
 			 */
 			unregister_ftrace_profiler();
 		}
@@ -1086,7 +1086,7 @@ struct ftrace_ops *ftrace_ops_trampoline(unsigned long addr)
 
 	/*
 	 * Some of the ops may be dynamically allocated,
-	 * they are freed after a synchronize_sched().
+	 * they are freed after a synchronize_rcu().
 	 */
 	preempt_disable_notrace();
 
@@ -1286,7 +1286,7 @@ static void free_ftrace_hash_rcu(struct ftrace_hash *hash)
 {
 	if (!hash || hash == EMPTY_HASH)
 		return;
-	call_rcu_sched(&hash->rcu, __free_ftrace_hash_rcu);
+	call_rcu(&hash->rcu, __free_ftrace_hash_rcu);
 }
 
 void ftrace_free_filter(struct ftrace_ops *ops)
@@ -1501,7 +1501,7 @@ static bool hash_contains_ip(unsigned long ip,
  * the ip is not in the ops->notrace_hash.
  *
  * This needs to be called with preemption disabled as
- * the hashes are freed with call_rcu_sched().
+ * the hashes are freed with call_rcu().
  */
 static int
 ftrace_ops_test(struct ftrace_ops *ops, unsigned long ip, void *regs)
@@ -4496,7 +4496,7 @@ unregister_ftrace_function_probe_func(char *glob, struct trace_array *tr,
 	if (ftrace_enabled && !ftrace_hash_empty(hash))
 		ftrace_run_modify_code(&probe->ops, FTRACE_UPDATE_CALLS,
 				       &old_hash_ops);
-	synchronize_sched();
+	synchronize_rcu();
 
 	hlist_for_each_entry_safe(entry, tmp, &hhd, hlist) {
 		hlist_del(&entry->hlist);
@@ -5314,7 +5314,7 @@ ftrace_graph_release(struct inode *inode, struct file *file)
 		mutex_unlock(&graph_lock);
 
 		/* Wait till all users are no longer using the old hash */
-		synchronize_sched();
+		synchronize_rcu();
 
 		free_ftrace_hash(old_hash);
 	}
@@ -5707,7 +5707,7 @@ void ftrace_release_mod(struct module *mod)
 	list_for_each_entry_safe(mod_map, n, &ftrace_mod_maps, list) {
 		if (mod_map->mod == mod) {
 			list_del_rcu(&mod_map->list);
-			call_rcu_sched(&mod_map->rcu, ftrace_free_mod_map);
+			call_rcu(&mod_map->rcu, ftrace_free_mod_map);
 			break;
 		}
 	}
@@ -5927,7 +5927,7 @@ ftrace_mod_address_lookup(unsigned long addr, unsigned long *size,
 	struct ftrace_mod_map *mod_map;
 	const char *ret = NULL;
 
-	/* mod_map is freed via call_rcu_sched() */
+	/* mod_map is freed via call_rcu() */
 	preempt_disable();
 	list_for_each_entry_rcu(mod_map, &ftrace_mod_maps, list) {
 		ret = ftrace_func_address_lookup(mod_map, addr, size, off, sym);
@@ -6262,7 +6262,7 @@ __ftrace_ops_list_func(unsigned long ip, unsigned long parent_ip,
 
 	/*
 	 * Some of the ops may be dynamically allocated,
-	 * they must be freed after a synchronize_sched().
+	 * they must be freed after a synchronize_rcu().
 	 */
 	preempt_disable_notrace();
 
@@ -6433,7 +6433,7 @@ static void clear_ftrace_pids(struct trace_array *tr)
 	rcu_assign_pointer(tr->function_pids, NULL);
 
 	/* Wait till all users are no longer using pid filtering */
-	synchronize_sched();
+	synchronize_rcu();
 
 	trace_free_pid_list(pid_list);
 }
@@ -6580,7 +6580,7 @@ ftrace_pid_write(struct file *filp, const char __user *ubuf,
 	rcu_assign_pointer(tr->function_pids, pid_list);
 
 	if (filtered_pids) {
-		synchronize_sched();
+		synchronize_rcu();
 		trace_free_pid_list(filtered_pids);
 	} else if (pid_list) {
 		/* Register a probe to set whether to ignore the tracing of a task */
diff --git a/kernel/trace/ring_buffer.c b/kernel/trace/ring_buffer.c
index 65bd4616220d..4f3247a53259 100644
--- a/kernel/trace/ring_buffer.c
+++ b/kernel/trace/ring_buffer.c
@@ -1834,7 +1834,7 @@ int ring_buffer_resize(struct ring_buffer *buffer, unsigned long size,
 		 * There could have been a race between checking
 		 * record_disable and incrementing it.
 		 */
-		synchronize_sched();
+		synchronize_rcu();
 		for_each_buffer_cpu(buffer, cpu) {
 			cpu_buffer = buffer->buffers[cpu];
 			rb_check_pages(cpu_buffer);
@@ -3151,7 +3151,7 @@ static bool rb_per_cpu_empty(struct ring_buffer_per_cpu *cpu_buffer)
  * This prevents all writes to the buffer. Any attempt to write
  * to the buffer after this will fail and return NULL.
  *
- * The caller should call synchronize_sched() after this.
+ * The caller should call synchronize_rcu() after this.
  */
 void ring_buffer_record_disable(struct ring_buffer *buffer)
 {
@@ -3253,7 +3253,7 @@ bool ring_buffer_record_is_set_on(struct ring_buffer *buffer)
  * This prevents all writes to the buffer. Any attempt to write
  * to the buffer after this will fail and return NULL.
  *
- * The caller should call synchronize_sched() after this.
+ * The caller should call synchronize_rcu() after this.
  */
 void ring_buffer_record_disable_cpu(struct ring_buffer *buffer, int cpu)
 {
@@ -4191,7 +4191,7 @@ EXPORT_SYMBOL_GPL(ring_buffer_read_prepare);
 void
 ring_buffer_read_prepare_sync(void)
 {
-	synchronize_sched();
+	synchronize_rcu();
 }
 EXPORT_SYMBOL_GPL(ring_buffer_read_prepare_sync);
 
@@ -4363,7 +4363,7 @@ void ring_buffer_reset_cpu(struct ring_buffer *buffer, int cpu)
 	atomic_inc(&cpu_buffer->record_disabled);
 
 	/* Make sure all commits have finished */
-	synchronize_sched();
+	synchronize_rcu();
 
 	raw_spin_lock_irqsave(&cpu_buffer->reader_lock, flags);
 
@@ -4496,7 +4496,7 @@ int ring_buffer_swap_cpu(struct ring_buffer *buffer_a,
 		goto out;
 
 	/*
-	 * We can't do a synchronize_sched here because this
+	 * We can't do a synchronize_rcu here because this
 	 * function can be called in atomic context.
 	 * Normally this will be called from the same CPU as cpu.
 	 * If not it's up to the caller to protect this.
diff --git a/kernel/trace/trace.c b/kernel/trace/trace.c
index ff1c4b20cd0a..51612b4a603f 100644
--- a/kernel/trace/trace.c
+++ b/kernel/trace/trace.c
@@ -1681,7 +1681,7 @@ void tracing_reset(struct trace_buffer *buf, int cpu)
 	ring_buffer_record_disable(buffer);
 
 	/* Make sure all commits have finished */
-	synchronize_sched();
+	synchronize_rcu();
 	ring_buffer_reset_cpu(buffer, cpu);
 
 	ring_buffer_record_enable(buffer);
@@ -1698,7 +1698,7 @@ void tracing_reset_online_cpus(struct trace_buffer *buf)
 	ring_buffer_record_disable(buffer);
 
 	/* Make sure all commits have finished */
-	synchronize_sched();
+	synchronize_rcu();
 
 	buf->time_start = buffer_ftrace_now(buf, buf->cpu);
 
@@ -2250,7 +2250,7 @@ void trace_buffered_event_disable(void)
 	preempt_enable();
 
 	/* Wait for all current users to finish */
-	synchronize_sched();
+	synchronize_rcu();
 
 	for_each_tracing_cpu(cpu) {
 		free_page((unsigned long)per_cpu(trace_buffered_event, cpu));
@@ -5398,7 +5398,7 @@ static int tracing_set_tracer(struct trace_array *tr, const char *buf)
 	if (tr->current_trace->reset)
 		tr->current_trace->reset(tr);
 
-	/* Current trace needs to be nop_trace before synchronize_sched */
+	/* Current trace needs to be nop_trace before synchronize_rcu */
 	tr->current_trace = &nop_trace;
 
 #ifdef CONFIG_TRACER_MAX_TRACE
@@ -5412,7 +5412,7 @@ static int tracing_set_tracer(struct trace_array *tr, const char *buf)
 		 * The update_max_tr is called from interrupts disabled
 		 * so a synchronized_sched() is sufficient.
 		 */
-		synchronize_sched();
+		synchronize_rcu();
 		free_snapshot(tr);
 	}
 #endif
diff --git a/kernel/trace/trace_events_filter.c b/kernel/trace/trace_events_filter.c
index 84a65173b1e9..35f3aa55be85 100644
--- a/kernel/trace/trace_events_filter.c
+++ b/kernel/trace/trace_events_filter.c
@@ -1614,7 +1614,7 @@ static int process_system_preds(struct trace_subsystem_dir *dir,
 
 	/*
 	 * The calls can still be using the old filters.
-	 * Do a synchronize_sched() and to ensure all calls are
+	 * Do a synchronize_rcu() and to ensure all calls are
 	 * done with them before we free them.
 	 */
 	tracepoint_synchronize_unregister();
@@ -1845,7 +1845,7 @@ int apply_subsystem_event_filter(struct trace_subsystem_dir *dir,
 	if (filter) {
 		/*
 		 * No event actually uses the system filter
-		 * we can free it without synchronize_sched().
+		 * we can free it without synchronize_rcu().
 		 */
 		__free_filter(system->filter);
 		system->filter = filter;
diff --git a/kernel/trace/trace_kprobe.c b/kernel/trace/trace_kprobe.c
index fec67188c4d2..adc153ab51c0 100644
--- a/kernel/trace/trace_kprobe.c
+++ b/kernel/trace/trace_kprobe.c
@@ -333,7 +333,7 @@ disable_trace_kprobe(struct trace_kprobe *tk, struct trace_event_file *file)
 		 * event_call related objects, which will be accessed in
 		 * the kprobe_trace_func/kretprobe_trace_func.
 		 */
-		synchronize_sched();
+		synchronize_rcu();
 		kfree(link);	/* Ignored if link == NULL */
 	}
 
diff --git a/kernel/tracepoint.c b/kernel/tracepoint.c
index a3be42304485..46f2ab1e08a9 100644
--- a/kernel/tracepoint.c
+++ b/kernel/tracepoint.c
@@ -92,7 +92,7 @@ static __init int release_early_probes(void)
 	while (early_probes) {
 		tmp = early_probes;
 		early_probes = tmp->next;
-		call_rcu_sched(tmp, rcu_free_old_probes);
+		call_rcu(tmp, rcu_free_old_probes);
 	}
 
 	return 0;
@@ -123,7 +123,7 @@ static inline void release_probes(struct tracepoint_func *old)
 		 * cover both cases. So let us chain the SRCU and sched RCU
 		 * callbacks to wait for both grace periods.
 		 */
-		call_rcu_sched(&tp_probes->rcu, rcu_free_old_probes);
+		call_rcu(&tp_probes->rcu, rcu_free_old_probes);
 	}
 }
 
