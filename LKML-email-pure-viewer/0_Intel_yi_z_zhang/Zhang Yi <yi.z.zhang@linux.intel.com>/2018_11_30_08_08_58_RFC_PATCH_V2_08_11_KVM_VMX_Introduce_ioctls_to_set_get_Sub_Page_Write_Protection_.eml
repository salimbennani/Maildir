Return-Path: <linux-kernel-owner@vger.kernel.org>
Delivered-To: unknown
Received: from linux.intel.com (10.54.29.200:995) by likexu-workstation with
  POP3-SSL; 30 Nov 2018 16:09:43 -0000
X-Original-To: like.xu@linux.intel.com
Delivered-To: like.xu@linux.intel.com
Received: from orsmga006.jf.intel.com (orsmga006.jf.intel.com [10.7.209.51])
	(using TLSv1.2 with cipher ECDHE-RSA-AES256-GCM-SHA384 (256/256 bits))
	(No client certificate requested)
	by linux.intel.com (Postfix) with ESMTPS id 69188580460;
	Fri, 30 Nov 2018 00:09:25 -0800 (PST)
Received: from orsmga101.jf.intel.com ([10.7.208.22])
  by orsmga006-1.jf.intel.com with ESMTP/TLS/DHE-RSA-AES256-GCM-SHA384; 30 Nov 2018 00:09:25 -0800
X-SG-BADATTACHMENTNOREPLY: True
IronPort-PHdr: =?us-ascii?q?9a23=3AJxMPeBP326bveRsDeHQl6mtUPXoX/o7sNwtQ0KIM?=
 =?us-ascii?q?zox0KPj/ocbcNUDSrc9gkEXOFd2Cra4c26yO6+jJYi8p2d65qncMcZhBBVcuqP?=
 =?us-ascii?q?49uEgeOvODElDxN/XwbiY3T4xoXV5h+GynYwAOQJ6tL1LdrWev4jEMBx7xKRR6?=
 =?us-ascii?q?JvjvGo7Vks+7y/2+94fcbglUhzexe69+IAmrpgjNq8cahpdvJLwswRXTuHtIfO?=
 =?us-ascii?q?pWxWJsJV2Nmhv3+9m98p1+/SlOovwt78FPX7n0cKQ+VrxYES8pM3sp683xtBnM?=
 =?us-ascii?q?VhWA630BWWgLiBVIAgzF7BbnXpfttybxq+Rw1DWGMcDwULs5Xymp4aV2Rx/ykC?=
 =?us-ascii?q?oJNyA3/nzZhMJzi6xUohyhpwdnw4PWe4yZKOZyc7nBcd4AWWZNQsBcXDFBDIOm?=
 =?us-ascii?q?aIsPCvIMMuVYr4bnoVsOoga1CgutBOjyzTJJhn720bc70ug7EADG3BYvH9QBsH?=
 =?us-ascii?q?nPqNX1NaESUf26zaXSzDXDae9W1in56ITSbh8hpvSMUKt2fMHMykcvDxvIgkuM?=
 =?us-ascii?q?pYHhJT+Zy+oAv3aB4+Z9Vu+jl3QrpgBzrzS328shjpfFipgVx13E7yl0wJg5Kc?=
 =?us-ascii?q?e8RUN1Z9OvDYFeuDuAN4RsR8MvW2Fotzg+yr0BoZO7YicKx4o9xxLFaPyIbZKI?=
 =?us-ascii?q?4hT9W+aVOzt4g2hleL2nixaz90iv1PH8W9Gq3FpWqidJiMTAu34T2xDJ98SKSe?=
 =?us-ascii?q?dx8l2g1DuNzwzT7/tLIUEwlarVMZ4hxbswm4IXsUTCGC/2hUr3gLaVdko64Oio?=
 =?us-ascii?q?7froYrH/qp+bOY50jB/xMr41l8yhDuQ3LBIOU3KY+euizr3j+1P2QLFQgv0xiK?=
 =?us-ascii?q?nZv4jWJd4Hqa6hHw9VzoEj5g67Dzen09QXg2MLLV1YeB+ci4jpOlfOIO33DPul?=
 =?us-ascii?q?glSslitryO7CPrH7HprNKX3Dmq/7fblh805c1BYzzddH6pJUEL4BIe7zVVX2tN?=
 =?us-ascii?q?DCDh85Lha7w+DoCNhm0oMeWGSPArKWMa/IsF+I4P4vLPeIZIMPpDn9LP0l7eb0?=
 =?us-ascii?q?jXAlgV8dYbWp3ZwPZXC6GfRpPV+VYXnrgtcHF2cKuREzTOjriF2ETD5SaGy+X6?=
 =?us-ascii?q?M65jEnFo2mCZ3PSZyqgLyExC27BIFZZnhaClCQFnflb5+LW+wMaCKVIc9tiCYE?=
 =?us-ascii?q?WqKjS4I60RGutQn6y6doL+bO+y0Ys47j28Zx5+HJiR4y8jl0BdyH026RV2F0gn?=
 =?us-ascii?q?8IRzgu0aB8u0N9zE2P0ax5g/NCE9xT6OhEUgM7NZ7a0ux7BMr+WgPHfteVVlmm?=
 =?us-ascii?q?Rs+qDi02TtI029UOeVpyG82+jhDf2CqnG6IamKaVBJMq6K7c32L+J8Bmy3nY0q?=
 =?us-ascii?q?ktiF0mQshKNW2inaN/8wnTB4jUk0SWjaqqdKIc3DLT+2eH12aBoEZYUAtoW6Xf?=
 =?us-ascii?q?QX8fflfWrcj+5k7aUrChE6onPRVbxc6CMKRKbMbpgktARPr4PNTeYmSxm3q/BB?=
 =?us-ascii?q?qSx7OMapbqdHsZ3CnHFEcElAUT926cNQciHiehv37eDDt2GFLzYkPs9O5+qG+7?=
 =?us-ascii?q?Tk401Q2Kc1dt172v+h4RhPycTfwT06kAuCcgrTV0AVm808jXC9qGuwpuYqFcbc?=
 =?us-ascii?q?kh71dA0GLTrxZ9MYC4L6B+ml4edBx6sFnq1xppBYRPj8groGkxwwpvNK2XylVB?=
 =?us-ascii?q?dzCf3ZDuIbDXLmjy/Baya6/ZwF3e0dCW+rsR5/Q8sVnsoAapFk86+XV9z9ZVy2?=
 =?us-ascii?q?ec5onNDAcKUZPxT1w7+ARgq7DbYiky/YXU1XJ3PKmwsz/C3c8pBeQ/xhaheddf?=
 =?us-ascii?q?LL2LFAvoH8IGAMiuLfQgm0K1YRIcIOBS6Kk0Mtu8d/uHxKGkJvxgky+hjWhd5o?=
 =?us-ascii?q?ByzFiM9ytlRuHUxZkFx+yX0RWdVzf7ilesqcT3mYFCZTEPEWuz0ynkBIhNZqJs?=
 =?us-ascii?q?eYYHE3uhI8qyxt9mnZ7iR2ZY9EK/B1MBwMKoeRuSY0b93AFKzkQXvHqnlDC8zz?=
 =?us-ascii?q?x1lTEps6We0DbPw+TkaBoIJGpLSHN+glfrJIi+l8oaU1Swbwg1iBul4l73x6pB?=
 =?us-ascii?q?q6RlLGnTQkBIczLtL254UauwtbuCY8hR55MuqihXVOW8YVaHSr/yuRca0iXjH3?=
 =?us-ascii?q?dAyzA/bT2lppL5nxligmKHMHlztGbZed13xRrH5N3TX/lR0iAERCl5jznaHVy8?=
 =?us-ascii?q?P9iv/dWJmJbPqOG+V2S9VpJNdSnn15+PtCy+5WdyGx2wg+izmsH7EQg9ySL71M?=
 =?us-ascii?q?NlVSTSoBb8f4nkzaK6Me18c0lsBV/87dd6G45knosxgpEQxWYVhpGP8XUblmfz?=
 =?us-ascii?q?NM1R2bjiY3oVWT4L39nV7RDg2E1iLXKG3Zj1V3uDzct6e9m1fHkW1Tkj4MBQB6?=
 =?us-ascii?q?eZ97hEnSpzolqlogPde/l9njEByfQw7H4Wmf0GuA0ozi+FGLAdAVFYPTDwlxSP?=
 =?us-ascii?q?992+sKJXZGO1fbmxzkV+m82hDKqZogFdQ3v5fpYiHSlt7sRwKl7M0Xvz6p36d9?=
 =?us-ascii?q?nUd94cqhqUkxLYhehPNJ0xjuYKhTZgOW/lpnIq0ek7jRhz3Z2guIiHNn5g/Ka4?=
 =?us-ascii?q?Ah5eKz30aNkf+jDrjaZCgMmW25qjEYlmGjUORJHoV+6nECoOtfT7MAaDCD88pW?=
 =?us-ascii?q?2eGbXBBg+T8ltmo2jME5C2NHGXOX8Zws95RBSGIExfgQYUXCg1n5IjFwCqwtDh?=
 =?us-ascii?q?f1l95jwL+lH4rR5MwPpyNxbjSmffuBuoajAsRZmfKxpW8xhC51rPPsyY9O5zBC?=
 =?us-ascii?q?ZY/puurAGWLmybZgJIDXwGW0CeBlDjOKWu6sfE8+SCGuW+KP7Oa62UqeNCT/eI?=
 =?us-ascii?q?2Y6v0ox+8jaMKMqPP3piD/462kZZXnB5AcPZmzoRRCwNiiLNdNWWpBO9+i1xs8?=
 =?us-ascii?q?C+/+7nWAPp5YuTFbRSNc9j9AyxgaeGL+SQnjp2KS5E1pMQwn/F0KIQ3EMJhCF0?=
 =?us-ascii?q?aTasEa4MtSrMTK/Lnq9XDhgbaz58NcdS7qI82BVNNtDfit/vyrF4ifs1AU9fVV?=
 =?us-ascii?q?P9gsGpedAKI2alOVPbBUaLMa6KKiHRz87rYaOzV7tQgf5Qtx2xvzabDkDiMi6C?=
 =?us-ascii?q?lznvSxCgL+VMgDuHMxxZvYG3agxtBnT7TNL6dh27N8d6jD0szr0yg3PKNGgcPi?=
 =?us-ascii?q?B9ckNNtLKQ6yxYj+57G2xA6HplMOaFlzyY7+neNpYZr/9rDj5omOJd5XRpg4dS?=
 =?us-ascii?q?uTlOQ/pnmS3ThsRjr1Gvjq+EzT8jGB9CrTBXmaqBvFluNKvU8JVNQzDP+xdJpW?=
 =?us-ascii?q?ObCggXj9FkFtHita1WxtXV0qn0LWRs6dXRqPkcDs7bYPOGeC4wMFz7XizUBQ0K?=
 =?us-ascii?q?ZTqqM3zPwU1bjPyWsHaSq85p+dDXhJMSR+oDBxQOHfQABxE9EQ=3D=3D?=
X-IronPort-Anti-Spam-Filtered: true
X-IronPort-Anti-Spam-Result: =?us-ascii?q?A0AIAAD27gBch0O0hNFiGwEBAQEDAQEBB?=
 =?us-ascii?q?wMBAQGBUQYBAQELAYNrJ4wRjAgpgT85lzKBdhEYEwGHdCI0CQ0BAwEBAQEBAQI?=
 =?us-ascii?q?BEwEBAQgNCQgpL4I2IoJlAwMBAiRSBgkBAVADVAcSBYMcggIFp3wzii+HbIQre?=
 =?us-ascii?q?oEcgREzAYcohhICkB2QCQcCDZEpGF6QPoh5j16BRoINcIM8gicXEo4YMgEBMQE?=
 =?us-ascii?q?BgQMBAYs0gk0BAQ?=
X-IPAS-Result: =?us-ascii?q?A0AIAAD27gBch0O0hNFiGwEBAQEDAQEBBwMBAQGBUQYBAQE?=
 =?us-ascii?q?LAYNrJ4wRjAgpgT85lzKBdhEYEwGHdCI0CQ0BAwEBAQEBAQIBEwEBAQgNCQgpL?=
 =?us-ascii?q?4I2IoJlAwMBAiRSBgkBAVADVAcSBYMcggIFp3wzii+HbIQreoEcgREzAYcohhI?=
 =?us-ascii?q?CkB2QCQcCDZEpGF6QPoh5j16BRoINcIM8gicXEo4YMgEBMQEBgQMBAYs0gk0BA?=
 =?us-ascii?q?Q?=
X-IronPort-AV: E=Sophos;i="5.56,297,1539673200"; 
   d="scan'208";a="42970678"
X-Amp-Result: SKIPPED(no attachment in message)
X-Amp-File-Uploaded: False
Received: from vger.kernel.org ([209.132.180.67])
  by mtab.intel.com with ESMTP; 30 Nov 2018 00:09:23 -0800
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
        id S1727343AbeK3TRt (ORCPT <rfc822;like.xu@linux.intel.com>
        + 23 others); Fri, 30 Nov 2018 14:17:49 -0500
Received: from mga11.intel.com ([192.55.52.93]:64152 "EHLO mga11.intel.com"
        rhost-flags-OK-OK-OK-OK) by vger.kernel.org with ESMTP
        id S1727109AbeK3TRt (ORCPT <rfc822;linux-kernel@vger.kernel.org>);
        Fri, 30 Nov 2018 14:17:49 -0500
X-Amp-Result: SKIPPED(no attachment in message)
X-Amp-File-Uploaded: False
Received: from fmsmga004.fm.intel.com ([10.253.24.48])
  by fmsmga102.fm.intel.com with ESMTP/TLS/DHE-RSA-AES256-GCM-SHA384; 30 Nov 2018 00:09:16 -0800
X-ExtLoop1: 1
X-IronPort-AV: E=Sophos;i="5.56,297,1539673200"; 
   d="scan'208";a="117412120"
Received: from linux.intel.com ([10.54.29.200])
  by fmsmga004.fm.intel.com with ESMTP; 30 Nov 2018 00:09:16 -0800
Received: from dazhang1-ssd.sh.intel.com (unknown [10.239.48.128])
        by linux.intel.com (Postfix) with ESMTP id D7772580213;
        Fri, 30 Nov 2018 00:09:13 -0800 (PST)
From: Zhang Yi <yi.z.zhang@linux.intel.com>
To: pbonzini@redhat.com, mdontu@bitdefender.com, ncitu@bitdefender.com
Cc: rkrcmar@redhat.com, linux-kernel@vger.kernel.org,
        kvm@vger.kernel.org, Zhang Yi <yi.z.zhang@linux.intel.com>
Subject: [RFC PATCH V2 08/11] KVM: VMX: Introduce ioctls to set/get Sub-Page Write Protection.
Date: Fri, 30 Nov 2018 16:08:58 +0800
Message-Id: <c53fda52c3599677945c0a2c65debb9f273a5fc0.1543481993.git.yi.z.zhang@linux.intel.com>
X-Mailer: git-send-email 2.7.4
In-Reply-To: <cover.1543481993.git.yi.z.zhang@linux.intel.com>
References: <cover.1543481993.git.yi.z.zhang@linux.intel.com>
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: <linux-kernel.vger.kernel.org>
X-Mailing-List: linux-kernel@vger.kernel.org

We introduced 2 ioctls to let user application to set/get subpage write
protection bitmap per gfn, each gfn corresponds to a bitmap.

The user application, qemu, or some other security control daemon. will
set the protection bitmap via this ioctl.

the API defined as:

struct kvm_subpage {
	__u64 base_gfn;
	__u64 npages;
	/* sub-page write-access bitmap array */
	__u32 access_map[SUBPAGE_MAX_BITMAP];
}sp;

kvm_vm_ioctl(s, KVM_SUBPAGES_SET_ACCESS, &sp)
kvm_vm_ioctl(s, KVM_SUBPAGES_GET_ACCESS, &sp)

Signed-off-by: Zhang Yi <yi.z.zhang@linux.intel.com>
Signed-off-by: He Chen <he.chen@linux.intel.com>
---
 arch/x86/include/asm/kvm_host.h |   9 +++
 arch/x86/kvm/mmu.c              |  49 ++++++++++++++++
 arch/x86/kvm/vmx.c              |  20 +++++++
 arch/x86/kvm/x86.c              | 124 +++++++++++++++++++++++++++++++++++++++-
 include/linux/kvm_host.h        |   5 ++
 include/uapi/linux/kvm.h        |  11 ++++
 6 files changed, 217 insertions(+), 1 deletion(-)

diff --git a/arch/x86/include/asm/kvm_host.h b/arch/x86/include/asm/kvm_host.h
index 46312b9..3218d91 100644
--- a/arch/x86/include/asm/kvm_host.h
+++ b/arch/x86/include/asm/kvm_host.h
@@ -397,6 +397,8 @@ struct kvm_mmu {
 	void (*invlpg)(struct kvm_vcpu *vcpu, gva_t gva, hpa_t root_hpa);
 	void (*update_pte)(struct kvm_vcpu *vcpu, struct kvm_mmu_page *sp,
 			   u64 *spte, const void *pte);
+	int (*get_subpages)(struct kvm *kvm, struct kvm_subpage *spp_info);
+	int (*set_subpages)(struct kvm *kvm, struct kvm_subpage *spp_info);
 	hpa_t root_hpa;
 	hpa_t sppt_root;
 	union kvm_mmu_role mmu_role;
@@ -784,6 +786,7 @@ struct kvm_lpage_info {
 
 struct kvm_arch_memory_slot {
 	struct kvm_rmap_head *rmap[KVM_NR_PAGE_SIZES];
+	u32 *subpage_wp_info;
 	struct kvm_lpage_info *lpage_info[KVM_NR_PAGE_SIZES - 1];
 	unsigned short *gfn_track[KVM_PAGE_TRACK_MAX];
 };
@@ -1187,6 +1190,9 @@ struct kvm_x86_ops {
 
 	int (*nested_enable_evmcs)(struct kvm_vcpu *vcpu,
 				   uint16_t *vmcs_version);
+
+	int (*get_subpages)(struct kvm *kvm, struct kvm_subpage *spp_info);
+	int (*set_subpages)(struct kvm *kvm, struct kvm_subpage *spp_info);
 };
 
 struct kvm_arch_async_pf {
@@ -1400,6 +1406,9 @@ void kvm_mmu_invlpg(struct kvm_vcpu *vcpu, gva_t gva);
 void kvm_mmu_invpcid_gva(struct kvm_vcpu *vcpu, gva_t gva, unsigned long pcid);
 void kvm_mmu_new_cr3(struct kvm_vcpu *vcpu, gpa_t new_cr3, bool skip_tlb_flush);
 
+int kvm_mmu_get_subpages(struct kvm *kvm, struct kvm_subpage *spp_info);
+int kvm_mmu_set_subpages(struct kvm *kvm, struct kvm_subpage *spp_info);
+
 void kvm_enable_tdp(void);
 void kvm_disable_tdp(void);
 
diff --git a/arch/x86/kvm/mmu.c b/arch/x86/kvm/mmu.c
index d077693..b1773c6 100644
--- a/arch/x86/kvm/mmu.c
+++ b/arch/x86/kvm/mmu.c
@@ -1430,6 +1430,15 @@ static u64 *rmap_get_next(struct rmap_iterator *iter)
 	return sptep;
 }
 
+static u32 *gfn_to_subpage_wp_info(struct kvm_memory_slot *slot,
+				   gfn_t gfn)
+{
+	unsigned long idx;
+
+	idx = gfn_to_index(gfn, slot->base_gfn, PT_PAGE_TABLE_LEVEL);
+	return &slot->arch.subpage_wp_info[idx];
+}
+
 #define for_each_rmap_spte(_rmap_head_, _iter_, _spte_)			\
 	for (_spte_ = rmap_get_first(_rmap_head_, _iter_);		\
 	     _spte_; _spte_ = rmap_get_next(_iter_))
@@ -4141,6 +4150,44 @@ static int tdp_page_fault(struct kvm_vcpu *vcpu, gva_t gpa, u32 error_code,
 	return RET_PF_RETRY;
 }
 
+int kvm_mmu_get_subpages(struct kvm *kvm, struct kvm_subpage *spp_info)
+{
+	u32 *access = spp_info->access_map;
+	gfn_t gfn = spp_info->base_gfn;
+	int npages = spp_info->npages;
+	struct kvm_memory_slot *slot;
+	int i;
+
+	for (i = 0; i < npages; i++, gfn++) {
+		slot = gfn_to_memslot(kvm, gfn);
+		if (!slot)
+			return -EFAULT;
+		access[i] = *gfn_to_subpage_wp_info(slot, gfn);
+	}
+
+	return i;
+}
+
+int kvm_mmu_set_subpages(struct kvm *kvm, struct kvm_subpage *spp_info)
+{
+	u32 access = spp_info->access_map[0];
+	gfn_t gfn = spp_info->base_gfn;
+	int npages = spp_info->npages;
+	struct kvm_memory_slot *slot;
+	u32 *wp_map;
+	int i;
+
+	for (i = 0; i < npages; i++, gfn++) {
+		slot = gfn_to_memslot(kvm, gfn);
+		if (!slot)
+			return -EFAULT;
+		wp_map = gfn_to_subpage_wp_info(slot, gfn);
+		*wp_map = access;
+	}
+
+	return i;
+}
+
 static void nonpaging_init_context(struct kvm_vcpu *vcpu,
 				   struct kvm_mmu *context)
 {
@@ -4835,6 +4882,8 @@ static void init_kvm_tdp_mmu(struct kvm_vcpu *vcpu)
 	context->get_cr3 = get_cr3;
 	context->get_pdptr = kvm_pdptr_read;
 	context->inject_page_fault = kvm_inject_page_fault;
+	context->get_subpages = kvm_x86_ops->get_subpages;
+	context->set_subpages = kvm_x86_ops->set_subpages;
 
 	if (!is_paging(vcpu)) {
 		context->nx = false;
diff --git a/arch/x86/kvm/vmx.c b/arch/x86/kvm/vmx.c
index 6634098..b660812 100644
--- a/arch/x86/kvm/vmx.c
+++ b/arch/x86/kvm/vmx.c
@@ -8028,6 +8028,11 @@ static __init int hardware_setup(void)
 		kvm_x86_ops->enable_log_dirty_pt_masked = NULL;
 	}
 
+	if (!enable_ept_spp) {
+		kvm_x86_ops->get_subpages = NULL;
+		kvm_x86_ops->set_subpages = NULL;
+	}
+
 	if (!cpu_has_vmx_preemption_timer())
 		kvm_x86_ops->request_immediate_exit = __kvm_request_immediate_exit;
 
@@ -15037,6 +15042,18 @@ static int vmx_set_nested_state(struct kvm_vcpu *vcpu,
 	return 0;
 }
 
+static int vmx_get_subpages(struct kvm *kvm,
+			    struct kvm_subpage *spp_info)
+{
+	return kvm_get_subpages(kvm, spp_info);
+}
+
+static int vmx_set_subpages(struct kvm *kvm,
+			    struct kvm_subpage *spp_info)
+{
+	return kvm_set_subpages(kvm, spp_info);
+}
+
 static struct kvm_x86_ops vmx_x86_ops __ro_after_init = {
 	.cpu_has_kvm_support = cpu_has_kvm_support,
 	.disabled_by_bios = vmx_disabled_by_bios,
@@ -15184,6 +15201,9 @@ static struct kvm_x86_ops vmx_x86_ops __ro_after_init = {
 	.enable_smi_window = enable_smi_window,
 
 	.nested_enable_evmcs = nested_enable_evmcs,
+
+	.get_subpages = vmx_get_subpages,
+	.set_subpages = vmx_set_subpages,
 };
 
 static void vmx_cleanup_l1d_flush(void)
diff --git a/arch/x86/kvm/x86.c b/arch/x86/kvm/x86.c
index 5cd5647..fa36858 100644
--- a/arch/x86/kvm/x86.c
+++ b/arch/x86/kvm/x86.c
@@ -4507,6 +4507,44 @@ static int kvm_vm_ioctl_enable_cap(struct kvm *kvm,
 	return r;
 }
 
+static int kvm_vm_ioctl_get_subpages(struct kvm *kvm,
+				     struct kvm_subpage *spp_info)
+{
+	return kvm_arch_get_subpages(kvm, spp_info);
+}
+
+static int kvm_vm_ioctl_set_subpages(struct kvm *kvm,
+				     struct kvm_subpage *spp_info)
+{
+	return kvm_arch_set_subpages(kvm, spp_info);
+}
+
+int kvm_get_subpages(struct kvm *kvm,
+		     struct kvm_subpage *spp_info)
+{
+	int ret;
+
+	mutex_lock(&kvm->slots_lock);
+	ret = kvm_mmu_get_subpages(kvm, spp_info);
+	mutex_unlock(&kvm->slots_lock);
+
+	return ret;
+}
+EXPORT_SYMBOL_GPL(kvm_get_subpages);
+
+int kvm_set_subpages(struct kvm *kvm,
+		     struct kvm_subpage *spp_info)
+{
+	int ret;
+
+	mutex_lock(&kvm->slots_lock);
+	ret = kvm_mmu_set_subpages(kvm, spp_info);
+	mutex_unlock(&kvm->slots_lock);
+
+	return ret;
+}
+EXPORT_SYMBOL_GPL(kvm_set_subpages);
+
 long kvm_arch_vm_ioctl(struct file *filp,
 		       unsigned int ioctl, unsigned long arg)
 {
@@ -4811,6 +4849,39 @@ long kvm_arch_vm_ioctl(struct file *filp,
 		if (copy_from_user(&hvevfd, argp, sizeof(hvevfd)))
 			goto out;
 		r = kvm_vm_ioctl_hv_eventfd(kvm, &hvevfd);
+	}
+	case KVM_SUBPAGES_GET_ACCESS: {
+		struct kvm_subpage spp_info;
+
+		r = -EFAULT;
+		if (copy_from_user(&spp_info, argp, sizeof(spp_info)))
+			goto out;
+
+		r = -EINVAL;
+		if (spp_info.npages == 0 ||
+		    spp_info.npages > SUBPAGE_MAX_BITMAP)
+			goto out;
+
+		r = kvm_vm_ioctl_get_subpages(kvm, &spp_info);
+		if (copy_to_user(argp, &spp_info, sizeof(spp_info))) {
+			r = -EFAULT;
+			goto out;
+		}
+		break;
+	}
+	case KVM_SUBPAGES_SET_ACCESS: {
+		struct kvm_subpage spp_info;
+
+		r = -EFAULT;
+		if (copy_from_user(&spp_info, argp, sizeof(spp_info)))
+			goto out;
+
+		r = -EINVAL;
+		if (spp_info.npages == 0 ||
+		    spp_info.npages > SUBPAGE_MAX_BITMAP)
+			goto out;
+
+		r = kvm_vm_ioctl_set_subpages(kvm, &spp_info);
 		break;
 	}
 	default:
@@ -9152,6 +9223,34 @@ void kvm_arch_destroy_vm(struct kvm *kvm)
 	kvm_hv_destroy_vm(kvm);
 }
 
+int kvm_subpage_create_memslot(struct kvm_memory_slot *slot,
+			       unsigned long npages)
+{
+	int lpages;
+
+	lpages = gfn_to_index(slot->base_gfn + npages - 1,
+			      slot->base_gfn, 1) + 1;
+
+	slot->arch.subpage_wp_info =
+	      kvzalloc(lpages * sizeof(*slot->arch.subpage_wp_info),
+		       GFP_KERNEL);
+
+	if (!slot->arch.subpage_wp_info)
+		return -ENOMEM;
+
+	return 0;
+}
+
+void kvm_subpage_free_memslot(struct kvm_memory_slot *free,
+			      struct kvm_memory_slot *dont)
+{
+	if (!dont || free->arch.subpage_wp_info !=
+		dont->arch.subpage_wp_info) {
+		kvfree(free->arch.subpage_wp_info);
+		free->arch.subpage_wp_info = NULL;
+	}
+}
+
 void kvm_arch_free_memslot(struct kvm *kvm, struct kvm_memory_slot *free,
 			   struct kvm_memory_slot *dont)
 {
@@ -9173,6 +9272,7 @@ void kvm_arch_free_memslot(struct kvm *kvm, struct kvm_memory_slot *free,
 	}
 
 	kvm_page_track_free_memslot(free, dont);
+	kvm_subpage_free_memslot(free, dont);
 }
 
 int kvm_arch_create_memslot(struct kvm *kvm, struct kvm_memory_slot *slot,
@@ -9225,8 +9325,12 @@ int kvm_arch_create_memslot(struct kvm *kvm, struct kvm_memory_slot *slot,
 	if (kvm_page_track_create_memslot(slot, npages))
 		goto out_free;
 
-	return 0;
+	if (kvm_subpage_create_memslot(slot, npages))
+		goto out_free_page_track;
 
+	return 0;
+out_free_page_track:
+	kvm_page_track_free_memslot(slot, NULL);
 out_free:
 	for (i = 0; i < KVM_NR_PAGE_SIZES; ++i) {
 		kvfree(slot->arch.rmap[i]);
@@ -9713,6 +9817,24 @@ int kvm_arch_update_irqfd_routing(struct kvm *kvm, unsigned int host_irq,
 	return kvm_x86_ops->update_pi_irte(kvm, host_irq, guest_irq, set);
 }
 
+int kvm_arch_get_subpages(struct kvm *kvm,
+			  struct kvm_subpage *spp_info)
+{
+	if (!kvm_x86_ops->get_subpages)
+		return -EINVAL;
+
+	return kvm_x86_ops->get_subpages(kvm, spp_info);
+}
+
+int kvm_arch_set_subpages(struct kvm *kvm,
+			  struct kvm_subpage *spp_info)
+{
+	if (!kvm_x86_ops->set_subpages)
+		return -EINVAL;
+
+	return kvm_x86_ops->set_subpages(kvm, spp_info);
+}
+
 bool kvm_vector_hashing_enabled(void)
 {
 	return vector_hashing;
diff --git a/include/linux/kvm_host.h b/include/linux/kvm_host.h
index c926698..7f29f97 100644
--- a/include/linux/kvm_host.h
+++ b/include/linux/kvm_host.h
@@ -816,6 +816,11 @@ int kvm_arch_vcpu_runnable(struct kvm_vcpu *vcpu);
 bool kvm_arch_vcpu_in_kernel(struct kvm_vcpu *vcpu);
 int kvm_arch_vcpu_should_kick(struct kvm_vcpu *vcpu);
 
+int kvm_get_subpages(struct kvm *kvm, struct kvm_subpage *spp_info);
+int kvm_set_subpages(struct kvm *kvm, struct kvm_subpage *spp_info);
+int kvm_arch_get_subpages(struct kvm *kvm, struct kvm_subpage *spp_info);
+int kvm_arch_set_subpages(struct kvm *kvm, struct kvm_subpage *spp_info);
+
 #ifndef __KVM_HAVE_ARCH_VM_ALLOC
 /*
  * All architectures that want to use vzalloc currently also
diff --git a/include/uapi/linux/kvm.h b/include/uapi/linux/kvm.h
index 01174f8..3fd6d14 100644
--- a/include/uapi/linux/kvm.h
+++ b/include/uapi/linux/kvm.h
@@ -102,6 +102,15 @@ struct kvm_userspace_memory_region {
 	__u64 userspace_addr; /* start of the userspace allocated memory */
 };
 
+/* for KVM_SUBPAGES_GET_ACCESS and KVM_SUBPAGES_SET_ACCESS */
+#define SUBPAGE_MAX_BITMAP 128
+struct kvm_subpage {
+	__u64 base_gfn;
+	__u64 npages;
+	 /* sub-page write-access bitmap array */
+	__u32 access_map[SUBPAGE_MAX_BITMAP];
+};
+
 /*
  * The bit 0 ~ bit 15 of kvm_memory_region::flags are visible for userspace,
  * other bits are reserved for kvm internal use which are defined in
@@ -1229,6 +1238,8 @@ struct kvm_vfio_spapr_tce {
 					struct kvm_userspace_memory_region)
 #define KVM_SET_TSS_ADDR          _IO(KVMIO,   0x47)
 #define KVM_SET_IDENTITY_MAP_ADDR _IOW(KVMIO,  0x48, __u64)
+#define KVM_SUBPAGES_GET_ACCESS   _IOR(KVMIO,  0x49, __u64)
+#define KVM_SUBPAGES_SET_ACCESS   _IOW(KVMIO,  0x4a, __u64)
 
 /* enable ucontrol for s390 */
 struct kvm_s390_ucas_mapping {
-- 
2.7.4

