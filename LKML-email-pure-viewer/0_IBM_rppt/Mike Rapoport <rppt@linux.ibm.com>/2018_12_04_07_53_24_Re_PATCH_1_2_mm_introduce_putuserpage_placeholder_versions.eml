Return-Path: <linux-kernel-owner@vger.kernel.org>
Delivered-To: unknown
Received: from linux.intel.com (10.54.29.200:995) by likexu-workstation with
  POP3-SSL; 04 Dec 2018 18:30:15 -0000
X-Original-To: like.xu@linux.intel.com
Delivered-To: like.xu@linux.intel.com
Received: from orsmga007.jf.intel.com (orsmga007.jf.intel.com [10.7.209.58])
	(using TLSv1.2 with cipher ECDHE-RSA-AES256-GCM-SHA384 (256/256 bits))
	(No client certificate requested)
	by linux.intel.com (Postfix) with ESMTPS id F3B1B580117;
	Mon,  3 Dec 2018 23:53:43 -0800 (PST)
Received: from fmsmga103.fm.intel.com ([10.1.193.90])
  by orsmga007-1.jf.intel.com with ESMTP/TLS/DHE-RSA-AES256-GCM-SHA384; 03 Dec 2018 23:53:43 -0800
X-SG-BADATTACHMENTNOREPLY: True
IronPort-PHdr: =?us-ascii?q?9a23=3A6dmJWhZqtpKw2mzYqN64Rc//LSx+4OfEezUN459i?=
 =?us-ascii?q?sYplN5qZpcizYh7h7PlgxGXEQZ/co6odzbaO4+a4ASQp2tWoiDg6aptCVhsI24?=
 =?us-ascii?q?09vjcLJ4q7M3D9N+PgdCcgHc5PBxdP9nC/NlVJSo6lPwWB6nK94iQPFRrhKAF7?=
 =?us-ascii?q?Ovr6GpLIj8Swyuu+54Dfbx9HiTahYr5+Ngm6oRnMvcQKnIVuLbo8xAHUqXVSYe?=
 =?us-ascii?q?RWwm1oJVOXnxni48q74YBu/SdNtf8/7sBMSar1cbg2QrxeFzQmLns65Nb3uhnZ?=
 =?us-ascii?q?TAuA/WUTX2MLmRdVGQfF7RX6XpDssivms+d2xSeXMdHqQb0yRD+v9LlgRgP2hy?=
 =?us-ascii?q?gbNj456GDXhdJ2jKJHuxKquhhzz5fJbI2JKPZye6XQds4YS2VcRMZcTyJPDIOi?=
 =?us-ascii?q?YYUSAeoOMvpXoJT/qFQArhW+HhGsCeH0xz9UmnP7x7E23/g7HA3Y2gErAtIAsG?=
 =?us-ascii?q?7TrNXwLKocVuG1zKrWwj7ec/1Zwy/96I/QchAmu/GMQa97fM3LyUk3DwPFkk6d?=
 =?us-ascii?q?qYjkPzOTy+QMvHKX7+t7WuKqkWIotwZxoj22y8oql4LHiIUVylXe+iV4xoY4Pd?=
 =?us-ascii?q?64R1BhYd6iDpRQszuWN4xsQsMtW21ovCg7yrsctZ69YicK1JIqzAPcZfyfa4WE?=
 =?us-ascii?q?/A7vWeKLLTtlin9pZqiziwux/ES80OHxV8u53E5OoyZfj9XBuXMA2wbN5sSbS/?=
 =?us-ascii?q?Zx5Fqt1DKO2g3V9+pKO1o7lbDBJJ4k2rMwloQcsUDEHiLuhkX2g7GZdl8+9uir?=
 =?us-ascii?q?9evneLPmqYGYN4NujQH+KKsultS+AeQ+LAcOQ3CW9fqg2LDn50H1XbtHguMsnq?=
 =?us-ascii?q?XEs53WOd4Xq6+7DgNN14Ys8Re/DzOo0NQCmnkHKUpIeBaGj4jvJlHPL+n0DfSh?=
 =?us-ascii?q?jFS2ljdk2fTGMqTmApTDKHjMjq3hcK1j605T1gUz18pT55FKBbEbJvL8REvxuM?=
 =?us-ascii?q?bfDh8jPAy42/znB8ll1oMCRWKPBbeUMKfTsV+L+O0jOeaNZJIOtTb5Kvgl4ePu?=
 =?us-ascii?q?jHAjlV8ce6mpwYUYaHSiEvt6JEWZZGLmgs0dHmcSogo+UOvqhUWCUTFJZnayQ7?=
 =?us-ascii?q?gz5jYhBIKmEIfMXIatgLOa0Se/H51WYH1GC1+WHXfpcYWER+kDaCaILsB9lTwE?=
 =?us-ascii?q?UKCrS5U92hG2qA/6171nI/LW+i0fq53vztt15+rVlRE08jx5FMCd02CLT2FpkW?=
 =?us-ascii?q?IEXT423KZjoUNjzlePy7R3g/tdFdZL/fNGTh86NYLAz+x9E939QBnBfteOSFal?=
 =?us-ascii?q?WNmmGys+TtAqzt8KYkZ9Hciijx/Z0yqrBb8Vi6KEBJgu/q3A2HjxIt53y2za26?=
 =?us-ascii?q?k5k1kmXsxPOHWlhqFl8QjfHYrJk0SDmKaseqQRxyrN9GaFzWqTs0BUSg9wUaPZ?=
 =?us-ascii?q?XX8BYkvat8j25kTHT7W2E7QoLhNBydKeKqtNctDmkE9JROn9N9jEY2K+gWGwBQ?=
 =?us-ascii?q?2WybOKa4bqf2Yd3CDZCEUflwAT/HCGNRUxByu7omLeCiBuGkzrY0/27eZ+r3a7?=
 =?us-ascii?q?RFcuzw6Wd01hy6a1+hkNiPOBUfwTwKwLtD0hqzpuGla9xMzZC9ybqgplfaVcZ8?=
 =?us-ascii?q?494Vhd2WLYsQx9IoKvL6R4ilECdAR3ulvk1w9rBYVYjcgqsHQqwRJuKaKZ1VNB?=
 =?us-ascii?q?cC+Y3ZDwO7HNNmn+5heva7TS2lHf1taW9bwC6PA5q1XloQGoGVAu83Rh09lJzX?=
 =?us-ascii?q?Sc4o/GAxYVUZL0Skw37QR1p6nGYikh4IPZzWdjMa2qvT7Nxd0oBPEpxQ29f9hC?=
 =?us-ascii?q?KqyEEgzyE8oEB8W1LOwqml6pbg8LPexI9a40Od+meOWC2KKxIOlgmzemh3xd4I?=
 =?us-ascii?q?9hykKM6zZ8SunQ0pcF3vGUxBeIWy39jVehqM/3n49EaCoWHmq+zyjkGYFQardz?=
 =?us-ascii?q?fYYNFWehPcm3ys9iiJ7qXn5S7ESjCE8e2M+1ZRqSaETw3RdR1UsLu3Ongza3zz?=
 =?us-ascii?q?tunzEvsKWfxi3Oz/3+exUdPm5EWXdtjU3rIYiylN0aWEmobw40lBqq/0r6xq5b?=
 =?us-ascii?q?pLhhIGnXW0tHYy/2L2R6WKuqqrWCe9JP6I8vsShPUOW8YEqWS77nrxsBziPjGX?=
 =?us-ascii?q?BTxDQ6dzGsp5X4kAZ2iGObLHZvsnXZfdt8ygvY5NzZXfRRxCYJRDFkiTnLAVix?=
 =?us-ascii?q?J9up8s+Ol5fAseC+UHitVoZJfinozoOAtS276nNsARCkm/Czm9vnERU10CPh1t?=
 =?us-ascii?q?lqUznIowj4YoXxy6u6NudndFFyBFDg88p6Bp1+kowoiZAQw3cagY+Z/XgGkWf1?=
 =?us-ascii?q?Kthb3aP+bHwQRT8E2dLV4Q7l2FF9IXKN3Y72SnKdws55bdmgfmwWwj4979xNCK?=
 =?us-ascii?q?qM77xLhyp1rkC4rQLMe/d9mDgdxOAq6H4bheEJpQUswj+cArAUAUlXIyjsmw6U?=
 =?us-ascii?q?4NC5qaVdfHyvfqSo1EpigdChC6mPogRdWHb6YJguByFx4dtkMFLQznLz8Jrrd8?=
 =?us-ascii?q?fKbdIcrRCUlxbAj+5IKJM+jPYKhCxnOX7jsn0h0eI0kRtu3ZSitoidN2pt5L65?=
 =?us-ascii?q?AgJfNjDte8MT/TTtgbxfn8mM2YCvA45hGi4KXJbzSfKoETQStenoNgqUET08rG?=
 =?us-ascii?q?ubFqTbHQOF9EhmqHfPGYixN36LPHkZ0cliRB6FKUNEmg8UWzE6noMjGgCu2czs?=
 =?us-ascii?q?a0N55jEX5l7lpRpA0ONoNx/jUmjBoAekcCs7SJ+aLBBO9AFN+1/VMdCC7uJ0By?=
 =?us-ascii?q?xY/IeurAmTJWyAfQhIEXsFWk+ZB1DgI7mu48PP8/ODC+q6LvvOZ6iOqONEW/eJ?=
 =?us-ascii?q?w5KvzpVp/zKWOsqTOXliCuUx2lBfUnBhB8TZhzIPRjQXliLKcs6bvQq89Tdxrs?=
 =?us-ascii?q?yl6/TrXwTv5YSUBrtWMNVv/Q22gKiZO+6RgiZ5NShX1pcWyXDUz7gf2UYYizty?=
 =?us-ascii?q?eDm1DbQAqSnNQbrQmqBJDh4baCBzNMpS46I/xAlNPsHbhc3v1r5llf44EFNFVV?=
 =?us-ascii?q?3nmsG0as0GOWC9NFXbBEmVMLSKPyHEw8byYamkU71fkP1UtwGsuTacC0LsJCmD?=
 =?us-ascii?q?mCLzVx+xMeBAliWbPB1FtYG5cxZtD3XjTd38Zh26Nt93kSM5wbkuinzWMm4cNC?=
 =?us-ascii?q?B2c1lRob2I8SNYnvJ/FnRd7npkKOmIgTqW4/PEJZYWr/RrBD95l+Zb4HQ81rtU?=
 =?us-ascii?q?4ztIRP1zmCvOsNFup0uqnfWIyjpiSBBOsCpEhJqXvUV+PqXU7plBVmzC/BII7G?=
 =?us-ascii?q?WQDQwFptplCtL1vaBQxcPClKbyKDdE7tLV8tEQB8nSKMKbLnUhNQDlFyLTDAsA?=
 =?us-ascii?q?HnaXMjTdgExb1vGP/HectJQSpZ3lmZ5IQbheB3IvEfZPL0VmEZQ4KY9wRjQ+jf?=
 =?us-ascii?q?bPltYQ+VK6rR/MVINbtJWBXfWXV6a8YA2FhKVJMkNbiYjzKp4eY8iigxRv?=
X-IronPort-Anti-Spam-Filtered: true
X-IronPort-Anti-Spam-Result: =?us-ascii?q?A0ACAAB9MQZch0O0hNFcCBoBAQEBAQIBA?=
 =?us-ascii?q?QEBBwIBAQEBgVIEAQEBAQsBgmmBAieMcYsvUAEBBoE1FIh9DoR7iS+BcxIBARg?=
 =?us-ascii?q?NBgGBG4ZzIjUIDQEDAQEBAQEBAgETAQEBCgsJCCkjDII2JAGCYQEBAQEDAQIPK?=
 =?us-ascii?q?DkGBgkBAQoVAwklAwwFDU8FHYJ/AYFpAwgNAwEBCplUiVgBAQGCHYQtAQsBB0C?=
 =?us-ascii?q?DCA2CFwWIMoNqF3iBB4ERgxKCV0cBAwKBOIYAAokfD4FylHguCYcChw+DIyMKA?=
 =?us-ascii?q?oFPhREFijUsiVuDY4ELiVYCBAYFAhMBgUgBggpNIxWDJx+CCBeIIzuFQXABgQQ?=
 =?us-ascii?q?BASGKYgEB?=
X-IPAS-Result: =?us-ascii?q?A0ACAAB9MQZch0O0hNFcCBoBAQEBAQIBAQEBBwIBAQEBgVI?=
 =?us-ascii?q?EAQEBAQsBgmmBAieMcYsvUAEBBoE1FIh9DoR7iS+BcxIBARgNBgGBG4ZzIjUID?=
 =?us-ascii?q?QEDAQEBAQEBAgETAQEBCgsJCCkjDII2JAGCYQEBAQEDAQIPKDkGBgkBAQoVAwk?=
 =?us-ascii?q?lAwwFDU8FHYJ/AYFpAwgNAwEBCplUiVgBAQGCHYQtAQsBB0CDCA2CFwWIMoNqF?=
 =?us-ascii?q?3iBB4ERgxKCV0cBAwKBOIYAAokfD4FylHguCYcChw+DIyMKAoFPhREFijUsiVu?=
 =?us-ascii?q?DY4ELiVYCBAYFAhMBgUgBggpNIxWDJx+CCBeIIzuFQXABgQQBASGKYgEB?=
X-IronPort-AV: E=Sophos;i="5.56,313,1539673200"; 
   d="scan'208";a="54405070"
X-Amp-Result: UNKNOWN
X-Amp-Original-Verdict: FILE UNKNOWN
X-Amp-File-Uploaded: False
Received: from vger.kernel.org ([209.132.180.67])
  by mtab.intel.com with ESMTP; 03 Dec 2018 23:53:41 -0800
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
        id S1726075AbeLDHxj (ORCPT <rfc822;like.xu@linux.intel.com>
        + 23 others); Tue, 4 Dec 2018 02:53:39 -0500
Received: from mx0a-001b2d01.pphosted.com ([148.163.156.1]:46404 "EHLO
        mx0a-001b2d01.pphosted.com" rhost-flags-OK-OK-OK-OK)
        by vger.kernel.org with ESMTP id S1725996AbeLDHxi (ORCPT
        <rfc822;linux-kernel@vger.kernel.org>);
        Tue, 4 Dec 2018 02:53:38 -0500
Received: from pps.filterd (m0098409.ppops.net [127.0.0.1])
        by mx0a-001b2d01.pphosted.com (8.16.0.22/8.16.0.22) with SMTP id wB47nAYW030964
        for <linux-kernel@vger.kernel.org>; Tue, 4 Dec 2018 02:53:37 -0500
Received: from e06smtp04.uk.ibm.com (e06smtp04.uk.ibm.com [195.75.94.100])
        by mx0a-001b2d01.pphosted.com with ESMTP id 2p5kmrw8pj-1
        (version=TLSv1.2 cipher=AES256-GCM-SHA384 bits=256 verify=NOT)
        for <linux-kernel@vger.kernel.org>; Tue, 04 Dec 2018 02:53:37 -0500
Received: from localhost
        by e06smtp04.uk.ibm.com with IBM ESMTP SMTP Gateway: Authorized Use Only! Violators will be prosecuted
        for <linux-kernel@vger.kernel.org> from <rppt@linux.ibm.com>;
        Tue, 4 Dec 2018 07:53:34 -0000
Received: from b06cxnps4075.portsmouth.uk.ibm.com (9.149.109.197)
        by e06smtp04.uk.ibm.com (192.168.101.134) with IBM ESMTP SMTP Gateway: Authorized Use Only! Violators will be prosecuted;
        (version=TLSv1/SSLv3 cipher=AES256-GCM-SHA384 bits=256/256)
        Tue, 4 Dec 2018 07:53:29 -0000
Received: from d06av26.portsmouth.uk.ibm.com (d06av26.portsmouth.uk.ibm.com [9.149.105.62])
        by b06cxnps4075.portsmouth.uk.ibm.com (8.14.9/8.14.9/NCO v10.0) with ESMTP id wB47rSwm25821414
        (version=TLSv1/SSLv3 cipher=DHE-RSA-AES256-GCM-SHA384 bits=256 verify=FAIL);
        Tue, 4 Dec 2018 07:53:28 GMT
Received: from d06av26.portsmouth.uk.ibm.com (unknown [127.0.0.1])
        by IMSVA (Postfix) with ESMTP id 2A463AE045;
        Tue,  4 Dec 2018 07:53:28 +0000 (GMT)
Received: from d06av26.portsmouth.uk.ibm.com (unknown [127.0.0.1])
        by IMSVA (Postfix) with ESMTP id 30932AE053;
        Tue,  4 Dec 2018 07:53:26 +0000 (GMT)
Received: from rapoport-lnx (unknown [9.148.206.196])
        by d06av26.portsmouth.uk.ibm.com (Postfix) with ESMTPS;
        Tue,  4 Dec 2018 07:53:26 +0000 (GMT)
Date: Tue, 4 Dec 2018 09:53:24 +0200
From: Mike Rapoport <rppt@linux.ibm.com>
To: john.hubbard@gmail.com
Cc: Andrew Morton <akpm@linux-foundation.org>, linux-mm@kvack.org,
        Jan Kara <jack@suse.cz>, Tom Talpey <tom@talpey.com>,
        Al Viro <viro@zeniv.linux.org.uk>,
        Christian Benvenuti <benve@cisco.com>,
        Christoph Hellwig <hch@infradead.org>,
        Christopher Lameter <cl@linux.com>,
        Dan Williams <dan.j.williams@intel.com>,
        Dennis Dalessandro <dennis.dalessandro@intel.com>,
        Doug Ledford <dledford@redhat.com>,
        Jason Gunthorpe <jgg@ziepe.ca>,
        Jerome Glisse <jglisse@redhat.com>,
        Matthew Wilcox <willy@infradead.org>,
        Michal Hocko <mhocko@kernel.org>,
        Mike Marciniszyn <mike.marciniszyn@intel.com>,
        Ralph Campbell <rcampbell@nvidia.com>,
        LKML <linux-kernel@vger.kernel.org>,
        linux-fsdevel@vger.kernel.org, John Hubbard <jhubbard@nvidia.com>
Subject: Re: [PATCH 1/2] mm: introduce put_user_page*(), placeholder versions
References: <20181204001720.26138-1-jhubbard@nvidia.com>
 <20181204001720.26138-2-jhubbard@nvidia.com>
MIME-Version: 1.0
Content-Type: text/plain; charset=us-ascii
Content-Disposition: inline
In-Reply-To: <20181204001720.26138-2-jhubbard@nvidia.com>
User-Agent: Mutt/1.5.24 (2015-08-30)
X-TM-AS-GCONF: 00
x-cbid: 18120407-0016-0000-0000-00000231B04F
X-IBM-AV-DETECTION: SAVI=unused REMOTE=unused XFE=unused
x-cbparentid: 18120407-0017-0000-0000-00003289B913
Message-Id: <20181204075323.GI26700@rapoport-lnx>
X-Proofpoint-Virus-Version: vendor=fsecure engine=2.50.10434:,, definitions=2018-12-04_04:,,
 signatures=0
X-Proofpoint-Spam-Details: rule=outbound_notspam policy=outbound score=0 priorityscore=1501
 malwarescore=0 suspectscore=0 phishscore=0 bulkscore=0 spamscore=0
 clxscore=1015 lowpriorityscore=0 mlxscore=0 impostorscore=0
 mlxlogscore=999 adultscore=0 classifier=spam adjust=0 reason=mlx
 scancount=1 engine=8.0.1-1810050000 definitions=main-1812040071
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: <linux-kernel.vger.kernel.org>
X-Mailing-List: linux-kernel@vger.kernel.org

Hi John,

Thanks for having documentation as a part of the patch. Some kernel-doc
nits below.

On Mon, Dec 03, 2018 at 04:17:19PM -0800, john.hubbard@gmail.com wrote:
> From: John Hubbard <jhubbard@nvidia.com>
> 
> Introduces put_user_page(), which simply calls put_page().
> This provides a way to update all get_user_pages*() callers,
> so that they call put_user_page(), instead of put_page().
> 
> Also introduces put_user_pages(), and a few dirty/locked variations,
> as a replacement for release_pages(), and also as a replacement
> for open-coded loops that release multiple pages.
> These may be used for subsequent performance improvements,
> via batching of pages to be released.
> 
> This is the first step of fixing the problem described in [1]. The steps
> are:
> 
> 1) (This patch): provide put_user_page*() routines, intended to be used
>    for releasing pages that were pinned via get_user_pages*().
> 
> 2) Convert all of the call sites for get_user_pages*(), to
>    invoke put_user_page*(), instead of put_page(). This involves dozens of
>    call sites, and will take some time.
> 
> 3) After (2) is complete, use get_user_pages*() and put_user_page*() to
>    implement tracking of these pages. This tracking will be separate from
>    the existing struct page refcounting.
> 
> 4) Use the tracking and identification of these pages, to implement
>    special handling (especially in writeback paths) when the pages are
>    backed by a filesystem. Again, [1] provides details as to why that is
>    desirable.
> 
> [1] https://lwn.net/Articles/753027/ : "The Trouble with get_user_pages()"
> 
> Reviewed-by: Jan Kara <jack@suse.cz>
> 
> Cc: Matthew Wilcox <willy@infradead.org>
> Cc: Michal Hocko <mhocko@kernel.org>
> Cc: Christopher Lameter <cl@linux.com>
> Cc: Jason Gunthorpe <jgg@ziepe.ca>
> Cc: Dan Williams <dan.j.williams@intel.com>
> Cc: Jan Kara <jack@suse.cz>
> Cc: Al Viro <viro@zeniv.linux.org.uk>
> Cc: Jerome Glisse <jglisse@redhat.com>
> Cc: Christoph Hellwig <hch@infradead.org>
> Cc: Ralph Campbell <rcampbell@nvidia.com>
> Signed-off-by: John Hubbard <jhubbard@nvidia.com>
> ---
>  include/linux/mm.h | 20 ++++++++++++
>  mm/swap.c          | 80 ++++++++++++++++++++++++++++++++++++++++++++++
>  2 files changed, 100 insertions(+)
> 
> diff --git a/include/linux/mm.h b/include/linux/mm.h
> index 5411de93a363..09fbb2c81aba 100644
> --- a/include/linux/mm.h
> +++ b/include/linux/mm.h
> @@ -963,6 +963,26 @@ static inline void put_page(struct page *page)
>  		__put_page(page);
>  }
> 
> +/*
> + * put_user_page() - release a page that had previously been acquired via
> + * a call to one of the get_user_pages*() functions.

Please add @page parameter description, otherwise kernel-doc is unhappy

> + *
> + * Pages that were pinned via get_user_pages*() must be released via
> + * either put_user_page(), or one of the put_user_pages*() routines
> + * below. This is so that eventually, pages that are pinned via
> + * get_user_pages*() can be separately tracked and uniquely handled. In
> + * particular, interactions with RDMA and filesystems need special
> + * handling.
> + */
> +static inline void put_user_page(struct page *page)
> +{
> +	put_page(page);
> +}
> +
> +void put_user_pages_dirty(struct page **pages, unsigned long npages);
> +void put_user_pages_dirty_lock(struct page **pages, unsigned long npages);
> +void put_user_pages(struct page **pages, unsigned long npages);
> +
>  #if defined(CONFIG_SPARSEMEM) && !defined(CONFIG_SPARSEMEM_VMEMMAP)
>  #define SECTION_IN_PAGE_FLAGS
>  #endif
> diff --git a/mm/swap.c b/mm/swap.c
> index aa483719922e..bb8c32595e5f 100644
> --- a/mm/swap.c
> +++ b/mm/swap.c
> @@ -133,6 +133,86 @@ void put_pages_list(struct list_head *pages)
>  }
>  EXPORT_SYMBOL(put_pages_list);
> 
> +typedef int (*set_dirty_func)(struct page *page);
> +
> +static void __put_user_pages_dirty(struct page **pages,
> +				   unsigned long npages,
> +				   set_dirty_func sdf)
> +{
> +	unsigned long index;
> +
> +	for (index = 0; index < npages; index++) {
> +		struct page *page = compound_head(pages[index]);
> +
> +		if (!PageDirty(page))
> +			sdf(page);
> +
> +		put_user_page(page);
> +	}
> +}
> +
> +/*
> + * put_user_pages_dirty() - for each page in the @pages array, make
> + * that page (or its head page, if a compound page) dirty, if it was
> + * previously listed as clean. Then, release the page using
> + * put_user_page().
> + *
> + * Please see the put_user_page() documentation for details.
> + *
> + * set_page_dirty(), which does not lock the page, is used here.
> + * Therefore, it is the caller's responsibility to ensure that this is
> + * safe. If not, then put_user_pages_dirty_lock() should be called instead.
> + *
> + * @pages:  array of pages to be marked dirty and released.
> + * @npages: number of pages in the @pages array.

Please put the parameters description next to the brief function
description, as described in [1]

[1] https://www.kernel.org/doc/html/latest/doc-guide/kernel-doc.html#function-documentation


> + *
> + */
> +void put_user_pages_dirty(struct page **pages, unsigned long npages)
> +{
> +	__put_user_pages_dirty(pages, npages, set_page_dirty);
> +}
> +EXPORT_SYMBOL(put_user_pages_dirty);
> +
> +/*
> + * put_user_pages_dirty_lock() - for each page in the @pages array, make
> + * that page (or its head page, if a compound page) dirty, if it was
> + * previously listed as clean. Then, release the page using
> + * put_user_page().
> + *
> + * Please see the put_user_page() documentation for details.
> + *
> + * This is just like put_user_pages_dirty(), except that it invokes
> + * set_page_dirty_lock(), instead of set_page_dirty().
> + *
> + * @pages:  array of pages to be marked dirty and released.
> + * @npages: number of pages in the @pages array.

Ditto

> + *
> + */
> +void put_user_pages_dirty_lock(struct page **pages, unsigned long npages)
> +{
> +	__put_user_pages_dirty(pages, npages, set_page_dirty_lock);
> +}
> +EXPORT_SYMBOL(put_user_pages_dirty_lock);
> +
> +/*
> + * put_user_pages() - for each page in the @pages array, release the page
> + * using put_user_page().
> + *
> + * Please see the put_user_page() documentation for details.
> + *
> + * @pages:  array of pages to be marked dirty and released.
> + * @npages: number of pages in the @pages array.
> + *

And here as well :)

> + */
> +void put_user_pages(struct page **pages, unsigned long npages)
> +{
> +	unsigned long index;
> +
> +	for (index = 0; index < npages; index++)
> +		put_user_page(pages[index]);
> +}
> +EXPORT_SYMBOL(put_user_pages);
> +
>  /*
>   * get_kernel_pages() - pin kernel pages in memory
>   * @kiov:	An array of struct kvec structures
> -- 
> 2.19.2
> 

-- 
Sincerely yours,
Mike.

