Return-Path: <linux-kernel-owner@vger.kernel.org>
Delivered-To: unknown
Received: from linux.intel.com (10.54.29.200:995) by likexu-workstation with
  POP3-SSL; 07 Dec 2018 16:17:02 -0000
X-Original-To: like.xu@linux.intel.com
Delivered-To: like.xu@linux.intel.com
Received: from fmsmga001.fm.intel.com (fmsmga001.fm.intel.com [10.253.24.23])
	(using TLSv1.2 with cipher ECDHE-RSA-AES256-GCM-SHA384 (256/256 bits))
	(No client certificate requested)
	by linux.intel.com (Postfix) with ESMTPS id C13115804F9;
	Thu,  6 Dec 2018 17:13:48 -0800 (PST)
Received: from orsmga101.jf.intel.com ([10.7.208.22])
  by fmsmga001-1.fm.intel.com with ESMTP/TLS/DHE-RSA-AES256-GCM-SHA384; 06 Dec 2018 17:13:48 -0800
X-SG-BADATTACHMENTNOREPLY: True
IronPort-PHdr: =?us-ascii?q?9a23=3AqCiouhIjq1pD+ylGH9mcpTZWNBhigK39O0sv0rFi?=
 =?us-ascii?q?tYgULvv7rarrMEGX3/hxlliBBdydt6oUzbKO+4nbGkU4qa6bt34DdJEeHzQksu?=
 =?us-ascii?q?4x2zIaPcieFEfgJ+TrZSFpVO5LVVti4m3peRMNQJW2aFLduGC94iAPERvjKwV1?=
 =?us-ascii?q?Ov71GonPhMiryuy+4ZLebxlLiTanfb9+MAi9oBnMuMURnYZsMLs6xAHTontPde?=
 =?us-ascii?q?RWxGdoKkyWkh3h+Mq+/4Nt/jpJtf45+MFOTav1f6IjTbxFFzsmKHw65NfqtRbY?=
 =?us-ascii?q?UwSC4GYXX3gMnRpJBwjF6wz6Xov0vyDnuOdxxDWWMMvrRr0vRz+s87lkRwPpiC?=
 =?us-ascii?q?cfNj427mfXitBrjKlGpB6tvgFzz5LIbI2QMvd1Y6HTcs4ARWdZXshfSTFPDI2/?=
 =?us-ascii?q?YYUIDeUBM+lXoYb8p1sVtRuzBxKhCP/sxzJSmnP7x7E23/gnHArb3AIgBdUOsH?=
 =?us-ascii?q?HModjoLqgSS/y1x7THwjrZafNdxCvw6JPTch89ofGDQ697fM3KxkkxDQzFiE+f?=
 =?us-ascii?q?qZf+PzyJ1uQCrXOW4PB8WuKqkWInrBtxoje2y8oql4LHhZoVx0ja+SllxIs5P8?=
 =?us-ascii?q?C0RUBlbdK+DZddtD2WO5F3T84gW21kpSQ3x74ctZKlYCQHy44ryhDbZvCdboSF?=
 =?us-ascii?q?4hLuWP6MLTtki39pYq+zihi8/ES6yeDwTMq53VJMoyFYiNfDrGoN2AbW6sWfSv?=
 =?us-ascii?q?ty4EOh2TGX2gDN5eFLP1o0mbDYK5E/2L4wkIQcsUDZEi/xgkX2g7eadkQi+ue2?=
 =?us-ascii?q?9+TqeqvqqoOYOoNulw3zPLoiltaiDek7LgQCRWmW9Oak2L3m50L5QbFKjvMskq?=
 =?us-ascii?q?netZDXPcAbpq+/Aw9I3Ycv8hW/ACm80NQeg3YHKEtJeBWJjojvJV7OOuv1Demw?=
 =?us-ascii?q?g1uyijdn3fPGMaP7ApXLMHfDlK3tfbFn605T0AYz18xQ54pICrEdJ/L+QkvxtN?=
 =?us-ascii?q?3bDhAnKQC1zPvnBc551oMfX2KPH6CYPLnTsV+O+uIgPe2MaJUJtzb6Lvgv/+Tu?=
 =?us-ascii?q?gmMhmV8BYamp2oMaaHCiEfRnP0WWe33sjs0BEWcXpAU+SuPqhUaGUT5SYXayQq?=
 =?us-ascii?q?096is6CIKgEYfMWIStjKad0ye8G51cfnpGBUyUEXf0a4WEXO8BaCCVIsB/iDAE?=
 =?us-ascii?q?Vr+hS4kn1RGprwL6z7tnLuzJ+iwXr57j1d515/HNmhE27zB7E8Od02SVRWFugm?=
 =?us-ascii?q?wIXyM23Lx4oUFl0FiDyqh4g/tbFdBJ/fNGSAU6OIXYz+x7DdDyRw3Acs2ISFag?=
 =?us-ascii?q?XtWpHzUxQsgtzN8JZkZ3A8+igQzb3yq2H78VkKSGBJ8u/aLaxXTxI8d9xGzA1K?=
 =?us-ascii?q?kulFQmRspPNWu7hq9w7QTTBojJk1mHmKaub6gTwCnN9GKbx2qUoE5YSBJwUbnC?=
 =?us-ascii?q?XX0He0TZt8r56V3YQ7+uE7snNBBBxtCEKqdNbt3pjlBGRPP4NdTaYmKxnXqwBB?=
 =?us-ascii?q?mSyrONaorqZ3sS3CHHBEcYlAAT+G6MNRIiCSe5v2LeEDtuGErybEz27+lxtmm3?=
 =?us-ascii?q?Tk8uwAGMdE1uyby19wURhfydTfMTw70FtD0gqzVyAFaywdbWB8CcqApmeaVWec?=
 =?us-ascii?q?k970tf1WLFqwx9OYStL7xjhl4bdAR3o0Pu1hVtBoVci8Qqq2kqzA5zKaKe31NM?=
 =?us-ascii?q?bDeY3ZH2Or3KJWj+5hGva6jK2l7A1Naa4LsA6PM9q1/7pgGmClIi82l709lSy3?=
 =?us-ascii?q?aT/JHKAxQdUJ3vUkc77QN1p6zHbSYn4YPU1npsMbevvz/G2tIpAvYlyxm6c9de?=
 =?us-ascii?q?NqOECBH9E8kAC8eyL+wqnkCjbggYM+BK6K40I8SmeuOG2a62JupvgCiqjGVH4I?=
 =?us-ascii?q?9n1EKM+DFxSurJ35YD3vGZ0RGLVzb6jFe9rM/3nZpIai0VHmq60SLkHpJeZrVu?=
 =?us-ascii?q?fYYXDmejO9e3xtRiiJH3QX5X6VmjC0kA2MC3YxqSbkXx0hFK2kQTvHOohzG4zz?=
 =?us-ascii?q?tykzwyqqqf3SrOw/ntdRYdO25LQnVigknoIYSuk98aW02oZRAzlBS5/Ub627Rb?=
 =?us-ascii?q?pKNnImjTQEdEZSj3I3t5UqutsLqPeMpP6JIusSVKX+Wwe1GaSrjhoxQE1yPvBX?=
 =?us-ascii?q?dRxDc+dzuyoJX2gwR6iH6BLHZ0tHfZe9t/xQ3c5NzfQv5dxCEGSzN7iTnUB1i8?=
 =?us-ascii?q?Ocem/dOPmpfHs+C+UX+hV5JJfSnqy4OAqDW05WlwDRKjmPCzn8XtERIm3i/jy9?=
 =?us-ascii?q?lqSSLIoQ78Y4bx0KS2K+BnfkhuBFLn78p6G4d+kpY/hZ0K2HgagImV8mQDkWvp?=
 =?us-ascii?q?Ldpb3qf+ZmIXRTEX297V/BTl2Ep7I3KK3Y35V2+Rwst8Z9agZGMW1Tkw78RLCK?=
 =?us-ascii?q?eS8bxFkjF5olu+rQLNf/d9mi0Rxucp6H4fm+sJohYizj2BArAOGklVJSnslxWL?=
 =?us-ascii?q?79+ktqlWanigcaOs1EVgh9CuF6+NohtTWHvifpciHClw7thwMV7W0X3z7J3kd8?=
 =?us-ascii?q?fUbd4JqhKUlBLAhfBPKJ0tjvoKmTZnOWXlsH05zO47iAZi3JCgs4iBNmVt57m5?=
 =?us-ascii?q?Ah9DOz3xZsMT/CztjKlEksaX2YCvAotuGjERUJT0SvKoFSoYte77OAaWDD08tn?=
 =?us-ascii?q?CbFKLEEgCF70dmq2/PH4qvN3GKP3QZydRiRB+AJE1QmgwUXTM6noInGQCu3sDu?=
 =?us-ascii?q?bEB55jUJ7F7ithRM0v5oNwX4UmrHpgencDI0R4aELBZM8gFO/UTVMdGd7uJuGS?=
 =?us-ascii?q?FX5IahoReJKmyaYQRIEG4IVlaFB1DlIrmh+93A//KECeq5KvvEea+OpvBGV/eU?=
 =?us-ascii?q?2ZKv1ZNr/jaLNsWSJ3liEuc02kxZUXBiHMTZnToPRjcTlyLMac6buRi99jd2rs?=
 =?us-ascii?q?C57PTkRgbv6ZGTBLtVNNVl4wq2jrubN+6MmCZ5Li5V1pMSyn/Jy7gf318Shztt?=
 =?us-ascii?q?dzm3FrQAujDCTLjNmq9MFBMbbyJzNM1V76MzxAVNOMjbis/r2b58lPI6F1BFVV?=
 =?us-ascii?q?n5kMGzecMKO329NE/ABEuTLruGOCbEw9vpbqK8U7FQiORUuga0uTaaFU/jIzuC?=
 =?us-ascii?q?myPoVxCpLeFDkiWbMAZCt4G6dxZnEXLjQ87+ah2nLN93iiU7waE1hnPPL2ITLS?=
 =?us-ascii?q?JwfF9NrrKO6yNVmfF/G21H7np4IuiIgSeZ7+/EKpkItftnGDh7l+Vf4H4i0bta?=
 =?us-ascii?q?8DlEROBpmCvVttNvo0upku+KyjpmVhpBsjdKhIKRskVkNqXU7Z1AWXfC/BIQ4m?=
 =?us-ascii?q?ScERUKp915CtLxv6Bc0MTAlKX2KGQKz9WB+MoaCM/8Ms+LMHM9dxHuHW36FgwA?=
 =?us-ascii?q?GBSiL32XuUVb2NiJ7XaVo9BuoIblnpMVUbRbWXQ8HfZcDV5qSo9RaKxrVy8pxO?=
 =?us-ascii?q?bIxPUD4mCz+VyIHJ1X?=
X-IronPort-Anti-Spam-Filtered: true
X-IronPort-Anti-Spam-Result: =?us-ascii?q?A0AYAADkxwlch0O0hNFjHgEGBwaBUQkLA?=
 =?us-ascii?q?YIAgWsnCpgZgiFollKBdhEYEwGHVyI0CQ0BAwEBAQEBAQIBEwEBAQgNCQgpIwy?=
 =?us-ascii?q?CNiQBgmIDAwECJAsBDQEBNwEFCQEBUAMyBR0ZBYMcggIEAZpTPIodgWwzgnYBA?=
 =?us-ascii?q?QWHKggWh1qELxeBf4ERgl0HiwqJN4YCfJAsCYo7hwAjgVyFFYJxCIdMmQyBRoI?=
 =?us-ascii?q?NMxowQ4JsghsMF4IsjBJRgQUBASGIfAGBHgEB?=
X-IPAS-Result: =?us-ascii?q?A0AYAADkxwlch0O0hNFjHgEGBwaBUQkLAYIAgWsnCpgZgiF?=
 =?us-ascii?q?ollKBdhEYEwGHVyI0CQ0BAwEBAQEBAQIBEwEBAQgNCQgpIwyCNiQBgmIDAwECJ?=
 =?us-ascii?q?AsBDQEBNwEFCQEBUAMyBR0ZBYMcggIEAZpTPIodgWwzgnYBAQWHKggWh1qELxe?=
 =?us-ascii?q?Bf4ERgl0HiwqJN4YCfJAsCYo7hwAjgVyFFYJxCIdMmQyBRoINMxowQ4JsghsMF?=
 =?us-ascii?q?4IsjBJRgQUBASGIfAGBHgEB?=
X-IronPort-AV: E=Sophos;i="5.56,324,1539673200"; 
   d="scan'208";a="43949609"
X-Amp-Result: SKIPPED(no attachment in message)
X-Amp-File-Uploaded: False
Received: from vger.kernel.org ([209.132.180.67])
  by mtab.intel.com with ESMTP; 06 Dec 2018 17:13:46 -0800
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
        id S1726205AbeLGBNo (ORCPT <rfc822;like.xu@linux.intel.com>
        + 23 others); Thu, 6 Dec 2018 20:13:44 -0500
Received: from com-out001.mailprotect.be ([83.217.72.83]:47709 "EHLO
        com-out001.mailprotect.be" rhost-flags-OK-OK-OK-OK) by vger.kernel.org
        with ESMTP id S1726182AbeLGBNl (ORCPT
        <rfc822;linux-kernel@vger.kernel.org>);
        Thu, 6 Dec 2018 20:13:41 -0500
DKIM-Signature: v=1; a=rsa-sha256; q=dns/txt; c=relaxed/relaxed;
        d=mailprotect.be; s=mail; h=Content-Transfer-Encoding:MIME-Version:References
        :In-Reply-To:Message-Id:Date:Subject:Cc:To:From:reply-to:sender:bcc:
        content-type; bh=FI1MFxkfoADuq8N1clf4xj+R/2ZxgUV4DoMQSX6JHbs=; b=rc3wA3gCaXmS
        EqG3WzQg0bHsX8hHmGuRT6B08uPAKBfNAxXCqk76Z0/H+22FWLGKIlThLjzt3+hSVubmN4Cyk5sRM
        9+MXqLa5e/lu86JtIvPZe+ihpcvP/EChE50tt1ROuXzdguAZv9nAlqmEdjoFExTnqiiZdszkJvUu5
        0A1pPAxf11IrvJz1SMcJ+uAc1J9MTIUklWur9vG4lTXOvrxPnCKLqVn13RhMHkp6PMJBIr8dRgAeH
        2iZOa4EMde9no/Sf1xuakdsBd5tSqzB9dHYUJGGp0dyQA9dZilkbeWyc8cKWoWKZ8uPvCCQlsUxJA
        Ykzu56MKD4MUJvjhb8Kb9A==;
Received: from smtp-auth.mailprotect.be ([178.208.39.155])
        by com-mpt-out001.mailprotect.be with esmtp (Exim 4.89)
        (envelope-from <bvanassche@acm.org>)
        id 1gV4hn-0008rQ-SO; Fri, 07 Dec 2018 02:13:24 +0100
Received: from desktop-bart.svl.corp.google.com (unknown [104.133.8.89])
        (using TLSv1 with cipher DHE-RSA-AES256-SHA (256/256 bits))
        (No client certificate requested)
        by smtp-auth.mailprotect.be (Postfix) with ESMTPSA id 420D5C0774;
        Fri,  7 Dec 2018 02:13:19 +0100 (CET)
From: Bart Van Assche <bvanassche@acm.org>
To: mingo@redhat.com
Cc: peterz@infradead.org, tj@kernel.org, longman@redhat.com,
        johannes.berg@intel.com, linux-kernel@vger.kernel.org,
        Bart Van Assche <bvanassche@acm.org>,
        Will Deacon <will.deacon@arm.com>
Subject: [PATCH v3 23/24] kernel/workqueue: Use dynamic lockdep keys for workqueues
Date: Thu,  6 Dec 2018 17:11:47 -0800
Message-Id: <20181207011148.251812-24-bvanassche@acm.org>
X-Mailer: git-send-email 2.20.0.rc2.403.gdbc3b29805-goog
In-Reply-To: <20181207011148.251812-1-bvanassche@acm.org>
References: <20181207011148.251812-1-bvanassche@acm.org>
MIME-Version: 1.0
Content-Transfer-Encoding: 8bit
X-Originating-IP: 178.208.39.155
X-SpamExperts-Domain: mailprotect.be
X-SpamExperts-Username: 178.208.39.128/27
Authentication-Results: mailprotect.be; auth=pass smtp.auth=178.208.39.128/27@mailprotect.be
X-SpamExperts-Outgoing-Class: ham
X-SpamExperts-Outgoing-Evidence: SB/global_tokens (0.000824872924076)
X-Recommended-Action: accept
X-Filter-ID: EX5BVjFpneJeBchSMxfU5oGtbb9gnLb9+z6XJyfmErl602E9L7XzfQH6nu9C/Fh9KJzpNe6xgvOx
 q3u0UDjvO1tLifGj39bI0bcPyaJsYTbXCyMe5v8y2H30acbVA7+CsLowAEMLnIs/c915wTAPANfX
 yKo+pvzCeHRww82sG/8HW2me2F11ZDpUG2A5Oiv0I5mALh2L1FvYZOvwUqXjvDk55wR+TsdsSUF6
 GKzdvFr/HXw7HB6/ASdSFy6HwS/kPXDwAtkmamZ68x0sIvfyXcDIKE+0kbt+hzad+8LmAP3bC8dt
 /CV3fELBVC/AS5PvSbXcS42ZV4hGYRCvRHS3A+fHzJ6mVE7ewsipSVIfs4aUceICwLxbw5jC7C83
 W5VZQ2EZL/JNL8UUAaUS/T4q/hyWVd53YytHpjB/ujB/2NTonZtAvX1WzENHOSMGSyH2zE++dJZh
 hWbGyID6cWhsJRhb5RzkLIvXya0B9hweynIpEbHgsgY3JWab+g/Mh1jtnnOnAcd69x18pg0p8FqR
 rrmbyc5aB71wGr2Wbtmzh89JTRBxdS0lhfyuKilVxvWjCdK5dbUFdaYh4OLOUeZKO4TBa7kme6ff
 96X9WP+3jk0SJ/kTJjKPZ/8yaP/4XwlZZAHYSttyJwNs842uSNa4gyQXDpdUnGtbQi4spq0UVwRE
 wz3BDlSGdw7VMtZPUeP8kDkXGJvniGivX1Fq/UQDddsCO69AoU2oRPPFpAmM+MP3ndP5vfUQ4ul/
 XTPIgii6Kq6qRvDQ2XYchg9MrxV4mWaBWuZZ1rE+MiszWwrZbclSzNQilWcl+AAZWR29Qk/naAdK
 j4hWhfECyeV8ncDFva5No9GEWJe3jHoeJ2GRKtY5TqQtU3Fmv+9rOFh5/4AztW1xD7NPHFVkxC5Y
 VnU16VdtBKql0yaiWVS4FZeRyGrddKrYTaNJmUrP3aGF8PhBfZvJhEai+eHegH0Ec43kUsw4Oh2L
 kwsmIC+tUiJAU2HV4JjSb8ZA1ph/XcllGuCYWh77szDFCGzgTVmU0LEvaBxwEiTVJqDh0qKoKsXx
 5lkrB0NgADpo+u70e0mb9CuXdB+oFNx/mz3B+VhqlC4E7rXNP8evbj93rcJzfRecDffpfj5sSQhb
 3cc4IkKXIhy+VQFYdTkvI7AHf8uIH0A8UoKhd6FzBtileDUVqU9xfPdO+eyolGM4l8rlxuGfhU+3
 4oc3K5BE7o/7xI7rcp+XGKuAzBSdqYsFmB+z+c7xrxi9hX6LDkmm4X5IcVM5U1xd
X-Report-Abuse-To: spam@com-mpt-mgt001.mailprotect.be
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: <linux-kernel.vger.kernel.org>
X-Mailing-List: linux-kernel@vger.kernel.org

Commit 87915adc3f0a ("workqueue: re-add lockdep dependencies for flushing")
improved deadlock checking in the workqueue implementation. Unfortunately
that patch also introduced a few false positive lockdep complaints. This
patch suppresses these false positives by allocating the workqueue mutex
lockdep key dynamically. An example of a false positive lockdep complaint
suppressed by this report can be found below. The root cause of the
lockdep complaint shown below is that the direct I/O code can call
alloc_workqueue() from inside a work item created by another
alloc_workqueue() call and that both workqueues share the same lockdep
key. This patch avoids that that lockdep complaint is triggered by
allocating the work queue lockdep keys dynamically. In other words, this
patch guarantees that a unique lockdep key is associated with each work
queue mutex.

======================================================
WARNING: possible circular locking dependency detected
4.19.0-dbg+ #1 Not tainted
------------------------------------------------------
fio/4129 is trying to acquire lock:
00000000a01cfe1a ((wq_completion)"dio/%s"sb->s_id){+.+.}, at: flush_workqueue+0xd0/0x970

but task is already holding lock:
00000000a0acecf9 (&sb->s_type->i_mutex_key#14){+.+.}, at: ext4_file_write_iter+0x154/0x710

which lock already depends on the new lock.

the existing dependency chain (in reverse order) is:

-> #2 (&sb->s_type->i_mutex_key#14){+.+.}:
       down_write+0x3d/0x80
       __generic_file_fsync+0x77/0xf0
       ext4_sync_file+0x3c9/0x780
       vfs_fsync_range+0x66/0x100
       dio_complete+0x2f5/0x360
       dio_aio_complete_work+0x1c/0x20
       process_one_work+0x481/0x9f0
       worker_thread+0x63/0x5a0
       kthread+0x1cf/0x1f0
       ret_from_fork+0x24/0x30

-> #1 ((work_completion)(&dio->complete_work)){+.+.}:
       process_one_work+0x447/0x9f0
       worker_thread+0x63/0x5a0
       kthread+0x1cf/0x1f0
       ret_from_fork+0x24/0x30

-> #0 ((wq_completion)"dio/%s"sb->s_id){+.+.}:
       lock_acquire+0xc5/0x200
       flush_workqueue+0xf3/0x970
       drain_workqueue+0xec/0x220
       destroy_workqueue+0x23/0x350
       sb_init_dio_done_wq+0x6a/0x80
       do_blockdev_direct_IO+0x1f33/0x4be0
       __blockdev_direct_IO+0x79/0x86
       ext4_direct_IO+0x5df/0xbb0
       generic_file_direct_write+0x119/0x220
       __generic_file_write_iter+0x131/0x2d0
       ext4_file_write_iter+0x3fa/0x710
       aio_write+0x235/0x330
       io_submit_one+0x510/0xeb0
       __x64_sys_io_submit+0x122/0x340
       do_syscall_64+0x71/0x220
       entry_SYSCALL_64_after_hwframe+0x49/0xbe

other info that might help us debug this:

Chain exists of:
  (wq_completion)"dio/%s"sb->s_id --> (work_completion)(&dio->complete_work) --> &sb->s_type->i_mutex_key#14

 Possible unsafe locking scenario:

       CPU0                    CPU1
       ----                    ----
  lock(&sb->s_type->i_mutex_key#14);
                               lock((work_completion)(&dio->complete_work));
                               lock(&sb->s_type->i_mutex_key#14);
  lock((wq_completion)"dio/%s"sb->s_id);

 *** DEADLOCK ***

1 lock held by fio/4129:
 #0: 00000000a0acecf9 (&sb->s_type->i_mutex_key#14){+.+.}, at: ext4_file_write_iter+0x154/0x710

stack backtrace:
CPU: 3 PID: 4129 Comm: fio Not tainted 4.19.0-dbg+ #1
Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS 1.10.2-1 04/01/2014
Call Trace:
 dump_stack+0x86/0xc5
 print_circular_bug.isra.32+0x20a/0x218
 __lock_acquire+0x1c68/0x1cf0
 lock_acquire+0xc5/0x200
 flush_workqueue+0xf3/0x970
 drain_workqueue+0xec/0x220
 destroy_workqueue+0x23/0x350
 sb_init_dio_done_wq+0x6a/0x80
 do_blockdev_direct_IO+0x1f33/0x4be0
 __blockdev_direct_IO+0x79/0x86
 ext4_direct_IO+0x5df/0xbb0
 generic_file_direct_write+0x119/0x220
 __generic_file_write_iter+0x131/0x2d0
 ext4_file_write_iter+0x3fa/0x710
 aio_write+0x235/0x330
 io_submit_one+0x510/0xeb0
 __x64_sys_io_submit+0x122/0x340
 do_syscall_64+0x71/0x220
 entry_SYSCALL_64_after_hwframe+0x49/0xbe

Cc: Ingo Molnar <mingo@redhat.com>
Cc: Peter Zijlstra <peterz@infradead.org>
Cc: Will Deacon <will.deacon@arm.com>
Cc: Tejun Heo <tj@kernel.org>
Cc: Waiman Long <longman@redhat.com>
Cc: Johannes Berg <johannes.berg@intel.com>
Signed-off-by: Bart Van Assche <bvanassche@acm.org>
---
 include/linux/workqueue.h | 28 +++---------------
 kernel/workqueue.c        | 60 +++++++++++++++++++++++++++++++++------
 2 files changed, 55 insertions(+), 33 deletions(-)

diff --git a/include/linux/workqueue.h b/include/linux/workqueue.h
index 60d673e15632..d9a1a480e920 100644
--- a/include/linux/workqueue.h
+++ b/include/linux/workqueue.h
@@ -390,43 +390,23 @@ extern struct workqueue_struct *system_freezable_wq;
 extern struct workqueue_struct *system_power_efficient_wq;
 extern struct workqueue_struct *system_freezable_power_efficient_wq;
 
-extern struct workqueue_struct *
-__alloc_workqueue_key(const char *fmt, unsigned int flags, int max_active,
-	struct lock_class_key *key, const char *lock_name, ...) __printf(1, 6);
-
 /**
  * alloc_workqueue - allocate a workqueue
  * @fmt: printf format for the name of the workqueue
  * @flags: WQ_* flags
  * @max_active: max in-flight work items, 0 for default
- * @args...: args for @fmt
+ * remaining args: args for @fmt
  *
  * Allocate a workqueue with the specified parameters.  For detailed
  * information on WQ_* flags, please refer to
  * Documentation/core-api/workqueue.rst.
  *
- * The __lock_name macro dance is to guarantee that single lock_class_key
- * doesn't end up with different namesm, which isn't allowed by lockdep.
- *
  * RETURNS:
  * Pointer to the allocated workqueue on success, %NULL on failure.
  */
-#ifdef CONFIG_LOCKDEP
-#define alloc_workqueue(fmt, flags, max_active, args...)		\
-({									\
-	static struct lock_class_key __key;				\
-	const char *__lock_name;					\
-									\
-	__lock_name = "(wq_completion)"#fmt#args;			\
-									\
-	__alloc_workqueue_key((fmt), (flags), (max_active),		\
-			      &__key, __lock_name, ##args);		\
-})
-#else
-#define alloc_workqueue(fmt, flags, max_active, args...)		\
-	__alloc_workqueue_key((fmt), (flags), (max_active),		\
-			      NULL, NULL, ##args)
-#endif
+struct workqueue_struct *alloc_workqueue(const char *fmt,
+					 unsigned int flags,
+					 int max_active, ...);
 
 /**
  * alloc_ordered_workqueue - allocate an ordered workqueue
diff --git a/kernel/workqueue.c b/kernel/workqueue.c
index 0280deac392e..82e155f764b7 100644
--- a/kernel/workqueue.c
+++ b/kernel/workqueue.c
@@ -259,6 +259,8 @@ struct workqueue_struct {
 	struct wq_device	*wq_dev;	/* I: for sysfs interface */
 #endif
 #ifdef CONFIG_LOCKDEP
+	char			*lock_name;
+	struct lock_class_key	key;
 	struct lockdep_map	lockdep_map;
 #endif
 	char			name[WQ_NAME_LEN]; /* I: workqueue name */
@@ -3314,11 +3316,50 @@ static int init_worker_pool(struct worker_pool *pool)
 	return 0;
 }
 
+#ifdef CONFIG_LOCKDEP
+static void wq_init_lockdep(struct workqueue_struct *wq)
+{
+	char *lock_name;
+
+	lockdep_register_key(&wq->key);
+	lock_name = kasprintf(GFP_KERNEL, "%s%s", "(wq_completion)", wq->name);
+	if (!lock_name)
+		lock_name = wq->name;
+	lockdep_init_map(&wq->lockdep_map, lock_name, &wq->key, 0);
+}
+
+static void wq_unregister_lockdep(struct workqueue_struct *wq)
+{
+	lockdep_reset_lock(&wq->lockdep_map);
+	lockdep_unregister_key(&wq->key);
+}
+
+static void wq_free_lockdep(struct workqueue_struct *wq)
+{
+	if (wq->lock_name != wq->name)
+		kfree(wq->lock_name);
+}
+#else
+static void wq_init_lockdep(struct workqueue_struct *wq)
+{
+}
+
+static void wq_unregister_lockdep(struct workqueue_struct *wq)
+{
+}
+
+static void wq_free_lockdep(struct workqueue_struct *wq)
+{
+}
+#endif
+
 static void rcu_free_wq(struct rcu_head *rcu)
 {
 	struct workqueue_struct *wq =
 		container_of(rcu, struct workqueue_struct, rcu);
 
+	wq_free_lockdep(wq);
+
 	if (!(wq->flags & WQ_UNBOUND))
 		free_percpu(wq->cpu_pwqs);
 	else
@@ -3509,8 +3550,10 @@ static void pwq_unbound_release_workfn(struct work_struct *work)
 	 * If we're the last pwq going away, @wq is already dead and no one
 	 * is gonna access it anymore.  Schedule RCU free.
 	 */
-	if (is_last)
+	if (is_last) {
+		wq_unregister_lockdep(wq);
 		call_rcu_sched(&wq->rcu, rcu_free_wq);
+	}
 }
 
 /**
@@ -4044,11 +4087,9 @@ static int init_rescuer(struct workqueue_struct *wq)
 	return 0;
 }
 
-struct workqueue_struct *__alloc_workqueue_key(const char *fmt,
-					       unsigned int flags,
-					       int max_active,
-					       struct lock_class_key *key,
-					       const char *lock_name, ...)
+struct workqueue_struct *alloc_workqueue(const char *fmt,
+					 unsigned int flags,
+					 int max_active, ...)
 {
 	size_t tbl_size = 0;
 	va_list args;
@@ -4083,7 +4124,7 @@ struct workqueue_struct *__alloc_workqueue_key(const char *fmt,
 			goto err_free_wq;
 	}
 
-	va_start(args, lock_name);
+	va_start(args, max_active);
 	vsnprintf(wq->name, sizeof(wq->name), fmt, args);
 	va_end(args);
 
@@ -4100,7 +4141,7 @@ struct workqueue_struct *__alloc_workqueue_key(const char *fmt,
 	INIT_LIST_HEAD(&wq->flusher_overflow);
 	INIT_LIST_HEAD(&wq->maydays);
 
-	lockdep_init_map(&wq->lockdep_map, lock_name, key, 0);
+	wq_init_lockdep(wq);
 	INIT_LIST_HEAD(&wq->list);
 
 	if (alloc_and_link_pwqs(wq) < 0)
@@ -4138,7 +4179,7 @@ struct workqueue_struct *__alloc_workqueue_key(const char *fmt,
 	destroy_workqueue(wq);
 	return NULL;
 }
-EXPORT_SYMBOL_GPL(__alloc_workqueue_key);
+EXPORT_SYMBOL_GPL(alloc_workqueue);
 
 /**
  * destroy_workqueue - safely terminate a workqueue
@@ -4191,6 +4232,7 @@ void destroy_workqueue(struct workqueue_struct *wq)
 		kthread_stop(wq->rescuer->task);
 
 	if (!(wq->flags & WQ_UNBOUND)) {
+		wq_unregister_lockdep(wq);
 		/*
 		 * The base ref is never dropped on per-cpu pwqs.  Directly
 		 * schedule RCU free.
-- 
2.20.0.rc2.403.gdbc3b29805-goog

