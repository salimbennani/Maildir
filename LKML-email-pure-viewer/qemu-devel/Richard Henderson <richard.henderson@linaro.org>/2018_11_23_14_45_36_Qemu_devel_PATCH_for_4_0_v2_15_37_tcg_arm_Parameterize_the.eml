Return-Path: <qemu-devel-bounces+like.xu=linux.intel.com@nongnu.org>
Delivered-To: unknown
Received: from linux.intel.com (10.54.29.200:995) by likexu-workstation with
  POP3-SSL; 23 Nov 2018 23:36:22 -0000
X-Original-To: like.xu@linux.intel.com
Delivered-To: like.xu@linux.intel.com
Received: from fmsmga002.fm.intel.com (fmsmga002.fm.intel.com [10.253.24.26])
	(using TLSv1.2 with cipher ECDHE-RSA-AES256-GCM-SHA384 (256/256 bits))
	(No client certificate requested)
	by linux.intel.com (Postfix) with ESMTPS id 938905803EB
	for <like.xu@linux.intel.com>; Fri, 23 Nov 2018 06:57:34 -0800 (PST)
Received: from fmsmga104.fm.intel.com ([10.1.193.100])
  by fmsmga002-1.fm.intel.com with ESMTP/TLS/DHE-RSA-AES256-GCM-SHA384; 23 Nov 2018 06:57:34 -0800
IronPort-PHdr: =?us-ascii?q?9a23=3AYO89txfJKfxbPm8t/Dbybdb/lGMj4u6mDksu8pMi?=
 =?us-ascii?q?zoh2WeGdxcW/ZR7h7PlgxGXEQZ/co6odzbaO4+a4ASQp2tWoiDg6aptCVhsI24?=
 =?us-ascii?q?09vjcLJ4q7M3D9N+PgdCcgHc5PBxdP9nC/NlVJSo6lPwWB6nK94iQPFRrhKAF7?=
 =?us-ascii?q?Ovr6GpLIj8Swyuu+54Dfbx9HiTahYr5+Ngm6oRnMvcQKnIVuLbo8xAHUqXVSYe?=
 =?us-ascii?q?RWwm1oJVOXnxni48q74YBu/SdNtf8/7sBMSar1cbg2QrxeFzQmLns65Nb3uhnZ?=
 =?us-ascii?q?TAuA/WUTX2MLmRdVGQfF7RX6XpDssivms+d2xSeXMdHqQb0yRD+v6bpgRh31hy?=
 =?us-ascii?q?cdLzM38H/ZhMJzgqxcoh2hqQFxw5bWbY+XO/dyY63Qcc8ESmpaRctdSzBND5mg?=
 =?us-ascii?q?Y4YVE+YNIeBVpJT9qVsUqhu+ABGhCv/uyjBUhn/5x7c63Pk8Gg/EwgMgGc8Bv2?=
 =?us-ascii?q?rOrNXuM6cSV/2+wa7SzTXCc/xW2S3y6JLVfRw7ofGDQ7RwftfPxkk1DAPFiVOQ?=
 =?us-ascii?q?pJfhPzOU0OQCqXKb7+16WeKokW4npBh8rz6yzckvkonEnpwZxkzH+Clj3Yo5ON?=
 =?us-ascii?q?61RFRlbdOqEJZcrTyWOoluTs8/R2xluDw2x78EtJKhYiQHx5UqywTfZvCbdYWD?=
 =?us-ascii?q?/wjtW/yLIThigXJoYLK/iAi28Uin0uD8Usi00E1WripeiNXMuXYN1wHJ5siAUP?=
 =?us-ascii?q?t98V+t2TeJ1w/N9uFJOV44mbbYJpI737I8i5kevV7dEiL4mEj6lrKae0c89uit?=
 =?us-ascii?q?8evnY7HmppGGN49zjwHzKr0uldK6AeQlKwQBQnaU+fqi273n5EH2W7JKjuAwkq?=
 =?us-ascii?q?bFrp/aPsMXpqq4Aw9WzIkv8Rm+Dyq+3dQcnHkHKk9FeR2dg4joPVHOPO73DfOl?=
 =?us-ascii?q?j1uwlzdrwuvLPrvmApXLIXjDlqrhcax6605Gxwo/1cpf6I5MCrEdPPLzXVf8tN?=
 =?us-ascii?q?jZDh86LQO42enmCMhm24MaWGKPBLKZMazIvV+J4OIvP/eDZIsPtDnhLPgl4q2m?=
 =?us-ascii?q?sHkihFVIfbW1xYBFLze8H+96OAOfZnzjhMpHFn0F+Q83TejvgVvFViZPZnG0RO?=
 =?us-ascii?q?Ul6zQmTY6rE4rHFb2rm6GLiSKyH5lKYTJfB1WRVHvlaYiAHu0BcT+fOdNJlDsC?=
 =?us-ascii?q?Wr68DYg72ka1qQX4xrF7e/fS4TASrpn51dJ4tNHUwAg/8CExA8mD3mWlSWZykW?=
 =?us-ascii?q?UVATgs0/NRu0t4n22C2qhxmfAQNdFV6/5TSQA8fcrGzud6Asr+HALMeNuEUk2h?=
 =?us-ascii?q?RP2iADc4VNV3xMUBNRUuU+6+hwzOinL5S4QekKaGUcQ5?=
X-IronPort-Anti-Spam-Filtered: true
X-IronPort-Anti-Spam-Result: =?us-ascii?q?A0AtAAAyFPhbhxHrdtBjHgEGBwaBUQkLA?=
 =?us-ascii?q?YEwKoI4jHCLIYMHkUqEd4FzEgEBGBSIWiI0CQ0BAwEBAQEBAQIBEwEBAQoLCQg?=
 =?us-ascii?q?bDiMMgjYFAgMYCYJcAwMBAj0BAQQKKQECAwECBgEBPgoIAwEwAQUBHBkFgxyCA?=
 =?us-ascii?q?gEDAZtAPIodgh+CdgEBBYJDhFEIEodMgw+BHIFXP4ERgl2LDoklD5ZQBwKCHAS?=
 =?us-ascii?q?PBAsYiVGHNyyXXQYCCQcPIYElgg1NMIMvghsMFxJtAQGHXYU/cYEHiiqBdwEB?=
X-IPAS-Result: =?us-ascii?q?A0AtAAAyFPhbhxHrdtBjHgEGBwaBUQkLAYEwKoI4jHCLIYM?=
 =?us-ascii?q?HkUqEd4FzEgEBGBSIWiI0CQ0BAwEBAQEBAQIBEwEBAQoLCQgbDiMMgjYFAgMYC?=
 =?us-ascii?q?YJcAwMBAj0BAQQKKQECAwECBgEBPgoIAwEwAQUBHBkFgxyCAgEDAZtAPIodgh+?=
 =?us-ascii?q?CdgEBBYJDhFEIEodMgw+BHIFXP4ERgl2LDoklD5ZQBwKCHASPBAsYiVGHNyyXX?=
 =?us-ascii?q?QYCCQcPIYElgg1NMIMvghsMFxJtAQGHXYU/cYEHiiqBdwEB?=
X-IronPort-AV: E=Sophos;i="5.56,270,1539673200"; 
   d="scan'208";a="52393052"
X-Amp-Result: SKIPPED(no attachment in message)
X-Amp-File-Uploaded: False
Received: from lists.gnu.org ([208.118.235.17])
  by mtab.intel.com with ESMTP/TLS/AES256-SHA; 23 Nov 2018 06:57:33 -0800
Received: from localhost ([::1]:52814 helo=lists.gnu.org)
	by lists.gnu.org with esmtp (Exim 4.71)
	(envelope-from <qemu-devel-bounces+like.xu=linux.intel.com@nongnu.org>)
	id 1gQCtg-0002Je-Nm
	for like.xu@linux.intel.com; Fri, 23 Nov 2018 09:57:32 -0500
Received: from eggs.gnu.org ([2001:4830:134:3::10]:44027)
	by lists.gnu.org with esmtp (Exim 4.71)
	(envelope-from <richard.henderson@linaro.org>) id 1gQCis-0008GY-35
	for qemu-devel@nongnu.org; Fri, 23 Nov 2018 09:46:23 -0500
Received: from Debian-exim by eggs.gnu.org with spam-scanned (Exim 4.71)
	(envelope-from <richard.henderson@linaro.org>) id 1gQCin-0003Mi-5G
	for qemu-devel@nongnu.org; Fri, 23 Nov 2018 09:46:20 -0500
Received: from mail-wr1-x443.google.com ([2a00:1450:4864:20::443]:45075)
	by eggs.gnu.org with esmtps (TLS1.0:RSA_AES_128_CBC_SHA1:16)
	(Exim 4.71) (envelope-from <richard.henderson@linaro.org>)
	id 1gQCim-0003LE-Ph
	for qemu-devel@nongnu.org; Fri, 23 Nov 2018 09:46:17 -0500
Received: by mail-wr1-x443.google.com with SMTP id v6so12573029wrr.12
	for <qemu-devel@nongnu.org>; Fri, 23 Nov 2018 06:46:16 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed; d=linaro.org; s=google;
	h=from:to:cc:subject:date:message-id:in-reply-to:references;
	bh=8t7gEiP0UljdZGOq63+3IiIupXpsvdWUor96eMaww/U=;
	b=Mqq7XUuC0JQsXv+tyGQoxIx/uCgeohv6aUAGqdRPkOcMZN661/wj4kZmbLrlFYsz0t
	WNa+A9x6hlbLgzsEYD1pJxoH/Kt6h8u2H4pnDhUKPKFIsEt7CInyKcjXHIb1/N+WE1fZ
	nqoa/IjYEXqMXmo9gxHy3sTRdR6gXkQMzaU0g=
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
	d=1e100.net; s=20161025;
	h=x-gm-message-state:from:to:cc:subject:date:message-id:in-reply-to
	:references;
	bh=8t7gEiP0UljdZGOq63+3IiIupXpsvdWUor96eMaww/U=;
	b=ULz0sbO/YmE3g2LrVrPGLGR/onJtg1Ek5G+DsRaILDmgpjCoL3Awa0U0aiEKveBKa5
	KDL0VK/8rYLIW1J7Otql2aOabTox1NdboAAJCnW7VtRhMWUEDNxLF8JgQARB5SACap7m
	7EBdmX+LCpnYGbVDLTXLCXRPfCexScMB1i0/BkFMi5bVm3DKilKRfd8dLmDC7PpESIy5
	v61dGOTKorJ7aYXhAiJLFmBpUfzTU8rEruH9nfle5qIxZ5aJX0MmhJ4OiVJN78MqHIVi
	wyoJkDE+TN9mAearY3ZDsLTH4PQ/g+ptx1miNIycDZgw89HluMbpjrZWKxfQME8itqTT
	SMKw==
X-Gm-Message-State: AA+aEWZfqR0uA0Qwi8FZURFNDwtx1Fft8EevGzgsBmIMGpYG+3wiLPol
	1fyOD5MR0tf9VWBnmzsXwoN0jpznXP4BbQ==
X-Google-Smtp-Source: AFSGD/VTFjayYkaXIU45MVrUi0o0jQDw/SPCEMj7bRx70wvmDvZDK8XTx19/6MBbu4nmmxOQqI5LJA==
X-Received: by 2002:adf:ef50:: with SMTP id c16mr13861349wrp.198.1542984375308;
	Fri, 23 Nov 2018 06:46:15 -0800 (PST)
Received: from cloudburst.twiddle.net ([195.77.246.50])
	by smtp.gmail.com with ESMTPSA id
	p74sm10339630wmd.29.2018.11.23.06.46.14
	(version=TLS1_2 cipher=ECDHE-RSA-CHACHA20-POLY1305 bits=256/256);
	Fri, 23 Nov 2018 06:46:14 -0800 (PST)
From: Richard Henderson <richard.henderson@linaro.org>
To: qemu-devel@nongnu.org
Date: Fri, 23 Nov 2018 15:45:36 +0100
Message-Id: <20181123144558.5048-16-richard.henderson@linaro.org>
X-Mailer: git-send-email 2.17.2
In-Reply-To: <20181123144558.5048-1-richard.henderson@linaro.org>
References: <20181123144558.5048-1-richard.henderson@linaro.org>
X-detected-operating-system: by eggs.gnu.org: Genre and OS details not
	recognized.
X-Received-From: 2a00:1450:4864:20::443
Subject: [Qemu-devel] [PATCH for-4.0 v2 15/37] tcg/arm: Parameterize the
 temps for tcg_out_tlb_read
X-BeenThere: qemu-devel@nongnu.org
X-Mailman-Version: 2.1.21
Precedence: list
List-Id: <qemu-devel.nongnu.org>
List-Unsubscribe: <https://lists.nongnu.org/mailman/options/qemu-devel>,
	<mailto:qemu-devel-request@nongnu.org?subject=unsubscribe>
List-Archive: <http://lists.nongnu.org/archive/html/qemu-devel/>
List-Post: <mailto:qemu-devel@nongnu.org>
List-Help: <mailto:qemu-devel-request@nongnu.org?subject=help>
List-Subscribe: <https://lists.nongnu.org/mailman/listinfo/qemu-devel>,
	<mailto:qemu-devel-request@nongnu.org?subject=subscribe>
Cc: Alistair.Francis@wdc.com
Errors-To: qemu-devel-bounces+like.xu=linux.intel.com@nongnu.org
Sender: "Qemu-devel" <qemu-devel-bounces+like.xu=linux.intel.com@nongnu.org>

When moving the qemu_ld/st arguments to the right place for
a function call, we'll need to move the temps out of the way.

Signed-off-by: Richard Henderson <richard.henderson@linaro.org>
---
 tcg/arm/tcg-target.inc.c | 89 +++++++++++++++++++++-------------------
 1 file changed, 46 insertions(+), 43 deletions(-)

diff --git a/tcg/arm/tcg-target.inc.c b/tcg/arm/tcg-target.inc.c
index 80d174ef44..414c91c9ea 100644
--- a/tcg/arm/tcg-target.inc.c
+++ b/tcg/arm/tcg-target.inc.c
@@ -1245,11 +1245,14 @@ static TCGReg tcg_out_arg_reg64(TCGContext *s, TCGReg argreg,
 /* We're expecting to use an 8-bit immediate and to mask.  */
 QEMU_BUILD_BUG_ON(CPU_TLB_BITS > 8);
 
-/* Load and compare a TLB entry, leaving the flags set.  Returns the register
-   containing the addend of the tlb entry.  Clobbers R0, R1, R2, TMP.  */
-
+/*
+ *Load and compare a TLB entry, leaving the flags set.  Returns the register
+ * containing the addend of the tlb entry.  Clobbers t0, t1, t2, t3.
+ * T0 and T1 must be consecutive for LDRD.
+ */
 static TCGReg tcg_out_tlb_read(TCGContext *s, TCGReg addrlo, TCGReg addrhi,
-                               TCGMemOp opc, int mem_index, bool is_load)
+                               TCGMemOp opc, int mem_index, bool is_load,
+                               TCGReg t0, TCGReg t1, TCGReg t2, TCGReg t3)
 {
     TCGReg base = TCG_AREG0;
     int cmp_off =
@@ -1262,36 +1265,37 @@ static TCGReg tcg_out_tlb_read(TCGContext *s, TCGReg addrlo, TCGReg addrhi,
     unsigned a_bits = get_alignment_bits(opc);
 
     /* V7 generates the following:
-     *   ubfx   r0, addrlo, #TARGET_PAGE_BITS, #CPU_TLB_BITS
-     *   add    r2, env, #high
-     *   add    r2, r2, r0, lsl #CPU_TLB_ENTRY_BITS
-     *   ldr    r0, [r2, #cmp]
-     *   ldr    r2, [r2, #add]
-     *   movw   tmp, #page_align_mask
-     *   bic    tmp, addrlo, tmp
-     *   cmp    r0, tmp
+     *   ubfx   t0, addrlo, #TARGET_PAGE_BITS, #CPU_TLB_BITS
+     *   add    t2, env, #high
+     *   add    t2, t2, r0, lsl #CPU_TLB_ENTRY_BITS
+     *   ldr    t0, [t2, #cmp]  (and t1 w/ldrd)
+     *   ldr    t2, [t2, #add]
+     *   movw   t3, #page_align_mask
+     *   bic    t3, addrlo, t3
+     *   cmp    t0, t3
      *
      * Otherwise we generate:
-     *   shr    tmp, addrlo, #TARGET_PAGE_BITS
-     *   add    r2, env, #high
-     *   and    r0, tmp, #(CPU_TLB_SIZE - 1)
-     *   add    r2, r2, r0, lsl #CPU_TLB_ENTRY_BITS
-     *   ldr    r0, [r2, #cmp]
-     *   ldr    r2, [r2, #add]
+     *   shr    t3, addrlo, #TARGET_PAGE_BITS
+     *   add    t2, env, #high
+     *   and    t0, t3, #(CPU_TLB_SIZE - 1)
+     *   add    t2, t2, t0, lsl #CPU_TLB_ENTRY_BITS
+     *   ldr    t0, [t2, #cmp]  (and t1 w/ldrd)
+     *   ldr    t2, [t2, #add]
      *   tst    addrlo, #s_mask
-     *   cmpeq  r0, tmp, lsl #TARGET_PAGE_BITS
+     *   cmpeq  t0, t3, lsl #TARGET_PAGE_BITS
      */
     if (use_armv7_instructions) {
-        tcg_out_extract(s, COND_AL, TCG_REG_R0, addrlo,
+        tcg_out_extract(s, COND_AL, t0, addrlo,
                         TARGET_PAGE_BITS, CPU_TLB_BITS);
     } else {
-        tcg_out_dat_reg(s, COND_AL, ARITH_MOV, TCG_REG_TMP,
+        tcg_out_dat_reg(s, COND_AL, ARITH_MOV, t3,
                         0, addrlo, SHIFT_IMM_LSR(TARGET_PAGE_BITS));
     }
 
     /* Add portions of the offset until the memory access is in range.
      * If we plan on using ldrd, reduce to an 8-bit offset; otherwise
-     * we can use a 12-bit offset.  */
+     * we can use a 12-bit offset.
+     */
     if (use_armv6_instructions && TARGET_LONG_BITS == 64) {
         mask_off = 0xff;
     } else {
@@ -1301,34 +1305,33 @@ static TCGReg tcg_out_tlb_read(TCGContext *s, TCGReg addrlo, TCGReg addrhi,
         int shift = ctz32(cmp_off & ~mask_off) & ~1;
         int rot = ((32 - shift) << 7) & 0xf00;
         int addend = cmp_off & (0xff << shift);
-        tcg_out_dat_imm(s, COND_AL, ARITH_ADD, TCG_REG_R2, base,
+        tcg_out_dat_imm(s, COND_AL, ARITH_ADD, t2, base,
                         rot | ((cmp_off >> shift) & 0xff));
-        base = TCG_REG_R2;
+        base = t2;
         add_off -= addend;
         cmp_off -= addend;
     }
 
     if (!use_armv7_instructions) {
-        tcg_out_dat_imm(s, COND_AL, ARITH_AND,
-                        TCG_REG_R0, TCG_REG_TMP, CPU_TLB_SIZE - 1);
+        tcg_out_dat_imm(s, COND_AL, ARITH_AND, t0, t3, CPU_TLB_SIZE - 1);
     }
-    tcg_out_dat_reg(s, COND_AL, ARITH_ADD, TCG_REG_R2, base,
-                    TCG_REG_R0, SHIFT_IMM_LSL(CPU_TLB_ENTRY_BITS));
+    tcg_out_dat_reg(s, COND_AL, ARITH_ADD, t2, base, t0,
+                    SHIFT_IMM_LSL(CPU_TLB_ENTRY_BITS));
 
     /* Load the tlb comparator.  Use ldrd if needed and available,
        but due to how the pointer needs setting up, ldm isn't useful.
        Base arm5 doesn't have ldrd, but armv5te does.  */
     if (use_armv6_instructions && TARGET_LONG_BITS == 64) {
-        tcg_out_ldrd_8(s, COND_AL, TCG_REG_R0, TCG_REG_R2, cmp_off);
+        tcg_out_ldrd_8(s, COND_AL, t0, t2, cmp_off);
     } else {
-        tcg_out_ld32_12(s, COND_AL, TCG_REG_R0, TCG_REG_R2, cmp_off);
+        tcg_out_ld32_12(s, COND_AL, t0, t2, cmp_off);
         if (TARGET_LONG_BITS == 64) {
-            tcg_out_ld32_12(s, COND_AL, TCG_REG_R1, TCG_REG_R2, cmp_off + 4);
+            tcg_out_ld32_12(s, COND_AL, t1, t2, cmp_off + 4);
         }
     }
 
     /* Load the tlb addend.  */
-    tcg_out_ld32_12(s, COND_AL, TCG_REG_R2, TCG_REG_R2, add_off);
+    tcg_out_ld32_12(s, COND_AL, t2, t2, add_off);
 
     /* Check alignment.  We don't support inline unaligned acceses,
        but we can easily support overalignment checks.  */
@@ -1341,29 +1344,27 @@ static TCGReg tcg_out_tlb_read(TCGContext *s, TCGReg addrlo, TCGReg addrhi,
         int rot = encode_imm(mask);
 
         if (rot >= 0) { 
-            tcg_out_dat_imm(s, COND_AL, ARITH_BIC, TCG_REG_TMP, addrlo,
+            tcg_out_dat_imm(s, COND_AL, ARITH_BIC, t3, addrlo,
                             rotl(mask, rot) | (rot << 7));
         } else {
-            tcg_out_movi32(s, COND_AL, TCG_REG_TMP, mask);
-            tcg_out_dat_reg(s, COND_AL, ARITH_BIC, TCG_REG_TMP,
-                            addrlo, TCG_REG_TMP, 0);
+            tcg_out_movi32(s, COND_AL, t3, mask);
+            tcg_out_dat_reg(s, COND_AL, ARITH_BIC, t3, addrlo, t3, 0);
         }
-        tcg_out_dat_reg(s, COND_AL, ARITH_CMP, 0, TCG_REG_R0, TCG_REG_TMP, 0);
+        tcg_out_dat_reg(s, COND_AL, ARITH_CMP, 0, t0, t3, 0);
     } else {
         if (a_bits) {
             tcg_out_dat_imm(s, COND_AL, ARITH_TST, 0, addrlo,
                             (1 << a_bits) - 1);
         }
         tcg_out_dat_reg(s, (a_bits ? COND_EQ : COND_AL), ARITH_CMP,
-                        0, TCG_REG_R0, TCG_REG_TMP,
-                        SHIFT_IMM_LSL(TARGET_PAGE_BITS));
+                        0, t0, t3, SHIFT_IMM_LSL(TARGET_PAGE_BITS));
     }
 
     if (TARGET_LONG_BITS == 64) {
-        tcg_out_dat_reg(s, COND_EQ, ARITH_CMP, 0, TCG_REG_R1, addrhi, 0);
+        tcg_out_dat_reg(s, COND_EQ, ARITH_CMP, 0, t1, addrhi, 0);
     }
 
-    return TCG_REG_R2;
+    return t2;
 }
 
 /* Record the context of a call to the out of line helper code for the slow
@@ -1629,7 +1630,8 @@ static void tcg_out_qemu_ld(TCGContext *s, const TCGArg *args, bool is64)
 
 #ifdef CONFIG_SOFTMMU
     mem_index = get_mmuidx(oi);
-    addend = tcg_out_tlb_read(s, addrlo, addrhi, opc, mem_index, 1);
+    addend = tcg_out_tlb_read(s, addrlo, addrhi, opc, mem_index, 1,
+                              TCG_REG_R0, TCG_REG_R1, TCG_REG_R2, TCG_REG_R14);
 
     /* This a conditional BL only to load a pointer within this opcode into LR
        for the slow path.  We will not be using the value for a tail call.  */
@@ -1760,7 +1762,8 @@ static void tcg_out_qemu_st(TCGContext *s, const TCGArg *args, bool is64)
 
 #ifdef CONFIG_SOFTMMU
     mem_index = get_mmuidx(oi);
-    addend = tcg_out_tlb_read(s, addrlo, addrhi, opc, mem_index, 0);
+    addend = tcg_out_tlb_read(s, addrlo, addrhi, opc, mem_index, 0,
+                              TCG_REG_R0, TCG_REG_R1, TCG_REG_R2, TCG_REG_R14);
 
     tcg_out_qemu_st_index(s, COND_EQ, opc, datalo, datahi, addrlo, addend);
 
-- 
2.17.2


