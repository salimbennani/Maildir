Return-Path: <linux-kernel-owner@vger.kernel.org>
Delivered-To: unknown
Received: from linux.intel.com (10.54.29.200:995) by likexu-workstation with
  POP3-SSL; 04 Dec 2018 20:36:06 -0000
X-Original-To: like.xu@linux.intel.com
Delivered-To: like.xu@linux.intel.com
Received: from orsmga004.jf.intel.com (orsmga004.jf.intel.com [10.7.209.38])
	(using TLSv1.2 with cipher ECDHE-RSA-AES256-GCM-SHA384 (256/256 bits))
	(No client certificate requested)
	by linux.intel.com (Postfix) with ESMTPS id 0DAC3580375;
	Tue,  4 Dec 2018 03:05:25 -0800 (PST)
Received: from orsmga102-1.jf.intel.com (HELO mga09.intel.com) ([10.7.208.27])
  by orsmga004-1.jf.intel.com with ESMTP; 04 Dec 2018 03:05:25 -0800
X-SG-BADATTACHMENTNOREPLY: True
IronPort-PHdr: =?us-ascii?q?9a23=3Av4PqvBCU0gWnMLHPs0w2UyQJP3N1i/DPJgcQr6Af?=
 =?us-ascii?q?oPdwSP7+pcmwAkXT6L1XgUPTWs2DsrQY07qQ6/iocFdDyK7JiGoFfp1IWk1Nou?=
 =?us-ascii?q?QttCtkPvS4D1bmJuXhdS0wEZcKflZk+3amLRodQ56mNBXdrXKo8DEdBAj0OxZr?=
 =?us-ascii?q?KeTpAI7SiNm82/yv95HJbAhEmDmwbaluIBmqsA7cqtQYjYx+J6gr1xDHuGFIe+?=
 =?us-ascii?q?NYxWNpIVKcgRPx7dqu8ZBg7ipdpesv+9ZPXqvmcas4S6dYDCk9PGAu+MLrrxjD?=
 =?us-ascii?q?QhCR6XYaT24bjwBHAwnB7BH9Q5fxri73vfdz1SWGIcH7S60/VC+85Kl3VhDnlC?=
 =?us-ascii?q?YHNyY48G7JjMxwkLlbqw+lqxBm3oLYfJ2ZOP94c6jAf90VWHBBU95RWSJfH42y?=
 =?us-ascii?q?YYgBAe0DMuZWoYbyqEcBoxSlBQm0Bu7i0SNIi3z40KEmyeksCwPL0Qo9FNwOqn?=
 =?us-ascii?q?TUq9D1Ob8TX+Cv0qbIwijIYfZM2Tf68ofIcgktr/OWUrJqbcrRzFMgFwXYhViX?=
 =?us-ascii?q?pozlJS2a1usOs2ib9OdgUeOvi2g6qwB+rDivwdosio/UiY0P1lDE9CJ5wIAvKd?=
 =?us-ascii?q?2/Uk57bsepHZ1NvC+UMIt2R9ktQ2BuuCsiyb0Jp4S7fC4Ux5Qj3RLfbOaHc4eO?=
 =?us-ascii?q?7xn+V+iROS91iGx5dL+7nRq+7EatxvPmWsWp01tGsjBJn9jOu3wV1BHe5NKLR/?=
 =?us-ascii?q?h880u72juC0xrf5vxYLU02k6fQNoQvzaQqlpUJtETOBi/2l1vyjK+Rbkgk5Oeo?=
 =?us-ascii?q?5Pr9Yrn8pZ+TKZV0igfgPaQqgMC/Bv44MgcWU2ia/+SzyqHj8FXnTLlWivA6iL?=
 =?us-ascii?q?TVvZ7EKcgBu6K0ABNZ3pwi5hu9Fzum1c4XnXgDLFJLYhKHiI3pNknKIPD5C/e/?=
 =?us-ascii?q?nlutnC5ox//YJL3hBIvCLnzanLfmc7d97VBTyBAowNBB6JJbFKsBLOjwWkDvrt?=
 =?us-ascii?q?zYCAE2Mwiuz+bgEtV92ZsSWXiTDa+BLKPSrViI6/orI+mNZ48apizxKvc45/P1?=
 =?us-ascii?q?iX85mFkdfbSm3JcNaXC4GOhmLFudYXb2ntgBFmIKtBIkTOP2kF2CTSJTZ3GqUq?=
 =?us-ascii?q?I8/D47CZ6mAp3ERoy3gLyBwT20HptZZm1dDlCMEHHod5iLWvsWaSKSJNNhnSIA?=
 =?us-ascii?q?VbS7V4Ah0hSuvhfgy7V7NurU5jEYtZX72dh34O3ciws+9T9zD8Sb1WGNSHp5nm?=
 =?us-ascii?q?cJRz8wwaB+rlZxylaF0ahknfNYEcZf6O9OUgc/LZTc1fB1C8juWgLdedeEUEyp?=
 =?us-ascii?q?Qs6mATE2TdI92cUObFx/G9i5ihDD3iyqA6IalrCRBZw09L7c0Gb1J8pn13nG06?=
 =?us-ascii?q?whhUE8QsRTLW2mmrJ/9w/LCo7KiUqZkbymdaAd3CHX8meDwnGDvEVZUA52TKXE?=
 =?us-ascii?q?UmoTZkrQrdTl+EzCS6WiBqggMgtE0cSCMLdFasX1jVVaQ/fuIMnRbHivm2iuHx?=
 =?us-ascii?q?qIxqmDbIzxe2oD2iXRD0wEkwMW/XaCLgU+Aiaho2TDDD1hD17vYkXs8fVgp3O/?=
 =?us-ascii?q?VEM70waKb0h53bqv5hEVneCcS+8U3r8cpSgusSt0E0in09LWEdWAoRFhc7taYd?=
 =?us-ascii?q?4m5FdH1GTZtxFyP5C6LqBigEIefBpzv0/0yxp3DYBAm9AwrHw21ApyNb6Y0FRZ?=
 =?us-ascii?q?ejOE3JDwP7rXKnXy/BGvcaLWxkvS0NGM+qcL6fQ4rVrjsRqtFkoj9XVnztZU32?=
 =?us-ascii?q?Gd5pXMEAodT5bxXlwr+Bh9orHQejM96J/M1X1wLam0tSfP1MgtBOQ7xRevYdde?=
 =?us-ascii?q?PLmfGw/vDsIVHc6uKO8tm1i3dR8EOOFS9KgpP8KpbfeG2airPPp+kzKil2hI/I?=
 =?us-ascii?q?d90keU/SpmVuHIx4oFw+2f3gafVzb8kU2tvdztlYFFZTEdBGy/ySf/CY5VZ61y?=
 =?us-ascii?q?e5sLCGi0L822wNV+m4DiW3pC+FG/AFMG3dejeQCOYFzlwQ1QyUMXrGS9mSu50z?=
 =?us-ascii?q?N7iSspobeY3CDUxeTtagAHOm9SSGZ+l1jsJZW7gM4AXEivaQgkjx+l5Uf8x6hG?=
 =?us-ascii?q?q6VzNWjTQUFUfyfoK2FuSLe/tr2HY8RX8pMnrT1XUPigYVCdUrP8oxoa3znjHm?=
 =?us-ascii?q?dE3zA7ajeqt479nxx7jmKdMXlyoGDYecF22RfQ+tjcSeRN0ToBQSlykSPXCUSk?=
 =?us-ascii?q?P9m14dWUkI/OsuKkWGK7VZ1Tci7rwZmbtCSh5m1qAhy/n/atld3hCgU61S7719?=
 =?us-ascii?q?93VSTHthr8Y4/r17ikPuJjZEVnGFj8689iEIFkjoQwnI0Q2WQdhpiN/XsIi2Dz?=
 =?us-ascii?q?Pc9Z2aL/anoAXjoLw9/T4Aj410xvNHOJx4TlVnqDxsttfcW1YmQT2igl9cBFFL?=
 =?us-ascii?q?+U7KBYnStyule4rhjeYflnkjcd1Psh8ngag+4StQopzyWdBK0SHEZCMSztkRSI?=
 =?us-ascii?q?886xrKFNaGmzdriw0VJ0ncq9A7GavgFcRHH5d48nHS9x7cVwKkjA0XPt5YH/ZN?=
 =?us-ascii?q?nfc8gTuQaKnBfagOhYM5YxlvsMhSp6NmPxp3wly+gnjRNw2ZG2ppSIK2Jo/Kih?=
 =?us-ascii?q?GB5XKiX1Z98P+jHqlategsGW34W1EpRgADoLWoboTemzEDITrvnnMweOEDshqn?=
 =?us-ascii?q?aUA7bfHAmf6Ft4oHLLCZykK3aXJHwBx9V4WBadPFBfgBwTXDgihZE2DAeqxMj8?=
 =?us-ascii?q?cEtj4jAR+0X1qh9NyuJuKhn+XX3TpAauajcoVpefKABa4R1F50fQKcae9P58Hz?=
 =?us-ascii?q?lE/p29qwyAMm6baB5NDW4XQUyIHUzjMqOt5dnd8OiYG+y+IOHVYbiVrexeVvGI?=
 =?us-ascii?q?xY+g04d8/jaMMNmPMWdmD/EhxkVDWnV5EdzDmzoTUywXiz7Nb8mDqRa8/S13s9?=
 =?us-ascii?q?m/8OnxVwLp/4ePELxSMdNg+x2thaeDNuiQhDt2KDpC15MMw2PIx6Yb3FIIly5u?=
 =?us-ascii?q?cDytG6watSHRVKLQhrNXDxkDZiNzKsRI7qE83gpMOcLBidP1zLl4jvErBFdfSF?=
 =?us-ascii?q?zhgdqkZcgLI2G7KVPGC1yHNLWAJT3X3c73ZbmwRqFXjOVRrxewoyqUE1f/PjSf?=
 =?us-ascii?q?kDnkTwqgMfxXgyGBIhNfuJuxchJsCWX4SNLmaxu7MMJ4jDEswL00gG/KOnAYMT?=
 =?us-ascii?q?Rmb0xNqbiQ5ztCgvpjA2xB8mZlLe6cliaF7unYL4wavudxDitol+JV/nI6xqBR?=
 =?us-ascii?q?7CFFQvx1hSTTosRvo1GgjumA1D5nXABSpTZMgYKBpV9iNrnB9plcRXbE+woA7G?=
 =?us-ascii?q?WKBBQMottlC9vvtLhRy9jPjq3zLjhC/snQ/csdAcjUNc2GPGAgMRrvBD7bEg8F?=
 =?us-ascii?q?QSS3OmHYgkwO2M2Vo3mUqIUq75vhgpwDTpdFW1EvUPAXEEJoGJoFOpgkcCkjlO?=
 =?us-ascii?q?u0lsMHrVmkqxDRAeVTpIzCX/TaVfr1JTmajZFAZh0V0b3/MIIfP5H63EokbUN1?=
 =?us-ascii?q?yteZU3HMVMxA93UyJjQ/p19ApT0nFjU+?=
X-IronPort-Anti-Spam-Filtered: true
X-IronPort-Anti-Spam-Result: =?us-ascii?q?A0ARAAAEXgZch0O0hNFjHAEBAQQBAQcEA?=
 =?us-ascii?q?QGBUQcBAQsBAYJogQIng3mIGV+LL4INFIh9jjiBcxQYCwgBiBEiNAkNAQMBAQE?=
 =?us-ascii?q?BAQECARMBAQEKCwkIKSMMQgEQAYFiJAGCYgMDAQIgBAsBDQEBNwEFCQEBHwUCB?=
 =?us-ascii?q?SECAgMMEjYZBYMcAYFpAxUEAQqjEHB8DCeCdgEBBYEwAYNdDYIUAwWBC4ZkgxO?=
 =?us-ascii?q?BHBeBf4ERhWmFLoJXiS8EgW+UYRguCYcDhxCDIyOBW4URijosjUCBDIl9gUaCD?=
 =?us-ascii?q?TMaCCgIgycTgggMF4hehUA/MgEBgQADAQEhE4U8hSIBAQ?=
X-IPAS-Result: =?us-ascii?q?A0ARAAAEXgZch0O0hNFjHAEBAQQBAQcEAQGBUQcBAQsBAYJ?=
 =?us-ascii?q?ogQIng3mIGV+LL4INFIh9jjiBcxQYCwgBiBEiNAkNAQMBAQEBAQECARMBAQEKC?=
 =?us-ascii?q?wkIKSMMQgEQAYFiJAGCYgMDAQIgBAsBDQEBNwEFCQEBHwUCBSECAgMMEjYZBYM?=
 =?us-ascii?q?cAYFpAxUEAQqjEHB8DCeCdgEBBYEwAYNdDYIUAwWBC4ZkgxOBHBeBf4ERhWmFL?=
 =?us-ascii?q?oJXiS8EgW+UYRguCYcDhxCDIyOBW4URijosjUCBDIl9gUaCDTMaCCgIgycTggg?=
 =?us-ascii?q?MF4hehUA/MgEBgQADAQEhE4U8hSIBAQ?=
X-IronPort-AV: E=Sophos;i="5.56,313,1539673200"; 
   d="scan'208";a="55988710"
X-Amp-Result: SKIPPED(no attachment in message)
X-Amp-File-Uploaded: False
Received: from vger.kernel.org ([209.132.180.67])
  by mtab.intel.com with ESMTP; 04 Dec 2018 03:05:23 -0800
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
        id S1728106AbeLDLFN (ORCPT <rfc822;like.xu@linux.intel.com>
        + 23 others); Tue, 4 Dec 2018 06:05:13 -0500
Received: from mail.kernel.org ([198.145.29.99]:52788 "EHLO mail.kernel.org"
        rhost-flags-OK-OK-OK-OK) by vger.kernel.org with ESMTP
        id S1728086AbeLDLFL (ORCPT <rfc822;linux-kernel@vger.kernel.org>);
        Tue, 4 Dec 2018 06:05:11 -0500
Received: from localhost (5356596B.cm-6-7b.dynamic.ziggo.nl [83.86.89.107])
        (using TLSv1.2 with cipher ECDHE-RSA-AES256-GCM-SHA384 (256/256 bits))
        (No client certificate requested)
        by mail.kernel.org (Postfix) with ESMTPSA id BF3F821527;
        Tue,  4 Dec 2018 11:05:09 +0000 (UTC)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/simple; d=kernel.org;
        s=default; t=1543921510;
        bh=3zy4MXkZCPn8Q4g9ttxWKZeDnJp862fE3WJpdM3914I=;
        h=From:To:Cc:Subject:Date:In-Reply-To:References:From;
        b=L+GPuoRFum0l1na5Sjpn3VMdSZWt8P9vy7zXJs55myP16y+bpOSV7sSIaYL23uSKK
         yWDNeRXnn3VfPjL94r6eAJhdEzuJloIy2js3rjoBuB0ktDI01fuYDO0Yh0olAZ+FhE
         XQWcwHX+yvjg6DYoEbdAm786MnZxDso8jq+MRMbc=
From: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
To: linux-kernel@vger.kernel.org
Cc: Greg Kroah-Hartman <gregkh@linuxfoundation.org>,
        stable@vger.kernel.org, Thomas Gleixner <tglx@linutronix.de>,
        Ingo Molnar <mingo@kernel.org>,
        Peter Zijlstra <peterz@infradead.org>,
        Andy Lutomirski <luto@kernel.org>,
        Linus Torvalds <torvalds@linux-foundation.org>,
        Jiri Kosina <jkosina@suse.cz>,
        Tom Lendacky <thomas.lendacky@amd.com>,
        Josh Poimboeuf <jpoimboe@redhat.com>,
        Andrea Arcangeli <aarcange@redhat.com>,
        David Woodhouse <dwmw@amazon.co.uk>,
        Tim Chen <tim.c.chen@linux.intel.com>,
        Andi Kleen <ak@linux.intel.com>,
        Dave Hansen <dave.hansen@intel.com>,
        Casey Schaufler <casey.schaufler@intel.com>,
        Asit Mallick <asit.k.mallick@intel.com>,
        Arjan van de Ven <arjan@linux.intel.com>,
        Jon Masters <jcm@redhat.com>,
        Waiman Long <longman9394@gmail.com>,
        Dave Stewart <david.c.stewart@intel.com>,
        Kees Cook <keescook@chromium.org>
Subject: [PATCH 4.14 098/146] x86/process: Consolidate and simplify switch_to_xtra() code
Date: Tue,  4 Dec 2018 11:49:44 +0100
Message-Id: <20181204103730.767674414@linuxfoundation.org>
X-Mailer: git-send-email 2.19.2
In-Reply-To: <20181204103726.750894136@linuxfoundation.org>
References: <20181204103726.750894136@linuxfoundation.org>
User-Agent: quilt/0.65
X-stable: review
X-Patchwork-Hint: ignore
MIME-Version: 1.0
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: 8bit
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: <linux-kernel.vger.kernel.org>
X-Mailing-List: linux-kernel@vger.kernel.org

4.14-stable review patch.  If anyone has any objections, please let me know.

------------------

From: Thomas Gleixner tglx@linutronix.de

commit ff16701a29cba3aafa0bd1656d766813b2d0a811 upstream

Move the conditional invocation of __switch_to_xtra() into an inline
function so the logic can be shared between 32 and 64 bit.

Remove the handthrough of the TSS pointer and retrieve the pointer directly
in the bitmap handling function. Use this_cpu_ptr() instead of the
per_cpu() indirection.

This is a preparatory change so integration of conditional indirect branch
speculation optimization happens only in one place.

Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
Reviewed-by: Ingo Molnar <mingo@kernel.org>
Cc: Peter Zijlstra <peterz@infradead.org>
Cc: Andy Lutomirski <luto@kernel.org>
Cc: Linus Torvalds <torvalds@linux-foundation.org>
Cc: Jiri Kosina <jkosina@suse.cz>
Cc: Tom Lendacky <thomas.lendacky@amd.com>
Cc: Josh Poimboeuf <jpoimboe@redhat.com>
Cc: Andrea Arcangeli <aarcange@redhat.com>
Cc: David Woodhouse <dwmw@amazon.co.uk>
Cc: Tim Chen <tim.c.chen@linux.intel.com>
Cc: Andi Kleen <ak@linux.intel.com>
Cc: Dave Hansen <dave.hansen@intel.com>
Cc: Casey Schaufler <casey.schaufler@intel.com>
Cc: Asit Mallick <asit.k.mallick@intel.com>
Cc: Arjan van de Ven <arjan@linux.intel.com>
Cc: Jon Masters <jcm@redhat.com>
Cc: Waiman Long <longman9394@gmail.com>
Cc: Greg KH <gregkh@linuxfoundation.org>
Cc: Dave Stewart <david.c.stewart@intel.com>
Cc: Kees Cook <keescook@chromium.org>
Cc: stable@vger.kernel.org
Link: https://lkml.kernel.org/r/20181125185005.280855518@linutronix.de
Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
---
 arch/x86/include/asm/switch_to.h |    3 ---
 arch/x86/kernel/process.c        |   12 +++++++-----
 arch/x86/kernel/process.h        |   24 ++++++++++++++++++++++++
 arch/x86/kernel/process_32.c     |    8 +-------
 arch/x86/kernel/process_64.c     |   10 +++-------
 5 files changed, 35 insertions(+), 22 deletions(-)

--- a/arch/x86/include/asm/switch_to.h
+++ b/arch/x86/include/asm/switch_to.h
@@ -11,9 +11,6 @@ struct task_struct *__switch_to_asm(stru
 
 __visible struct task_struct *__switch_to(struct task_struct *prev,
 					  struct task_struct *next);
-struct tss_struct;
-void __switch_to_xtra(struct task_struct *prev_p, struct task_struct *next_p,
-		      struct tss_struct *tss);
 
 /* This runs runs on the previous thread's stack. */
 static inline void prepare_switch_to(struct task_struct *prev,
--- a/arch/x86/kernel/process.c
+++ b/arch/x86/kernel/process.c
@@ -41,6 +41,8 @@
 #include <asm/prctl.h>
 #include <asm/spec-ctrl.h>
 
+#include "process.h"
+
 /*
  * per-CPU TSS segments. Threads are completely 'soft' on Linux,
  * no more per-task TSS's. The TSS size is kept cacheline-aligned
@@ -255,11 +257,12 @@ void arch_setup_new_exec(void)
 		enable_cpuid();
 }
 
-static inline void switch_to_bitmap(struct tss_struct *tss,
-				    struct thread_struct *prev,
+static inline void switch_to_bitmap(struct thread_struct *prev,
 				    struct thread_struct *next,
 				    unsigned long tifp, unsigned long tifn)
 {
+	struct tss_struct *tss = this_cpu_ptr(&cpu_tss_rw);
+
 	if (tifn & _TIF_IO_BITMAP) {
 		/*
 		 * Copy the relevant range of the IO bitmap.
@@ -451,8 +454,7 @@ void speculation_ctrl_update(unsigned lo
 	preempt_enable();
 }
 
-void __switch_to_xtra(struct task_struct *prev_p, struct task_struct *next_p,
-		      struct tss_struct *tss)
+void __switch_to_xtra(struct task_struct *prev_p, struct task_struct *next_p)
 {
 	struct thread_struct *prev, *next;
 	unsigned long tifp, tifn;
@@ -462,7 +464,7 @@ void __switch_to_xtra(struct task_struct
 
 	tifn = READ_ONCE(task_thread_info(next_p)->flags);
 	tifp = READ_ONCE(task_thread_info(prev_p)->flags);
-	switch_to_bitmap(tss, prev, next, tifp, tifn);
+	switch_to_bitmap(prev, next, tifp, tifn);
 
 	propagate_user_return_notify(prev_p, next_p);
 
--- /dev/null
+++ b/arch/x86/kernel/process.h
@@ -0,0 +1,24 @@
+// SPDX-License-Identifier: GPL-2.0
+//
+// Code shared between 32 and 64 bit
+
+void __switch_to_xtra(struct task_struct *prev_p, struct task_struct *next_p);
+
+/*
+ * This needs to be inline to optimize for the common case where no extra
+ * work needs to be done.
+ */
+static inline void switch_to_extra(struct task_struct *prev,
+				   struct task_struct *next)
+{
+	unsigned long next_tif = task_thread_info(next)->flags;
+	unsigned long prev_tif = task_thread_info(prev)->flags;
+
+	/*
+	 * __switch_to_xtra() handles debug registers, i/o bitmaps,
+	 * speculation mitigations etc.
+	 */
+	if (unlikely(next_tif & _TIF_WORK_CTXSW_NEXT ||
+		     prev_tif & _TIF_WORK_CTXSW_PREV))
+		__switch_to_xtra(prev, next);
+}
--- a/arch/x86/kernel/process_32.c
+++ b/arch/x86/kernel/process_32.c
@@ -234,7 +234,6 @@ __switch_to(struct task_struct *prev_p,
 	struct fpu *prev_fpu = &prev->fpu;
 	struct fpu *next_fpu = &next->fpu;
 	int cpu = smp_processor_id();
-	struct tss_struct *tss = &per_cpu(cpu_tss_rw, cpu);
 
 	/* never put a printk in __switch_to... printk() calls wake_up*() indirectly */
 
@@ -266,12 +265,7 @@ __switch_to(struct task_struct *prev_p,
 	if (get_kernel_rpl() && unlikely(prev->iopl != next->iopl))
 		set_iopl_mask(next->iopl);
 
-	/*
-	 * Now maybe handle debug registers and/or IO bitmaps
-	 */
-	if (unlikely(task_thread_info(prev_p)->flags & _TIF_WORK_CTXSW_PREV ||
-		     task_thread_info(next_p)->flags & _TIF_WORK_CTXSW_NEXT))
-		__switch_to_xtra(prev_p, next_p, tss);
+	switch_to_extra(prev_p, next_p);
 
 	/*
 	 * Leave lazy mode, flushing any hypercalls made here.
--- a/arch/x86/kernel/process_64.c
+++ b/arch/x86/kernel/process_64.c
@@ -59,6 +59,8 @@
 #include <asm/unistd_32_ia32.h>
 #endif
 
+#include "process.h"
+
 __visible DEFINE_PER_CPU(unsigned long, rsp_scratch);
 
 /* Prints also some state that isn't saved in the pt_regs */
@@ -400,7 +402,6 @@ __switch_to(struct task_struct *prev_p,
 	struct fpu *prev_fpu = &prev->fpu;
 	struct fpu *next_fpu = &next->fpu;
 	int cpu = smp_processor_id();
-	struct tss_struct *tss = &per_cpu(cpu_tss_rw, cpu);
 
 	WARN_ON_ONCE(IS_ENABLED(CONFIG_DEBUG_ENTRY) &&
 		     this_cpu_read(irq_count) != -1);
@@ -467,12 +468,7 @@ __switch_to(struct task_struct *prev_p,
 	/* Reload sp0. */
 	update_sp0(next_p);
 
-	/*
-	 * Now maybe reload the debug registers and handle I/O bitmaps
-	 */
-	if (unlikely(task_thread_info(next_p)->flags & _TIF_WORK_CTXSW_NEXT ||
-		     task_thread_info(prev_p)->flags & _TIF_WORK_CTXSW_PREV))
-		__switch_to_xtra(prev_p, next_p, tss);
+	__switch_to_xtra(prev_p, next_p);
 
 #ifdef CONFIG_XEN_PV
 	/*


