Return-Path: <linux-kernel-owner@vger.kernel.org>
Delivered-To: unknown
Received: from linux.intel.com (10.54.29.200:995) by likexu-workstation with
  POP3-SSL; 05 Dec 2018 09:04:56 -0000
X-Original-To: like.xu@linux.intel.com
Delivered-To: like.xu@linux.intel.com
Received: from orsmga008.jf.intel.com (orsmga008.jf.intel.com [10.7.209.65])
	(using TLSv1.2 with cipher ECDHE-RSA-AES256-GCM-SHA384 (256/256 bits))
	(No client certificate requested)
	by linux.intel.com (Postfix) with ESMTPS id 552CC58014B;
	Tue,  4 Dec 2018 17:00:04 -0800 (PST)
Received: from fmsmga103.fm.intel.com ([10.1.193.90])
  by orsmga008-1.jf.intel.com with ESMTP/TLS/DHE-RSA-AES256-GCM-SHA384; 04 Dec 2018 17:00:04 -0800
X-SG-BADATTACHMENTNOREPLY: True
IronPort-PHdr: =?us-ascii?q?9a23=3AE2LrLR9vrNv7nP9uRHKM819IXTAuvvDOBiVQ1KB9?=
 =?us-ascii?q?1u0TIJqq85mqBkHD//Il1AaPAd2Lraocw8Pt8InYEVQa5piAtH1QOLdtbDQizf?=
 =?us-ascii?q?ssogo7HcSeAlf6JvO5JwYzHcBFSUM3tyrjaRsdF8nxfUDdrWOv5jAOBBr/KRB1?=
 =?us-ascii?q?JuPoEYLOksi7ze+/94HQbglSmDaxfa55IQmrownWqsQYm5ZpJLwryhvOrHtIeu?=
 =?us-ascii?q?BWyn1tKFmOgRvy5dq+8YB6/ShItP0v68BPUaPhf6QlVrNYFygpM3o05MLwqxbO?=
 =?us-ascii?q?SxaE62YGXWUXlhpIBBXF7A3/U5zsvCb2qvZx1S+HNsDtU7s6RSqt4LtqSB/wiS?=
 =?us-ascii?q?cIKTg58H3MisdtiK5XuQ+tqwBjz4LRZoyeKfhwcb7Hfd4CWGRPQMhRWSxCDI2y?=
 =?us-ascii?q?YYQAAOgOPedEoIfyvFsOtRmzCBKwBO7t0DJEmmP60KM43uknDArI3BYgH9ULsH?=
 =?us-ascii?q?nMqNv1M6cSUeaox6fK0DXMdOhZ1i3n6IfVbxsspvOMXbJtccXK0kYgDRnFgUiL?=
 =?us-ascii?q?pIzjITOV1/kCs2mB4OZ6Se2vjGsnphh3rzOyyMksjYzJiZgUylDC7Sh5w5g6Jc?=
 =?us-ascii?q?e+SEFlZd6oCpxQtzuVN4duRsMjTWdotDw8yrIYpZ62ejUBxpc/xxPHdfCLb4yF?=
 =?us-ascii?q?7gj+WOufPzt0nm9pdbGjixqo8EWtyPXwWtSo3FpQsyZJjNbBumoQ2xDJ6sWLUu?=
 =?us-ascii?q?Vx8lqg1DqVyQzf9OJJLVopmabFNpIt2L89m5UVvE/eBCH5gl/2g7WTdkg8+uin?=
 =?us-ascii?q?9eDnYrL+q5+COI97lBv+Pr4tmsOhG+Q4NBYBX2yB9eS7zr3j8lX1QLRMjvIojq?=
 =?us-ascii?q?nUqI7WKdgfq6KjHgNY3Jgv5wyiAzqlzNgUh3gKIVBddBKClYfpOlXOIP7iDfe4?=
 =?us-ascii?q?hlShiDNrx/HAPr38DZTBN3vDn6n7fbZ79UFczBM/zddR5pJSFL4BOun+WlH+tN?=
 =?us-ascii?q?PGFB81KQ+0zPj9CNV7yIweXXiDAqiDMKPdqVOI/P4gI/GQZI8JvzbwM/wl5//t?=
 =?us-ascii?q?jXAng1MccrSp0IATaHC5GPRmPkqYbWDtgtcHDWcFoA4+QPb2h12FVD5Zf2yyUL?=
 =?us-ascii?q?4k5jEnFIKmCp/ORoC3j7yAwCe0BJpWanpGClCRC3jocYqEVuwIaCKTJM9hjzMF?=
 =?us-ascii?q?WaKgS48nyRGhqgv6x6B7IerT/y0SrYjj28Rt5+3PiREy8iR5D8aa026TVW10nW?=
 =?us-ascii?q?QIRzkw3KB4ukF9zlaD0a5lg/1XD9BT5vVJUhskOp7Y1eB1F9fyWgfZdNeTVFmm?=
 =?us-ascii?q?WsmmAS02Tt8p2dAOeEZ9G9KhjhzZxSqlGb0VmqePBJw19KLcwnfwK9x8y3bAyK?=
 =?us-ascii?q?kukV0mTtFTOm2hg6517xLTCJLRk0WFi6aqcrwR3C3X+2eF12aOuEBYXxR2UaXK?=
 =?us-ascii?q?Rn0fYkrWrdLk5kLNVbOuCLInMhdfxs6GMKdFdtrpjVBeTvf5JNvee36xm3u3BR?=
 =?us-ascii?q?uQ27yDdpTqdHsH0CXdEkcElRsT8miANQQ5AiehoGfeDDh1GFLrYkPs9/R+qXyh?=
 =?us-ascii?q?Qk81yQGKc1Nu176v9hEJgvycTusZ3qgYtyc5tzV0AFG90srLBNWauQpuYr9QYd?=
 =?us-ascii?q?Mn71dBzmLWqQp9M4ekL6BjgF4ebgt2s1nv1xVxFoVPj8wqoGk2wwp1LKKSyElB?=
 =?us-ascii?q?eC+A3ZDsJr3XLXH//Ayua67T3VHezNaW+6cV5PQksVnjuxupFk4j83Vh3NlYyH?=
 =?us-ascii?q?+c5pTMDAoPXpP9SEc39x5mp77EZikx/Z/b1XppMaOsqD/Nx8opBPc5yhanZ9pQ?=
 =?us-ascii?q?KqeEGxH9EsIEB8miMvclm0W0YR0eOuBS96k0P929evuC2a6rOvtgnT28gWRG5o?=
 =?us-ascii?q?B9zlyD9y5mRuHU2JYFxumS3hGbWDfkkFehrsf3lJhEZDEPBGaw1TLoBY9RZqJo?=
 =?us-ascii?q?e4YLBnyjI8m2xtV4mp7sVGRU9F+lB1MaxsCpfQCeYED63Q1VzU4Xu2ComTOkzz?=
 =?us-ascii?q?xolDEktrCf3C3SzOv4bhoIJ2lLSHNkjVjyO4i0jskWU1SyYAgtiRSq+1z6x69d?=
 =?us-ascii?q?pKlkK2nTQEFIfzX5Lm14U6uwsKaCbNBL6J8yrSpXV+G8a0iASrHhuxsazz/jH2?=
 =?us-ascii?q?xGyTE7djGmoJX4kwZhiGKAKnZ+t37ZecB2xRfC693QX/9R3jwaRCZmjTnbHESz?=
 =?us-ascii?q?P96s/d+MjZfMrvi+V369Vp1UaSTrz5mPtDG45W1pBh2zheuzlcfkEQg50C/70c?=
 =?us-ascii?q?dlVSPToRb4Y4nr0bm6MO19cklpAl/899R1GoVknoQsg5EQ3GAQho+J8nofjWfz?=
 =?us-ascii?q?LdJb1Lr+bXUXQj4H2dzV4Anj2EB4KnKJxoT5VmiSw8d7Ztm6ZH8W1Tw578xQFK?=
 =?us-ascii?q?iU67lElzNvolWktQLRfeR9njAFxPst8nEagvsFuAowziqHBLASElJVPSjtlxSO?=
 =?us-ascii?q?8tC/o79bZGepcbisykV+mcqtA62FogFZQHz5YIstHTds7sVjN1LByHjz6oDneN?=
 =?us-ascii?q?bKd94SuAObkwzcj+dLMpI+jeQFhTBoOW/muX0lyug7jQFh3J2gvYiHLXlt87y9?=
 =?us-ascii?q?AhJCKjL1YMYT8Cn3jalChsaWw5yvHpJ5FzUXW5voSOikETMIuvThKgaOCyY8qn?=
 =?us-ascii?q?aAFLrbHA+f7lpmrn3VH5CqMXGXOGcWzdF4SBaBI0xfhRgeXC8mkZ4hCgCq2Mvh?=
 =?us-ascii?q?fV9i6T8L4V74rgZMxvhsNxniSWrfoAaoajEpSJmQNhZW7wdC51vLPsya9O58Ay?=
 =?us-ascii?q?ZY/pi5pgyXNmObfxhIDX0OWkGcBVDsJLyu6sfb8+SCGuqyNfjOYaiNqexDUfeH?=
 =?us-ascii?q?34mv35Bi/zaNMMWPI3ZjA+c62kpFQXB2BcDZly8TRCwQkiLHd9Sbqwuk+i1rss?=
 =?us-ascii?q?C/9+zmWQLo5YuSErtSLM9g+xasjaeYMO6Qgil5JC1c1pMNw3/I1bce0EQTiyFo?=
 =?us-ascii?q?azmiD7AAuTTRQ6LXn69dFwQbZD9rNMtU86I82RFAOc7FhdP01b54jf81B01GVV?=
 =?us-ascii?q?z7ncGpatIFI3ugNFPcH0uLMLWGJTvWw8D4e6+8SLtQjPlKuB20ozqUD0jjPjGb?=
 =?us-ascii?q?nTnzSx+vKf1MjD2cPBFGoo69bw1iCXL9Q9PmcBG7NN53gCYywb01gHPKKGEdPS?=
 =?us-ascii?q?J9c0NLsr2f8ydYju9jFGxG63pvNfOElDqB7+nENpYWtuNmAjh1l+Jf+ng116FZ?=
 =?us-ascii?q?4z1ERPNrnivftdpuo1CgkumSxTtrShtOqjBXhI2VuUVuI7nW9p5FWXzc5hIC8X?=
 =?us-ascii?q?2QCwgWp9tiEtDuu7pfyt7KlKLyLjdN69PV/csGCMjSJ8KKK34hMRvvGD7JAwoJ?=
 =?us-ascii?q?Vz+rNWfDh0NDlPGe7GGarp8/qsukpJ1bZrZdHGM0EvcbA0F+VIgOKZExXHU7kL?=
 =?us-ascii?q?qfjccN/lK/qgXcQINRuZWRErqwgO9zLTvRor1FfAAFief6IoASLZb281ZvZllz?=
 =?us-ascii?q?gMLBHE+GDv5XpSg0TAg0pg1t7XJ0R3c/kxbnah6n6nYJGdaygB86iwI4auMoom?=
 =?us-ascii?q?S/q2wrL0bH8XNj2HI6ns/o1HXIKGb8?=
X-IronPort-Anti-Spam-Filtered: true
X-IronPort-Anti-Spam-Result: =?us-ascii?q?A0AhAAAYIgdch0O0hNFcCBoBAQEBAQIBA?=
 =?us-ascii?q?QEBBwIBAQEBgWWBW4EPgQInCoNvlCeBYC0UiH6QKhQYCwgBh0wiOBIBAwEBAQE?=
 =?us-ascii?q?BAQIBEwEBAQgNCQgpIwyCNiQBgmEBAQEBAgEBAiAdAQEmEQEFCQEBChUDAgImA?=
 =?us-ascii?q?gIDHiYQBgEMAQUCAQEBglFLAYFpAw0IBQqkJnCBL4J2AQEFgTABCwGBBoJEDYI?=
 =?us-ascii?q?UAwWBC4l3gRwXgUA/gTiCNjWCV0cBA4E6gymCV4khDoFzhFg2j2wuCYcDhxCDK?=
 =?us-ascii?q?AYYgVuIEIc7LIhagQODZYEMiXyBXYF2MxoIGxWDJxMMgXyDbYRZO4VgHwExAQG?=
 =?us-ascii?q?BAwEBiFcrgQGBHwEB?=
X-IPAS-Result: =?us-ascii?q?A0AhAAAYIgdch0O0hNFcCBoBAQEBAQIBAQEBBwIBAQEBgWW?=
 =?us-ascii?q?BW4EPgQInCoNvlCeBYC0UiH6QKhQYCwgBh0wiOBIBAwEBAQEBAQIBEwEBAQgNC?=
 =?us-ascii?q?QgpIwyCNiQBgmEBAQEBAgEBAiAdAQEmEQEFCQEBChUDAgImAgIDHiYQBgEMAQU?=
 =?us-ascii?q?CAQEBglFLAYFpAw0IBQqkJnCBL4J2AQEFgTABCwGBBoJEDYIUAwWBC4l3gRwXg?=
 =?us-ascii?q?UA/gTiCNjWCV0cBA4E6gymCV4khDoFzhFg2j2wuCYcDhxCDKAYYgVuIEIc7LIh?=
 =?us-ascii?q?agQODZYEMiXyBXYF2MxoIGxWDJxMMgXyDbYRZO4VgHwExAQGBAwEBiFcrgQGBH?=
 =?us-ascii?q?wEB?=
X-IronPort-AV: E=Sophos;i="5.56,316,1539673200"; 
   d="scan'208";a="54557421"
X-Amp-Result: SKIPPED(no attachment in message)
X-Amp-File-Uploaded: False
Received: from vger.kernel.org ([209.132.180.67])
  by mtab.intel.com with ESMTP; 04 Dec 2018 17:00:01 -0800
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
        id S1726702AbeLEA76 (ORCPT <rfc822;like.xu@linux.intel.com>
        + 23 others); Tue, 4 Dec 2018 19:59:58 -0500
Received: from hqemgate15.nvidia.com ([216.228.121.64]:18795 "EHLO
        hqemgate15.nvidia.com" rhost-flags-OK-OK-OK-OK) by vger.kernel.org
        with ESMTP id S1725905AbeLEA76 (ORCPT
        <rfc822;linux-kernel@vger.kernel.org>);
        Tue, 4 Dec 2018 19:59:58 -0500
Received: from hqpgpgate101.nvidia.com (Not Verified[216.228.121.13]) by hqemgate15.nvidia.com (using TLS: TLSv1.2, DES-CBC3-SHA)
        id <B5c0723090001>; Tue, 04 Dec 2018 16:59:53 -0800
Received: from hqmail.nvidia.com ([172.20.161.6])
  by hqpgpgate101.nvidia.com (PGP Universal service);
  Tue, 04 Dec 2018 16:59:56 -0800
X-PGP-Universal: processed;
        by hqpgpgate101.nvidia.com on Tue, 04 Dec 2018 16:59:56 -0800
Received: from [10.110.48.28] (10.124.1.5) by HQMAIL101.nvidia.com
 (172.20.187.10) with Microsoft SMTP Server (TLS) id 15.0.1395.4; Wed, 5 Dec
 2018 00:59:55 +0000
Subject: Re: [PATCH 1/2] mm: introduce put_user_page*(), placeholder versions
To: Dan Williams <dan.j.williams@intel.com>,
        =?UTF-8?B?SsOpcsO0bWUgR2xpc3Nl?= <jglisse@redhat.com>
CC: John Hubbard <john.hubbard@gmail.com>,
        Andrew Morton <akpm@linux-foundation.org>,
        Linux MM <linux-mm@kvack.org>, Jan Kara <jack@suse.cz>,
        <tom@talpey.com>, Al Viro <viro@zeniv.linux.org.uk>,
        <benve@cisco.com>, Christoph Hellwig <hch@infradead.org>,
        Christopher Lameter <cl@linux.com>,
        "Dalessandro, Dennis" <dennis.dalessandro@intel.com>,
        Doug Ledford <dledford@redhat.com>,
        Jason Gunthorpe <jgg@ziepe.ca>,
        Matthew Wilcox <willy@infradead.org>,
        Michal Hocko <mhocko@kernel.org>, <mike.marciniszyn@intel.com>,
        <rcampbell@nvidia.com>,
        Linux Kernel Mailing List <linux-kernel@vger.kernel.org>,
        linux-fsdevel <linux-fsdevel@vger.kernel.org>
References: <20181204001720.26138-1-jhubbard@nvidia.com>
 <20181204001720.26138-2-jhubbard@nvidia.com>
 <CAPcyv4h99JVHAS7Q7k3iPPUq+oc1NxHdyBHMjpgyesF1EjVfWA@mail.gmail.com>
 <a0adcf7c-5592-f003-abc5-a2645eb1d5df@nvidia.com>
 <CAPcyv4iNtamDAY9raab=iXhSZByecedBpnGybjLM+PuDMwq7SQ@mail.gmail.com>
 <20181205003648.GT2937@redhat.com>
 <CAPcyv4hhkB09eBzPErVntZrNYE0RP5+6Z6+sP0kq6ng9ZOzTfg@mail.gmail.com>
X-Nvconfidentiality: public
From: John Hubbard <jhubbard@nvidia.com>
Message-ID: <6455f657-708d-5b7f-00bf-89ca8a226c8e@nvidia.com>
Date: Tue, 4 Dec 2018 16:59:55 -0800
User-Agent: Mozilla/5.0 (X11; Linux x86_64; rv:60.0) Gecko/20100101
 Thunderbird/60.3.2
MIME-Version: 1.0
In-Reply-To: <CAPcyv4hhkB09eBzPErVntZrNYE0RP5+6Z6+sP0kq6ng9ZOzTfg@mail.gmail.com>
X-Originating-IP: [10.124.1.5]
X-ClientProxiedBy: HQMAIL108.nvidia.com (172.18.146.13) To
 HQMAIL101.nvidia.com (172.20.187.10)
Content-Type: text/plain; charset="utf-8"
Content-Language: en-US-large
Content-Transfer-Encoding: 7bit
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed; d=nvidia.com; s=n1;
        t=1543971593; bh=8QJN4s9oL68HqMKTn7Fdg7/S8pnuk2TmHNx0aEohZc0=;
        h=X-PGP-Universal:Subject:To:CC:References:X-Nvconfidentiality:From:
         Message-ID:Date:User-Agent:MIME-Version:In-Reply-To:
         X-Originating-IP:X-ClientProxiedBy:Content-Type:Content-Language:
         Content-Transfer-Encoding;
        b=i5k306EhJGFbOsJy4Z5+5xINWh4dM/CeqifwCgg4ekiDtFLCAqDMrgiuX6azXO8WZ
         Lz4iGJHh3tMVDEWCbmtoJfxx91hoZ+vQsBNYw4hETQJpOVhJ6rmoL4BpZg23fW0yVZ
         KLPOs2ZblLq3MFX++oA1SUL34RWKzcA3Rv0vBiALK4EfjGVAoFrDoQg28nLDjaZ9Bo
         yXVT24TRcdBdiNNtHKMFSi6IRP51gKHrKJ5kr4yB8QgXxL0FtCR2C2g4B0if05utTQ
         Xm6XFI+h5cYqEFLSxbm8MSzLtIGhOMpDPe2MA+pOvY1Z31cF3Wslnj3QaWM52WHWxC
         Qb6hwHLvLtRDA==
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: <linux-kernel.vger.kernel.org>
X-Mailing-List: linux-kernel@vger.kernel.org

On 12/4/18 4:40 PM, Dan Williams wrote:
> On Tue, Dec 4, 2018 at 4:37 PM Jerome Glisse <jglisse@redhat.com> wrote:
>>
>> On Tue, Dec 04, 2018 at 03:03:02PM -0800, Dan Williams wrote:
>>> On Tue, Dec 4, 2018 at 1:56 PM John Hubbard <jhubbard@nvidia.com> wrote:
>>>>
>>>> On 12/4/18 12:28 PM, Dan Williams wrote:
>>>>> On Mon, Dec 3, 2018 at 4:17 PM <john.hubbard@gmail.com> wrote:
>>>>>>
>>>>>> From: John Hubbard <jhubbard@nvidia.com>
>>>>>>
>>>>>> Introduces put_user_page(), which simply calls put_page().
>>>>>> This provides a way to update all get_user_pages*() callers,
>>>>>> so that they call put_user_page(), instead of put_page().
>>>>>>
>>>>>> Also introduces put_user_pages(), and a few dirty/locked variations,
>>>>>> as a replacement for release_pages(), and also as a replacement
>>>>>> for open-coded loops that release multiple pages.
>>>>>> These may be used for subsequent performance improvements,
>>>>>> via batching of pages to be released.
>>>>>>
>>>>>> This is the first step of fixing the problem described in [1]. The steps
>>>>>> are:
>>>>>>
>>>>>> 1) (This patch): provide put_user_page*() routines, intended to be used
>>>>>>    for releasing pages that were pinned via get_user_pages*().
>>>>>>
>>>>>> 2) Convert all of the call sites for get_user_pages*(), to
>>>>>>    invoke put_user_page*(), instead of put_page(). This involves dozens of
>>>>>>    call sites, and will take some time.
>>>>>>
>>>>>> 3) After (2) is complete, use get_user_pages*() and put_user_page*() to
>>>>>>    implement tracking of these pages. This tracking will be separate from
>>>>>>    the existing struct page refcounting.
>>>>>>
>>>>>> 4) Use the tracking and identification of these pages, to implement
>>>>>>    special handling (especially in writeback paths) when the pages are
>>>>>>    backed by a filesystem. Again, [1] provides details as to why that is
>>>>>>    desirable.
>>>>>
>>>>> I thought at Plumbers we talked about using a page bit to tag pages
>>>>> that have had their reference count elevated by get_user_pages()? That
>>>>> way there is no need to distinguish put_page() from put_user_page() it
>>>>> just happens internally to put_page(). At the conference Matthew was
>>>>> offering to free up a page bit for this purpose.
>>>>>
>>>>
>>>> ...but then, upon further discussion in that same session, we realized that
>>>> that doesn't help. You need a reference count. Otherwise a random put_page
>>>> could affect your dma-pinned pages, etc, etc.
>>>
>>> Ok, sorry, I mis-remembered. So, you're effectively trying to capture
>>> the end of the page pin event separate from the final 'put' of the
>>> page? Makes sense.
>>>
>>>> I was not able to actually find any place where a single additional page
>>>> bit would help our situation, which is why this still uses LRU fields for
>>>> both the two bits required (the RFC [1] still applies), and the dma_pinned_count.
>>>
>>> Except the LRU fields are already in use for ZONE_DEVICE pages... how
>>> does this proposal interact with those?
>>>
>>>> [1] https://lore.kernel.org/r/20181110085041.10071-7-jhubbard@nvidia.com
>>>>
>>>>>> [1] https://lwn.net/Articles/753027/ : "The Trouble with get_user_pages()"
>>>>>>
>>>>>> Reviewed-by: Jan Kara <jack@suse.cz>
>>>>>
>>>>> Wish, you could have been there Jan. I'm missing why it's safe to
>>>>> assume that a single put_user_page() is paired with a get_user_page()?
>>>>>
>>>>
>>>> A put_user_page() per page, or a put_user_pages() for an array of pages. See
>>>> patch 0002 for several examples.
>>>
>>> Yes, however I was more concerned about validation and trying to
>>> locate missed places where put_page() is used instead of
>>> put_user_page().
>>>
>>> It would be interesting to see if we could have a debug mode where
>>> get_user_pages() returned dynamically allocated pages from a known
>>> address range and catch drivers that operate on a user-pinned page
>>> without using the proper helper to 'put' it. I think we might also
>>> need a ref_user_page() for drivers that may do their own get_page()
>>> and expect the dma_pinned_count to also increase.

Good idea about a new ref_user_page() call. It's going to hard to find 
those places at all of the call sites, btw.

>>
>> Total crazy idea for this, but this is the right time of day
>> for this (for me at least it is beer time :)) What about mapping
>> all struct page in two different range of kernel virtual address
>> and when get user space is use it returns a pointer from the second
>> range of kernel virtual address to the struct page. Then in put_page
>> you know for sure if the code putting the page got it from GUP or
>> from somewhere else. page_to_pfn() would need some trickery to
>> handle that.
> 
> Yes, exactly what I was thinking, if only as a debug mode since
> instrumenting every pfn/page translation would be expensive.
> 

That does sound viable as a debug mode. I'll try it out. A reliable way
(in both directions) of sorting out put_page() vs. put_user_page() 
would be a huge improvement, even if just in debug mode.

>> Dunno if we are running out of kernel virtual address (outside
>> 32bits that i believe we are trying to shot down quietly behind
>> the bar).
> 
> There's room, KASAN is in a roughly similar place.
> 

Looks like I'd better post a new version of the entire RFC, rather than just
these two patches. It's still less fully-baked than I'd hoped. :)

thanks,
-- 
John Hubbard
NVIDIA
