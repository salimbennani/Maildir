Return-Path: <linux-kernel-owner@vger.kernel.org>
Delivered-To: unknown
Received: from linux.intel.com (10.54.29.200:995) by i7-8700 with POP3-SSL;
  13 Dec 2018 08:54:37 -0000
X-Original-To: like.xu@linux.intel.com
Delivered-To: like.xu@linux.intel.com
Received: from orsmga003.jf.intel.com (orsmga003.jf.intel.com [10.7.209.27])
	(using TLSv1.2 with cipher ECDHE-RSA-AES256-GCM-SHA384 (256/256 bits))
	(No client certificate requested)
	by linux.intel.com (Postfix) with ESMTPS id C5D2658079D;
	Wed, 12 Dec 2018 11:08:04 -0800 (PST)
Received: from orsmga102-1.jf.intel.com (HELO mga09.intel.com) ([10.7.208.27])
  by orsmga003-1.jf.intel.com with ESMTP; 12 Dec 2018 11:08:04 -0800
X-SG-BADATTACHMENTNOREPLY: True
IronPort-PHdr: =?us-ascii?q?9a23=3AbLCXKxWAadhMqhTXCitK2tuqZvbV8LGtZVwlr6E/?=
 =?us-ascii?q?grcLSJyIuqrYZhGFuKdThVPEFb/W9+hDw7KP9fy4CSpYud6oizMrSNR0TRgLiM?=
 =?us-ascii?q?EbzUQLIfWuLgnFFsPsdDEwB89YVVVorDmROElRH9viNRWJ+iXhpTEdFQ/iOgVr?=
 =?us-ascii?q?O+/7BpDdj9it1+C15pbffxhEiCCybL9uLxi6txndutULioZ+N6g9zQfErGFVcO?=
 =?us-ascii?q?pM32NoIlyTnxf45siu+ZNo7jpdtfE8+cNeSKv2Z6s3Q6BWAzQgKGA1+dbktQLf?=
 =?us-ascii?q?QguV53sTSXsZnxxVCAXY9h76X5Pxsizntuph3SSRIMP7QawoVTmk8qxmUwHjhj?=
 =?us-ascii?q?sZODEl8WHXks1wg7xdoBK9vBx03orYbJiIOPZiYq/ReNUXTndDUMlMTSxMGp6y?=
 =?us-ascii?q?YZUBD+QBPuhWoYfyqFQMohu/GQaiC/jvyidKi3Ltwa06yv4sHR3a0AEuHd8Dtm?=
 =?us-ascii?q?nfotXvNKcVVOC41K3GzTLDb/NQxDzz6pXIfQs6rv6WR7J/bNfaxE4tFwPFk1Wf?=
 =?us-ascii?q?spfqMCmP1usQqGWb6fRgVeOyhG4msQ59uCSgxsApioTQgI8e11PK9T1hzYorOd?=
 =?us-ascii?q?G1TFR3bcOqHZdOrS2WKoh7Tt84T2xpuis20qAKtJylcCQQ1pgr2wTTZ+GJfoSS?=
 =?us-ascii?q?7B/uUP6dLSlliH9kYr6zmQi+/Eu6xuHhSMW4zUxGoytKn9TKq3sDzQbc6tKdRf?=
 =?us-ascii?q?t45kqh2SiA1wTU6uxcP0A0mrTUK4Q7zr4ziJUTq0LDETHymEnsi6+WbEok9vCp?=
 =?us-ascii?q?6+ThfLrmuoeRO5Fohgz6KKgih8KyDfoiPgQTXGWX5f6w2bzh8EHhRbVFlPw2kq?=
 =?us-ascii?q?3XsJDAIsQbo7a0AwtU0oYl9ha+AC6q0NcGknkdKlJKZhaHg5HuO1DAJvD3E+2/?=
 =?us-ascii?q?jk+ykDdk2f/GJKftApbTIXjZlrfuY7J951RbyAopwtBT/4hUBa0ZIPLvRk/xs8?=
 =?us-ascii?q?TVDhs4Mwy33enrEtp81p4FVGKLA6+ZNr7SsFCS6uIuJemMeJEauDLnJ/c54P7u?=
 =?us-ascii?q?iGczmUUBcqmxwZsXdHe4E+xmI0qDYHrsns0OEWAQsgo+UezlkluCUTFIana2Xq?=
 =?us-ascii?q?I84Cw7CY28AYfCQICtnKKO3COhEpJKYWBGD0iGEW30eIWcR/cMdCWSL9djkjwD?=
 =?us-ascii?q?S7etUYwh1RaotA/8zLpqNe7U+iwetZL+29l5/ezTlRcu9TNqC8SRyX2CT2Zxnm?=
 =?us-ascii?q?kQXT85wLh/oVBhyleEyaV3medYFdxU5/NKSAs6L4TTz+5hBtD2WwLBeMqJSVm8?=
 =?us-ascii?q?TtWnBzExUsw+w9sUb0lhHNWiiwjJ3zC2DL8Ni7yLGJs0/7rf33frIcZx0XLG1K?=
 =?us-ascii?q?g7gFkgTctCLmmmhq959wjOCI/FiUSZl6C2dasC2C7B7nuMzW2LvEtASg5/Tb3F?=
 =?us-ascii?q?XWwDZkvRtdn2+1nNT6GwBrg9MgtO08iCKrBUZd3villGQPTjONHaY2+qn2ewBB?=
 =?us-ascii?q?CIxq6DbYbwemUd2jndB1YAkwwJ4XmGMg0+DD+7o23CFDxuCU7vY0T0/OZjsny7?=
 =?us-ascii?q?UFE7wxuKb0J70bq14QAahfqHRvMX37IEvjohqjpuEFa82dLWF8SPpw57cKpAZt?=
 =?us-ascii?q?M95U9N1XjFuAxlIpygM6dii0YCcwR2ukPu0Al3CoVAkMQwsHMm1g1yKbic0FNA?=
 =?us-ascii?q?cTOY0ov9OrnWKmn04RCuZLTa2lDY0NaK5KgP7O40pEnkvAGsDkAi6Wlo08FJ03?=
 =?us-ascii?q?uA4ZXHFBAdUZbvXUc46Rd7p6vWbTIg54zJz3JsN6q0sjjc298yAOslyxCgf8pQ?=
 =?us-ascii?q?Ma+eFQ/yFdEaCNaqKOAwh1epaRcENvhI9KEoJ8Oma+eG2KmzMedggTKql3hI7J?=
 =?us-ascii?q?p800KM7SV8TOHI0o0Bw/GZ2AuHSjj9gE2gssDxhYBLezUSEnCjxijjAY5bfrdy?=
 =?us-ascii?q?cpoTCWeyP823wc1zh4TsW3FE7lGjHU4J2MizdRqUcVP9xwxQ2V0LrnO9nSu30i?=
 =?us-ascii?q?J7kysurqqZxyHOx+XidBwaOm9EXmVijFHsIZSqgNAeRkSncw8plB6970bg26db?=
 =?us-ascii?q?vLh/L3XUQUpQfyn2LntuU6uqurqZfs5P7oglsSFWUOS6fFCbRaTxoxoc0yP/AW?=
 =?us-ascii?q?RewCo3eC2tupX8hxZ6kn6SLG5vrHrFfsF93RXf68bGRf5S3ToGQzN0iSLNCVi/?=
 =?us-ascii?q?PNmp/NOUmInFsu2lU2KhV5tTcTTkzI+atSu743FqDgO7n/yphtLnFg062zfh19?=
 =?us-ascii?q?Z2TSXIsAr8Yo7z2qW6K+1neVNkBF3968p8AYx+loowhJcN2XkVnJmV/HwHkXvt?=
 =?us-ascii?q?PtVfw67xcH0NRTsTyd7P/AflwFFjLm6Ox4/hVXWS2Mpha8O6YmMLwC096c9KBb?=
 =?us-ascii?q?yQ7LxFmyt1v1W5oRjQYfh7gjcS1/8u5GQGjOEOvQon1j+dDawKHUlEISzskAyF?=
 =?us-ascii?q?79W/rKVUfmmja7ax21RlndC9Er6CuBpTV2jjepctBiJw6sR/MFTR0Hz88I3ked?=
 =?us-ascii?q?/Qbc4NuR2QiRvPk+9VKJcpnPoQmSVnIX79vWEiy+MjkRxu2pS6sJKGKmp3+qK5?=
 =?us-ascii?q?HwVYNib0Z84I/jHtjKBentuZ3oy1H5VhHCkLU4XsTf6yDD0SsvHnPR6UEDIgsn?=
 =?us-ascii?q?ebBabfHQiH5Uh9tX3PFJSrN2yNKHkd0NVvXx2dJE1ZgAAJUzQ2hJ85Fga2xMP/?=
 =?us-ascii?q?dEd1/Cwe5ln9qhFU0OJnKwH/UnvDpAevcjo0SoKQLB9I4QFZ/UvVLdaS7uFuHy?=
 =?us-ascii?q?Fb452hqhaCKneAagRMDGEJXFGEBl/5Mrmv49nA7/aXBu6kI/TSZrWOrPRUV+2U?=
 =?us-ascii?q?ypK3zotm4zGMO92PP3llEv07w1dDUmp/G8jDgDUPTCoXly3WYs6fpRe8/DB3r8?=
 =?us-ascii?q?+l/PTqXgLv+ZWAC79IPdpz/BC2hL+JN/SMiyZhNTZYypQMyGfIyLcB3V4SiCJu?=
 =?us-ascii?q?dzi3HbQDry7NS63QlbFNDx4GcCN+L89I76M63glQNs/XkNL11rhkjvErD1dJT0?=
 =?us-ascii?q?DumsasZcYSOWGyKEvHBFqXNLSBPTDE2dz3brimSbJOjORYrRmwuTeAHk/nPzSD?=
 =?us-ascii?q?kSTpVh+1PeFNiiGbIAJRuIWnfhlxDmjjScrsagenP99vkT023bo0i2vWNW4dND?=
 =?us-ascii?q?hwaV9CoqeM4iNYnPp/HXdM7n5kLemChiaY4PPUKpcQsft3HCt0k/hW72g9y7tQ?=
 =?us-ascii?q?9CtEXuB6mDPOrt5ypFGriumOxSBhUBpLqzZLgpqEvERiOarD8JlAVm3J/BYM7W?=
 =?us-ascii?q?WWFhQLqMFpCtzpu6BM1NfPkLj/JytF89LRroMgAJ34IcTPD3slNRvgHSWcWAcM?=
 =?us-ascii?q?S3ipc37eg0hcmfSJ3nyTspU+7JPrncxKAp3aTsAwG7s1DkV+B9FKdJV4WjI/ir?=
 =?us-ascii?q?OzlsME5XOi6hLWQZMJkIrAU6ewBvXpYBaEh7NNfRdAlbH4MI4ZP5f380p8a1V7?=
 =?us-ascii?q?lcLBHE+GDoMFmTFocgJh+BYFy3N5VGBmnhu9Mg4=3D?=
X-IronPort-Anti-Spam-Filtered: true
X-IronPort-Anti-Spam-Result: =?us-ascii?q?A0ADAADmWxFch0O0hNFkGgEBAQEBAgEBA?=
 =?us-ascii?q?QEHAgEBAQGBUwMBAQEBCwGDaycKg3KUKoFgLRSXP4FzFBgTAYRAgn4iNgcNAQM?=
 =?us-ascii?q?BAQEBAQECARMBAQEIDQkIKSMMgjYkAYJiAQIDAQIgBBkBATcBBQkBAQoYAgImA?=
 =?us-ascii?q?gIDRBAGAQwBBQIBAQEWA4MDggIFpXNwfDOCdgEBBYJDhGEIgQuKFYEcF4FAP4E?=
 =?us-ascii?q?RJ4JrhE00gwSCV4kbEoIFhROQSQmRUQYYgVyIHSaHJyyIfZAWgU0LgXwzGggbF?=
 =?us-ascii?q?TuCbIIbDBeDSop0HwExgQUBAYozKIEGgR8BAQ?=
X-IPAS-Result: =?us-ascii?q?A0ADAADmWxFch0O0hNFkGgEBAQEBAgEBAQEHAgEBAQGBUwM?=
 =?us-ascii?q?BAQEBCwGDaycKg3KUKoFgLRSXP4FzFBgTAYRAgn4iNgcNAQMBAQEBAQECARMBA?=
 =?us-ascii?q?QEIDQkIKSMMgjYkAYJiAQIDAQIgBBkBATcBBQkBAQoYAgImAgIDRBAGAQwBBQI?=
 =?us-ascii?q?BAQEWA4MDggIFpXNwfDOCdgEBBYJDhGEIgQuKFYEcF4FAP4ERJ4JrhE00gwSCV?=
 =?us-ascii?q?4kbEoIFhROQSQmRUQYYgVyIHSaHJyyIfZAWgU0LgXwzGggbFTuCbIIbDBeDSop?=
 =?us-ascii?q?0HwExgQUBAYozKIEGgR8BAQ?=
X-IronPort-AV: E=Sophos;i="5.56,345,1539673200"; 
   d="scan'208";a="57214186"
X-Amp-Result: SKIPPED(no attachment in message)
X-Amp-File-Uploaded: False
Received: from vger.kernel.org ([209.132.180.67])
  by mtab.intel.com with ESMTP; 12 Dec 2018 11:08:02 -0800
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
        id S1726796AbeLLTH7 (ORCPT <rfc822;like.xu@linux.intel.com>
        + 23 others); Wed, 12 Dec 2018 14:07:59 -0500
Received: from hqemgate15.nvidia.com ([216.228.121.64]:13431 "EHLO
        hqemgate15.nvidia.com" rhost-flags-OK-OK-OK-OK) by vger.kernel.org
        with ESMTP id S1726235AbeLLTH7 (ORCPT
        <rfc822;linux-kernel@vger.kernel.org>);
        Wed, 12 Dec 2018 14:07:59 -0500
Received: from hqpgpgate101.nvidia.com (Not Verified[216.228.121.13]) by hqemgate15.nvidia.com (using TLS: TLSv1.2, DES-CBC3-SHA)
        id <B5c115c890001>; Wed, 12 Dec 2018 11:07:53 -0800
Received: from hqmail.nvidia.com ([172.20.161.6])
  by hqpgpgate101.nvidia.com (PGP Universal service);
  Wed, 12 Dec 2018 11:07:56 -0800
X-PGP-Universal: processed;
        by hqpgpgate101.nvidia.com on Wed, 12 Dec 2018 11:07:56 -0800
Received: from [10.2.165.33] (172.20.13.39) by HQMAIL101.nvidia.com
 (172.20.187.10) with Microsoft SMTP Server (TLS) id 15.0.1395.4; Wed, 12 Dec
 2018 19:07:52 +0000
Subject: Re: [PATCH 1/2] mm: introduce put_user_page*(), placeholder versions
To: Dan Williams <dan.j.williams@intel.com>,
        =?UTF-8?B?SsOpcsO0bWUgR2xpc3Nl?= <jglisse@redhat.com>
CC: Jan Kara <jack@suse.cz>, Matthew Wilcox <willy@infradead.org>,
        John Hubbard <john.hubbard@gmail.com>,
        Andrew Morton <akpm@linux-foundation.org>,
        Linux MM <linux-mm@kvack.org>, <tom@talpey.com>,
        Al Viro <viro@zeniv.linux.org.uk>, <benve@cisco.com>,
        Christoph Hellwig <hch@infradead.org>,
        Christopher Lameter <cl@linux.com>,
        "Dalessandro, Dennis" <dennis.dalessandro@intel.com>,
        Doug Ledford <dledford@redhat.com>,
        Jason Gunthorpe <jgg@ziepe.ca>,
        Michal Hocko <mhocko@kernel.org>,
        Mike Marciniszyn <mike.marciniszyn@intel.com>,
        <rcampbell@nvidia.com>,
        Linux Kernel Mailing List <linux-kernel@vger.kernel.org>,
        linux-fsdevel <linux-fsdevel@vger.kernel.org>
References: <20181205011519.GV10377@bombadil.infradead.org>
 <20181205014441.GA3045@redhat.com>
 <59ca5c4b-fd5b-1fc6-f891-c7986d91908e@nvidia.com>
 <7b4733be-13d3-c790-ff1b-ac51b505e9a6@nvidia.com>
 <20181207191620.GD3293@redhat.com>
 <3c4d46c0-aced-f96f-1bf3-725d02f11b60@nvidia.com>
 <20181208022445.GA7024@redhat.com> <20181210102846.GC29289@quack2.suse.cz>
 <20181212150319.GA3432@redhat.com>
 <CAPcyv4go0Xzhz8rXdfscWuXDu83BO9v8WD4upDUJWb7gKzX5OQ@mail.gmail.com>
 <20181212170220.GA5037@redhat.com>
 <CAPcyv4hnQ-4DKwtrJjy9euvJvRf_sDO+1hbxuFCQv5m9qd9Drg@mail.gmail.com>
From: John Hubbard <jhubbard@nvidia.com>
X-Nvconfidentiality: public
Message-ID: <78dc9959-5e9c-8a57-05e4-da02f688cc24@nvidia.com>
Date: Wed, 12 Dec 2018 11:07:52 -0800
User-Agent: Mozilla/5.0 (X11; Linux x86_64; rv:60.0) Gecko/20100101
 Thunderbird/60.3.2
MIME-Version: 1.0
In-Reply-To: <CAPcyv4hnQ-4DKwtrJjy9euvJvRf_sDO+1hbxuFCQv5m9qd9Drg@mail.gmail.com>
X-Originating-IP: [172.20.13.39]
X-ClientProxiedBy: HQMAIL103.nvidia.com (172.20.187.11) To
 HQMAIL101.nvidia.com (172.20.187.10)
Content-Type: text/plain; charset="utf-8"
Content-Language: en-US
Content-Transfer-Encoding: quoted-printable
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed; d=nvidia.com; s=n1;
        t=1544641674; bh=GImQPXizU5WXSaCeGZGcLwQgKxMqTe9fuSijHAQjNO4=;
        h=X-PGP-Universal:Subject:To:CC:References:From:X-Nvconfidentiality:
         Message-ID:Date:User-Agent:MIME-Version:In-Reply-To:
         X-Originating-IP:X-ClientProxiedBy:Content-Type:Content-Language:
         Content-Transfer-Encoding;
        b=do9T6+y+sjhvyTKwioO3trdY4kelePWMlLpZDiIFv4EgDaIlEPi/gGFP2PrlUnjep
         D6xd5GYrvOJ1r1EwUrn9Yvd3u/wm4cSXbORWgZzSYVnFCBG9xd7cnpx4NsO/nlX3JC
         9wQAnnN6yGuIPUvbqgnclGhwOz55aoQAKm/VPDWjSTMpmnYUtX8FIt4912l+39AshU
         OcKH7uMzRr9LwznZDwoEtLOgDrOHLxgFrU4FvhQMR7IitvAECB+DZ3ZIOeQRwtj0w5
         KYeywp3abdF+gG51lhB1oDsrV32kZoY/Y/YfBnAcKhpivs/BmAB+hWTd50OJ/jyn76
         ZLbCJ6PEpDi/w==
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: <linux-kernel.vger.kernel.org>
X-Mailing-List: linux-kernel@vger.kernel.org

On 12/12/18 9:49 AM, Dan Williams wrote:
> On Wed, Dec 12, 2018 at 9:02 AM Jerome Glisse <jglisse@redhat.com> wrote:
>>
>> On Wed, Dec 12, 2018 at 08:27:35AM -0800, Dan Williams wrote:
>>> On Wed, Dec 12, 2018 at 7:03 AM Jerome Glisse <jglisse@redhat.com> wrot=
e:
>>>>
>>>> On Mon, Dec 10, 2018 at 11:28:46AM +0100, Jan Kara wrote:
>>>>> On Fri 07-12-18 21:24:46, Jerome Glisse wrote:
>>>>>> Another crazy idea, why not treating GUP as another mapping of the p=
age
>>>>>> and caller of GUP would have to provide either a fake anon_vma struc=
t or
>>>>>> a fake vma struct (or both for PRIVATE mapping of a file where you c=
an
>>>>>> have a mix of both private and file page thus only if it is a read o=
nly
>>>>>> GUP) that would get added to the list of existing mapping.
>>>>>>
>>>>>> So the flow would be:
>>>>>>     somefunction_thatuse_gup()
>>>>>>     {
>>>>>>         ...
>>>>>>         GUP(_fast)(vma, ..., fake_anon, fake_vma);
>>>>>>         ...
>>>>>>     }
>>>>>>
>>>>>>     GUP(vma, ..., fake_anon, fake_vma)
>>>>>>     {
>>>>>>         if (vma->flags =3D=3D ANON) {
>>>>>>             // Add the fake anon vma to the anon vma chain as a chil=
d
>>>>>>             // of current vma
>>>>>>         } else {
>>>>>>             // Add the fake vma to the mapping tree
>>>>>>         }
>>>>>>
>>>>>>         // The existing GUP except that now it inc mapcount and not
>>>>>>         // refcount
>>>>>>         GUP_old(..., &nanonymous, &nfiles);
>>>>>>
>>>>>>         atomic_add(&fake_anon->refcount, nanonymous);
>>>>>>         atomic_add(&fake_vma->refcount, nfiles);
>>>>>>
>>>>>>         return nanonymous + nfiles;
>>>>>>     }
>>>>>
>>>>> Thanks for your idea! This is actually something like I was suggestin=
g back
>>>>> at LSF/MM in Deer Valley. There were two downsides to this I remember
>>>>> people pointing out:
>>>>>
>>>>> 1) This cannot really work with __get_user_pages_fast(). You're not a=
llowed
>>>>> to get necessary locks to insert new entry into the VMA tree in that
>>>>> context. So essentially we'd loose get_user_pages_fast() functionalit=
y.
>>>>>
>>>>> 2) The overhead e.g. for direct IO may be noticeable. You need to all=
ocate
>>>>> the fake tracking VMA, get VMA interval tree lock, insert into the tr=
ee.
>>>>> Then on IO completion you need to queue work to unpin the pages again=
 as you
>>>>> cannot remove the fake VMA directly from interrupt context where the =
IO is
>>>>> completed.
>>>>>
>>>>> You are right that the cost could be amortized if gup() is called for
>>>>> multiple consecutive pages however for small IOs there's no help...
>>>>>
>>>>> So this approach doesn't look like a win to me over using counter in =
struct
>>>>> page and I'd rather try looking into squeezing HMM public page usage =
of
>>>>> struct page so that we can fit that gup counter there as well. I know=
 that
>>>>> it may be easier said than done...
>>>>
>>>> So i want back to the drawing board and first i would like to ascertai=
n
>>>> that we all agree on what the objectives are:
>>>>
>>>>     [O1] Avoid write back from a page still being written by either a
>>>>          device or some direct I/O or any other existing user of GUP.
>>>>          This would avoid possible file system corruption.
>>>>
>>>>     [O2] Avoid crash when set_page_dirty() is call on a page that is
>>>>          considered clean by core mm (buffer head have been remove and
>>>>          with some file system this turns into an ugly mess).
>>>>
>>>>     [O3] DAX and the device block problems, ie with DAX the page map i=
n
>>>>          userspace is the same as the block (persistent memory) and no
>>>>          filesystem nor block device understand page as block or pinne=
d
>>>>          block.
>>>>
>>>> For [O3] i don't think any pin count would help in anyway. I believe
>>>> that the current long term GUP API that does not allow GUP of DAX is
>>>> the only sane solution for now.
>>>
>>> No, that's not a sane solution, it's an emergency hack.
>>
>> Then how do you want to solve it ? Knowing pin count does not help
>> you, at least i do not see how that would help and if it does then
>> my solution allow you to know pin count it is the difference between
>> real mapping and mapcount value.
>=20
> True, pin count doesn't help, and indefinite waits are intolerable, so
> I think we need to make "long term" GUP revokable, but otherwise
> hopefully use the put_user_page() scheme to replace the use of the pin
> count for dax_layout_busy_page().
>=20
>>>> The real fix would be to teach file-
>>>> system about DAX/pinned block so that a pinned block is not reuse
>>>> by filesystem.
>>>
>>> We already have taught filesystems about pinned dax pages, see
>>> dax_layout_busy_page(). As much as possible I want to eliminate the
>>> concept of "dax pages" as a special case that gets sprinkled
>>> throughout the mm.
>>>
>>>> For [O1] and [O2] i believe a solution with mapcount would work. So
>>>> no new struct, no fake vma, nothing like that. In GUP for file back
>>>> pages
>>>
>>> With get_user_pages_fast() we don't know that we have a file-backed
>>> page, because we don't have a vma.
>>
>> You do not need a vma to know that we have PageAnon() for that so my
>> solution is just about adding to core GUP page table walker:
>>
>>     if (!PageAnon(page))
>>         atomic_inc(&page->mapcount);
>=20
> Ah, ok, would need to add proper mapcount manipulation for dax and
> audit that nothing makes page-cache assumptions based on a non-zero
> mapcount.
>=20
>> Then in put_user_page() you add the opposite. In page_mkclean() you
>> count the number of real mapping and voil=C3=A0 ... you got an answer fo=
r
>> [O1]. You could use the same count real mapping to get the pin count
>> in other place that cares about it but i fails to see why the actual
>> pin count value would matter to any one.
>=20
> Sounds like a could work... devil is in the details.
>=20

I also like this solution. It uses existing information and existing pointe=
rs
(PageAnon, page_mapping) plus a tiny bit more (another pointer in struct=20
address_space, probably, and that's not a size-contentious struct) to figur=
e
out the DMA pinned count, which neatly avoids the struct page contention th=
at I=20
ran into.=20

Thanks for coming up with this! I'll put together a patchset that shows the=
 details
so we can all take a closer look. This is on the top of my list.


--=20
thanks,
John Hubbard
NVIDIA

