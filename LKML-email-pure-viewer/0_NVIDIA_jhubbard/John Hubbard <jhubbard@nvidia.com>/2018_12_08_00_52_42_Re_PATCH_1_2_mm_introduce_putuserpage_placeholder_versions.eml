Return-Path: <linux-kernel-owner@vger.kernel.org>
Delivered-To: unknown
Received: from linux.intel.com (10.54.29.200:995) by likexu-workstation with
  POP3-SSL; 09 Dec 2018 18:54:23 -0000
X-Original-To: like.xu@linux.intel.com
Delivered-To: like.xu@linux.intel.com
Received: from orsmga007.jf.intel.com (orsmga007.jf.intel.com [10.7.209.58])
	(using TLSv1.2 with cipher ECDHE-RSA-AES256-GCM-SHA384 (256/256 bits))
	(No client certificate requested)
	by linux.intel.com (Postfix) with ESMTPS id 472295804F7;
	Fri,  7 Dec 2018 16:52:51 -0800 (PST)
Received: from fmsmga102.fm.intel.com ([10.1.193.69])
  by orsmga007-1.jf.intel.com with ESMTP/TLS/DHE-RSA-AES256-GCM-SHA384; 07 Dec 2018 16:52:50 -0800
X-SG-BADATTACHMENTNOREPLY: True
IronPort-PHdr: =?us-ascii?q?9a23=3AMV3u6x3N0M/Ky7t1smDT+DRfVm0co7zxezQtwd8Z?=
 =?us-ascii?q?segSIvzxwZ3uMQTl6Ol3ixeRBMOHs6IC07KempujcFRI2YyGvnEGfc4EfD4+ou?=
 =?us-ascii?q?JSoTYdBtWYA1bwNv/gYn9yNs1DUFh44yPzahANS47xaFLIv3K98yMZFAnhOgpp?=
 =?us-ascii?q?POT1HZPZg9iq2+yo9JDffwZFiCChbb9uMR67sRjfus4KjIV4N60/0AHJonxGe+?=
 =?us-ascii?q?RXwWNnO1eelAvi68mz4ZBu7T1et+ou+MBcX6r6eb84TaFDAzQ9L281/szrugLd?=
 =?us-ascii?q?QgaJ+3ART38ZkhtMAwjC8RH6QpL8uTb0u+ZhxCWXO9D9QKsqUjq+8ahkVB7oiD?=
 =?us-ascii?q?8GNzEn9mHXltdwh79frB64uhBz35LYbISTOfFjfK3SYMkaSHJcUMhPWSxPAoCy?=
 =?us-ascii?q?YYUBAOUOP+lYrpXyqVQVrRumBwShH//vxz1Si3PqwaE33eYsHAfb1wIgBdIOt3?=
 =?us-ascii?q?HUoc3xOqcVUeC1yrTDwzfeb/xNwjjy8pLIfQ08qvyLX7JwcdfRxlI0GAzflFWf?=
 =?us-ascii?q?tJfoPzWL1uQMrmeb7vBvWfizhG4grgF8uz6izdovhInRno8Z1EzI+CFjzIooK9?=
 =?us-ascii?q?C0VlR3bcOnHZdMrS2XNol7Tts/T210oio216MKtJGhcCQX0pgqxwbTZ+Kaf4WJ?=
 =?us-ascii?q?+B7vSvidLDRiiH54Zr6zmgy+/Emgx+D6S8K6ykxFrjBfndnJrn0N1wLc6syASv?=
 =?us-ascii?q?Zl4Eeh1iiA1xrJ5uFHP080j6zbJIAlwrIqkZoTq0vDEjf3mEXwkqCWal0p9va0?=
 =?us-ascii?q?5+njeLnqu5GRO5Fuhg3jMakihtazDOU6PwQWWmiU4+W81Lnt/U3jR7VKi+U7kq?=
 =?us-ascii?q?3YsJDcOMQaqbe1AwxL3YY57RawETOm3M0fnXgJKlJKZgiHgpP3O1HBPv/4F+2z?=
 =?us-ascii?q?g1eynzdxwfDJILnhDo/KLnjZn7ftZax95FJEyAov0dBf4IpZCrUAIPLwRED9rt?=
 =?us-ascii?q?PZDgIiPgywwubnDsh914wEVWKOBK+ZLL3dsVuS6u0zJOmMYZcfuCzhJPg9+/7u?=
 =?us-ascii?q?kXg5lEcdfaaz3JsXdGq3HvN8L0WZfHrjmNEBEWgRswo6TezqjkCCUDFJa3azWa?=
 =?us-ascii?q?I8+i80CIa8AYjfQYCthaSL3D2nEZ1OemBGFleMHG/qd4WDRfgAciGSIshnkjwC?=
 =?us-ascii?q?UrisUIsh1RCotA/nxLtrNOvU+isEtZ390Nh5/fHclRY39TZsFcSSz3mNT31onm?=
 =?us-ascii?q?MPXzI5xrt/oUx6yleAy6R4meZXFd5I6vNNUwc6M4PczuNgB9DzXALBYsmGSFK8?=
 =?us-ascii?q?Ttq6BjExS8o7w8USbEZlB9WikhfD0jKpA7APkbyHHpg08qPG0Hj3KMZw0HLG1K?=
 =?us-ascii?q?gnj1k7TcpDL2ymhqhj9wfNA47FiVmWl6Gvda4Exi7C6H+DzXaSvEFfSAN/TL/K?=
 =?us-ascii?q?XW4BaUfMrdT2/EXCT6SwBrQhNQdBzc2CKq5OatDyiVVGRfHjOMnRYm6rmmewAw?=
 =?us-ascii?q?qIya2IbIbwZ2od2yDdAlAekw8P5XaGKRQ+BiC5rm3DFjNuC0zgb1ns8eZkrnO7?=
 =?us-ascii?q?VVE7zweRYk1l1rq1/AMVhPOGR/MS2LIEpDkuqzFuEFmh2NLWDsKKpxB9c6VEfd?=
 =?us-ascii?q?M9/FBH2HrFtwx8O5ygKLxihl4ecghto0PizRJ3Cp9EkcgrqnMqwxF/KaaZ0FNH?=
 =?us-ascii?q?ajOZ0or8OrzRKmnu4h+vb7Ta1U3Z0NaT4q0P8ug3q03/vAG1EUov629o091L3H?=
 =?us-ascii?q?qT+JrLDBAeXonsUkkq7Rd6obLaYi4j547P0X1sMK+0siLN2t4zBeslzAqgcMlb?=
 =?us-ascii?q?MK+eCADyFMgaDdC0KOM2g1ipcg4EPOdK+a80IsOqbeeJ1LSqPeZghj2mi2tH7Z?=
 =?us-ascii?q?t50kKN8Sp8V+HJ04wEw/GewguISTP8gE29vcDwnIBOfSsSEXanySj4GI5RYbV/?=
 =?us-ascii?q?fZwKCWiyOcK33Mhxh5n3V35e6lGjHVIG1Na1dhWIa1zywBNf1V4QoXyhgia4yz?=
 =?us-ascii?q?10kzc0rquQxiDOwuLidAYZNW5PXmVtkVDsIY2shdAAQEeodxQplAei5Uvix6lb?=
 =?us-ascii?q?pb5zLmnJTUdTYij2KXpvUq+xtrqEfs5O54kksSRRUOSgf1+aTqTxrAcd0yPmB2?=
 =?us-ascii?q?Fe3iw0dym2upXlmBx3kGCdI2xprHraesFwwg3T5MfGSv5S3ToGRS94hifRBlWn?=
 =?us-ascii?q?O9mp/NOUl4rMs+ykVmKhUIFTfjfvzY+aqCS74mhqCwWln/+vgt3nDRQ60Sjj2t?=
 =?us-ascii?q?hqTyrIqwzwYovq16S8Ku9nekhoBFnh68t1AI1+k40whI0O1ngenJma4X0HkWLr?=
 =?us-ascii?q?O9VBxa3+dGYNRSIMw9PN4wjqwkxjImiJx4LkTHqdxMRhasK+YmMX3CI98s9LBL?=
 =?us-ascii?q?2V7LxCgSt6vF64oRjNbvh6mzcX0eEu52ICg+EVpAotyT2QArUTHUlbJyPgjRqJ?=
 =?us-ascii?q?4M6lrKVLemmva6O/21RkndCuF7yCpgBcWHDkepYtByNw78N/ME7S33338I3rZN?=
 =?us-ascii?q?7QbdcLvB2OjxjAl/RVKI42lvcSmSpnPmf9sWckyuEhixxuwIq6vJOGK2h2+KK5?=
 =?us-ascii?q?AxhYNiD6Zs8J+zHti7pekdiS34y1ApphHTALVoPyTf20CDISqejnNwGWHTInsH?=
 =?us-ascii?q?ibHr7fHRKF5EdisnLCCJSrN3CRJHkEwtRuXhidJEpDgA8KWDU2hII2FgevxMb5?=
 =?us-ascii?q?akd2+igR5kLkqhtL0u9oNQPwUmLBqwezcDs0VIKTLBlL7gFB+kfVN9aR7vloEi?=
 =?us-ascii?q?Fc/52hqhGNK2OBawRJC2EJRlKLB1T5Mray4tnA9vCSBvCiIPvWfbWOteteWu+I?=
 =?us-ascii?q?xJKoz4tm5iuMOd+JPnV4FP073UxDXX9iFsTdmjUPTTEXli3XY86aohe85jN4rs?=
 =?us-ascii?q?Sl/Pv3XwLv4JOFC6FOPtV35xC2naCDOvaQhClnKDZY1ZAMxX7SxLgcxl4SjC5u?=
 =?us-ascii?q?eCe3EbQdri7AV6bQmq5RDx4GZCJ/LspI76Qg3gZTPc7XkM/61rl9jvQtEVdKSU?=
 =?us-ascii?q?Thmt21ZcwNO2yyLk7HC12RNLuYJTzH2cX3YaKnRL1UjeVUsQCwuDmBH0/iODSD?=
 =?us-ascii?q?iyfmVxS1Pe5QiyGbOQRUuJuhfRZ1FWjjUNXmZwWnMN92iD0626E7imnWOm4cLz?=
 =?us-ascii?q?d8dVhArrmR7SNen/V+FHZN7ntjLemYhSmZ6/PUJYoRsftuGi50jf5V4Gwmy7tJ?=
 =?us-ascii?q?6yFJXPx0lzHUrt5rolGmlPGAyztnUBVUrDZLi5mGvUFjOaXf65lBVmzI/BML7W?=
 =?us-ascii?q?WMFRsKo8FpBcHou6BVmZDzk/fRJS1F9t+c0s8dHNPZYJaFP34gKgHkMCTZAAsM?=
 =?us-ascii?q?UXigMmSJ1GJHl/TH1HqVqNAat5LmkYACAutZVEE/HPoABmxjAt0OIZ4xVTQhx+?=
 =?us-ascii?q?3IxPUU7Gaz+UGCDP5RuYrKA7fLWa3i?=
X-IronPort-Anti-Spam-Filtered: true
X-IronPort-Anti-Spam-Result: =?us-ascii?q?A0ADAACcFQtch0O0hNFkGgEBAQEBAgEBA?=
 =?us-ascii?q?QEHAgEBAQGBUwMBAQEBCwGDaycKg3CUKoFgLRSXO4IHKwGHXSI2Bw0BAwEBAQE?=
 =?us-ascii?q?BAQIBEwEBAQoLCQgpIwyCNiQBgmIBAgMBAiAEGQEBNwEFCQEBCg4KAgImAgIDR?=
 =?us-ascii?q?BAGDQEHAQEBgxyCAgWlEHB8M4J2AQEFgkOEZAiBC4l7gRwXgUA/gREngmuIBYJ?=
 =?us-ascii?q?XiRVSgUKEWjaQMAmKP4cGBhiBXIUWgwGHRSyYb4FNAoIEMxoIGxWDJ4IbDBeDS?=
 =?us-ascii?q?op0HwExgQUBAYk+gR8BAQ?=
X-IPAS-Result: =?us-ascii?q?A0ADAACcFQtch0O0hNFkGgEBAQEBAgEBAQEHAgEBAQGBUwM?=
 =?us-ascii?q?BAQEBCwGDaycKg3CUKoFgLRSXO4IHKwGHXSI2Bw0BAwEBAQEBAQIBEwEBAQoLC?=
 =?us-ascii?q?QgpIwyCNiQBgmIBAgMBAiAEGQEBNwEFCQEBCg4KAgImAgIDRBAGDQEHAQEBgxy?=
 =?us-ascii?q?CAgWlEHB8M4J2AQEFgkOEZAiBC4l7gRwXgUA/gREngmuIBYJXiRVSgUKEWjaQM?=
 =?us-ascii?q?AmKP4cGBhiBXIUWgwGHRSyYb4FNAoIEMxoIGxWDJ4IbDBeDSop0HwExgQUBAYk?=
 =?us-ascii?q?+gR8BAQ?=
X-IronPort-AV: E=Sophos;i="5.56,328,1539673200"; 
   d="scan'208";a="56047817"
X-Amp-Result: SKIPPED(no attachment in message)
X-Amp-File-Uploaded: False
Received: from vger.kernel.org ([209.132.180.67])
  by mtab.intel.com with ESMTP; 07 Dec 2018 16:52:48 -0800
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
        id S1726132AbeLHAwq (ORCPT <rfc822;like.xu@linux.intel.com>
        + 23 others); Fri, 7 Dec 2018 19:52:46 -0500
Received: from hqemgate16.nvidia.com ([216.228.121.65]:18799 "EHLO
        hqemgate16.nvidia.com" rhost-flags-OK-OK-OK-OK) by vger.kernel.org
        with ESMTP id S1726070AbeLHAwq (ORCPT
        <rfc822;linux-kernel@vger.kernel.org>);
        Fri, 7 Dec 2018 19:52:46 -0500
Received: from hqpgpgate102.nvidia.com (Not Verified[216.228.121.13]) by hqemgate16.nvidia.com (using TLS: TLSv1.2, DES-CBC3-SHA)
        id <B5c0b15da0000>; Fri, 07 Dec 2018 16:52:42 -0800
Received: from hqmail.nvidia.com ([172.20.161.6])
  by hqpgpgate102.nvidia.com (PGP Universal service);
  Fri, 07 Dec 2018 16:52:43 -0800
X-PGP-Universal: processed;
        by hqpgpgate102.nvidia.com on Fri, 07 Dec 2018 16:52:43 -0800
Received: from [10.2.174.74] (10.124.1.5) by HQMAIL101.nvidia.com
 (172.20.187.10) with Microsoft SMTP Server (TLS) id 15.0.1395.4; Sat, 8 Dec
 2018 00:52:42 +0000
Subject: Re: [PATCH 1/2] mm: introduce put_user_page*(), placeholder versions
To: Jerome Glisse <jglisse@redhat.com>
CC: Matthew Wilcox <willy@infradead.org>,
        Dan Williams <dan.j.williams@intel.com>,
        John Hubbard <john.hubbard@gmail.com>,
        Andrew Morton <akpm@linux-foundation.org>,
        Linux MM <linux-mm@kvack.org>, Jan Kara <jack@suse.cz>,
        <tom@talpey.com>, Al Viro <viro@zeniv.linux.org.uk>,
        <benve@cisco.com>, Christoph Hellwig <hch@infradead.org>,
        Christopher Lameter <cl@linux.com>,
        "Dalessandro, Dennis" <dennis.dalessandro@intel.com>,
        Doug Ledford <dledford@redhat.com>,
        Jason Gunthorpe <jgg@ziepe.ca>,
        Michal Hocko <mhocko@kernel.org>, <mike.marciniszyn@intel.com>,
        <rcampbell@nvidia.com>,
        Linux Kernel Mailing List <linux-kernel@vger.kernel.org>,
        linux-fsdevel <linux-fsdevel@vger.kernel.org>
References: <20181204001720.26138-1-jhubbard@nvidia.com>
 <20181204001720.26138-2-jhubbard@nvidia.com>
 <CAPcyv4h99JVHAS7Q7k3iPPUq+oc1NxHdyBHMjpgyesF1EjVfWA@mail.gmail.com>
 <a0adcf7c-5592-f003-abc5-a2645eb1d5df@nvidia.com>
 <CAPcyv4iNtamDAY9raab=iXhSZByecedBpnGybjLM+PuDMwq7SQ@mail.gmail.com>
 <3c91d335-921c-4704-d159-2975ff3a5f20@nvidia.com>
 <20181205011519.GV10377@bombadil.infradead.org>
 <20181205014441.GA3045@redhat.com>
 <59ca5c4b-fd5b-1fc6-f891-c7986d91908e@nvidia.com>
 <7b4733be-13d3-c790-ff1b-ac51b505e9a6@nvidia.com>
 <20181207191620.GD3293@redhat.com>
From: John Hubbard <jhubbard@nvidia.com>
X-Nvconfidentiality: public
Message-ID: <3c4d46c0-aced-f96f-1bf3-725d02f11b60@nvidia.com>
Date: Fri, 7 Dec 2018 16:52:42 -0800
User-Agent: Mozilla/5.0 (X11; Linux x86_64; rv:60.0) Gecko/20100101
 Thunderbird/60.3.2
MIME-Version: 1.0
In-Reply-To: <20181207191620.GD3293@redhat.com>
X-Originating-IP: [10.124.1.5]
X-ClientProxiedBy: HQMAIL104.nvidia.com (172.18.146.11) To
 HQMAIL101.nvidia.com (172.20.187.10)
Content-Type: text/plain; charset="utf-8"
Content-Language: en-US
Content-Transfer-Encoding: 7bit
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed; d=nvidia.com; s=n1;
        t=1544230363; bh=O1CsolTRdVsJWOGgyKNIfTwcwwkP1Vlc+CMECC9GAE8=;
        h=X-PGP-Universal:Subject:To:CC:References:From:X-Nvconfidentiality:
         Message-ID:Date:User-Agent:MIME-Version:In-Reply-To:
         X-Originating-IP:X-ClientProxiedBy:Content-Type:Content-Language:
         Content-Transfer-Encoding;
        b=Bw6Nx7rlfQ+6eW33BvBW2QbKgAE4VYE7BErYAGcvrfO60ziHDbUrwDfKTiX/F3BPJ
         WQ2MqwwRnheuBGAeZJvEDRH1W+nI+TIlC/Qjkor8Jey71wSIU16WlDP59zM7QHEora
         rCMMBW8hZUgG6ewIkqRlSy0xlTKx/I9g00qLIIDPj2WIsgnGvCvGcvj64KsSaoARNg
         nfMQltv/5GuCHJcU7r9Qqt7BRclZpBzsVFcnPvHs2SAC5MyA0F+cXx/7BsaKI4WI/y
         sFCpHJjHbrvNtdDr93k4QLeOJIeaTcObQABBpGckjDNtAA08I8q+2jFxVauy2DMZOE
         psNQYo1tDIt3w==
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: <linux-kernel.vger.kernel.org>
X-Mailing-List: linux-kernel@vger.kernel.org

On 12/7/18 11:16 AM, Jerome Glisse wrote:
> On Thu, Dec 06, 2018 at 06:45:49PM -0800, John Hubbard wrote:
>> On 12/4/18 5:57 PM, John Hubbard wrote:
>>> On 12/4/18 5:44 PM, Jerome Glisse wrote:
>>>> On Tue, Dec 04, 2018 at 05:15:19PM -0800, Matthew Wilcox wrote:
>>>>> On Tue, Dec 04, 2018 at 04:58:01PM -0800, John Hubbard wrote:
>>>>>> On 12/4/18 3:03 PM, Dan Williams wrote:
>>>>>>> Except the LRU fields are already in use for ZONE_DEVICE pages... how
>>>>>>> does this proposal interact with those?
>>>>>>
>>>>>> Very badly: page->pgmap and page->hmm_data both get corrupted. Is there an entire
>>>>>> use case I'm missing: calling get_user_pages() on ZONE_DEVICE pages? Said another
>>>>>> way: is it reasonable to disallow calling get_user_pages() on ZONE_DEVICE pages?
>>>>>>
>>>>>> If we have to support get_user_pages() on ZONE_DEVICE pages, then the whole 
>>>>>> LRU field approach is unusable.
>>>>>
>>>>> We just need to rearrange ZONE_DEVICE pages.  Please excuse the whitespace
>>>>> damage:
>>>>>
>>>>> +++ b/include/linux/mm_types.h
>>>>> @@ -151,10 +151,12 @@ struct page {
>>>>>  #endif
>>>>>                 };
>>>>>                 struct {        /* ZONE_DEVICE pages */
>>>>> +                       unsigned long _zd_pad_2;        /* LRU */
>>>>> +                       unsigned long _zd_pad_3;        /* LRU */
>>>>> +                       unsigned long _zd_pad_1;        /* uses mapping */
>>>>>                         /** @pgmap: Points to the hosting device page map. */
>>>>>                         struct dev_pagemap *pgmap;
>>>>>                         unsigned long hmm_data;
>>>>> -                       unsigned long _zd_pad_1;        /* uses mapping */
>>>>>                 };
>>>>>  
>>>>>                 /** @rcu_head: You can use this to free a page by RCU. */
>>>>>
>>>>> You don't use page->private or page->index, do you Dan?
>>>>
>>>> page->private and page->index are use by HMM DEVICE page.
>>>>
>>>
>>> OK, so for the ZONE_DEVICE + HMM case, that leaves just one field remaining for 
>>> dma-pinned information. Which might work. To recap, we need:
>>>
>>> -- 1 bit for PageDmaPinned
>>> -- 1 bit, if using LRU field(s), for PageDmaPinnedWasLru.
>>> -- N bits for a reference count
>>>
>>> Those *could* be packed into a single 64-bit field, if really necessary.
>>>
>>
>> ...actually, this needs to work on 32-bit systems, as well. And HMM is using a lot.
>> However, it is still possible for this to work.
>>
>> Matthew, can I have that bit now please? I'm about out of options, and now it will actually
>> solve the problem here.
>>
>> Given:
>>
>> 1) It's cheap to know if a page is ZONE_DEVICE, and ZONE_DEVICE means not on the LRU.
>> That, in turn, means only 1 bit instead of 2 bits (in addition to a counter) is required, 
>> for that case. 
>>
>> 2) There is an independent bit available (according to Matthew). 
>>
>> 3) HMM uses 4 of the 5 struct page fields, so only one field is available for a counter 
>>    in that case.
> 
> To expend on this, HMM private page are use for anonymous page
> so the index and mapping fields have the value you expect for
> such pages. Down the road i want also to support file backed
> page with HMM private (mapping, private, index).
> 
> For HMM public both anonymous and file back page are supported
> today (HMM public is only useful on platform with something like
> OpenCAPI, CCIX or NVlink ... so PowerPC for now).
> 
>> 4) get_user_pages() must work on ZONE_DEVICE and HMM pages.
> 
> get_user_pages() only need to work with HMM public page not the
> private one as we can not allow _anyone_ to pin HMM private page.
> So on get_user_pages() on HMM private we get a page fault and
> it is migrated back to regular memory.
> 
> 
>> 5) For a proper atomic counter for both 32- and 64-bit, we really do need a complete
>> unsigned long field.
>>
>> So that leads to the following approach:
>>
>> -- Use a single unsigned long field for an atomic reference count for the DMA pinned count.
>> For normal pages, this will be the *second* field of the LRU (in order to avoid PageTail bit).
>>
>> For ZONE_DEVICE pages, we can also line up the fields so that the second LRU field is 
>> available and reserved for this DMA pinned count. Basically _zd_pad_1 gets move up and
>> optionally renamed:
>>
>> diff --git a/include/linux/mm_types.h b/include/linux/mm_types.h
>> index 017ab82e36ca..b5dcd9398cae 100644
>> --- a/include/linux/mm_types.h
>> +++ b/include/linux/mm_types.h
>> @@ -90,8 +90,8 @@ struct page {
>>                                  * are in use.
>>                                  */
>>                                 struct {
>> -                                       unsigned long dma_pinned_flags;
>> -                                       atomic_t      dma_pinned_count;
>> +                                       unsigned long dma_pinned_flags; /* LRU.next */
>> +                                       atomic_t      dma_pinned_count; /* LRU.prev */
>>                                 };
>>                         };
>>                         /* See page-flags.h for PAGE_MAPPING_FLAGS */
>> @@ -161,9 +161,9 @@ struct page {
>>                 };
>>                 struct {        /* ZONE_DEVICE pages */
>>                         /** @pgmap: Points to the hosting device page map. */
>> -                       struct dev_pagemap *pgmap;
>> -                       unsigned long hmm_data;
>> -                       unsigned long _zd_pad_1;        /* uses mapping */
>> +                       struct dev_pagemap *pgmap;      /* LRU.next */
>> +                       unsigned long _zd_pad_1;        /* LRU.prev or dma_pinned_count */
>> +                       unsigned long hmm_data;         /* uses mapping */
> 
> This breaks HMM today as hmm_data would alias with mapping field.
> hmm_data can only be in LRU.prev
> 

I see. OK, HMM has done an efficient job of mopping up unused fields, and now we are
completely out of space. At this point, after thinking about it carefully, it seems clear
that it's time for a single, new field:

diff --git a/include/linux/mm_types.h b/include/linux/mm_types.h
index 5ed8f6292a53..1c789e324da8 100644
--- a/include/linux/mm_types.h
+++ b/include/linux/mm_types.h
@@ -182,6 +182,9 @@ struct page {
        /* Usage count. *DO NOT USE DIRECTLY*. See page_ref.h */
        atomic_t _refcount;
 
+       /* DMA usage count. See get_user_pages*(), put_user_page*(). */
+       atomic_t _dma_pinned_count;
+
 #ifdef CONFIG_MEMCG
        struct mem_cgroup *mem_cgroup;
 #endif


...because after all, the reason this is so difficult is that this fix has to work
in pretty much every configuration. get_user_pages() use is widespread, it's a very
general facility, and...it needs fixing.  And we're out of space. 

I'm going to send out an updated RFC that shows the latest, and I think it's going
to include the above.

-- 
thanks,
John Hubbard
NVIDIA

