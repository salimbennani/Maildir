Return-Path: <linux-kernel-owner@vger.kernel.org>
Delivered-To: unknown
Received: from pop3.zju.edu.cn (61.164.42.155:110) by
  likexu-MOBL1.ccr.corp.intel.com with POP3; 21 Nov 2018 10:58:27 -0000
Received: from icoremail.net (unknown [209.85.214.177])
	by mail-app2 (Coremail) with SMTP id by_KCgDnX+_0yvRbhy3EAQ--.57580S3;
	Wed, 21 Nov 2018 11:03:16 +0800 (CST)
Received: from mail-pl1-f177.google.com (unknown [209.85.214.177])
	by mx2.icoremail.net (Coremail) with SMTP id AQAAfwBX0EzyyvRbMQxhAA--.8780S3;
	Wed, 21 Nov 2018 11:03:14 +0800 (CST)
Received: by mail-pl1-f177.google.com with SMTP id b5-v6so3261186pla.6
        for <xuliker@zju.edu.cn>; Tue, 20 Nov 2018 19:03:14 -0800 (PST)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20161025;
        h=x-gm-message-state:delivered-to:dkim-signature:date:from:to:cc
         :subject:message-id:reply-to:references:mime-version
         :content-disposition:in-reply-to:user-agent:sender:precedence
         :list-id;
        bh=OFqt+td86dq7iDFU+/epHvtt6pV0iZ9bBu0MS+valDI=;
        b=bkqg7I+S16HZSWwl6DeH3xE9F22jqi1iYfL62k1JVxAtdzHgjorOMFqeGklHSY/ZUJ
         5sZlNAfi/YnRuTx5WVRd2twE958HT0dUHYhmdleV/lmTzVgPbGzR7OxrMMifv0bGjs2a
         EHbe52Xrre8KWfJC5A4cCmfsifoVIF7YFr7NZMGZ5ODRdutkURvZ9o5AKw1H8B8zhrq8
         agOJFDILl6fYZpXIZPwMb8QVj6lm9cSjAHp7EVVWicg8rAU701m4IqnfJyrfT/o92cf7
         o1tvW+ksMg30G/hIPGeYyidGpPl2tfH+RIjt2POmk4TaLx4nDu+hIyqoZ86Lzh2/ecnB
         /lIw==
X-Gm-Message-State: AGRZ1gIdYlgbL35YIcYUhD3n7e/94ec0UE0M6st50GjX9lqCV/yT+eff
	k2WRAZ62YeY4J0pDZVyG7rMpqHuhSrmTqStLAcDUkXlAxiGY+gc=
X-Received: by 2002:a62:6085:: with SMTP id u127-v6mr5171697pfb.147.1542769394164;
        Tue, 20 Nov 2018 19:03:14 -0800 (PST)
X-Forwarded-To: xuliker@zju.edu.cn
X-Forwarded-For: liker.xu@gmail.com xuliker@zju.edu.cn
Delivered-To: liker.xu@gmail.com
Received: by 2002:a17:90a:d106:0:0:0:0 with SMTP id l6-v6csp1413054pju;
        Tue, 20 Nov 2018 19:03:13 -0800 (PST)
X-Google-Smtp-Source: AFSGD/VXt4tlROVxSzaOS0h+4ylaFGsBedFNFIYAj6vV/Y4Yfm9zlcgBZBUkWcpL7cpgv0cXGwze
X-Received: by 2002:a63:5207:: with SMTP id g7mr4381348pgb.253.1542769393122;
        Tue, 20 Nov 2018 19:03:13 -0800 (PST)
ARC-Seal: i=1; a=rsa-sha256; t=1542769393; cv=none;
        d=google.com; s=arc-20160816;
        b=NhJV97MVvbc7RDP+235Ixi2/YbVpGid2kppepm7DSyRimhmdibM9guXYkjH6fOshc2
         +RbN3fJLywbBQrwSrpt1mq7BPwPWapilhTQ1LB/Z8n013cfbr9h1m2eYUgXPZ63wdgUb
         tnboIfFerIYJ0lheyGbUAF25KqMWzTLkvMBYM/UdCTyNBnoLSnjrmE+eeQ7qmTSQrvFC
         uqSq9RTOQhU9kAoCeYUzC1tGh/gDLn9q1WWNKENSOEdUn0EzvbtTeeIgYkJrTXJsoCZT
         gnHeBW0xBBfVeiMnMbltoJmyrKpUL5DrW+z/lzRVpi7cFmf1hV4bQVplPXt9aCdrxdjK
         nWOw==
ARC-Message-Signature: i=1; a=rsa-sha256; c=relaxed/relaxed; d=google.com; s=arc-20160816;
        h=list-id:precedence:sender:user-agent:in-reply-to
         :content-disposition:mime-version:references:reply-to:message-id
         :subject:cc:to:from:date:dkim-signature;
        bh=OFqt+td86dq7iDFU+/epHvtt6pV0iZ9bBu0MS+valDI=;
        b=QAmHAaTquGrbNS4vK9twfH9e2uYZzE/AQYNdvnwSrlaLnG9Rf68qtRO+6/mp2EOBws
         29fMTB+zUhspHG6Jjv/AUlbA7yj/8noxXjXUFTtnqO9+TEk2EnmtEmhaa7x+siGPCTtt
         Wl1QfYxUB1wINAX2LeXH1Tu38o5NitR5VQc1wNCqm+VWDUf55EIGwcP6Ew12ms2PfwYI
         mI0QKOFq8weJLxRxHpdx4YBwbgKaPSCc/n94w1P7RtLlVIL5KwZvNPk0ODwSkuEN8hbo
         2MN8wjSx0NGKaQDnmxvhi0PAplMciLfqbk5lnPoZgbdKmqVwV/N2kH/200fAF5/biYA/
         o+sw==
ARC-Authentication-Results: i=1; mx.google.com;
       dkim=pass header.i=@gmail.com header.s=20161025 header.b=QCzkQf7H;
       spf=pass (google.com: best guess record for domain of linux-kernel-owner@vger.kernel.org designates 209.132.180.67 as permitted sender) smtp.mailfrom=linux-kernel-owner@vger.kernel.org;
       dmarc=pass (p=NONE sp=QUARANTINE dis=NONE) header.from=gmail.com
Received: from vger.kernel.org (vger.kernel.org. [209.132.180.67])
        by mx.google.com with ESMTP id b137-v6si48328538pfb.144.2018.11.20.19.02.57;
        Tue, 20 Nov 2018 19:03:13 -0800 (PST)
Received-SPF: pass (google.com: best guess record for domain of linux-kernel-owner@vger.kernel.org designates 209.132.180.67 as permitted sender) client-ip=209.132.180.67;
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
        id S1726336AbeKUNfK (ORCPT <rfc822;nullbytes00@gmail.com>
        + 99 others); Wed, 21 Nov 2018 08:35:10 -0500
Received: from mail-ed1-f66.google.com ([209.85.208.66]:38471 "EHLO
        mail-ed1-f66.google.com" rhost-flags-OK-OK-OK-OK) by vger.kernel.org
        with ESMTP id S1725926AbeKUNfK (ORCPT
        <rfc822;linux-kernel@vger.kernel.org>);
        Wed, 21 Nov 2018 08:35:10 -0500
Received: by mail-ed1-f66.google.com with SMTP id h50so3671058ede.5
        for <linux-kernel@vger.kernel.org>; Tue, 20 Nov 2018 19:02:43 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20161025;
        h=date:from:to:cc:subject:message-id:reply-to:references:mime-version
         :content-disposition:in-reply-to:user-agent;
        bh=OFqt+td86dq7iDFU+/epHvtt6pV0iZ9bBu0MS+valDI=;
        b=QCzkQf7HgwMY3q0KLHHlk2/ybwhFbBD5d9QFXt+2ek3rLbKa7VEqLJ9bBpyJQEs1V+
         hvs3XLPyFgQAbuW5q1ARpwXFfLbZOIIxstRteL8E4+fYkGRIL+2E2ZINPETrf31nrSQZ
         wyiF3YfxdVUV+ZLvqSrcI1MUg3dABHwix4+mjzuMJ137G+R/jO5JWCaYHS1kdOd1oQMK
         uHw7Q/IkmhRnQ4AqrQZrUdUMD1/0WIXER0MiHrIPOEOs/+/rXvwB1FWjpJTl/9QibadQ
         HLwiKgnMvLeW1rw2UMV5OcnHTw9f2paoOJV+bT5oPHGwsa1k7M+8H0Y2t1dmvQ88TC3D
         DO8A==
X-Received: by 2002:a17:906:603:: with SMTP id s3-v6mr3543442ejb.81.1542769362411;
        Tue, 20 Nov 2018 19:02:42 -0800 (PST)
Received: from localhost ([185.92.221.13])
        by smtp.gmail.com with ESMTPSA id x38sm5793849edx.24.2018.11.20.19.02.41
        (version=TLS1_2 cipher=ECDHE-RSA-CHACHA20-POLY1305 bits=256/256);
        Tue, 20 Nov 2018 19:02:41 -0800 (PST)
Date: Wed, 21 Nov 2018 03:02:41 +0000
From: Wei Yang <richard.weiyang@gmail.com>
To: Wengang Wang <wen.gang.wang@oracle.com>
Cc: Wei Yang <richard.weiyang@gmail.com>, cl@linux.com,
        penberg@kernel.org, rientjes@google.com, iamjoonsoo.kim@lge.com,
        akpm@linux-foundation.org, linux-mm@kvack.org,
        linux-kernel@vger.kernel.org
Subject: Re: [PATCH] mm: use this_cpu_cmpxchg_double in put_cpu_partial
Message-ID: <20181121030241.h7rgyjtlfcnm3hki@master>
Reply-To: Wei Yang <richard.weiyang@gmail.com>
References: <20181117013335.32220-1-wen.gang.wang@oracle.com>
 <20181118010229.esa32zk5hpob67y7@master>
 <d3e91590-adaa-11a5-67f9-0ef15df6b07d@oracle.com>
MIME-Version: 1.0
Content-Type: text/plain; charset=us-ascii
Content-Disposition: inline
In-Reply-To: <d3e91590-adaa-11a5-67f9-0ef15df6b07d@oracle.com>
User-Agent: NeoMutt/20170113 (1.7.2)
Sender: liker.xu+caf_=xuliker=zju.edu.cn@gmail.com
Precedence: bulk
List-ID: <linux-kernel.vger.kernel.org>
X-Mailing-List: linux-kernel@vger.kernel.org
X-CM-TRANSID: AQAAfwBX0EzyyvRbMQxhAA--.8780S3
Authentication-Results: mail-app2; spf=pass smtp.mail=liker.xu+caf_=xu
	liker=zju.edu.cn@gmail.com;
X-Coremail-Antispam: 1UD129KBjvJXoWxAr4rXr4rCrWUtFykAF1UJrb_yoWrGFWrp3
	yfG3W3KF4kCryIkw1xGFs2y3y0v3yxAFW5GF9aqrykur4rZrn7trWIyw1DuFyDurn7Z340
	vr4jyF109r45ZaUanT9S1TB71UUUUUUqnTZGkaVYY2UrUUUUjbIjqfuFe4nvWSU8nxnvy2
	9KBjDU0xBIdaVrnRJUUUP0b7Iv0xC_tr1lb4IE77IF4wAFF20E14v26r1j6r4UM7CIcVAF
	z4kK6r1j6r18M28lY4IEw2IIxxk0rwA2F7IY1VAKz4vEj48ve4kI8wA2z4x0Y4vE2Ix0cI
	8IcVAFwI0_Xr0_Ar1l84ACjcxK6xIIjxv20xvEc7CjxVAFwI0_Gr0_Cr1l84ACjcxK6I8E
	87Iv67AKxVW0oVCq3wA2z4x0Y4vEx4A2jsIEc7CjxVAFwI0_GcCE3s1le2I262IYc4CY6c
	8Ij28IcVAaY2xG8wAqx4xG64xvF2IEw4CE5I8CrVC2j2WlYx0E2Ix0cI8IcVAFwI0_Jr0_
	Jr4lYx0Ex4A2jsIE14v26r4j6F4UMcvjeVCFs4IE7xkEbVWUJVW8JwACjcxG0xvEwIxGrw
	CjxxvEa2IrMxkF7I0Ew4C26cxK6c8Ij28IcwCY1Ik26cxK6xAEc7vF6xCjj44lc2xSY4AK
	6IIF6r48MxkI7II2jI8vz4vEwIxGrwCYIxAIcVC0I7IYx2IY67AKxVWUJVWUCwCYIxAIcV
	C0I7IYx2IY6xkF7I0E14v26r1j6r4UMxvI42IY6I8E87Iv67AKxVWxJr0_GcWlcIIF0xvE
	x4A2jsIEc7CjxVAFwI0_Cr1j6rxdMxAIw28IcxkI7VAKI48JMxAIw28IcVAKzI0EY4vE52
	x082I5MxCjnVCjjxCrMxC20s026xCaFVCjc4AY6r1j6r4UMI8I3I0E5I8CrVAFwI0_Jr0_
	Jr4lx2IqxVCjr7xvwVAFwI0_JrI_JrWlx4CE17CEb7AF67AKxVWUtVW8ZwCIc40Y0x0EwI
	xGrwCI42IY6xAIw20EY4v20xvaj40_Gr0_ZrUvcSsGvfC2KfnxnUUI43ZEXa7IU5L2-5UU
	UUU==

On Tue, Nov 20, 2018 at 09:58:58AM -0800, Wengang Wang wrote:
>Hi Wei,
>
>
>On 2018/11/17 17:02, Wei Yang wrote:
>> On Fri, Nov 16, 2018 at 05:33:35PM -0800, Wengang Wang wrote:
>> > The this_cpu_cmpxchg makes the do-while loop pass as long as the
>> > s->cpu_slab->partial as the same value. It doesn't care what happened to
>> > that slab. Interrupt is not disabled, and new alloc/free can happen in the
>> Well, I seems to understand your description.
>> 
>> There are two slabs
>> 
>>     * one which put_cpu_partial() trying to free an object
>>     * one which is the first slab in cpu_partial list
>> 
>> There is some tricky case, the first slab in cpu_partial list we
>> reference to will change since interrupt is not disabled.
>Yes, two slabs involved here just as you said above.
>And yes, the case is really tricky, but it's there.
>
>> > interrupt handlers. Theoretically, after we have a reference to the it,
>>                                                                   ^^^
>> 							 one more word?
>sorry, "the" should not be there.
>
>> > stored in _oldpage_, the first slab on the partial list on this CPU can be
>>                                              ^^^
>> One little suggestion here, mayby use cpu_partial would be more easy to
>> understand. I confused this with the partial list in kmem_cache_node at
>> the first time.  :-)
>Right, making others understanding easily is very important. I just meant
>cpu_partial.
>
>> > moved to kmem_cache_node and then moved to different kmem_cache_cpu and
>> > then somehow can be added back as head to partial list of current
>> > kmem_cache_cpu, though that is a very rare case. If that rare case really
>> Actually, no matter what happens after the removal of the first slab in
>> cpu_partial, it would leads to problem.
>Maybe you are right, what I see is the problem on the page->pobjects.
>
>> 
>> > happened, the reading of oldpage->pobjects may get a 0xdead0000
>> > unexpectedly, stored in _pobjects_, if the reading happens just after
>> > another CPU removed the slab from kmem_cache_node, setting lru.prev to
>> > LIST_POISON2 (0xdead000000000200). The wrong _pobjects_(negative) then
>> > prevents slabs from being moved to kmem_cache_node and being finally freed.
>> > 
>> > We see in a vmcore, there are 375210 slabs kept in the partial list of one
>> > kmem_cache_cpu, but only 305 in-use objects in the same list for
>> > kmalloc-2048 cache. We see negative values for page.pobjects, the last page
>> > with negative _pobjects_ has the value of 0xdead0004, the next page looks
>> > good (_pobjects is 1).
>> > 
>> > For the fix, I wanted to call this_cpu_cmpxchg_double with
>> > oldpage->pobjects, but failed due to size difference between
>> > oldpage->pobjects and cpu_slab->partial. So I changed to call
>> > this_cpu_cmpxchg_double with _tid_. I don't really want no alloc/free
>> > happen in between, but just want to make sure the first slab did expereince
>> > a remove and re-add. This patch is more to call for ideas.
>> Maybe not an exact solution.
>> 
>> I took a look into the code and change log.
>> 
>> _tid_ is introduced by commit 8a5ec0ba42c4 ('Lockless (and preemptless)
>> fastpaths for slub'), which is used to guard cpu_freelist. While we don't
>> modify _tid_ when cpu_partial changes.
>> 
>> May need another _tid_ for cpu_partial?
>Right, _tid_ changes later than cpu_partial changes.
>
>As pointed out by Zhong Jiang, the pobjects issue is fixed by commit

Where you discussed this issue? Any reference I could get a look?

>e5d9998f3e09 (not sure if by side effect, see my replay there),

I took a look at this commit e5d9998f3e09 ('slub: make ->cpu_partial
unsigned int'), but not see some relationship between them.

Would you mind show me a link or cc me in case you have further
discussion?

Thanks.

>I'd skip this patch.?? If we found other problems regarding the change of
>cpu_partial, let's fix them. What do you think?
>
>thanks,
>wengang

-- 
Wei Yang
Help you, Help me
