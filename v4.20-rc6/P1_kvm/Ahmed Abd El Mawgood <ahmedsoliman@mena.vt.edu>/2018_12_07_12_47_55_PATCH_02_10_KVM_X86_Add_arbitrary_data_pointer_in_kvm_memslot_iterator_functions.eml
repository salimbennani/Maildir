Return-Path: <linux-kernel-owner@vger.kernel.org>
Delivered-To: unknown
Received: from linux.intel.com (10.54.29.200:995) by likexu-workstation with
  POP3-SSL; 07 Dec 2018 21:02:54 -0000
X-Original-To: like.xu@linux.intel.com
Delivered-To: like.xu@linux.intel.com
Received: from orsmga001.jf.intel.com (orsmga001.jf.intel.com [10.7.209.18])
	(using TLSv1.2 with cipher ECDHE-RSA-AES256-GCM-SHA384 (256/256 bits))
	(No client certificate requested)
	by linux.intel.com (Postfix) with ESMTPS id ABC0E5803E4;
	Fri,  7 Dec 2018 04:49:03 -0800 (PST)
Received: from orsmga102-1.jf.intel.com (HELO mga09.intel.com) ([10.7.208.27])
  by orsmga001-1.jf.intel.com with ESMTP; 07 Dec 2018 04:49:03 -0800
X-SG-BADATTACHMENTNOREPLY: True
IronPort-PHdr: =?us-ascii?q?9a23=3A8fXKLBQh0P7Ak9yhNLVqeYmGXtpsv+yvbD5Q0YIu?=
 =?us-ascii?q?jvd0So/mwa64bRCAt8tkgFKBZ4jH8fUM07OQ7/iwHzRYqb+681k6OKRWUBEEjc?=
 =?us-ascii?q?hE1ycBO+WiTXPBEfjxciYhF95DXlI2t1uyMExSBdqsLwaK+i764jEdAAjwOhRo?=
 =?us-ascii?q?LerpBIHSk9631+ev8JHPfglEnjWwba9xIRmssQndqtQdjJd/JKo21hbHuGZDdf?=
 =?us-ascii?q?5MxWNvK1KTnhL86dm18ZV+7SleuO8v+tBZX6nicKs2UbJXDDI9M2Ao/8LrrgXM?=
 =?us-ascii?q?TRGO5nQHTGoblAdDDhXf4xH7WpfxtTb6tvZ41SKHM8D6Uaw4VDK/5KpwVhTmlD?=
 =?us-ascii?q?kIOCI48GHPi8x/kqRboA66pxdix4LYeZyZOOZicq/Ye94RWGhPUdtLVyFZAo2y?=
 =?us-ascii?q?cZYBAeQCM+hfrYb9qVQBoxSlBQm0Bu7i0SNEi3zs0KEmyektDR3K0Qo9FNwOqn?=
 =?us-ascii?q?TUq9D1Ob8OXOC1yanH0yjMZO5K1Djm9YfDbx8vofWRVrx3a8XQx0YvFwTCjlqN?=
 =?us-ascii?q?tIfoOCma1uQIs2eF8uVgTuWvi2omqwF0uDevwNwhiozXiYIT0F/I7zt5wJovKd?=
 =?us-ascii?q?KmVUF7fMepHZ1NvC+ZL4t7Wt0uT31stSog17ELt4C3cDIXxJkk2xLTcf2KfoqQ?=
 =?us-ascii?q?7h7+VOucIC10iGx4dL+xnRq/9Uutxvf4W8Wo1ltBszBLncPWtn8X0hze8siHRe?=
 =?us-ascii?q?V5/kemwTuPyQ/T5f9eIUwulqrUNYQhwrgumZoXq0jDGTX2mErugK+XcEUr5PSo?=
 =?us-ascii?q?5vz5brn6opKQLZJ4hw/gPqg0h8CyAvg0PhIPUmWZ4ei80afs/Uz9QLVElP02la?=
 =?us-ascii?q?zZvYjeJcQaoK65HgBU3p8g6xmhFTem1soXnX0eIFJCdhOHiZbmO0vVLfDmAvew?=
 =?us-ascii?q?nU6snC1ox//YJL3hBIvCLnzZnLfmZ7Z95FZQyBAvwtBH+5JUFrYBLer3Wk/wt9?=
 =?us-ascii?q?zXEAU1MgOpw+v8DNV914UeWX+AA6ODMaPSt0OI6fwrI+WWeIAVvzP9IeA/5/Hy?=
 =?us-ascii?q?lX85hUMdfa6x0JsXcn+4H+hmLF+eYXb2gtcBDH0FvgwxTOHxjF2CUDhTZ2u9Xq?=
 =?us-ascii?q?4m5zE7Dp6mApnHRoy3nLOB2yK7FIVMZm9aElCMDWvod4KcVvcObyKdPNVtkj8D?=
 =?us-ascii?q?VbinTY8h0gqjtAv7y7phM+rV9TcUtZPl1Nhp+eLTkQs++iBzD8SYy2uNVX17nn?=
 =?us-ascii?q?sURz8q26ByuVZyykyD0ah/gPxUD8ZT6OlLUgohMZ7czup6C839Ww7bf9eJTkqm?=
 =?us-ascii?q?TcuiAT0rUt0xxNoOaV5nG9q+lhDDwzaqA7gNmryIHpM09LjQ33zwJ8lnzXbG27?=
 =?us-ascii?q?Isj10nQstJKG2nibRz9wnVB47VjUqZk7ymergb3C7I7G2D13aBvFlEUA5sVqXI?=
 =?us-ascii?q?RW0QaVHIrdvn/E/CT6WhCbI8MgRfz86OLa9Kat7sjVVCX/rjPNXeY2Ssm2a/Hx?=
 =?us-ascii?q?qIx7WMbJb0dGUZxinSFE8EkwUL93acKQc+Hjuho37ZDDF2CF3geV3s/vdkpHO7?=
 =?us-ascii?q?VEA0yRqKYFNn17eu/h4VhPqcS+4c374euSchrSl0E0i5397MF9WAoA9hdr1GYd?=
 =?us-ascii?q?wh+FdHyX7ZtwtlM5y8LqBig1kecxh3v0LuzRl3Fp9Mkc8wrHMuzQpyL62Y3UhF?=
 =?us-ascii?q?dzOZ25DwJ7LWJnPz/BCpd67ZxFXe3MyK9acI7fQys0/jsx2xFko+73Vn1MFY3G?=
 =?us-ascii?q?GY5prUAwsdT5LwXlws+Bhnur7VeC8954DT1X1yKqS0tj7C29Q0BOoq0BqgftFf?=
 =?us-ascii?q?ML+aGw/2CcEVG8+uKOkykVizch0EJPxS9LIzP86+d/qGxbSnM/p6kDOnjWRI+o?=
 =?us-ascii?q?Z90k2X+ip4S+7I2YsFwv6C0guGUTf8kEmussTtlY9YYjESG3K1yTL4C45Jeq1y?=
 =?us-ascii?q?YYELBH+0I8222tpxnYTtVGNf9FK5AVMJxtWpeRuLY1PhxwJQ0VkYrmK9mSu/yT?=
 =?us-ascii?q?x5iDUprquZ3CzTzOXubhsHOmhXRGZ8iVfgO5S7j9cfXEKwdQgmiAOl5Vrmx6hc?=
 =?us-ascii?q?vKl+L2jTTV1IfiTsNGFiT62wu6GGY85O7pMorCpWXP69YVCcVr7yvR8a3zn/EG?=
 =?us-ascii?q?tZwTAxbyuqtYnhnxxmlGKdK25+rHjDdsFqxhff59vcSeRK3jUcRyl4ijjXBl6i?=
 =?us-ascii?q?MNmv5tiUk5bDsuajV2OuTJFTcC/rzZ+euyu//2FlHRq/n/WrkN39DQc6yTP718?=
 =?us-ascii?q?VtVSjQrBfzeI7r2764MeJmeEllH1v868t8GoFjnYo8npAQ2X4GhpqL+XoLi3v8?=
 =?us-ascii?q?MdJe2ajmdnoCWSYLw8LJ4AjiwEBjLWiGx4PjWnWd38tufd+6YmwN1yI57sBKDr?=
 =?us-ascii?q?qU7bNekSt0pFq4sRzeYfxnkjgBzvsu7WYQg/sVtwo10iWdHrcSEFFdPSztlBSH?=
 =?us-ascii?q?9cqyratJa2a0bbi/ylB+ksu/A7GYrQFRQ3L5epYkHS9t4cRzKlPM0Hvv6o76fN?=
 =?us-ascii?q?ncd84cthqRkx3YlehaNIoxluYWhSpgIW/9oXoly+shgR1vx566upWHK352/KK4?=
 =?us-ascii?q?GRNYMjz1Z8UO+jDil6pen8CW35yxEZVlADkEQJzoTfewGjIIqfvnLxqOECE7qn?=
 =?us-ascii?q?qDArXQBwif6EN7r37VF5CrKmqaJH0YzdVkWRmcK1ZTgAESXDUmgJE5Ehqmy9Dm?=
 =?us-ascii?q?cEd8/joR/EL3qgNQyuJ0MBnySmXfqx2tajgqU5iTNgZW4htB50fIMsye8+RzED?=
 =?us-ascii?q?tD/pC6qAyNK2qbZxlHDG0TW0yEAUzjMaeq5dXa7+eYAe++JePUYbqSsexeS+uI?=
 =?us-ascii?q?xZW334pm+DaMK9yPPmR4AP09wEZDRnd5G8LWmzgUTywXliTNb9OUpRum+y13qN?=
 =?us-ascii?q?y//+rvWA71+YSPDL5SO811+x+qmaeDK/KQhCFhJDZYyJwMxHzIyLse3FIIiCFu?=
 =?us-ascii?q?bT6tEbseui7XUaLQgbRaDxoaayN1KctJ4Lgw3ghLOc7HlNz10qR0geIyC1dATV?=
 =?us-ascii?q?bhgN2mZdQWI2GhM1PKHFyENKmdKj3R3c72YbmwSblRjOhPsx2wuDCbE1LsPziZ?=
 =?us-ascii?q?ljnpUQyvPv9IjC2BIBNev4S9eA53CWf/VNLmdgG7MNhvgD0qwL00g2nGOnIGPT?=
 =?us-ascii?q?dgc0NCsLuQ4DhcgvV+HWxB83VkIfOFmyaf8+nXNJIWveF3DSRzkuJQ+G46xKdN?=
 =?us-ascii?q?7CFYWPx1nzPfr950rFGgl+mPyzxnXwJPqzZLno2Lu0piNL7d9plBX3bE4R0M4X?=
 =?us-ascii?q?+RCxQMu9tqFNnvt7pMxdjIkaKgYAtFpurd+s8bT+LTLtCGNntpZQLjHzjGDQ0E?=
 =?us-ascii?q?ZSSmOWHWmwpWl/TEsjWPrYIxr5H2sIADRr9SSBo+EfZeQmZiGtUeIJ5xFhgji7?=
 =?us-ascii?q?SWkIZc7n2kphTNbMFFuNbBW+7ERb3TKDGchKIMSB8FwKP+IJ5bYpH031xKblh8?=
 =?us-ascii?q?gZjQHEzRTZZBr3slJi4yr0IF1X96SGQpkxbgawWi51cJGPK0lwJwgQx7N6Bl3j?=
 =?us-ascii?q?D24kwzL0SCnCYsk04v0YHvmRiYdD/8Kvf2UYwAT2L0r0EZIILnRBwzZgq32QR0?=
 =?us-ascii?q?ZGnsRL9LibZkM2dxh0uUuoVKMeBTQLcCYxIKw/yTIfIy3hAUriSh2F8C6ezOIY?=
 =?us-ascii?q?VtmRFscpO2qX9EnQV5Y5p9Ia3WOboMzVVKgK+KljGn2/p3wwIEIUsJtmSId2pA?=
 =?us-ascii?q?sUwNO7U9IC6p++VqsRzcxWVrd20FVv5sqfVvsgs6JeWLz3q4+7FGI0G1ceeYKu?=
 =?us-ascii?q?fRuGXak8OMB1M5zE8FkUhD8pBy0Nw/aAyTT00p07KVE1ICMs+GYQdUYMdWsnXf?=
 =?us-ascii?q?Yi+Uvf7lwYp4eY66E6SgZ+iUtb1cpl+nFR0pEppEus4FA5qly0HVM+/8IbsdxA?=
 =?us-ascii?q?8z5Q/3OU7DB/NMLlbDsTgAuYmE0JhvxYAVcjASBn87Kjmw/q7ejgAvifuHGtwx?=
 =?us-ascii?q?ZyFJcJEDMycfWMi3l2ZwtXgIIT3/9+sGxw+F43eoryTVATXnaN5iYf6STRZhDt?=
 =?us-ascii?q?jw5yl5/qSr3w2Euq7CLn33YIwx8uTE7vkX8tPeU6tZ?=
X-IronPort-Anti-Spam-Filtered: true
X-IronPort-Anti-Spam-Result: =?us-ascii?q?A0AGAAAtawpch0O0hNFjGwEBAQEDAQEBB?=
 =?us-ascii?q?wMBAQGBUgUBAQELAYNrJ5gjgiFollOBJANPBQoBARgTAYdbIjUIDQEDAQEBAQE?=
 =?us-ascii?q?BAgETAQEBCA0JCCkjDII2JAGCYgMDAQIkCwENAQE3AQUJAQEYOAMxAQUBHAYBE?=
 =?us-ascii?q?gWDHIICBZktPIodgWwzgnYBAQWBAAQBAYRYB4FECBKHXoMTgRwXgX+BEYJdB4s?=
 =?us-ascii?q?KiTmXMAmGRop6CxiJY4dViRCPZAIEAgQFAgUPIYEmAYILMxolgzqCGwwXEoM4i?=
 =?us-ascii?q?hwBOD4yAYEDAQEBO4oFAQE?=
X-IPAS-Result: =?us-ascii?q?A0AGAAAtawpch0O0hNFjGwEBAQEDAQEBBwMBAQGBUgUBAQE?=
 =?us-ascii?q?LAYNrJ5gjgiFollOBJANPBQoBARgTAYdbIjUIDQEDAQEBAQEBAgETAQEBCA0JC?=
 =?us-ascii?q?CkjDII2JAGCYgMDAQIkCwENAQE3AQUJAQEYOAMxAQUBHAYBEgWDHIICBZktPIo?=
 =?us-ascii?q?dgWwzgnYBAQWBAAQBAYRYB4FECBKHXoMTgRwXgX+BEYJdB4sKiTmXMAmGRop6C?=
 =?us-ascii?q?xiJY4dViRCPZAIEAgQFAgUPIYEmAYILMxolgzqCGwwXEoM4ihwBOD4yAYEDAQE?=
 =?us-ascii?q?BO4oFAQE?=
X-IronPort-AV: E=Sophos;i="5.56,326,1539673200"; 
   d="scan'208";a="56521388"
X-Amp-Result: SKIPPED(no attachment in message)
X-Amp-File-Uploaded: False
Received: from vger.kernel.org ([209.132.180.67])
  by mtab.intel.com with ESMTP; 07 Dec 2018 04:49:01 -0800
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
        id S1726166AbeLGMtA (ORCPT <rfc822;like.xu@linux.intel.com>
        + 23 others); Fri, 7 Dec 2018 07:49:00 -0500
Received: from mail-wm1-f65.google.com ([209.85.128.65]:34945 "EHLO
        mail-wm1-f65.google.com" rhost-flags-OK-OK-OK-OK) by vger.kernel.org
        with ESMTP id S1726134AbeLGMs7 (ORCPT
        <rfc822;linux-kernel@vger.kernel.org>);
        Fri, 7 Dec 2018 07:48:59 -0500
Received: by mail-wm1-f65.google.com with SMTP id c126so4407358wmh.0
        for <linux-kernel@vger.kernel.org>; Fri, 07 Dec 2018 04:48:57 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=mena-vt-edu.20150623.gappssmtp.com; s=20150623;
        h=from:to:cc:subject:date:message-id:in-reply-to:references
         :mime-version:content-transfer-encoding;
        bh=gaEl9B+1fs5S3TQoH2KhHb3ZJ2VSYAnXotEb17ocZSY=;
        b=oZHFny5AgpoiZULh1yYM+egFIww1rygmpHkoXI+D0CcLC2JwJTaDD8Kt15Wxc3Hnc5
         akZDh9gmX8HWr85IUpkbDooPXlwkP0hliQVSWKyYuMlmn5jDu0hInPl2V8VHVbSZWB39
         YnIw+jyhFH6WfdspwyrTw/U3Iav5Y2Wp/BwzuP7oWdeUjX5IbE0M9a5dk7Oi86vehHAe
         WYxDMiflh3aHfmTHQhE0yvJixTt/u3MWRSc+U7py4TcLr3Yn7mDAIzkl4vl16+/uY8BV
         JP0ffub73j1l5ae3m+UgILHO+Ydwtk1uLI78OnYw1G2yp2ul8UFIt/E0s/+SBnrO6hye
         H9zg==
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20161025;
        h=x-gm-message-state:from:to:cc:subject:date:message-id:in-reply-to
         :references:mime-version:content-transfer-encoding;
        bh=gaEl9B+1fs5S3TQoH2KhHb3ZJ2VSYAnXotEb17ocZSY=;
        b=dIFSxDs4IAQL2Y+F9lqIJBanixnVRvAbLTbZ+LmU8KXQwpqikfisqbF5oXOCdCCLom
         e/VwOg36DOTMkvo1Gz4yHdDCWT8i4rei4h47wFd4l0x4YJTgxg7poz7teA5q2mQnr6nv
         z/Iqw1U4nkhRoLC7m7liWLLLyJUOUZ/7bg3lA1wSAkWNTngjl4tf8yeUTIInj8Sf+gzY
         HsV3aH74RuvJnlbj2hXY05Uwr2gVrg6Gnpd30Qte5Wh1JhQsgETg1qzp9LkNH/h82cO0
         Uj7ksk/pfCS9VOUaGRSAQ85nI/gMOrueEOz4DGGY+crtYFvAar0E0l7zwuVNBLEaqhv+
         KmFg==
X-Gm-Message-State: AA+aEWY7Q/TFiiKfiotnFby97zmoheBzrnPw3V5rsXRKZUtELvKQEl3n
        Vk033iRE3nwsoNzgQM4wiVlczQ==
X-Google-Smtp-Source: AFSGD/V8u7Pc6TiTxTpXvK0xrD0lAvavKdeiWpCwIDXtVBtXh5+16jKAxEgR3z+pm3Jyx+3tIxjTLA==
X-Received: by 2002:a1c:848c:: with SMTP id g134mr1965101wmd.93.1544186937074;
        Fri, 07 Dec 2018 04:48:57 -0800 (PST)
Received: from localhost.localdomain ([156.213.98.90])
        by smtp.gmail.com with ESMTPSA id i192sm4362949wmg.7.2018.12.07.04.48.52
        (version=TLS1_2 cipher=ECDHE-RSA-AES128-GCM-SHA256 bits=128/128);
        Fri, 07 Dec 2018 04:48:56 -0800 (PST)
From: Ahmed Abd El Mawgood <ahmedsoliman@mena.vt.edu>
To: Paolo Bonzini <pbonzini@redhat.com>, rkrcmar@redhat.com,
        Jonathan Corbet <corbet@lwn.net>,
        Thomas Gleixner <tglx@linutronix.de>,
        Ingo Molnar <mingo@redhat.com>, Borislav Petkov <bp@alien8.de>,
        hpa@zytor.com, x86@kernel.org, kvm@vger.kernel.org,
        linux-doc@vger.kernel.org, linux-kernel@vger.kernel.org,
        ahmedsoliman0x666@gmail.com, ovich00@gmail.com,
        kernel-hardening@lists.openwall.com, nigel.edwards@hpe.com,
        Boris Lukashev <blukashev@sempervictus.com>,
        Igor Stoppa <igor.stoppa@gmail.com>
Cc: Ahmed Abd El Mawgood <ahmedsoliman@mena.vt.edu>
Subject: [PATCH 02/10] KVM: X86: Add arbitrary data pointer in kvm memslot iterator functions
Date: Fri,  7 Dec 2018 14:47:55 +0200
Message-Id: <20181207124803.10828-3-ahmedsoliman@mena.vt.edu>
X-Mailer: git-send-email 2.19.2
In-Reply-To: <20181207124803.10828-1-ahmedsoliman@mena.vt.edu>
References: <20181207124803.10828-1-ahmedsoliman@mena.vt.edu>
MIME-Version: 1.0
Content-Transfer-Encoding: 8bit
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: <linux-kernel.vger.kernel.org>
X-Mailing-List: linux-kernel@vger.kernel.org

This will help sharing data into the slot_level_handler callback. In my
case I need to a share a counter for the pages traversed to use it in some
bitmap. Being able to send arbitrary memory pointer into the
slot_level_handler callback made it easy.

Signed-off-by: Ahmed Abd El Mawgood <ahmedsoliman@mena.vt.edu>
---
 arch/x86/kvm/mmu.c | 65 ++++++++++++++++++++++++++--------------------
 1 file changed, 37 insertions(+), 28 deletions(-)

diff --git a/arch/x86/kvm/mmu.c b/arch/x86/kvm/mmu.c
index 7c03c0f354..b67d743c33 100644
--- a/arch/x86/kvm/mmu.c
+++ b/arch/x86/kvm/mmu.c
@@ -1492,7 +1492,7 @@ static bool spte_write_protect(u64 *sptep, bool pt_protect)
 
 static bool __rmap_write_protect(struct kvm *kvm,
 				 struct kvm_rmap_head *rmap_head,
-				 bool pt_protect)
+				 bool pt_protect, void *data)
 {
 	u64 *sptep;
 	struct rmap_iterator iter;
@@ -1531,7 +1531,8 @@ static bool wrprot_ad_disabled_spte(u64 *sptep)
  *	- W bit on ad-disabled SPTEs.
  * Returns true iff any D or W bits were cleared.
  */
-static bool __rmap_clear_dirty(struct kvm *kvm, struct kvm_rmap_head *rmap_head)
+static bool __rmap_clear_dirty(struct kvm *kvm, struct kvm_rmap_head *rmap_head,
+				void *data)
 {
 	u64 *sptep;
 	struct rmap_iterator iter;
@@ -1557,7 +1558,8 @@ static bool spte_set_dirty(u64 *sptep)
 	return mmu_spte_update(sptep, spte);
 }
 
-static bool __rmap_set_dirty(struct kvm *kvm, struct kvm_rmap_head *rmap_head)
+static bool __rmap_set_dirty(struct kvm *kvm, struct kvm_rmap_head *rmap_head,
+				void *data)
 {
 	u64 *sptep;
 	struct rmap_iterator iter;
@@ -1589,7 +1591,7 @@ static void kvm_mmu_write_protect_pt_masked(struct kvm *kvm,
 	while (mask) {
 		rmap_head = __gfn_to_rmap(slot->base_gfn + gfn_offset + __ffs(mask),
 					  PT_PAGE_TABLE_LEVEL, slot);
-		__rmap_write_protect(kvm, rmap_head, false);
+		__rmap_write_protect(kvm, rmap_head, false, NULL);
 
 		/* clear the first set bit */
 		mask &= mask - 1;
@@ -1615,7 +1617,7 @@ void kvm_mmu_clear_dirty_pt_masked(struct kvm *kvm,
 	while (mask) {
 		rmap_head = __gfn_to_rmap(slot->base_gfn + gfn_offset + __ffs(mask),
 					  PT_PAGE_TABLE_LEVEL, slot);
-		__rmap_clear_dirty(kvm, rmap_head);
+		__rmap_clear_dirty(kvm, rmap_head, NULL);
 
 		/* clear the first set bit */
 		mask &= mask - 1;
@@ -1668,7 +1670,8 @@ bool kvm_mmu_slot_gfn_write_protect(struct kvm *kvm,
 
 	for (i = PT_PAGE_TABLE_LEVEL; i <= PT_MAX_HUGEPAGE_LEVEL; ++i) {
 		rmap_head = __gfn_to_rmap(gfn, i, slot);
-		write_protected |= __rmap_write_protect(kvm, rmap_head, true);
+		write_protected |= __rmap_write_protect(kvm, rmap_head, true,
+				NULL);
 	}
 
 	return write_protected;
@@ -1682,7 +1685,8 @@ static bool rmap_write_protect(struct kvm_vcpu *vcpu, u64 gfn)
 	return kvm_mmu_slot_gfn_write_protect(vcpu->kvm, slot, gfn);
 }
 
-static bool kvm_zap_rmapp(struct kvm *kvm, struct kvm_rmap_head *rmap_head)
+static bool kvm_zap_rmapp(struct kvm *kvm, struct kvm_rmap_head *rmap_head,
+		void *data)
 {
 	u64 *sptep;
 	struct rmap_iterator iter;
@@ -1702,7 +1706,7 @@ static int kvm_unmap_rmapp(struct kvm *kvm, struct kvm_rmap_head *rmap_head,
 			   struct kvm_memory_slot *slot, gfn_t gfn, int level,
 			   unsigned long data)
 {
-	return kvm_zap_rmapp(kvm, rmap_head);
+	return kvm_zap_rmapp(kvm, rmap_head, NULL);
 }
 
 static int kvm_set_pte_rmapp(struct kvm *kvm, struct kvm_rmap_head *rmap_head,
@@ -5514,13 +5518,15 @@ void kvm_mmu_uninit_vm(struct kvm *kvm)
 }
 
 /* The return value indicates if tlb flush on all vcpus is needed. */
-typedef bool (*slot_level_handler) (struct kvm *kvm, struct kvm_rmap_head *rmap_head);
+typedef bool (*slot_level_handler) (struct kvm *kvm,
+		struct kvm_rmap_head *rmap_head, void *data);
 
 /* The caller should hold mmu-lock before calling this function. */
 static __always_inline bool
 slot_handle_level_range(struct kvm *kvm, struct kvm_memory_slot *memslot,
 			slot_level_handler fn, int start_level, int end_level,
-			gfn_t start_gfn, gfn_t end_gfn, bool lock_flush_tlb)
+			gfn_t start_gfn, gfn_t end_gfn, bool lock_flush_tlb,
+			void *data)
 {
 	struct slot_rmap_walk_iterator iterator;
 	bool flush = false;
@@ -5528,7 +5534,7 @@ slot_handle_level_range(struct kvm *kvm, struct kvm_memory_slot *memslot,
 	for_each_slot_rmap_range(memslot, start_level, end_level, start_gfn,
 			end_gfn, &iterator) {
 		if (iterator.rmap)
-			flush |= fn(kvm, iterator.rmap);
+			flush |= fn(kvm, iterator.rmap, data);
 
 		if (need_resched() || spin_needbreak(&kvm->mmu_lock)) {
 			if (flush && lock_flush_tlb) {
@@ -5550,36 +5556,36 @@ slot_handle_level_range(struct kvm *kvm, struct kvm_memory_slot *memslot,
 static __always_inline bool
 slot_handle_level(struct kvm *kvm, struct kvm_memory_slot *memslot,
 		  slot_level_handler fn, int start_level, int end_level,
-		  bool lock_flush_tlb)
+		  bool lock_flush_tlb, void *data)
 {
 	return slot_handle_level_range(kvm, memslot, fn, start_level,
 			end_level, memslot->base_gfn,
 			memslot->base_gfn + memslot->npages - 1,
-			lock_flush_tlb);
+			lock_flush_tlb, data);
 }
 
 static __always_inline bool
 slot_handle_all_level(struct kvm *kvm, struct kvm_memory_slot *memslot,
-		      slot_level_handler fn, bool lock_flush_tlb)
+		      slot_level_handler fn, bool lock_flush_tlb, void *data)
 {
 	return slot_handle_level(kvm, memslot, fn, PT_PAGE_TABLE_LEVEL,
-				 PT_MAX_HUGEPAGE_LEVEL, lock_flush_tlb);
+				 PT_MAX_HUGEPAGE_LEVEL, lock_flush_tlb, data);
 }
 
 static __always_inline bool
 slot_handle_large_level(struct kvm *kvm, struct kvm_memory_slot *memslot,
-			slot_level_handler fn, bool lock_flush_tlb)
+			slot_level_handler fn, bool lock_flush_tlb, void *data)
 {
 	return slot_handle_level(kvm, memslot, fn, PT_PAGE_TABLE_LEVEL + 1,
-				 PT_MAX_HUGEPAGE_LEVEL, lock_flush_tlb);
+				 PT_MAX_HUGEPAGE_LEVEL, lock_flush_tlb, data);
 }
 
 static __always_inline bool
 slot_handle_leaf(struct kvm *kvm, struct kvm_memory_slot *memslot,
-		 slot_level_handler fn, bool lock_flush_tlb)
+		 slot_level_handler fn, bool lock_flush_tlb, void *data)
 {
 	return slot_handle_level(kvm, memslot, fn, PT_PAGE_TABLE_LEVEL,
-				 PT_PAGE_TABLE_LEVEL, lock_flush_tlb);
+				 PT_PAGE_TABLE_LEVEL, lock_flush_tlb, data);
 }
 
 void kvm_zap_gfn_range(struct kvm *kvm, gfn_t gfn_start, gfn_t gfn_end)
@@ -5601,7 +5607,7 @@ void kvm_zap_gfn_range(struct kvm *kvm, gfn_t gfn_start, gfn_t gfn_end)
 
 			slot_handle_level_range(kvm, memslot, kvm_zap_rmapp,
 						PT_PAGE_TABLE_LEVEL, PT_MAX_HUGEPAGE_LEVEL,
-						start, end - 1, true);
+						start, end - 1, true, NULL);
 		}
 	}
 
@@ -5609,9 +5615,10 @@ void kvm_zap_gfn_range(struct kvm *kvm, gfn_t gfn_start, gfn_t gfn_end)
 }
 
 static bool slot_rmap_write_protect(struct kvm *kvm,
-				    struct kvm_rmap_head *rmap_head)
+				    struct kvm_rmap_head *rmap_head,
+				    void *data)
 {
-	return __rmap_write_protect(kvm, rmap_head, false);
+	return __rmap_write_protect(kvm, rmap_head, false, data);
 }
 
 void kvm_mmu_slot_remove_write_access(struct kvm *kvm,
@@ -5621,7 +5628,7 @@ void kvm_mmu_slot_remove_write_access(struct kvm *kvm,
 
 	spin_lock(&kvm->mmu_lock);
 	flush = slot_handle_all_level(kvm, memslot, slot_rmap_write_protect,
-				      false);
+				      false, NULL);
 	spin_unlock(&kvm->mmu_lock);
 
 	/*
@@ -5647,7 +5654,8 @@ void kvm_mmu_slot_remove_write_access(struct kvm *kvm,
 }
 
 static bool kvm_mmu_zap_collapsible_spte(struct kvm *kvm,
-					 struct kvm_rmap_head *rmap_head)
+					 struct kvm_rmap_head *rmap_head,
+					 void *data)
 {
 	u64 *sptep;
 	struct rmap_iterator iter;
@@ -5685,7 +5693,7 @@ void kvm_mmu_zap_collapsible_sptes(struct kvm *kvm,
 	/* FIXME: const-ify all uses of struct kvm_memory_slot.  */
 	spin_lock(&kvm->mmu_lock);
 	slot_handle_leaf(kvm, (struct kvm_memory_slot *)memslot,
-			 kvm_mmu_zap_collapsible_spte, true);
+			 kvm_mmu_zap_collapsible_spte, true, NULL);
 	spin_unlock(&kvm->mmu_lock);
 }
 
@@ -5695,7 +5703,7 @@ void kvm_mmu_slot_leaf_clear_dirty(struct kvm *kvm,
 	bool flush;
 
 	spin_lock(&kvm->mmu_lock);
-	flush = slot_handle_leaf(kvm, memslot, __rmap_clear_dirty, false);
+	flush = slot_handle_leaf(kvm, memslot, __rmap_clear_dirty, false, NULL);
 	spin_unlock(&kvm->mmu_lock);
 
 	lockdep_assert_held(&kvm->slots_lock);
@@ -5718,7 +5726,7 @@ void kvm_mmu_slot_largepage_remove_write_access(struct kvm *kvm,
 
 	spin_lock(&kvm->mmu_lock);
 	flush = slot_handle_large_level(kvm, memslot, slot_rmap_write_protect,
-					false);
+					false, NULL);
 	spin_unlock(&kvm->mmu_lock);
 
 	/* see kvm_mmu_slot_remove_write_access */
@@ -5735,7 +5743,8 @@ void kvm_mmu_slot_set_dirty(struct kvm *kvm,
 	bool flush;
 
 	spin_lock(&kvm->mmu_lock);
-	flush = slot_handle_all_level(kvm, memslot, __rmap_set_dirty, false);
+	flush = slot_handle_all_level(kvm, memslot, __rmap_set_dirty, false,
+			NULL);
 	spin_unlock(&kvm->mmu_lock);
 
 	lockdep_assert_held(&kvm->slots_lock);
-- 
2.19.2

