Return-Path: <linux-kernel-owner@vger.kernel.org>
Delivered-To: unknown
Received: from linux.intel.com (10.54.29.200:995) by likexu-workstation with
  POP3-SSL; 07 Dec 2018 16:17:28 -0000
X-Original-To: like.xu@linux.intel.com
Delivered-To: like.xu@linux.intel.com
Received: from orsmga002.jf.intel.com (orsmga002.jf.intel.com [10.7.209.21])
	(using TLSv1.2 with cipher ECDHE-RSA-AES256-GCM-SHA384 (256/256 bits))
	(No client certificate requested)
	by linux.intel.com (Postfix) with ESMTPS id 96FFC5804F9;
	Thu,  6 Dec 2018 18:45:57 -0800 (PST)
Received: from orsmga101.jf.intel.com ([10.7.208.22])
  by orsmga002-1.jf.intel.com with ESMTP/TLS/DHE-RSA-AES256-GCM-SHA384; 06 Dec 2018 18:45:57 -0800
X-SG-BADATTACHMENTNOREPLY: True
IronPort-PHdr: =?us-ascii?q?9a23=3A3VDKzRLG9yDMSAaEaNmcpTZWNBhigK39O0sv0rFi?=
 =?us-ascii?q?tYgUL/3zrarrMEGX3/hxlliBBdydt6oUzbKO+4nbGkU4qa6bt34DdJEeHzQksu?=
 =?us-ascii?q?4x2zIaPcieFEfgJ+TrZSFpVO5LVVti4m3peRMNQJW2aFLduGC94iAPERvjKwV1?=
 =?us-ascii?q?Ov71GonPhMiryuy+4ZLebxlLiTanfb9+MAi9oBnMuMURnYZsMLs6xAHTontPde?=
 =?us-ascii?q?RWxGdoKkyWkh3h+Mq+/4Nt/jpJtf45+MFOTav1f6IjTbxFFzsmKHw65NfqtRbY?=
 =?us-ascii?q?UwSC4GYXX3gMnRpJBwjF6wz6Xov0vyDnuOdxxDWWMMvrRr0vRz+s87lkRwPpiC?=
 =?us-ascii?q?cfNj427mfXitBrjKlGpB6tvgFzz5LIbI2QMvd1Y6HTcs4ARWdZQ8hfVzJPAo2/?=
 =?us-ascii?q?YYUBAeUOMuRXr4jhqFUBthu+HQuhCfjzyjJKnHL6wbE23uojHAzAwQcuH8gOsH?=
 =?us-ascii?q?PRrNjtMKkSVuC1zK/VxjvBcvNZwizy55LSch88vPqBWrBwccrMyUY0DAzKlE+Q?=
 =?us-ascii?q?ppH+MjOTyOQNsnWU7+t6Wu61l2EnrARxryGpy8wxiYfJnpoYxk7Y+Sh92oo5ON?=
 =?us-ascii?q?O1RFBhbdK5E5ZcqzuWOop0T886Xm1kpDw2xqAYtZO0ZiQG1Y4ryh7HZ/CZboSF?=
 =?us-ascii?q?4wjvWPiPLTp7nn5pZayziwuo/UWhxeDxUNS/3kxQoSpfiNbMs2gA1xzN5ciDTf?=
 =?us-ascii?q?tw5lmh2TmR2ADJ8O1EIl47lbDdK5E/xr48jJ0TsV7MHiPumUX2irGZdlk89+S2?=
 =?us-ascii?q?9+jqZq/qqoKSOoNqkA3yL6cjltClDek5MAUCR22b9v691L3n8035WrJKjvgun6?=
 =?us-ascii?q?ndsZDaI9kbp6GgDw9WzIkj8RC/ACmi0NgBmnkGIlRFdwydj4XyJVHOL+73De2l?=
 =?us-ascii?q?j1Svjjhr3fbGMaPlApnXKXjDirjhca5n60FA0Aoz0cxf55VMB7EFIfLzWVH+uM?=
 =?us-ascii?q?bXDx8kKAG0x+fnCNNg1oIRQ26PA6mZML/Mvl+M/O4gP+6MZIoNsjbnN/cl/+Lu?=
 =?us-ascii?q?jWM+mVIFfammx5oXaGyiEfRhOUmZYWfsjc0HEWcFpQc+SO3qiFufUT9cfXqyXq?=
 =?us-ascii?q?Q85i0lB4KiF4vMWoetgLmZ1iehApJWfnxGCkyLEXrwdYWEXOkDZDiRIs9mlDwE?=
 =?us-ascii?q?U7+hRpQl1RGvsg/61rVmIvDV+i0eqZLsytx16/fPmhE18Dx+F96d3H2VT2Fogm?=
 =?us-ascii?q?MIQCc707pkoUx9zVeD0rJ0g+ZCGtxR/P5JVgY6NZjBz+11EdzyWwTBfsuXR1ai?=
 =?us-ascii?q?WNmpHTYxTtcpyd8Uf0l9A8mijgzE3yeyAL8ajbqLCIYw8qLdxXfxIcl9xm3C1K?=
 =?us-ascii?q?kgiVkmX8ROOXenhq556wjcGYrJn1+FmKatcKQWxDTN+3ubzWqSoEFYVxZ9Xrjf?=
 =?us-ascii?q?UnABeETat9T56VnET7+1F7snNAxNycqBKqtPbt3kllFGRPblONTDbGO9gWawBR?=
 =?us-ascii?q?CUxrySaIrmYXkS3CLYCEIciQAc4W6GNRQiBiemu2/RESZhFUzxbE/28elxsnW7?=
 =?us-ascii?q?TlQqwAGMdEBh07u1+hgIhf2TUf8T37QEuDs/pDVwBlqyw9XWC9+YrQp7YKpcec?=
 =?us-ascii?q?894EtA1W/Bqwx9P5mgL6d+hl4ecwV7pV/u2w9wCoValcgqrXUqzAVpJKKc0VNB?=
 =?us-ascii?q?cS6Y3J/qNr3WLGny4A6ga6rM1l7C19aW/78F6O4kpFX7oAGpCk0i/m193NlRzX?=
 =?us-ascii?q?Sd6YvFDQoIXZ3qT0Y46gJ1p7fZYik6+YPZznlsMaiysj/f1NMlHuolyhC8f9hB?=
 =?us-ascii?q?NKOIDhP9E8ofB8K2Muwlh0Cpbg4YPOBV7KM1P96me+Ga16KxPedgnCipjWJI4I?=
 =?us-ascii?q?1m1kKM9ix8SvPH3pofwvGY2BeHWCn4jFu7rs/3noVEbykIHmWj0SjkGJJRZqpq?=
 =?us-ascii?q?cIYRCGehP9e4xs9jiJ7qQXJY8kCsB0kH2MOwZRWddVj90hBO2kQNpnynnzC1zz?=
 =?us-ascii?q?h1kzEvs6qe0zbCw+XkdBobJGFLQHNugkvrIYixl9oaRlSnbxA1lBu54kb336ha?=
 =?us-ascii?q?pKVlI2jTW0tIZDX2L2d5X6u0t7qCZdNP6ZwyvSVWVuS8fU6VSrrnrxQG1CPjGn?=
 =?us-ascii?q?NUxConeDGyppX5gxt6hXqfLHlptnrZesJwxRDF6NzHX/FR3TkGRCh+iTbJAFix?=
 =?us-ascii?q?JN2p/dSSl5feveGyTWOhVptPcSb1yYOMrje05WpvARenhfC8hsXnERQm0S/8z9?=
 =?us-ascii?q?RrVT/HrBHmbonp1qS6N/lqfk1pBF/69sp7FZtykoo2hJEMx3cago+Z8mYAkWf2?=
 =?us-ascii?q?Kd9bw77xbGIRRT4XxN7Y+Avl11diLn6Tx4L5S2+Sws1uZ9ShZmMW2yQ9791FCa?=
 =?us-ascii?q?uO7bxEmzd1rUS8rQ7Lffd9mTIdw+M06HEGm+EJpBYtziKFD7AXHElYPjbjmw6G?=
 =?us-ascii?q?7t+gt6VXeHigcaKr20Vgh9ChA6qPogVdWHb/Z5cjEjV87sR5MFLQznLz7pvod8?=
 =?us-ascii?q?XXbdIWrheUiQvPj/BJKJItkfoHnTZnOWX4vXE/yu80lxpu3YyhvIicKmVg56a5?=
 =?us-ascii?q?Ah9eNj3oaMIf4DDtjaBCnsmI24CjBIluGjIOXJHwV/KnDCoStej7NwaJCDAzsW?=
 =?us-ascii?q?2UGb3bHQ+C8ktmq2/PHouvN3GWInkZ0NpjSAOcJExZnAAbQjE6koQlGQCtwczr?=
 =?us-ascii?q?aF156SwJ5l7kthtMzfplNxvlXWfaugiocS04SISFIBpV8wFC5FrVMcqE4eJoBC?=
 =?us-ascii?q?xY+pyhrAqQKm2UfQhIDGcJWlCaCFDnJLWh+d7A8+2ADOqkM/TOeamOqfBZV/qQ?=
 =?us-ascii?q?xZOv1ZZm/y+RNsqVOHluFeY72k1FXXB2AMnZnzQPSyoKlyPCdcKbpRG8+jFpoc?=
 =?us-ascii?q?C76vjkRAXv5Y6XAbtILdpv4wy2gbuEN+OIhCZ2NzdY1pAPxX/J0rQf30QSiyZh?=
 =?us-ascii?q?dzazC7QAqDXNQbnUmq9WCR4bdixyONFJ76I6wglCJ8rbhsnp2b5/i/4/E01FWk?=
 =?us-ascii?q?D5msG1ecwKJHmwO0naBEmQLrSJOz3Kz9vzYaO9UrBQiORUtxutuTeUCUPjPzKD?=
 =?us-ascii?q?lyX3WBCrK+1DkCabPBlGsoGnbhltEXTjTM7hahCjLN93jDg2zacoiX/QKWEcMS?=
 =?us-ascii?q?Zzc0VWo72U7CNYhOh/GmNb4npkK+mEhziW7+3CJpkKtvtrBzx+l/hG73Qi17tV?=
 =?us-ascii?q?8CZESeR1mSTIqN5uplCmku+XxTtmUBpBsDBLhI2QsEVmOKXZ8IRAWHne8BIM62?=
 =?us-ascii?q?WQFwoFp99/BtLzvKBQz4uHqKWmCjpY9NfZteQYBtPPJYrTMnUlMAHyFRbOAQcF?=
 =?us-ascii?q?RCLtPmba0QgVtfiO6n2YsdAFq5znn4pGHqBaUFgkPvIcBF5sENELLNFwRDxywp?=
 =?us-ascii?q?CBi8tdx32+qlHxWc9Qt4rLHqaQAejlIj+DgZFCeRoEwLq+JoMWYN6ok3d+Y0V3?=
 =?us-ascii?q?ydyZU3HbWspA92g4Nlc5?=
X-IronPort-Anti-Spam-Filtered: true
X-IronPort-Anti-Spam-Result: =?us-ascii?q?A0ABAACA3glch0O0hNFjGQEBAQEBAQEBA?=
 =?us-ascii?q?QEBAQcBAQEBAQGBUQQBAQEBAQsBg2snCoNwiBmMEIFgLRSXOoIHKwGHVyI0CQ0?=
 =?us-ascii?q?BAwEBAQEBAQIBEwEBAQgNCQgpIwyCNiQBgmIBAgMBAiAEGQEBNwEFCQEBCg4KA?=
 =?us-ascii?q?gImAgIDRBAGAQwBBwEBAYMcggIFpSpwfDOCdgEBBYcqCIELiXiBHBeBQD+BOIJ?=
 =?us-ascii?q?riAWCV4kTghOEWTaQLAmKO4cFBhiBXIUVgwGHRCyIYo9+gUaCDTMaCBsVgyeCG?=
 =?us-ascii?q?wwXg0qKdB8BMYEFAQGJHYEfAQE?=
X-IPAS-Result: =?us-ascii?q?A0ABAACA3glch0O0hNFjGQEBAQEBAQEBAQEBAQcBAQEBAQG?=
 =?us-ascii?q?BUQQBAQEBAQsBg2snCoNwiBmMEIFgLRSXOoIHKwGHVyI0CQ0BAwEBAQEBAQIBE?=
 =?us-ascii?q?wEBAQgNCQgpIwyCNiQBgmIBAgMBAiAEGQEBNwEFCQEBCg4KAgImAgIDRBAGAQw?=
 =?us-ascii?q?BBwEBAYMcggIFpSpwfDOCdgEBBYcqCIELiXiBHBeBQD+BOIJriAWCV4kTghOEW?=
 =?us-ascii?q?TaQLAmKO4cFBhiBXIUVgwGHRCyIYo9+gUaCDTMaCBsVgyeCGwwXg0qKdB8BMYE?=
 =?us-ascii?q?FAQGJHYEfAQE?=
X-IronPort-AV: E=Sophos;i="5.56,324,1539673200"; 
   d="scan'208";a="43956183"
X-Amp-Result: SKIPPED(no attachment in message)
X-Amp-File-Uploaded: False
Received: from vger.kernel.org ([209.132.180.67])
  by mtab.intel.com with ESMTP; 06 Dec 2018 18:45:55 -0800
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
        id S1726043AbeLGCpx (ORCPT <rfc822;like.xu@linux.intel.com>
        + 23 others); Thu, 6 Dec 2018 21:45:53 -0500
Received: from hqemgate15.nvidia.com ([216.228.121.64]:13813 "EHLO
        hqemgate15.nvidia.com" rhost-flags-OK-OK-OK-OK) by vger.kernel.org
        with ESMTP id S1725939AbeLGCpw (ORCPT
        <rfc822;linux-kernel@vger.kernel.org>);
        Thu, 6 Dec 2018 21:45:52 -0500
Received: from hqpgpgate102.nvidia.com (Not Verified[216.228.121.13]) by hqemgate15.nvidia.com (using TLS: TLSv1.2, DES-CBC3-SHA)
        id <B5c09ded30000>; Thu, 06 Dec 2018 18:45:40 -0800
Received: from hqmail.nvidia.com ([172.20.161.6])
  by hqpgpgate102.nvidia.com (PGP Universal service);
  Thu, 06 Dec 2018 18:45:50 -0800
X-PGP-Universal: processed;
        by hqpgpgate102.nvidia.com on Thu, 06 Dec 2018 18:45:50 -0800
Received: from [10.110.48.28] (10.124.1.5) by HQMAIL101.nvidia.com
 (172.20.187.10) with Microsoft SMTP Server (TLS) id 15.0.1395.4; Fri, 7 Dec
 2018 02:45:50 +0000
Subject: Re: [PATCH 1/2] mm: introduce put_user_page*(), placeholder versions
From: John Hubbard <jhubbard@nvidia.com>
To: Jerome Glisse <jglisse@redhat.com>,
        Matthew Wilcox <willy@infradead.org>
CC: Dan Williams <dan.j.williams@intel.com>,
        John Hubbard <john.hubbard@gmail.com>,
        Andrew Morton <akpm@linux-foundation.org>,
        Linux MM <linux-mm@kvack.org>, Jan Kara <jack@suse.cz>,
        <tom@talpey.com>, Al Viro <viro@zeniv.linux.org.uk>,
        <benve@cisco.com>, Christoph Hellwig <hch@infradead.org>,
        Christopher Lameter <cl@linux.com>,
        "Dalessandro, Dennis" <dennis.dalessandro@intel.com>,
        Doug Ledford <dledford@redhat.com>,
        Jason Gunthorpe <jgg@ziepe.ca>,
        Michal Hocko <mhocko@kernel.org>, <mike.marciniszyn@intel.com>,
        <rcampbell@nvidia.com>,
        Linux Kernel Mailing List <linux-kernel@vger.kernel.org>,
        linux-fsdevel <linux-fsdevel@vger.kernel.org>
References: <20181204001720.26138-1-jhubbard@nvidia.com>
 <20181204001720.26138-2-jhubbard@nvidia.com>
 <CAPcyv4h99JVHAS7Q7k3iPPUq+oc1NxHdyBHMjpgyesF1EjVfWA@mail.gmail.com>
 <a0adcf7c-5592-f003-abc5-a2645eb1d5df@nvidia.com>
 <CAPcyv4iNtamDAY9raab=iXhSZByecedBpnGybjLM+PuDMwq7SQ@mail.gmail.com>
 <3c91d335-921c-4704-d159-2975ff3a5f20@nvidia.com>
 <20181205011519.GV10377@bombadil.infradead.org>
 <20181205014441.GA3045@redhat.com>
 <59ca5c4b-fd5b-1fc6-f891-c7986d91908e@nvidia.com>
X-Nvconfidentiality: public
Message-ID: <7b4733be-13d3-c790-ff1b-ac51b505e9a6@nvidia.com>
Date: Thu, 6 Dec 2018 18:45:49 -0800
User-Agent: Mozilla/5.0 (X11; Linux x86_64; rv:60.0) Gecko/20100101
 Thunderbird/60.3.2
MIME-Version: 1.0
In-Reply-To: <59ca5c4b-fd5b-1fc6-f891-c7986d91908e@nvidia.com>
X-Originating-IP: [10.124.1.5]
X-ClientProxiedBy: HQMAIL101.nvidia.com (172.20.187.10) To
 HQMAIL101.nvidia.com (172.20.187.10)
Content-Type: text/plain; charset="utf-8"
Content-Language: en-US-large
Content-Transfer-Encoding: 7bit
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed; d=nvidia.com; s=n1;
        t=1544150740; bh=LaX0+2IU5rWANDqZ8zQGftDp1otyHanUuEU1Zp6B9cg=;
        h=X-PGP-Universal:Subject:From:To:CC:References:X-Nvconfidentiality:
         Message-ID:Date:User-Agent:MIME-Version:In-Reply-To:
         X-Originating-IP:X-ClientProxiedBy:Content-Type:Content-Language:
         Content-Transfer-Encoding;
        b=eTi8abiJ70IRdR7JcO3Fth36VBJ+IyHedXL3yxdINXubk4JecUq+pI18SAWbwusYV
         sfyZTKMN5e474lpEAyz7XuW4e4dXeOnIIMnqi2gHWLDfaI3rtBf5Gx8fDkHIwfcZ8m
         YbTug1659Y9hfZin/Ys//DXxJr+hvcOiVkXNjLgPiBv3C3auzgojp7dNIH5syZLZ7U
         TgmTNumYJkMyAhxinesJRXVKNVel6nDaYXlMwUJphnrgQ/ImOBEt6R/ob/FL2Z3tQm
         V0gQrr3snlF3aZ+biS8GFfYtrh77Yw3293ufgzZOHroV8+kwbr8CacwztRGlpfVeXW
         1105ztsX0Chqg==
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: <linux-kernel.vger.kernel.org>
X-Mailing-List: linux-kernel@vger.kernel.org

On 12/4/18 5:57 PM, John Hubbard wrote:
> On 12/4/18 5:44 PM, Jerome Glisse wrote:
>> On Tue, Dec 04, 2018 at 05:15:19PM -0800, Matthew Wilcox wrote:
>>> On Tue, Dec 04, 2018 at 04:58:01PM -0800, John Hubbard wrote:
>>>> On 12/4/18 3:03 PM, Dan Williams wrote:
>>>>> Except the LRU fields are already in use for ZONE_DEVICE pages... how
>>>>> does this proposal interact with those?
>>>>
>>>> Very badly: page->pgmap and page->hmm_data both get corrupted. Is there an entire
>>>> use case I'm missing: calling get_user_pages() on ZONE_DEVICE pages? Said another
>>>> way: is it reasonable to disallow calling get_user_pages() on ZONE_DEVICE pages?
>>>>
>>>> If we have to support get_user_pages() on ZONE_DEVICE pages, then the whole 
>>>> LRU field approach is unusable.
>>>
>>> We just need to rearrange ZONE_DEVICE pages.  Please excuse the whitespace
>>> damage:
>>>
>>> +++ b/include/linux/mm_types.h
>>> @@ -151,10 +151,12 @@ struct page {
>>>  #endif
>>>                 };
>>>                 struct {        /* ZONE_DEVICE pages */
>>> +                       unsigned long _zd_pad_2;        /* LRU */
>>> +                       unsigned long _zd_pad_3;        /* LRU */
>>> +                       unsigned long _zd_pad_1;        /* uses mapping */
>>>                         /** @pgmap: Points to the hosting device page map. */
>>>                         struct dev_pagemap *pgmap;
>>>                         unsigned long hmm_data;
>>> -                       unsigned long _zd_pad_1;        /* uses mapping */
>>>                 };
>>>  
>>>                 /** @rcu_head: You can use this to free a page by RCU. */
>>>
>>> You don't use page->private or page->index, do you Dan?
>>
>> page->private and page->index are use by HMM DEVICE page.
>>
> 
> OK, so for the ZONE_DEVICE + HMM case, that leaves just one field remaining for 
> dma-pinned information. Which might work. To recap, we need:
> 
> -- 1 bit for PageDmaPinned
> -- 1 bit, if using LRU field(s), for PageDmaPinnedWasLru.
> -- N bits for a reference count
> 
> Those *could* be packed into a single 64-bit field, if really necessary.
> 

...actually, this needs to work on 32-bit systems, as well. And HMM is using a lot.
However, it is still possible for this to work.

Matthew, can I have that bit now please? I'm about out of options, and now it will actually
solve the problem here.

Given:

1) It's cheap to know if a page is ZONE_DEVICE, and ZONE_DEVICE means not on the LRU.
That, in turn, means only 1 bit instead of 2 bits (in addition to a counter) is required, 
for that case. 

2) There is an independent bit available (according to Matthew). 

3) HMM uses 4 of the 5 struct page fields, so only one field is available for a counter 
   in that case.

4) get_user_pages() must work on ZONE_DEVICE and HMM pages.

5) For a proper atomic counter for both 32- and 64-bit, we really do need a complete
unsigned long field.

So that leads to the following approach:

-- Use a single unsigned long field for an atomic reference count for the DMA pinned count.
For normal pages, this will be the *second* field of the LRU (in order to avoid PageTail bit).

For ZONE_DEVICE pages, we can also line up the fields so that the second LRU field is 
available and reserved for this DMA pinned count. Basically _zd_pad_1 gets move up and
optionally renamed:

diff --git a/include/linux/mm_types.h b/include/linux/mm_types.h
index 017ab82e36ca..b5dcd9398cae 100644
--- a/include/linux/mm_types.h
+++ b/include/linux/mm_types.h
@@ -90,8 +90,8 @@ struct page {
                                 * are in use.
                                 */
                                struct {
-                                       unsigned long dma_pinned_flags;
-                                       atomic_t      dma_pinned_count;
+                                       unsigned long dma_pinned_flags; /* LRU.next */
+                                       atomic_t      dma_pinned_count; /* LRU.prev */
                                };
                        };
                        /* See page-flags.h for PAGE_MAPPING_FLAGS */
@@ -161,9 +161,9 @@ struct page {
                };
                struct {        /* ZONE_DEVICE pages */
                        /** @pgmap: Points to the hosting device page map. */
-                       struct dev_pagemap *pgmap;
-                       unsigned long hmm_data;
-                       unsigned long _zd_pad_1;        /* uses mapping */
+                       struct dev_pagemap *pgmap;      /* LRU.next */
+                       unsigned long _zd_pad_1;        /* LRU.prev or dma_pinned_count */
+                       unsigned long hmm_data;         /* uses mapping */
                };
 
                /** @rcu_head: You can use this to free a page by RCU. */



-- Use an additional, fully independent page bit (from Matthew) for PageDmaPinned.


thanks,
-- 
John Hubbard
NVIDIA
